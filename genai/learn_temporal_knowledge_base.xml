<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/asynchronous-activity-completion.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/asynchronous-activity-completion.mdx</path>
  <content>
---
id: asynchronous-activity-completion
title: Asynchronous Activity Completion - Python SDK
sidebar_label: Asynchronous Activity Completion
description: Learn how to asynchronously complete an Activity using the Temporal Python SDK. Follow three steps for Activity completion and use the Temporal Client for Heartbeat and updates.
toc_max_heading_level: 2
keywords:
  - asynchronous activity completion
  - temporal python activities
  - async activity execution
  - temporal task token
  - temporal activity heartbeat
  - async activity updates
  - temporal client for activities
  - activity function async completion
tags:
  - Activities
  - Python SDK
  - Temporal SDKs
---

**How to Asynchronously complete an Activity using the Temporal Python SDK.**

[Asynchronous Activity Completion](/activities#asynchronous-activity-completion) enables the Activity Function to return without the Activity Execution completing.

There are three steps to follow:

1. The Activity provides the external system with identifying information needed to complete the Activity Execution.
   Identifying information can be a [Task Token](/activities#task-token), or a combination of Namespace, Workflow Id, and Activity Id.
2. The Activity Function completes in a way that identifies it as waiting to be completed by an external system.
3. The Temporal Client is used to Heartbeat and complete the Activity.

To mark an Activity as completing asynchronously, do the following inside the Activity.

```python
# Capture token for later completion
captured_token = activity.info().task_token
activity.raise_complete_async()
```

To update an Activity outside the Activity, use the [get_async_activity_handle()](https://python.temporal.io/temporalio.client.Client.html#get_async_activity_handle) method to get the handle of the Activity.

```python
handle = my_client.get_async_activity_handle(task_token=captured_token)
```

Then, on that handle, you can call the results of the Activity, `heartbeat`, `complete`, `fail`, or `report_cancellation` method to update the Activity.

```python
await handle.complete("Completion value.")
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/dataconversion.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/dataconversion.mdx</path>
  <content>
---
id: dataconversion
title: How does Temporal handle application data?
sidebar_label: Data conversion
description: This guide explores Data Converters in the Temporal Platform, detailing how they handle serialization and encoding for Workflow inputs and outputs, ensuring data stays secure and manageable.
slug: /dataconversion
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This guide provides an overview of data handling using a Data Converter on the Temporal Platform.

Data Converters in Temporal are SDK components that handle the serialization and encoding of data entering and exiting a Temporal Service.
Workflow inputs and outputs need to be serialized and deserialized so they can be sent as JSON to a Temporal Service.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Data Converter encodes and decodes data</p>
  </div>
  <div className="tdiiw" height="1240">
    <img
      className="img_ev3q"
      src="/diagrams/default-data-converter.svg"
      alt="Data Converter encodes and decodes data"
    />
  </div>
</div>

The Data Converter encodes data from your application to a [Payload](/dataconversion#payload) before it is sent to the Temporal Service in the Client call.
When the Temporal Server sends the encoded data back to the Worker, the Data Converter decodes it for processing within your application.
This ensures that all your sensitive data exists in its original format only on hosts that you control.

Data Converter steps are followed when data is sent to a Temporal Service (as input to a Workflow) and when it is returned from a Workflow (as output).
Due to how Temporal provides access to Workflow output, this implementation is asymmetric:

- Data encoding is performed automatically using the default converter provided by Temporal or your custom Data Converter when passing input to a Temporal Service. For example, plain text input is usually serialized into a JSON object.
- Data decoding may be performed by your application logic during your Workflows or Activities as necessary, but decoded Workflow results are never persisted back to the Temporal Service. Instead, they are stored encoded on the Temporal Service, and you need to provide an additional parameter when using [`temporal workflow show`](/cli/workflow#show) or when browsing the Web UI to view output.

Each piece of data (like a single argument or return value) is encoded as a [Payload](/dataconversion#payload), which consists of binary data and key-value metadata.

For details, see the API references:

- [Go](https://pkg.go.dev/go.temporal.io/sdk/converter#DataConverter)
- [Java](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/common/converter/DataConverter.html)
- [Python](https://python.temporal.io/temporalio.converter.DataConverter.html)
- [TypeScript](https://typescript.temporal.io/api/interfaces/common.DataConverter)

### What is a Payload? {#payload}

A [Payload](https://api-docs.temporal.io/#temporal.api.common.v1.Payload) represents binary data such as input and output from Activities and Workflows.
Payloads also contain metadata that describe their data type or other parameters for use by custom encoders/converters.

When processed through the SDK, the [default Data Converter](/default-custom-data-converters#default-data-converter) serializes your data/value to a Payload before sending it to the Temporal Server.
The default Data Converter processes supported type values to Payloads. You can create a custom [Payload Converter](/payload-converter) to apply different conversion steps.

You can additionally apply [custom codecs](/payload-codec), such as for encryption or compression, on your Payloads.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/task-routing-worker-sessions.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/task-routing-worker-sessions.mdx</path>
  <content>
---
id: task-routing-worker-sessions
title: Task Routing and Worker Sessions
sidebar_label: Task Routing and Worker Sessions
description: Learn about routing Tasks and Worker Sessions. 
slug: /task-routing
toc_max_heading_level: 4
keywords:
  - task routing
  - sticky execution
tags:
  - Workers
  - Task Queues
---

This page discusses the following:

- [Task Routing](#task-routing)
- [Worker Sessions](#worker-session)

## What is Task Routing? {#task-routing}

Task Routing is simply when a Task Queue is paired with one or more Workers, primarily for Activity Task Executions.

This could also mean employing multiple Task Queues, each one paired with a Worker Process.

Task Routing has many applicable use cases.

Some SDKs provide a [Session API](#worker-session) that provides a straightforward way to ensure that Activity Tasks are executed with the same Worker without requiring you to manually specify Task Queue names.
It also includes features like concurrent session limitations and worker failure detection.

### Flow control

A Worker that consumes from a Task Queue asks for an Activity Task only when it has available capacity, so it is never overloaded by request spikes.
If Activity Tasks get created faster than Workers can process them, they are backlogged in the Task Queue.

### Throttling

The rate at which each Activity Worker polls for and processes Activity Tasks is configurable per Worker.
Workers do not exceed this rate even if it has spare capacity.
There is also support for global Task Queue rate limiting.
This limit works across all Workers for the given Task Queue.
It is frequently used to limit load on a downstream service that an Activity calls into.

### Specific environments

In some cases, you might need to execute Activities in a dedicated environment.
To send Activity Tasks to this environment, use a dedicated Task Queue.

#### Route Activity Tasks to a specific host

In some use cases, such as file processing or machine learning model training, an Activity Task must be routed to a specific Worker Process or Worker Entity.

For example, suppose that you have a Workflow with the following three separate Activities:

- Download a file.
- Process the file in some way.
- Upload a file to another location.

The first Activity, to download the file, could occur on any Worker on any host.
However, the second and third Activities must be executed by a Worker on the same host where the first Activity downloaded the file.

In a real-life scenario, you might have many Worker Processes scaled over many hosts.
You would need to develop your Temporal Application to route Tasks to specific Worker Processes when needed.

Code samples:

- [Go file processing example](https://github.com/temporalio/samples-go/tree/main/fileprocessing)
- [Java file processing example](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/fileprocessing)
- [PHP file processing example](https://github.com/temporalio/samples-php/tree/master/app/src/FileProcessing)

#### Route Activity Tasks to a specific process

Some Activities load large datasets and cache them in the process.
The Activities that rely on those datasets should be routed to the same process.

In this case, a unique Task Queue would exist for each Worker Process involved.

#### Workers with different capabilities

Some Workers might exist on GPU boxes versus non-GPU boxes.
In this case, each type of box would have its own Task Queue and a Workflow can pick one to send Activity Tasks.

### Multiple priorities

If your use case involves more than one priority, you can create one Task Queue per priority, with a Worker pool per priority.

### Versioning

Task Routing is the simplest way to version your code.

If you have a new backward-incompatible Activity Definition, start by using a different Task Queue.

## What is a Worker Session? {#worker-session}

A Worker Session is a feature provided by some SDKs that provides a straightforward API for [Task Routing](#task-routing) to ensure that Activity Tasks are executed with the same Worker without requiring you to manually specify Task Queue names.
It also includes features like concurrent session limitations and Worker failure detection.

- [How to use Worker Sessions](/develop/go/sessions)
  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/temporal-nexus.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/temporal-nexus.mdx</path>
  <content>
---
id: nexus
title: Temporal Nexus - Temporal feature
description: Temporal Nexus enables durable execution across team and namespace boundaries and promotes a modular architecture that enables each team to have its own namespace for improved security, troubleshooting, and blast radius isolation.
sidebar_label: Temporal Nexus
slug: /evaluate/nexus
tags:
- Nexus
keywords:
  - temporal multi-team collaboration
  - modular temporal architecture
  - namespace boundary workflows
  - temporal nexus api registry
  - temporal nexus services
  - secure temporal workflows
  - multi-team integration temporal
  - temporal cloud nexus
  - connect
  - connect application
  - share workflows
  - multi-region
  - cross namespace
  - inter namespace
  - multi namespace
  - multiple namespaces
  - teams
  - communication
  - contract
  - service contract
  - API contract
  - microservice contract
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

## Connect Temporal Applications

Nexus allows you to connect Temporal Applications across (and within) isolated Namespaces.
This provides all the benefits of Durable Execution across team and application boundaries with improved modularity, security, debugging, and fault isolation.
Nexus supports cross-team, cross-domain, cross-namespace, and multi-region use cases.

## Why use Nexus?

Unlike other forms of inter-service communication, Nexus combines a familiar programming model with the resiliency of the Temporal Platform and its queue-based Worker architecture.

### Benefits

- **Integrated Temporal experience** \- with improved security, observability, and reliability.
- **Microservice contracts** \- suitable for sharing across teams or domains.
- **Abstract and share underlying Temporal primitives** \- like Workflows, Signals, or Updates.
- **At-least-once execution guarantees** \- with support for exactly-once execution using Workflow policy.
- **Improved security and blast-radius isolation** \- with separate Namespaces for each team or domain.
- **Modular design** \- for streamlined multi-team development.
- **Custom handlers** \- that execute arbitrary code.
- **No error-prone boilerplate code** \- with Temporal SDK support to build and use Nexus Services.
- **Same queue-based Worker architecture** \- so no bespoke service deployments are needed.

### Use cases

- **Cross-team, cross-domain, and cross-namespace** \-
  Nexus is purpose-built to connect Temporal Applications within and across Namespaces.
  It addresses the limitations of Child Workflows, Activity Wrappers, and bespoke APIs that target a remote Namespace; such as leaking implementation details, second-class observability, overly-permissive security, and error-prone boilerplate code.
  Nexus has a streamlined Temporal developer experience, reliable execution, and integrated observability.

- **Share a subset of a Temporal Application** \-
  Abstract and share a subset of an Application as a Nexus Service.
  Nexus Operations can span any length of execution, be synchronous or asynchronous, and be implemented with Temporal primitives, like Workflows, Signals, or Updates.
  Expose Services on a Nexus Endpoint for others to use and secure them with access control policies.
  Nexus Endpoints decouple callers from handlers, so teams can operate more autonomously.

- **Modular design for growth** \-
  Temporal Nexus enables a modular application design that can evolve as you grow.
  Start with Nexus Services in a monolithic Namespace and move Services to separate Namespaces with small configuration changes.

- **Smaller failure domains** \- When teams operate in the same monolithic Namespace, everything is available to everyone, and mis-behaving Workers can trigger rate limits that affect all teams operating in that monolithic Namespace.
  Nexus enables each team to have their own Namespace for improved security, troubleshooting, and fault isolation.

- **Multi-region** \-
  Nexus requests in Temporal Cloud are routed across a global mTLS-secured Envoy mesh.
  Built-in Nexus Machinery provides reliable at-least-once execution and Workflow policy can deduplicate requests for exactly-once execution, even across multi-region boundaries.

### Key features

- **Familiar developer experience** \-
  Temporal SDKs provide an integrated way to build and use Nexus Services.
  - Use Nexus Services from a caller Workflow.
  - Run Nexus Service handlers in a Worker, often the same Worker as underlying Temporal primitives.
  - Implement long-running asynchronous Nexus Operations as Workflows.
  - Handle low-latency synchronous Nexus Operations with Temporal primitives or arbitrary code.
  - Execute Operations with at-least-once semantics by default, and exactly-once semantics using Workflow ID reuse policies.

- **Nexus Endpoints with a queue-based Worker architecture** \- Nexus Endpoints are a reverse proxy for Nexus Services.
  - Connect callers and handlers through Nexus Endpoints, for looser coupling.
  - Manage Endpoints in the Nexus Registry using the UI, CLI, or Cloud Ops API.
  - Use a Nexus Endpoint by name, which routes requests to an upstream target Namespace and Task Queue.
  - Handle Nexus requests in a Nexus Worker by polling an Endpoint's target Task Queue, with automatic load balancing.
  - Streamline operations by running Nexus Services in existing queue-based Workers.

- **Built-in Nexus Machinery** \-
  Execution guarantees are provided with built-in Nexus Machinery.
  - Execute Nexus Operations with reliable state-machine-based invocation and completion callbacks.
  - Guarantee atomic handoff from Workflow Event History to Nexus Operation state machines.
  - Ensure reliable execution with automatic retries, rate limiting, concurrency limiting, and circuit breaking.

- **Integrated observability** \-
  Execution debugging and observability is integrated into the Temporal Platform.
  - View Nexus Operation lifecycle and error info in Workflow Event History.
  - Debug across Namespaces with bi-directional linking.
  - Generate metrics, traces, and logs.

- **Improved blast radius isolation** \-
  Separate Namespaces isolate underlying Workers and sensitive Workflow state.
  - Limit direct access to a Namespace, while exposing Nexus Endpoints for others to use.
  - Isolate misbehaving Workers that affect rate limits for all Workers in a Namespace.
  - Avoid leaking Workflow implementation details to external callers.

- **Enhanced security and connectivity** \-
  Temporal Cloud provides integrated Nexus access controls and multi-region routing.
  - Connect Applications across Namespaces in an Account with Temporal's private mTLS-secured Envoy mesh.
  - Restrict which callers can use a Nexus Endpoint, with built-in Endpoint access controls.
  - Stream audit logs including Nexus Registry actions to create, update, or delete Endpoints.

## Learn more

To connect with the Nexus community, join the [#nexus](https://temporalio.slack.com/archives/C07LQN0JK9B) channel in [Temporal Slack](https://t.mp/slack).

<RelatedReadContainer>
  <RelatedReadItem path="https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082" text="Nexus keynote & demo - Replay video" archetype="replay-talk" />
  <RelatedReadItem path="https://www.youtube.com/watch?v=izR9dQ_eIe4" text="Nexus deep dive - Replay video" archetype="replay-talk" />
  <RelatedReadItem path="/nexus" text="Nexus concepts and getting started" archetype="encyclopedia" />
  <RelatedReadItem path="/develop/go/nexus" text="Go SDK - Nexus quick start and code sample" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/nexus" text="Java SDK - Nexus quick start and code sample" archetype="feature-guide" />
  <RelatedReadItem path="/cloud/nexus" text="Production deployment in Temporal Cloud" archetype="feature-guide" />
  <RelatedReadItem path="/production-deployment/self-hosted-guide/nexus" text="Self-hosted deployment" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/multi-tenant.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/multi-tenant.mdx</path>
  <content>
---
id: multi-tenancy
title: Multi-tenancy - Temporal feature
description: Learn about Temporal Cloud's multi-tenant architecture and how it enhances scalability, efficiency, and cost-effectiveness.
sidebar_label: Multi-tenancy
tags:
- Temporal Cloud
keywords:
- multi-tenant
- Temporal Cloud
- cloud architecture
- scalability
- cost-effectiveness
- noisy neighbor
- database performance
- high throughput
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

A Namespace is a unit of isolation within the Temporal Platform -- but even a single Namespace is still multi-tenant.
Multi-tenancy ensures extra capacity is available for all customers during traffic spikes.

However, multi-tenancy can also presents the challenge of "noisy neighbors", where high-traffic tenants consume excess resources, causing slower performance for other tenants.
This is a common problem for database scaling.

Temporal's write-heavy workload, where changes in execution state are constantly written to the persistence layer, demands a database that supports reliably high throughput with low latency for multiple customers, concurrently and fairly.

With Temporal Cloud, customers pay for consumption instead of entire sets of hardware, providing a cost-effective solution.
Temporal Cloud's architecture scales to handle multiple tenants efficiently.

<RelatedReadContainer>
  <RelatedReadItem path="https://docs.temporal.io/cloud/security#namespace-isolation" text="Namespace Isolation" archetype="cloud-guide" />
  <RelatedReadItem path="https://docs.temporal.io/cloud/pricing" text="Cost-effective Consumption" archetype="cloud-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/release-stages.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/release-stages.mdx</path>
  <content>
---
id: release-stages
title: Temporal product release stages guide
sidebar_label: Product release stages
description: Discover Temporal's Product Release Stages Guide for detailed criteria on Pre-release, Public Preview, and General Availability. Make informed decisions on feature adoption!
toc_max_heading_level: 4
keywords:
  - product release stages
  - term
tags:
- Temporal
---

:::tip CHANGELOG
To stay up-to-date with the latest feature changes, visit the [changelog](https://temporal.io/change-log).
:::

This Product Release Stages Guide provides an understanding of how Temporal features are released. It describes and lists the criteria for each release stage, so that you can make informed decisions about the adoption of each new feature.

Product Release Guide Expectations:

|                                 | Pre-release                                                        | Public Preview                                                                              | General Availability                             |
| ------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------------- | ------------------------------------------------ |
| **Features access**             | Self-hosted Temporal users: Everyone; Temporal Cloud: Invite only. | Everyone. Temporal Cloud may limit the number of users being onboarded to ensure stability. | Everyone.                                        |
| **Feature completeness**        | Limited functionality.                                             | Core functionality is complete.                                                             | Mature and feature complete.                     |
| **API stability**               | Experimental; API is subject to change.                            | API breaking changes are kept to a minimum.                                                 | API is stable.                                   |
| **Feature region Availability** | Limited regions.                                                   | Most regions.                                                                               | All [regions](/cloud/regions).                   |
| **Feature support**             | Community and engineering team.                                    | [Formal support](/cloud/support#support-ticket).                                            | [Formal support](/cloud/support#support-ticket). |
| **Feature recommended usage**   | Experimental.                                                      | Production use cases.                                                                       | Production usage.                                |
| **Feature Cloud pricing**       | No additional cost.                                                | Pricing changes are kept to a minimum.                                                      | Pricing is stable.                               |
| **Feature Interoperability**    | Limited.                                                           | Features are compatible with each other, unless otherwise stated.                           | Features are compatible with each other.         |

## Pre-release {#pre-release}

**Access:** Most Pre-release features are released in the open source Temporal software and are publicly available.
However, some features which are explicit to hosting Temporal Services, such as [API Keys](/cloud/api-keys), may be specific to Temporal Cloud.

In Temporal Cloud, Pre-release features are invite-only: Temporal will work directly with a group of existing Temporal Cloud customers to be part of testing of each Pre-release feature.
These customers are invited to provide feedback to the Temporal team.

**Classification:** New features in Pre-release may not be fully mature and may have bugs.
Users acknowledge and agree that Pre-release features are provided on an “as-is” basis, and that they are provided without any indemnification, support, warranties, or representation of any kind.

**Feedback:** Feedback is highly encouraged and important for guiding Temporal feature development.
We encourage you to share your experience so that you can influence the future direction of Temporal.

**Availability:** Temporal may modify features before they become Generally Available, or may even decide to remove them.
This means there is no guarantee that a new feature will become Generally Available.
A Pre-release feature can be deprecated at any time.

Pre-release features may be disabled by default, and can be enabled via configuration.
Temporal Cloud customers can contact the Temporal account team or [Temporal Support Team](/cloud/support#support-ticket) to gain Pre-release access.

## Public Preview {#public-preview}

**Access:** New features in Public preview are available to everyone.

**Classification:** Features in public preview may undergo further development and testing before they are made Generally Available.
These features are being refined and are recommended for production usage.

**Feedback:** Temporal users are invited to share feedback via the [Community Slack](http://t.mp/slack), by reaching out directly to the Temporal team at product@temporal.io, or by creating issues in the relevant [GitHub repository](https://github.com/temporalio).
Temporal also encourages Temporal Cloud users to submit feedback via [support ticket](/cloud/support#support-ticket).
This feedback will assist in guiding the improvements for General Availability.

**Availability:** New Features in Public Preview may evolve.
The APIs may undergo changes; however, Temporal's goal is to maintain backward compatibility.

## General Availability {#general-availability}

**Access:** Features in General Availability are available to everyone.

**Classification:** The feature is now fully developed, tested, and available for use without further anticipated changes.

**Feedback:** Temporal users are invited to share feedback via the [Community Slack](http://t.mp/slack), by reaching out directly to the Temporal team at product@temporal.io, or by creating issues in the relevant [GitHub repository](https://github.com/temporalio).

**Availability:** Features in General Availability are released with stable APIs and recommended for production use with a committed SLA.

:::info Exceptions

There may be exceptions for different features, but this is the typical expectation.
Any variation will be documented.

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/batch.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/batch.mdx</path>
  <content>
---
id: batch
title: Temporal CLI batch command reference
sidebar_label: batch
description: Use Temporal CLI to manage multiple Workflow Executions with Batch Jobs that can Cancel, Signal, or Terminate Workflows. Filter and monitor Batch Jobs effectively.
toc_max_heading_level: 4
keywords:
  - batch
  - batch describe
  - batch list
  - batch terminate
  - cli reference
  - cli-feature
  - command-line-interface-cli
  - temporal cli
tags:
  - Temporal CLI
---

Batch commands change multiple [Workflow Executions](/workflows#workflow-execution) by providing a [List Filter](/clusters#visibility) and the type of Batch Job to execute.
The List Filter identifies the Workflow Executions in the Batch Job; the Batch type determines what will happen to the Workflow Executions.

**Which batch operations can be performed by the Temporal CLI?**

There are three types of Batch Jobs:

- Cancel: cancels the Workflow Executions specified by the List Filter.
- Signal: sends a [Signal](/sending-messages#sending-signals) to the Workflow Executions specified by the List Filter.
- Terminate: terminates the Workflow Executions specified by the List Filter.

Batch operations can affect multiple Workflows simultaneously.
Depending on your needs, you might want to send Signals to running Workflows, Cancel them, or even Terminate them entirely.
Below are examples of how to use the Temporal CLI for each type of Batch operation.

These commands will directly impact the Workflows you target, so it's important to use them judiciously.

You can use the `--query` flag, which acts as [List Filter](/list-filter), to filter the Workflow Executions to be affected by the Batch Job.

To Cancel Workflows:

```command
temporal workflow cancel \
  --query 'ExecutionStatus = "Running" AND WorkflowType="YourWorkflow"' \
  --reason "Testing"
```

To Signal Workflows:

```command
temporal workflow signal \
  --workflow-id MyWorkflowId \
  --name MySignal \
  --input '{"Input": "As-JSON"}' \
  --query 'ExecutionStatus = "Running" AND WorkflowType="YourWorkflow"' \
  --reason "Testing"
```

To Terminate Workflows:

```command
temporal workflow terminate \
  --query 'ExecutionStatus = "Running" AND WorkflowType="YourWorkflow"' \
  --reason "Testing"
```

A successfully started Batch job will return a Job ID.
Use this Job ID to execute other actions on the Batch job.

## list

The `temporal batch list` command returns all Batch jobs.
Batch Jobs can be returned for an entire Cluster or a single Namespace.

`temporal batch list --namespace=MyNamespace`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--limit](/cli/cmd-options#limit)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## describe

The `temporal batch describe` command shows the progress of an ongoing Batch job.

Pass a valid Job ID to return a Batch Job's information.

`temporal batch describe --job-id=MyJobId`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--job-id](/cli/cmd-options#job-id)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## terminate

The `temporal batch terminate` command terminates a Batch job with the provided Job ID.
For future reference, provide a reason for terminating the Batch Job.

`temporal batch terminate --job-id=MyJobId --reason=JobReason`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--job-id](/cli/cmd-options#job-id)

- [--namespace](/cli/cmd-options#namespace)

- [--reason](/cli/cmd-options#reason)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/cluster-metrics.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/cluster-metrics.mdx</path>
  <content>
---
id: cluster-metrics
title: OSS Temporal Service metrics reference
sidebar_label: Temporal Service metrics
description: A Temporal Service emits metrics helping operators monitor performance and set alerts. Metrics like service requests, latencies, and errors are tracked. Use metric_defs.go for more.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
  - Metrics
---

:::info OSS Temporal Service metrics

The information on this page is relevant to open source [Temporal Service deployments](/clusters).

See [Cloud metrics](/cloud/metrics/) for metrics emitted by [Temporal Cloud](/cloud/overview).

See [SDK metrics](/references/sdk-metrics) for metrics emitted by the [SDKs](/encyclopedia/temporal-sdks).

:::

A Temporal Service emits a range of metrics to help operators get visibility into the Temporal Service's performance and to set up alerts.

All metrics emitted by the Temporal Service are listed in [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go).

For details on setting up metrics in your Temporal Service configuration, see the [Temporal Service configuration reference](/references/configuration#global).

The [dashboards repository](https://github.com/temporalio/dashboards) contains community-driven Grafana dashboard templates that can be used as a starting point for monitoring the Temporal Service and SDK metrics.
You can use these templates as references to build your own dashboards.
For any metrics that are missing in the dashboards, use [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) as a reference.

Note that, apart from these metrics emitted by the Temporal Service, you should also monitor infrastructure-specific metrics like CPU, memory, and network for all hosts that are running Temporal Service services.

## Common metrics

Temporal emits metrics for each gRPC service request.
These metrics are emitted with `type`, `operation`, and `namespace` tags, which provide visibility into Service usage and show the request rates across Services, Namespaces, and Operations.

- Use the `operation` tag in your query to get request rates, error rates, or latencies per operation.
- Use the `service_name` tag with the [service role tag values](https://github.com/temporalio/temporal/blob/bba148cf1e1642fd39fa0174423b183d5fc62d95/common/metrics/defs.go#L108) to get details for the specific service.

All common tags that you can add in your query are defined in the [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) file.

For example, to see service requests by operation on the Frontend Service, use the following:

`sum by (operation) (rate(service_requests{service_name="frontend"}[2m]))`

Note: All metrics queries in this topic are [Prometheus queries](https://prometheus.io/docs/prometheus/latest/querying/basics/).

The following list describes some metrics you can get started with.

### `service_requests`

Shows service requests received per Task Queue.
Example: Service requests by operation
`sum(rate(service_requests{operation=\"AddWorkflowTask\"}[2m]))`

### `service_latency`

Shows latencies for all Client request operations.
Usually these are the starting point to investigate which operation is experiencing high-latency issues.
Example: P95 service latency by operation for the Frontend Service
`histogram_quantile(0.95, sum(rate(service_latency_bucket{service_name="frontend"}[5m])) by (operation, le))`

### `service_error_with_type`

(Available only in v1.17.0+) Identifies errors encountered by the service.
Example: Service errors by type for the Frontend Service
`sum(rate(service_errors_with_type{service_name="frontend"}[5m])) by (error_type)`

### `client_errors`

An indicator for connection issues between different Server roles.
Example: Client errors
`sum(rate(client_errors{service_name="frontend",service_role="history"}[5m]))`

In addition to these, you can define some service-specific metrics to get performance details for each service.
Start with the following list, and use [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) to define additional metrics as required.

## Matching Service metrics

### `poll_success`

Shows for Tasks that are successfully matched to a poller.
Example: `sum(rate(poll_success{}[5m]))`

### `poll_timeouts`

Shows when no Tasks are available for the poller within the poll timeout.
Example: `sum(rate(poll_timeouts{}[5m]))`

### `asyncmatch_latency`

Measures the time from creation to delivery for async matched Tasks.
The larger this latency, the longer Tasks are sitting in the queue waiting for your Workers to pick them up.
Example: `histogram_quantile(0.95, sum(rate(asyncmatch_latency_bucket{service_name=~"matching"}[5m])) by (operation, le))`

### `no_poller_tasks`

Emitted whenever a task is added to a task queue that has no poller, and is a counter metric.
This is usually an indicator that either the Worker or the starter programs are using the wrong Task Queue.

## History Service metrics

A History Task is an internal Task in Temporal that is created as part of a transaction to update Workflow state and is processed by the Temporal History service.
It is critical to ensure that the History Task processing system is healthy.
The following key metrics can be used to monitor the History Service health:

### `task_requests`

Emitted on every Task process request.
Example: `sum(rate(task_requests{service="$service",operation=~"TransferActive.*"}[1m]))`

### `task_errors`

Emitted on every Task process error.
Example: `sum(rate(task_errors{operation=~"TransferActive.*"}[1m]))`

### `task_attempt`

Number of attempts on each Task Execution.
A Task is retried forever, and each retry increases the attempt count.
Example: `histogram_quantile($percentile, sum(rate(task_attempt_bucket{service="$service",operation=~"TransferActive.*"}[1m])) by (operation, le))`

### `task_latency_processing`

Shows the processing latency per attempt.
Example: `histogram_quantile($percentile, sum(rate(task_latency_processing_bucket{operation=~"TransferActive.*",service="$service", service_name="history"}[1m])) by (operation, le))`

### `task_latency`

Measures the in-memory latency across multiple attempts.

### `task_latency_queue`

Measures the duration, end-to-end, from when the Task should be executed (from the time it was fired) to when the Task is done.

### `task_latency_load`

(Available only in v1.18.0+) Measures the duration from Task generation to Task loading (Task schedule to start latency for persistence queue).

### `task_latency_schedule`

(Available only in v1.18.0+) Measures the duration from Task submission (to the Task scheduler) to processing (Task schedule to start latency for in-memory queue).

### `queue_latency_schedule`

(Available only in v1.18.0+) Measures the time to schedule 100 Tasks in one Task channel in the host-level Task scheduler.
If fewer than 100 Tasks are in the Task channel for 30 seconds, the latency is scaled to 100 Tasks upon emission.
Note: This is still an experimental metric and is subject to change.

### `task_latency_userlatency`

Shows the latency introduced because of Workflow logic.
For example, if you have one Workflow scheduling many Activities or Child Workflows at the same time, it can cause a per-Workflow lock contention.
The wait period for the per-Workflow lock is counted as `userlatency`.

The `operation` tag contains details about Task type and Active versus Standby statuses, and can be used to get request rates, error rates, or latencies per operation, which can help identify issues caused by database problems.

## Persistence metrics

Temporal Server emits metrics for every persistence database read and write.
Some of the most important ones are the following:

### `persistence_requests`

Emitted on every persistence request.
Examples:

- Prometheus query for getting the total number of persistence requests by operation for the History Service:
  `sum by (operation) (rate(persistence_requests{service="$service",service_name="history"}[1m]))`
- Prometheus query for getting the total number of persistence requests by operation for the Matching Service:
  `sum by (operation) (rate(persistence_requests{cluster="$cluster",service_name="matching"}[5m]))`

### `persistence_errors`

Shows all persistence errors.
This metric is a good indicator for connection issues between the Temporal Service and the persistence store.
Example:

- Prometheus query for getting all persistence errors by service (history)
  `sum (rate(persistence_errors{service="$service",service_name="history"}[1m]))`

### `persistence_error_with_type`

Shows all errors related to the persistence store with type, and contain an `error_type` tag.

- Prometheus query for getting persistence errors with type by (history) and by error type:
  `sum(rate(persistence_error_with_type{service="$service",service_name="history"}[1m])) by (error_type)`

### `persistence_latency`

Shows the latency on persistence operations.
Example:

- Prometheus query for getting latency by percentile:
  `histogram_quantile($percentile, sum(rate(persistence_latency_bucket{service="$service" service_name="history"}[1m])) by (operation, le))`

## Schedule metrics

Temporal emits metrics that track the performance and outcomes of these Scheduled Executions.

Below are additional metrics that can help you monitor and optimize your Scheduled Workflow Executions.

### `schedule_buffer_overruns`

Indicates instances where the buffer for holding Scheduled Workflows exceeds its maximum capacity.
This scenario typically occurs when schedules with a `buffer_all` overlap policy have their average run length exceeding the average schedule interval.

Example: To monitor buffer overruns.

`sum(rate(schedule_buffer_overruns{namespace="$namespace"}[5m]))`

### `schedule_missed_catchup_window`

Tracks occurrences when the system fails to execute a Scheduled Action within the defined catchup window.
Missed catchup windows can result from extended outages beyond the configured catchup period.

Example: To identify missed catchup opportunities.

`sum(rate(schedule_missed_catchup_window{namespace="$namespace"}[5m]))`

### `schedule_rate_limited`

Reflects instances where the creation of Workflows by a Schedule is throttled due to rate limiting policies within a Namespace.
This metric is crucial for identifying scheduling patterns that frequently hit rate limits, potentially causing missed catchup windows.

Example: To assess the impact of rate limiting on Scheduled Executions.

`sum(rate(schedule_rate_limited{namespace="$namespace"}[5m]))`

### `schedule_action_success`

Measures the successful execution of Workflows as per their schedules or through manual triggers.
This metric is confirms that Workflows are running as expected without delays or errors.

Example: To track the success rate of Scheduled Workflow Executions.

`sum(rate(schedule_action_success{namespace="$namespace"}[5m]))`

## Workflow metrics

These metrics pertain to Workflow statistics.

### `workflow_cancel`

Number of Workflows canceled before completing execution.

### `workflow_continued_as_new`

Number of Workflow Executions that were Continued-As-New from a past execution.

### `workflow_failed`

Number of Workflows that failed before completion.

### `workflow_success`

Number of Workflows that successfully completed.

### `workflow_timeout`

Number of Workflows that timed out before completing execution.

## Nexus metrics

These metrics pertain to Nexus Operations.

### Nexus Machinery in the History Service

See [architecture document](https://github.com/temporalio/temporal/blob/5d55d6c707bd68d8f3274c57ae702331adf05e6e/docs/architecture/nexus.md#scheduler)
for more info.

#### In-Memory Buffer

`dynamic_worker_pool_scheduler_enqueued_tasks`: A counter that is incremented when a task is enqueued to the buffer.

`dynamic_worker_pool_scheduler_dequeued_tasks`: A counter that is incremented when a task is dequeued from the buffer.

`dynamic_worker_pool_scheduler_rejected_tasks`: A counter that is incremented when the buffer is full and adding the
task is rejected.

`dynamic_worker_pool_scheduler_buffer_size`: A gauge that periodically samples the size of the buffer.

### Concurrency Limiter

`dynamic_worker_pool_scheduler_active_workers`: A gauge that periodically samples the number of running goroutines.

#### Rate Limiter

`rate_limited_task_runnable_wait_time`: A histogram representing the time a task spends waiting for the rate limiter.

#### Circuit Breaker

`circuit_breaker_executable_blocked`: A counter that is incremented every time a task execution is blocked by the
circuit breaker.

#### Task Executors

`nexus_outbound_requests`: A counter representing the number of Nexus outbound requests made by the history service.

`nexus_outbound_latency`: A histogram representing the latency of outbound Nexus requests made by the history service.

`callback_outbound_requests`: A counter representing the number of callback outbound requests made by the history
service.

`callback_outbound_latency`: A histogram representing the latency histogram of outbound callback requests made by the
history service.

### Nexus Machinery on the Frontend Service

#### `nexus_requests`

The number of Nexus requests received by the service.

Type: Counter

#### `nexus_latency`

Latency of Nexus requests.

Type: Histogram

#### `nexus_request_preprocess_errors`

The number of Nexus requests for which pre-processing failed.

Type: Counter

#### `nexus_completion_requests`

The number of Nexus completion (callback) requests received by the service.

Type: Counter

#### `nexus_completion_latency`

Latency histogram of Nexus completion (callback) requests.

Type: Histogram

#### `nexus_completion_request_preprocess_errors`

The number of Nexus completion requests for which pre-processing failed.

Type: Counter

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/workflow.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/workflow.mdx</path>
  <content>
---
id: workflow
title: Temporal CLI workflow command reference
sidebar_label: workflow
description: Temporal Workflow commands enable operations on Workflow Executions, such as cancel, count, delete, describe, execute, list, query, reset, reset-batch, show, signal, stack, start, terminate, trace, and update, enhancing efficiency and control.
toc_max_heading_level: 4
keywords:
  - call stack
  - cancellation
  - child workflows
  - cli reference
  - command-line-interface-cli
  - event history
  - query
  - resets-feature
  - signals
  - signals-feature
  - stack trace
  - temporal cli
  - termination
  - workflow
  - workflow cancel
  - workflow count
  - workflow delete
  - workflow describe
  - workflow execute
  - workflow execution
  - workflow list
  - workflow query
  - workflow reset
  - workflow reset-batch
  - workflow show
  - workflow signal
  - workflow stack
  - workflow start
  - workflow terminate
  - workflow trace
tags:
  - Temporal CLI
  - Workflows
---

[Workflow](/workflows) commands allow operations to be performed on [Workflow Executions](/workflows#workflow-execution).

Workflow commands use this syntax:
`temporal workflow COMMAND [ARGS]`.

## cancel

The `temporal workflow cancel` command cancels a [Workflow Execution](/workflows#workflow-execution).

Canceling a running Workflow Execution records a [`WorkflowExecutionCancelRequested` event](/references/events#workflowexecutioncancelrequested) in the [Event History](/workflows#event-history).
A new [Workflow Task](/tasks#workflow-task) will be scheduled, and the Workflow Execution performs cleanup work.

`temporal workflow cancel --workflow-id=meaningful-business-id`

In addition to Workflow IDs, Workflows can also be cancelled by a [List Filter](/list-filter).
`temporal workflow cancel --query=MyListFilter`

Use the following options to change the behavior of this command.

- [--fields](/cli/cmd-options#fields)

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--query](/cli/cmd-options#query)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--yes](/cli/cmd-options#yes)

## count

The `temporal workflow count` command returns a count of [Workflow Executions](/workflows#workflow-execution).
This command requires Elasticsearch to be enabled.

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--query](/cli/cmd-options#query)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## delete

The `temporal workflow delete` command deletes the specified [Workflow Execution](/workflows#workflow-execution).

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--query](/cli/cmd-options#query)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--yes](/cli/cmd-options#yes)

## describe

The `temporal workflow describe` command shows information about a given [Workflow Execution](/workflows#workflow-execution).
This information can be used to locate Workflow Executions that weren't able to run successfully.

`temporal workflow describe --workflow-id=meaningful-business-id`

The output of this command can be changed to show as printed ('raw') or to only show the Workflow Execution's auto-reset points.

`temporal workflow describe --workflow-id=meaningful-business-id --raw=true --reset-points=true`

Use the following command options to change the information returned by this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--raw](/cli/cmd-options#raw)

- [--reset-points](/cli/cmd-options#reset-points)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## execute

The `temporal workflow execute` command starts a new [Workflow Execution](/workflows#workflow-execution) and prints its progress.
The command doesn't finish until the Workflow Execution completes.

To execute a [Workflow](/workflows) from the Temporal CLI:
`temporal workflow execute --workflow-id=meaningful-business-id --type=MyWorkflow --task-queue=MyTaskQueue`

Single quotes('') are used to wrap input as JSON.

`temporal workflow execute --workflow-id=meaningful-business-id --type-MyWorkflow --task-queue-MyTaskQueue --input='{"JSON": "Input"}'`

Use the following command options to change how the Workflow Execution behaves during its run.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--cron](/cli/cmd-options#cron)

- [--env](/cli/cmd-options#env)

- [--execution-timeout](/cli/cmd-options#execution-timeout)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--id-reuse-policy](/cli/cmd-options#id-reuse-policy)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--limit](/cli/cmd-options#limit)

- [--max-field-length](/cli/cmd-options#max-field-length)

- [--memo](/cli/cmd-options#memo)

- [--memo-file](/cli/cmd-options#memo-file)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--run-timeout](/cli/cmd-options#run-timeout)

- [--search-attribute](/cli/cmd-options#search-attribute)

- [--start-delay](/cli/cmd-options#start-delay)

- [--task-queue](/cli/cmd-options#task-queue)

- [--task-timeout](/cli/cmd-options#task-timeout)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

- [--workflow-id](/cli/cmd-options#workflow-id)

## list

The `temporal workflow list` command provides a list of [Workflow Executions](/workflows#workflow-execution) that meet the criteria of a given [List Filter](/list-filter).
By default, this command returns a list of up to 10 closed Workflow Executions.

`temporal workflow list --query=MyListFilter`

The command can also return a list of archived Workflow Executions.

`temporal workflow list --archived=true`

Use the following command options to change the information returned by this command.

- [--address](/cli/cmd-options#address)

- [--archived](/cli/cmd-options#archived)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--limit](/cli/cmd-options#limit)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--query](/cli/cmd-options#query)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## query

The `temporal workflow query` command sends a [Query](/sending-messages#sending-queries) to a [Workflow Execution](/workflows#workflow-execution).

Queries can retrieve all or part of the Workflow state within given parameters.
Queries can also be used on completed [Workflows](/workflows#workflow-execution).

`temporal workflow query --workflow-id=meaningful-business-id --type=MyQueryType`

Use the following command options to change the information returned by this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--namespace](/cli/cmd-options#namespace)

- [--reject-condition](/cli/cmd-options#reject-condition)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

- [--workflow-id](/cli/cmd-options#workflow-id)

## reset

The `temporal workflow reset` command resets a [Workflow Execution](/workflows#workflow-execution).
A reset resumes the Workflow from a certain point without losing your parameters or [Event History](/workflows#event-history).

The Workflow Execution can be set to a given [Event Type](/workflows#event).
For example, `temporal workflow reset --workflow-id=meaningful-business-id --type=LastContinuedAsNew`.

The Workflow Execution can also be reset to any Event after WorkflowTaskStarted.
For example, `temporal workflow reset --workflow-id=meaningful-business-id --event-id=MyLastEvent`.

Use the following options to change reset behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--event-id](/cli/cmd-options#event-id)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--reapply-type](/cli/cmd-options#reapply-type)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

- [--workflow-id](/cli/cmd-options#workflow-id)

## reset-batch

The `temporal workflow reset-batch` command resets multiple [Workflow Executions](/workflows#workflow-execution) by `resetType`.
Resetting a [Workflow](/workflows) resumes it from a certain point without losing your parameters or [Event History](/workflows#event-history).

The set of Workflow Executions to reset can be specified in an input file.
The input file must have a [Workflow ID](/workflows#workflow-id) on each line.

`temporal workflow reset-batch --input-file=MyInput --input-separator="\t"`

Workflow Executions can also be queried by a [List Filter](/list-filter).
`temporal workflow reset-batch --query=MyListFilter`

Use the following options to change reset behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--dry-run](/cli/cmd-options#dry-run)

- [--env](/cli/cmd-options#env)

- [--exclude-file](/cli/cmd-options#exclude-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input-file](/cli/cmd-options#input-file)

- [--input-parallelism](/cli/cmd-options#input-parallelism)

- [--input-separator](/cli/cmd-options#input-separator)

- [--namespace](/cli/cmd-options#namespace)

- [--non-deterministic](/cli/cmd-options#non-deterministic)

- [--query](/cli/cmd-options#query)

- [--reason](/cli/cmd-options#reason)

- [--skip-base-is-not-current](/cli/cmd-options#skip-base-is-not-current)

- [--skip-current-open](/cli/cmd-options#skip-current-open)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

## show

The `temporal workflow show` command provides the [Event History](/workflows#event-history) for a [Workflow Execution](/workflows#workflow-execution).

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--follow](/cli/cmd-options#follow)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--limit](/cli/cmd-options#limit)

- [--max-field-length](/cli/cmd-options#max-field-length)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--reset-points](/cli/cmd-options#reset-points)

- [--run-id](/cli/cmd-options#run-id)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## signal

The `temporal workflow signal` command is used to send a [Signal](/sending-messages#sending-signals) to a [Workflow Execution](/workflows#workflow-execution) by [Workflow Id](/workflows#workflow-id) or [List Filter](/list-filter).

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--query](/cli/cmd-options#query)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--yes](/cli/cmd-options#yes)

## stack

The `temporal workflow stack` command queries a [Workflow Execution](/workflows#workflow-execution) with `--stack-trace` as the [Query](/sending-messages#stack-trace-query) type.
Returning the call stack of all the threads owned by a Workflow Execution can be great for troubleshooting in production.

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--namespace](/cli/cmd-options#namespace)

- [--reject-condition](/cli/cmd-options#reject-condition)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## start

The `temporal workflow start` command starts a new [Workflow Execution](/workflows#workflow-execution).
When invoked successfully, the Workflow and Run ID are returned immediately after starting the [Workflow](/workflows).

`temporal workflow start --task-queue=MyTaskQueue --type=MyWorkflow`

Use the following command options to change how the Workflow Execution behaves upon starting.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--cron](/cli/cmd-options#cron)

- [--env](/cli/cmd-options#env)

- [--execution-timeout](/cli/cmd-options#execution-timeout)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--id-reuse-policy](/cli/cmd-options#id-reuse-policy)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--limit](/cli/cmd-options#limit)

- [--max-field-length](/cli/cmd-options#max-field-length)

- [--memo](/cli/cmd-options#memo)

- [--memo-file](/cli/cmd-options#memo-file)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--run-timeout](/cli/cmd-options#run-timeout)

- [--search-attribute](/cli/cmd-options#search-attribute)

- [--start-delay](/cli/cmd-options#start-delay)

- [--task-queue](/cli/cmd-options#task-queue)

- [--task-timeout](/cli/cmd-options#task-timeout)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

- [--workflow-id](/cli/cmd-options#workflow-id)

## terminate

The `temporal workflow terminate` command terminates a [Workflow Execution](/workflows#workflow-execution)

Terminating a running Workflow Execution records a [`WorkflowExecutionTerminated` event](/references/events#workflowexecutionterminated) as the closing Event in the [Event History](/workflows#event-history).
Any further [Command](/workflows#command) Tasks cannot be scheduled after running this command.

Workflow terminations require a valid [Workflow ID](/workflows#workflow-id) to function.
`temporal workflow terminate --workflow-id=meaningful-business-id`

Use the following options to change termination behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--query](/cli/cmd-options#query)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--yes](/cli/cmd-options#yes)

## trace

The `temporal workflow trace` command tracks the progress of a [Workflow Execution](/workflows#workflow-execution) and any [Child Workflows](/encyclopedia/child-workflows) it generates.

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--concurrency](/cli/cmd-options#concurrency)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--depth](/cli/cmd-options#depth)

- [--env](/cli/cmd-options#env)

- [--fold](/cli/cmd-options#fold)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--no-fold](/cli/cmd-options#no-fold)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## update

The `temporal workflow update` command synchronously updates a running [Workflow Execution](/workflows#workflow-execution).

Use the options listed below to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--first-execution-run-id](/cli/cmd-options#first-execution-run-id)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/understanding-temporal.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/understanding-temporal.mdx</path>
  <content>
---
id: understanding-temporal
title: Understanding Temporal
sidebar_label: Understanding Temporal 
description: This page provides a short overview of how Temporal works. 
toc_max_heading_level: 4
keywords:
  - durable execution

tags:
  - temporal
  - evaluate temporal
---

Temporal offers an entirely new way to build scalable and reliable applications.

## Build Invincible Apps

In any complex system, failures are bound to happen.
Software engineers spend a lot of time ensuring that what they build can withstand potential failures.
Temporal makes your code execution reliable and durable by default.

Normally, if a crash occurs then the state of your application's execution is lost.
The application has no memory of what happened before the failure, requiring extensive error handling logic and complex recovery code to resume.
The process is time-consuming and error-prone, making it difficult to ensure reliability.

Temporal tracks the progress of your application.
If something goes wrong, like a power outage, it guarantees that your application can pick up right where it left off — it’s like having the ultimate autosave.
Offloading the responsibility of failure management from the application to the platform removes the need for extensive recovery coding, testing, and maintenance tasks.

### Durable Execution

Temporal is a Durable Execution Platform.
Durable Execution ensures that your application behaves correctly despite adverse conditions by guaranteeing that it will run to completion.
This shift simplifies the development process. If a failure or a crash happens, your business processes keep running seamlessly without interruptions.
Developers shift their focus on business logic rather than infrastructure concerns and create applications that are inherently scalable and maintainable.

Thousands of developers trust Temporal for use cases like order processing, customer onboarding, and payment handling because it enables them to build invincible applications that are resilient, durable, and _just work_.
With Temporal, your applications keep running, no matter what happens.

## Temporal Application: The Building Blocks

### Workflow

Conceptually, a Workflow is a sequence of steps.
You've likely encountered Workflows in your daily life, whether it's:

- Using a mobile app to transfer money
- Booking a vacation
- Filing an expense report
- Creating a new employee onboarding process
- Deploying cloud infrastructure
- Training an AI model

A Temporal Workflow is your business logic, defined in code, outlining each step in your process.

Temporal isn’t a no-code Workflow engine — it is **Workflows-as-Code**.
Instead of dragging and dropping steps in a visual interface, you write your Workflows in code in your favorite programming language, code editor, and other tools.
No-code engines eventually hit their limitations however, Temporal gives you full control and flexibility over your business processes.
This allows you to build exactly what you need.

### Activities

Activities are the individual units of work in your Workflow.
Activities are defined as either functions or methods, depending on the programming language.
Activities often involve interacting with the outside world, such as sending emails, making network requests, writing to a database, or calling an API, which are prone to failure.
You can call Activities directly from your Workflow code.

If an Activity fails, Temporal automatically retries it based on your configuration.
Since Activities often rely on external systems, transient issues can occur.
These include temporary but critical problems like network failures, timeouts, or service outages.
You have full control over how often and how many times these retries should happen for each Activity.

### SDK

Developers create Temporal applications by writing code, just like you would to create any other software.

A Temporal SDK (software development kit) is an open-source library that developers add to their application to use Temporal.
It provides everything needed to build Workflows, Activities, and various other Temporal features in a specific programming language.

Temporal offers six SDKs: Java, Go, TypeScript, .NET, Python, and PHP.
Since Temporal supports multiple programming languages, you can mix-and-match between languages for polyglot teams.
You can easily add any Temporal SDK to your current projects without changing the tools you're already using to build and deploy.
Temporal fits right into your existing tech stack.

## Temporal Service

Temporal has two main parts:

1. Your application
2. The Temporal Service (a set of services and components)

At the heart of Temporal architecture is the Temporal Service, which provides durability, scalability, and reliability for your application.
Your application communicates with the Temporal Service and the Temporal Service oversees the execution of critical tasks such as making an API call, then records their completion.
It maintains a detailed history of each event, which it reliably persists to a database.

One of the biggest advantages of the Temporal Service is how it handles failures.
The Temporal Service maintains a meticulous record of every step in your Workflows.
By keeping a history of every step in your Workflow, it ensures that even if something goes wrong your Workflow can continue from the last successful point.
The Temporal Service knows exactly where to resume without losing any work.
This saves you from having to write complex error handling code or painstaking recovery mechanisms yourself.

You can run the Temporal Service on your own infrastructure or use Temporal Cloud, a managed service that handles operational overhead and offers scalability and expert support.

## Workers

The real strength of Temporal comes from the combination of your application and the Temporal Service.
Whenever your application needs to perform a task, like sending a notification or processing a payment, the Temporal Service orchestrates what needs to be done.
Workers, which are part of your application and provided by the Temporal SDK, then carry out the tasks defined in your Workflow.

The Worker polls the Temporal Service to see if there are tasks available and the Temporal Service matches the task with the Worker.
The Worker runs the Workflow code based on the details specified in the task.

This collaboration is crucial for building reliable, scalable, and durable applications.
You can run multiple Workers — often dozens, hundreds, or even thousands — to improve application performance and scalability.

A common misconception is that the Temporal Service runs your code.
In fact, the Worker runs your code and works with your data directly.
Temporal applications are secure by design.
Workflows and Activities are seamlessly deployed within your infrastructure, fully integrated into your application.
Your data is also protected with your encryption libraries and keys.
You maintain full control over the security of your application from end to end.

## Visibility

There are two tools provided by Temporal that allow you to see behind the scenes and interact with your Workflows.
These are powerful for debugging uses and provide real-time monitoring of your applications.

### Temporal UI

The Temporal UI is a browser-based user interface that allows you to see the progress of your application.
Also, known as the Web UI, it can also help you to quickly isolate, debug, and resolve production problems.

![Recent Workflows page](/img/webui/workflow-details-page-hiw.avif)

### Temporal CLI

The Temporal CLI is a command-line interface tool for managing, monitoring, and debugging Temporal Applications.
Through your terminal, you can:

- Start a Workflow
- Trace the progress of a Workflow
- Cancel or terminate a Workflow
- And perform other operations

The Temporal CLI provides developers with direct access to a Temporal Service for local development purposes.

## Reliable as Gravity

Temporal provides effortless durability, allowing applications to run for days, weeks, or even years without interruption even if the underlying infrastructure fails.
This is what we call _Durable Execution_. Temporal also represents a paradigm shift in software development.
It's not just about making existing patterns more reliable; it's about enabling entirely new approaches to building complex, distributed systems.

Temporal simplifies state management and developers don't have to write tons of extra code to handle every possible thing that could go wrong.
With built-in scalability, Temporal ensures that your application runs smoothly, no matter its size or complexity.

:::tip

Follow one of our tutorials to [Get Started](https://learn.temporal.io/getting_started/) learning how to use a Temporal SDK.
Or, jump straight into an [Introduction to Temporal 101](https://learn.temporal.io/courses/temporal_101/) course.

Looking for more? Explore Temporal's [Resource Library](https://temporal.io/resources).
:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/python-sdk-sync-vs-async.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/python-sdk-sync-vs-async.mdx</path>
  <content>
---
id: python-sdk-sync-vs-async
title: Temporal Python SDK synchronous vs. asynchronous Activity implementations
sidebar_label: Python SDK sync vs async
description: The Temporal Python SDK supports implementing Activities asynchronously with asyncio, synchronously with ThreadPoolExecutor or ProcessPoolExecutor. Choose the correct method to avoid application errors.
toc_max_heading_level: 4
keywords:
  - temporal python sdk
  - asynchronous activities
  - synchronous activities
  - asyncio python
  - multiprocessing.managers.syncmanager
  - python async event loop
  - blocking calls in python
  - aiohttp vs requests
  - python multithreading
  - python multiprocessing
  - async safe http library
  - http requests in python activities
  - activity implementation in temporal
  - async-vs-sync
tags:
  - Temporal SDKs
  - Python SDK
  - Concepts
---

The Temporal Python SDK supports multiple ways of implementing an Activity:

- Asynchronously using [`asyncio`](https://docs.python.org/3/library/asyncio.html)
- Synchronously multithreaded using [`concurrent.futures.ThreadPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
- Synchronously multiprocess using [`concurrent.futures.ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor) and [`multiprocessing.managers.SyncManager`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager)

It is important to implement your Activities using the correct method, otherwise
your application may fail in sporadic and unexpected ways. Which one you should
use depends on your use case. This section provides guidance to help you choose
the best approach.

## The Python Asynchronous Event Loop and Blocking Calls

First, let's look at how async event loops work in Python. The Python async
event loop runs in a thread and executes all tasks in its thread. When any
task is running in the event loop, the loop is blocked and no other tasks can be
running at the same time within that event loop. Whenever a task executes an
`await` expression, the task is suspended, and the event loop begins or resumes
execution of another task.

This means that the event loop can only pass the flow of control when the `await`
keyword is executed. If a program makes a blocking call, such as one that reads
from a file, makes a synchronous request to a network service, waits for user input,
or anything else that blocks the execution, the entire event loop must wait until
that execution has completed.

Blocking the async event loop in Python would turn your asynchronous program
into a synchronous program that executes serially, defeating the entire purpose
of using `asyncio`. This can also lead to potential deadlock, and unpredictable behavior
that causes tasks to be unable to execute. Debugging these issues can be difficult
and time consuming, as locating the source of the blocking call might not always
be immediately obvious.

Due to this, Python developers must be extra careful to not make blocking calls
from within an asynchronous Activity, or use an async safe library to perform
these actions.

For example, making an HTTP call with the popular `requests` library within an
asynchronous Activity would lead to blocking your event loop. If you want to make
an HTTP call from within an asynchronous Activity, you should use an async-safe HTTP library
such as `aiohttp` or `httpx`. Otherwise, use a synchronous Activity.

## Implementing Asynchronous Activities

The following code is an asynchronous Activity Definition that's similar to one
you will use during an upcoming exercise. Like the Workflow Definition
you've already run, it takes a name (`str`) as input and returns a
customized greeting (`str`) as output. However, this Activity makes
a call to a microservice, accessed through HTTP, to request this
greeting in Spanish. This activity uses the `aiohttp` library to make an async
safe HTTP request. Using the `requests` library here would have resulting in
blocking code within the async event loop, which will block the entire async
event loop. For more in-depth information about this issue, refer to the
[Python asyncio documentation](https://docs.python.org/3/library/asyncio-dev.html#running-blocking-code).

The code below also implements the Activity Definition as a class, rather than a
function. The `aiohttp` library requires an established `Session` to perform the
HTTP request. It would be inefficient to establish a `Session` every time an
Activity is invoked, so instead this code accepts a `Session` object as an instance
parameter and makes it available to the methods. This approach will also be
beneficial when the execution is over and the `Session` needs to be closed.

In this example, the Activity supplies the name in the URL and retrieves
the greeting from the body of the response.

```python
import aiohttp
import urllib.parse
from temporalio import activity

class TranslateActivities:
    def __init__(self, session: aiohttp.ClientSession):
        self.session = session

    @activity.defn
    async def greet_in_spanish(self, name: str) -> str:
        greeting = await self.call_service("get-spanish-greeting", name)
        return greeting

    # Utility method for making calls to the microservices
    async def call_service(self, stem: str, name: str) -> str:
        base = f"http://localhost:9999/{stem}"
        url = f"{base}?name={urllib.parse.quote(name)}"

        async with self.session.get(url) as response:
            translation = await response.text()

            if response.status >= 400:
                raise ApplicationError(
                    f"HTTP Error {response.status}: {translation}",
                    # We want to have Temporal automatically retry 5xx but not 4xx
                    non_retryable=response.status < 500,
                )

            return translation
```

## Implementing Synchronous Activities

The following code is an implementation of the above Activity, but as a
synchronous Activity Definition. When making the call to the microservice,
you'll notice that it uses the `requests` library. This is safe to do in
synchronous Activities.

```python
import urllib.parse
import requests
from temporalio import activity

class TranslateActivities:

    @activity.defn
    def greet_in_spanish(self, name: str) -> str:
        greeting = self.call_service("get-spanish-greeting", name)
        return greeting

    # Utility method for making calls to the microservices
    def call_service(self, stem: str, name: str) -> str:
        base = f"http://localhost:9999/{stem}"
        url = f"{base}?name={urllib.parse.quote(name)}"

        response = requests.get(url)
        return response.text
```

In the above example we chose not to share a session across the Activity, so
`__init__` was removed. While `requests` does have the ability to create sessions,
it is currently unknown if they are thread safe. Due to no longer having or needing
`__ini__`, the case could be made here to not implement the Activities as a class,
but just as decorated functions as shown below:

```python
@activity.defn
def greet_in_spanish(name: str) -> str:
    greeting = call_service("get-spanish-greeting", name)
    return greeting

# Utility method for making calls to the microservices
def call_service(stem: str, name: str) -> str:
    base = f"http://localhost:9999/{stem}"
    url = f"{base}?name={urllib.parse.quote(name)}"

    response = requests.get(url)
    return response.text
```

Whether to implement Activities as class methods or functions is a design choice
choice left up to the developer when cross-activity state is not needed. Both are
equally valid implementations.

## When Should You Use Async Activities

Asynchronous Activities have many advantages, such as potential speed up of execution.
However, as discussed above, making unsafe calls within the async event loop
can cause sporadic and difficult to diagnose bugs. For this reason, we recommend
using asynchronous Activities _only_ when you are certain that your Activities
are async safe and don't make blocking calls.

If you experience bugs that you think may be a result of an unsafe call being made in an asynchronous Activity, convert it to a synchronous Activity and see if the issue resolves.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/detecting-workflow-failures.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/detecting-workflow-failures.mdx</path>
  <content>
---
id: detecting-workflow-failures
title: Detecting Workflows failures
sidebar_label: Workflows
description: Learn about Workflow Execution Timeout, Workflow Run Timeout, and Workflow Task Timeout in Temporal. Maximize Workflow efficiency and manage durations effectively.
toc_max_heading_level: 4
keywords:
  - workflows
  - failures
  - timeouts
tags:
  - Concepts
  - Workflows
  - Failures
  - Timeouts
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal can detect different kinds of Workflow Execution failures through the following timeouts:

- [Workflow Execution Timeout](#workflow-execution-timeout)
- [Workflow Run Timeout](#workflow-run-timeout)
- [Workflow Task Timeout](#workflow-task-timeout)

## Workflow Execution Timeout? {#workflow-execution-timeout}

**What is a Workflow Execution Timeout in Temporal?**

A Workflow Execution Timeout is the maximum time that a Workflow Execution can be executing (have an Open status) including retries and any usage of Continue As New.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<PrettyImage src="/diagrams/workflow-execution-timeout.svg" title="Workflow Execution Timeout period" />

**The default value is ∞ (infinite).**
If this timeout is reached, the Workflow Execution changes to a Timed Out status.
This timeout is different from the [Workflow Run Timeout](#workflow-run-timeout).
This timeout is most commonly used for stopping the execution of a [Temporal Cron Job](/workflows#temporal-cron-job) after a certain amount of time has passed.

## Workflow Run Timeout? {#workflow-run-timeout}

**What is a Workflow Run Timeout in Temporal?**

A Workflow Run Timeout is the maximum amount of time that a single Workflow Run is restricted to.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<PrettyImage src="/diagrams/workflow-run-timeout.svg" title="Workflow Run Timeout period" />

**The default is set to the same value as the [Workflow Execution Timeout](#workflow-execution-timeout).**
This timeout is most commonly used to limit the execution time of a single [Temporal Cron Job Execution](/workflows#temporal-cron-job).

If the Workflow Run Timeout is reached, the Workflow Execution will be Timed Out.

## Workflow Task Timeout? {#workflow-task-timeout}

**What is a Workflow Task Timeout in Temporal?**

A Workflow Task Timeout is the maximum amount of time allowed for a [Worker](/workers#worker) to execute a [Workflow Task](/tasks#workflow-task) after the Worker has pulled that Workflow Task from the [Task Queue](/task-queue).

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<PrettyImage src="/diagrams/workflow-task-timeout.svg" title="Workflow Task Timeout period" />

**The default value is 10 seconds.**
This timeout is primarily available to recognize whether a Worker has gone down so that the Workflow Execution can be recovered on a different Worker.
The main reason for increasing the default value is to accommodate a Workflow Execution that has an extensive Workflow Execution History, requiring more than 10 seconds for the Worker to load.
It's worth mentioning that although you can extend the timeout up to the maximum value of 120 seconds, it's not recommended to move beyond the default value.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/index.mdx</path>
  <content>
---
id: index
title: Python SDK developer guide
sidebar_label: Python SDK
description: Explore Temporal's Python SDK feature guides to effortlessly develop, test, and manage Temporal Applications. Master Workflows, Activities, Workers, Failure Detection, and more!
toc_max_heading_level: 4
keywords:
  - Python SDK
tags:
  - Python SDK
  - Temporal SDKs
---

![Python SDK Banner](/img/assets/banner-python-temporal.png)

:::info PYTHON SPECIFIC RESOURCES
Build Temporal Applications with the Python SDK.

**Temporal Python Technical Resources:**

- [Python API Documentation](https://python.temporal.io)
- [Python SDK Code Samples](https://github.com/temporalio/samples-python)
- [Python SDK Github](https://github.com/temporalio/sdk-python)

**Get Connected with the Temporal Python Community:**

- [Temporal Python Community Slack](https://app.slack.com/client/TNWA8QCGZ)
- [Python SDK Forum](https://community.temporal.io/tag/python-sdk)
  :::

## [Core Application](/develop/python/core-application)

Use the essential components of a Temporal Application (Workflows, Activities, and Workers) to build and run a Temporal application.

- [Develop a Basic Workflow](/develop/python/core-application#develop-workflows)
- [Develop a Basic Activity](/develop/python/core-application#develop-activities)
- [Start an Activity Execution](/develop/python/core-application#activity-execution)
- [Run Worker Processes](/develop/python/core-application#run-a-dev-worker)

## [Temporal Client](/develop/python/temporal-clients)

Connect to a Temporal Service and start a Workflow Execution.

- [Connect to Development Temporal Service](/develop/python/temporal-clients#connect-to-development-service)
- [Connect a Temporal Client to a Temporal Service](/develop/python/temporal-clients#connect-to-a-dev-cluster)
- [Connect to Temporal Cloud](/develop/python/temporal-clients#connect-to-temporal-cloud)
- [Start a Workflow Execution](/develop/python/temporal-clients#start-workflow-execution)

## [Python SDK Sandbox](/develop/python/python-sdk-sandbox)

Use third-party Python modules without non-deterministic behavior.

## [Python SDK sync vs. async implementations](/develop/python/python-sdk-sync-vs-async)

Implement synchronous or asynchronous Activities.

## [Testing](/develop/python/testing-suite)

Set up the testing suite and test Workflows and Activities.

- [Test Frameworks](/develop/python/testing-suite#test-frameworks)
- [Testing Activities](/develop/python/testing-suite#test-activities)
- [Testing Workflows](/develop/python/testing-suite#test-workflows)
- [How to Replay a Workflow Execution](/develop/python/testing-suite#replay)

## [Failure detection](/develop/python/failure-detection)

Explore how your application can detect failures using timeouts and automatically attempt to mitigate them with retries.

- [Workflow Timeouts](/develop/python/failure-detection#workflow-timeouts)
- [Set Activity Timeouts](/develop/python/failure-detection#activity-timeouts)
- [Heartbeat an Activity](/develop/python/failure-detection#activity-heartbeats)

## [Workflow message passing](/develop/python/message-passing)

Send messages to and read the state of Workflow Executions.

- [Develop with Signals](/develop/python/message-passing#signals)
- [Develop with Queries](/develop/python/message-passing#queries)
- [Develop with Updates](/develop/python/message-passing#updates)
- [What is a Dynamic Handler](/develop/python/message-passing#dynamic-handler)

## [Interrupt a Workflow feature guide](/develop/python/cancellation)

Interrupt a Workflow Execution with a Cancel or Terminate action.

- [Cancel a Workflow](/develop/python/cancellation#cancellation)
- [Terminate a Workflow](/develop/python/cancellation#termination)
- [Cancel an Activity from a Workflow](/develop/python/cancellation#cancel-activity)

## [Asynchronous Activity completion](/develop/python/asynchronous-activity-completion)

Complete Activities asynchronously.

- [Asynchronously Complete an Activity](/develop/python/asynchronous-activity-completion)

## [Versioning](/develop/python/versioning)

Change Workflow Definitions without causing non-deterministic behavior in running Workflows.

- [Introduction to Versioning](/develop/python/versioning#introduction-to-versioning)
- [How to Use the Patching API](/develop/python/versioning#python-sdk-patching-api)
- [How to Use Worker Versioning](/develop/python/versioning#worker-versioning)

## [Observability](/develop/python/observability)

Configure and use the Temporal Observability APIs.

- [Emit Metrics](/develop/python/observability#metrics)
- [Set up tracing](/develop/python/observability#tracing)
- [Log from a Workflow](/develop/python/observability#logging)
- [Use Visibility APIs](/develop/python/observability#visibility)

## [Debugging](/develop/python/debugging)

Explore various ways to debug your application.

- [Debugging](/develop/python/debugging)

## [Schedules](/develop/python/schedules)

Run Workflows on a schedule and delay the start of a Workflow.

- [Schedule a Workflow](/develop/python/schedules#schedule-a-workflow)
- [Temporal Cron Jobs](/develop/python/schedules#temporal-cron-jobs)
- [Start Delay](/develop/python/schedules#start-delay)

## [Data encryption](/develop/python/converters-and-encryption)

Use compression, encryption, and other data handling by implementing custom converters and codecs.

- [Custom Payload Codec](/develop/python/converters-and-encryption#custom-payload-codec)
- [Payload Conversion](/develop/python/converters-and-encryption#payload-conversion)

## [Durable Timers](/develop/python/timers)

Use Timers to make a Workflow Execution pause or "sleep" for seconds, minutes, days, months, or years.

- [Sleep](/develop/python/timers)

## [Child Workflows](/develop/python/child-workflows)

Explore how to spawn a Child Workflow Execution and handle Child Workflow Events.

- [Start a Child Workflow Execution](/develop/python/child-workflows)

## [Continue-As-New](/develop/python/continue-as-new)

Continue the Workflow Execution with a new Workflow Execution using the same Workflow ID.

- [Continue-As-New](/develop/python/continue-as-new)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/failures.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/failures.mdx</path>
  <content>
---
id: failures
title: Temporal Failures reference
sidebar_label: Failures
description: A Failure in Temporal represents different types of errors in the system, categorized and managed uniquely within SDKs and protobuf messages, impacting Workflow and Activity operations.
toc_max_heading_level: 4
keywords:
  - explanation
  - failure
  - term
tags:
  - Reference
  - Failures
  - Timeouts
---

A Failure is Temporal's representation of various types of errors that occur in the system.

There are different types of Failures, and each has a different type in the SDKs and different information in the protobuf messages (which are used to communicate with the Temporal Service and appear in [Event History](/workflows#event-history)).

## Temporal Failure

Most SDKs have a base class that the other Failures extend:

- TypeScript: [TemporalFailure](https://typescript.temporal.io/api/classes/common.TemporalFailure)
- Java: [TemporalFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TemporalFailure.html)
- Python: [FailureError](https://python.temporal.io/temporalio.exceptions.FailureError.html)
- PHP: [TemporalFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TemporalFailure.html)

The base [Failure proto message](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure) has these fields:

- `string message`
- `string stack_trace`
- `string source`: The SDK this Failure originated in (for example, `"TypeScriptSDK"`). In some SDKs, this field is used to rehydrate the call stack into an exception object.
- `Failure cause`: The `Failure` message of the cause of this Failure (if applicable).
- `Payload encoded_attributes`: Contains the encoded `message` and `stack_trace` fields when using a [Failure Converter](/failure-converter).

## Application Failure

Workflow, and Activity, and Nexus Operation code use Application Failures to communicate application-specific failures that happen.
This is the only type of Temporal Failure created and thrown by user code.

- TypeScript: [ApplicationFailure](https://typescript.temporal.io/api/classes/common.ApplicationFailure)
- Java: [ApplicationFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ApplicationFailure.html)
- Go: [ApplicationError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ApplicationError)
- Python: [ApplicationError](https://python.temporal.io/temporalio.exceptions.ApplicationError.html)
- PHP: [ApplicationFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ApplicationFailure.html)
- Proto: [ApplicationFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ApplicationFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

### Errors in Workflows

An error in a Workflow can cause either a **Workflow Task Failure** (the Task will be retried) or a **Workflow Execution Failure** (the Workflow is marked as failed).

Only Workflow exceptions that are Temporal Failures cause the Workflow Execution to fail; all other exceptions cause the Workflow Task to fail and be retried (in Go, any error returned from the Workflow fails the Workflow Execution, and a panic fails the Workflow Task).
Most types of Temporal Failures are raised by the Temporal Service, like a [Cancelled Failure](#cancelled-failure) when the Workflow is Cancelled or an [Activity Failure](#activity-failure) when an Activity fails.
In contrast, you can explicitly fail the Workflow Execution by throwing an Application Failure (returning any error in Go) in Workflow Definition code.

#### Workflow Task Failures

A **Workflow Task Failure** is an unexpected situation failing to process a Workflow Task.
This could be triggered by a non-Temporal exception being raised (panicking in Go) in your Workflow code.
Any exception that does not extend Temporal's `FailureError` exception is considered a Workflow Task Failure.
These types of failures will cause the Workflow Task to be retried until the
Workflow Execution Timeout, which is unlimited by default.

#### Workflow Execution Failures

An `ApplicationError`, an extension of `FailureError`, can be raised in a Workflow to fail the Workflow Execution.
Workflow Execution Failures put the Workflow Execution into the "Failed" state and no more attempts will be made in progressing this execution.
If you are creating custom exceptions you would need to extend the [`ApplicationError`](https://docs.temporal.io/references/failures#application-failure) class—a child class of [`FailureError`](https://docs.temporal.io/references/failures#temporal-failure).

### Errors in Activities

In Activities, you can either throw an Application Failure or another Error to fail the Activity Task.
In the latter case, the error is converted to an Application Failure.
During conversion, the following Application Failure fields are set:

- `type` is set to the error's type name.
- `message` is set to the error message.
- `non_retryable` is set to false.
- `details` are left unset.
- `cause` is a Failure converted from the error's `cause` property.
- `next_retry_delay` is left unset.
- call stack is copied.

When an [Activity Execution](/activities#activity-execution) fails, the Application Failure from the last Activity Task is the `cause` field of the [ActivityFailure](#activity-failure).
This ActivityFailure is thrown by the Workflow's call to the Activity, and it can be handled in the Workflow Definition.

### Errors in Nexus Operations

Nexus Operations can end up in completed, failed, canceled, and timed out states.

Under the hood, the Nexus Operation machinery, breaks up the lifecycle of an Operation into one or more StartOperation requests and completion callbacks and automatically retries these requests as long they fail with retryable errors.

The Workflow-specified schedule-to-close timeout is enforced by the caller's machinery and the only way for an Operation to transition to the timed out state.

Operations can end up in the other three states either when a user handler returns a synchronous response or error, or when an asynchronous Operation (like one backed by a workflow) eventually reaches a terminal state.

A handler can return either retryable or non-retryable errors to indicate to the caller's Nexus machinery whether to retry a given request.
Requests that time out before a response is sent to the caller are automatically retried.

By default, errors are considered retryable, unless specified below:

- Non retryable Application Failures
- Unsuccessful Operation errors that can resolve an operation as either failed or canceled
- [Handler errors](https://github.com/nexus-rpc/api/blob/main/SPEC.md#predefined-handler-errors) with the following types: `BAD_REQUEST`, `UNAUTHENTICATED`, `UNAUTHORIZED`, `NOT_FOUND`, and `RESOURCE_EXHAUSTED`

#### Nexus Operation Task Failures

A Nexus Operation Task Failure is an unexpected situation failing to process a Nexus Operation Task in a handler.
This could be triggered by throwing an unknown error in your Nexus handler code.
These types of failures will cause the Nexus Operation Task to be retried.

#### Nexus Operation Execution Failures

A non-retryable Application Failure can be thrown by a Nexus Operation handler to fail the overall Nexus Operation Execution.
Nexus Operation Execution Failures put the Nexus Operation Execution into the "Failed" state and no more attempts will be made to complete the Nexus Operation.

#### Propagation of Workflow errors

Application Errors thrown from a Workflow created by a Nexus NewWorkflowRunOperation handler, will be automatically propagated to the caller as a non-retryable error and result in a Nexus Operation Execution Failure.

#### Using Failures in a Nexus handler

In a Nexus Operation handler, you can throw an Application Failure, a Nexus Error or another Error to fail the individual Nexus Operation Task or fail the overall Nexus Operation Execution.

Unknown errors are converted to a retryable Application Failure. During conversion, the following fields are set on the Application Failure:

- Non_retryable is set to false.
- Type is set to the error's type name.
- Message is set to the error message.

#### Retryable failures

Retryable Nexus Operation Task failures, like an unknown error, are automatically retried with a built-in Retry Policy.
When a Nexus Task fails, the caller Workflow records an event attempt failure on the pending Nexus Operation and sets the following fields:

- State is set to the new state, for example BackingOff.
- Attempt is set to an incremented count.
- Next_attempt_schedule_time is set when the Nexus Task will be retried.
- Last_attempt_failure is set with the following fields:
  - Message is set to the error message.
  - Failure_info is set to the Application Failure.

For example, an unknown error thrown in a Nexus handler will surface as:

```
temporal workflow describe -w my-workflow-id
...
Pending Nexus Operations: 1

  Endpoint                 myendpoint
  Service                  my-hello-service
  Operation                echo
  OperationToken
  State                    BackingOff
  Attempt                  6
  ScheduleToCloseTimeout   0s
  NextAttemptScheduleTime  20 seconds from now
  LastAttemptCompleteTime  11 seconds ago
  LastAttemptFailure       {"message":"unexpected response status: "500 Internal Server Error": internal error","applicationFailureInfo":{}}
```

### Non-retryable

When an Activity or Workflow throws an Application Failure, the Failure's `type` field is matched against a Retry Policy's list of [non-retryable errors](/encyclopedia/retry-policies#non-retryable-errors) to determine whether to retry the Activity or Workflow.
Activities and Workflow can also avoid retrying by setting an Application Failure's `non_retryable` flag to `true`.

When a Nexus Operation handler throws an Application Failure, it is retried by default using a built-in Retry Policy that cannot be customized.
Nexus Operation handlers can avoid retrying by setting an Application Failure's non_retryable flag to true.
When a non-retryable error is returned from a Nexus handler, the overall Nexus Operation Execution is failed and the error is returned to the caller’s Workflow Execution as a Nexus Operation Failure.

### Setting the Next Retry Delay {#activity-next-retry-delay}

By setting the Next Retry Delay for a given Application Failure, you can tell the server to wait that amount of time before trying the Activity or Workflow again.
This will override whatever the Retry Policy would have computed for your specific exception.

Java: [NextRetryDelay](/develop/java/failure-detection#activity-next-retry-delay)
TypeScript: [nextRetryDelay](/develop/typescript/failure-detection#activity-next-retry-delay)
PHP: [NextRetryDelay](/develop/php/failure-detection#activity-next-retry-delay)

### Nexus errors {#nexus-errors}

#### Default mapping

By default, Application Failures thrown from a Nexus Operation handler will be mapped to the following underlying Nexus Failures, based on what non_retryable is set to:

| non_retryable   | Nexus error                | HTTP status code          |
| :-------------- | :------------------------- | :------------------------ |
| false (default) | HandlerErrorTypeInternal   | 500 Internal Server Error |
| true            | UnsuccessfulOperationError | 424 Failed Dependency     |

#### Use Nexus Errors directly

For improved semantics and mapping to HTTP status codes for external Nexus callers (when supported), we recommend that Nexus Operation handlers throw a Nexus Error directly, which includes the list below with associated retry semantics.

For example the Nexus Go SDK provides

- `nexus.HandlerError(nexus.HandlerErrorType, msg)`
- `nexus.UnsuccessfulOperationError{state, failure}`

#### Retryable Nexus errors

| Nexus error type                  | non_retryable |
| :-------------------------------- | :------------ |
| HandlerErrorTypeResourceExhausted | false         |
| HandlerErrorTypeInternal          | false         |
| HandlerErrorTypeNotImplemented    | false         |
| HandlerErrorTypeUnavailable       | false         |

#### Non-retryable Nexus errors

| Nexus error type                | non_retryable |
| :------------------------------ | :------------ |
| HandlerErrorTypeBadRequest      | true          |
| HandlerErrorTypeUnauthenticated | true          |
| HandlerErrorTypeUnauthorized    | true          |
| HandlerErrorTypeNotFound        | true          |
| UnsuccessfulOperationError      | true          |

## Cancelled Failure

When [Cancellation](/activities#cancellation) of a Workflow, Activity or Nexus Operation is requested, SDKs represent the cancellation to the user in language-specific ways.
For example, in TypeScript, in some cases a Cancelled Failure is thrown directly by a Workflow API function, and in other cases the Cancelled Failure is wrapped in a different Failure.
To check both types of cases, TypeScript has the [isCancellation](https://typescript.temporal.io/api/namespaces/workflow#iscancellation) helper.

When a Workflow, Activity or Nexus Operation is successfully Cancelled, a Cancelled Failure is the `cause` field of the Activity Failure, Nexus Operation Failure or "Workflow failed" error.

- TypeScript: [CancelledFailure](https://typescript.temporal.io/api/classes/common.CancelledFailure)
- Java: [CanceledFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/CanceledFailure.html)
- Go: [CanceledError](https://pkg.go.dev/go.temporal.io/sdk/temporal#CanceledError)
- Python: [CancelledError](https://python.temporal.io/temporalio.exceptions.CancelledError.html)
- PHP: [CanceledFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-CanceledFailure.html)
- Proto: [CanceledFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.CanceledFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Activity Failure

An Activity Failure is delivered to the Workflow Execution when an Activity fails.
It contains information about the failure and the Activity Execution; for example, the Activity Type and Activity Id.
The reason for the failure is in the `cause` field.
For example, if an Activity Execution times out, the `cause` is a [Timeout Failure](#timeout-failure).

- TypeScript: [ActivityFailure](https://typescript.temporal.io/api/classes/common.ActivityFailure)
- Java: [ActivityFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ActivityFailure.html)
- Go: [ActivityError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ActivityError)
- Python: [ActivityError](https://python.temporal.io/temporalio.exceptions.ActivityError.html)
- PHP: [ActivityFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ActivityFailure.html)
- Proto: [ActivityFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ActivityFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Nexus Operation Failure

A Nexus Operation Failure is delivered to the Workflow Execution when a Nexus Operation fails.
It contains information about the failure and the Nexus Operation Execution; for example, the Nexus Operation name and Nexus Operation token.
The reason for the failure is in the message and cause (typically an Application Error or a Canceled Error).

- Go: NexusOperationError
- Proto: NexusOperationFailureInfo

A Nexus Operation Failure includes the following fields:

- Endpoint is set to the name of the endpoint.
- Service is set to the name of the service.
- Operation is set to the name of the operation.
- Operation_id is set to the id of the operation, if this is an async operation.
- Scheduled_event_id is set to the caller’s event id that scheduled the operation.
- Message is set to a generic unsuccessful error message.
- Cause is set to the underlying Application Failure with the following fields:
  - Non-retryable is set to true.
  - Type is set to the error's type name.
  - Message is set to the error message.
- Nexus_error_code is set the the underlying Nexus error code.

## Child Workflow Failure

A Child Workflow Failure is delivered to the Workflow Execution when a Child Workflow Execution fails.
It contains information about the failure and the Child Workflow Execution; for example, the Workflow Type and Workflow Id.
The reason for the failure is in the `cause` field.

- TypeScript: [ChildWorkflowFailure](https://typescript.temporal.io/api/classes/common.ChildWorkflowFailure)
- Java: [ChildWorkflowFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ChildWorkflowFailure.html)
- Go: [ChildWorkflowExecutionError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ChildWorkflowExecutionError)
- Python: [ChildWorkflowError](https://python.temporal.io/temporalio.exceptions.ChildWorkflowError.html)
- PHP: [ChildWorkflowFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ChildWorkflowFailure.html)
- Proto: [ChildWorkflowExecutionFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ChildWorkflowExecutionFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Timeout Failure

A Timeout Failure represents the timeout of an Activity or Workflow.

When an Activity times out, the last Heartbeat details it emitted is attached.

- TypeScript: [TimeoutFailure](https://typescript.temporal.io/api/classes/common.TimeoutFailure)
- Java: [TimeoutFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TimeoutFailure.html)
- Go: [TimeoutError](https://pkg.go.dev/go.temporal.io/sdk/temporal#TimeoutError)
- Python: [TimeoutError](https://python.temporal.io/temporalio.exceptions.TimeoutError.html)
- PHP: [TimeoutFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TimeoutFailure.html)
- Proto: [TimeoutFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.TimeoutFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Terminated Failure

A Terminated Failure is used as the `cause` of an error when a Workflow is terminated, and you receive the error in one of the following locations:

- Inside a Workflow that's waiting for the result of a Child Workflow.
- When waiting for the result of a Workflow on the Client.

In the SDKs:

- TypeScript: [TerminatedFailure](https://typescript.temporal.io/api/classes/common.TerminatedFailure)
- Java: [TerminatedFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TerminatedFailure.html)
- Go: [TerminatedError](https://pkg.go.dev/go.temporal.io/sdk/temporal#TerminatedError)
- Python: [TerminatedError](https://python.temporal.io/temporalio.exceptions.TerminatedError.html)
- PHP: [TerminatedFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TerminatedFailure.html)
- Proto: [TerminatedFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.TerminatedFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Server Failure

A Server Failure is used for errors that originate in the Temporal Service.

- TypeScript: [ServerFailure](https://typescript.temporal.io/api/classes/common.ServerFailure)
- Java: [ServerFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ServerFailure.html)
- Go: [ServerError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ServerError)
- Python: [ServerError](https://python.temporal.io/temporalio.exceptions.ServerError.html)
- PHP: [ServerFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ServerFailure.html)
- Proto: [ServerFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ServerFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/clusters.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/clusters.mdx</path>
  <content>
---
id: clusters
title: What is a Temporal Service?
sidebar_label: Temporal Service
description: This page provides a comprehensive technical overview of a Temporal Service, detailing its components and subsystems, including the Temporal Server, Frontend Service, History Service, Matching Service, and Worker Service.
slug: /clusters
toc_max_heading_level: 4
keywords:
  - temporal-service
tags:
  - Concepts
  - Temporal Service
---

:::info
Please note an important update in our terminology.

We now refer to the Temporal Cluster as the Temporal Service.
:::

This page provides a comprehensive technical overview of a Temporal Service.

A Temporal Service is the group of services, known as the [Temporal Server](#temporal-server), combined with [Persistence](#persistence) and [Visibility](#visibility) stores, that together act as a component of the Temporal Platform.

See the Self-hosted Temporal Service [production deployment guide](/self-hosted-guide) for implementation guidance.

![A Temporal Service (Server + persistence)](/diagrams/temporal-cluster.svg)

## What is the Temporal Server? {#temporal-server}

The Temporal Server consists of four independently scalable services:

- Frontend gateway: for rate limiting, routing, authorizing.
- History subsystem: maintains data (mutable state, queues, and timers).
- Matching subsystem: hosts Task Queues for dispatching.
- Worker Service: for internal background Workflows.

For example, a real-life production deployment can have 5 Frontend, 15 History, 17 Matching, and 3 Worker Services per Temporal Service.

The Temporal Server services can run independently or be grouped together into shared processes on one or more physical or virtual machines.
For live (production) environments, we recommend that each service runs independently, because each one has different scaling requirements and troubleshooting becomes easier.
The History, Matching, and Worker Services can scale horizontally within a Temporal Service.
The Frontend Service scales differently than the others because it has no sharding or partitioning; it is just stateless.

Each service is aware of the others, including scaled instances, through a membership protocol via [Ringpop](https://github.com/temporalio/ringpop-go).

#### Versions and support

All Temporal Server releases abide by the [Semantic Versioning Specification](https://semver.org/).

We support upgrade paths from every version beginning with Temporal v1.7.0.
For details on upgrading your Temporal Service, see [Upgrade Server](/self-hosted-guide/upgrade-server#upgrade-server).

We provide maintenance support for previously published minor and major versions by continuing to release critical bug fixes related to security, the prevention of data loss, and reliability, whenever they are found.

We aim to publish incremental upgrade guides for each minor and major version, which include specifics about dependency upgrades that we have tested for (such as Cassandra 3.0 -> 3.11).

We offer maintenance support of the last three **minor** versions after a release and do not plan to "backport" patches beyond that.

We offer maintenance support of **major** versions for at least 12 months after a GA release, and we provide at least 6 months' notice before EOL/deprecating support.

**Dependencies**

Temporal offers official support for, and is tested against, dependencies with the exact versions described in the `go.mod` file of the corresponding release tag.
(For example, [v1.5.1](https://github.com/temporalio/temporal/tree/v1.5.1) dependencies are documented in [the go.mod for v1.5.1](https://github.com/temporalio/temporal/blob/v1.5.1/go.mod).)

### What is a Frontend Service? {#frontend-service}

The Frontend Service is a stateless gateway service that exposes a strongly typed [Proto API](https://github.com/temporalio/api/blob/master/temporal/api/workflowservice/v1/service.proto).
The Frontend Service is responsible for rate limiting, authorizing, validating, and routing all inbound calls.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Frontend Service</p>
  </div>
  <div className="tdiiw" height="1040">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-frontend-service.svg"
      alt="Frontend Service"
    />
  </div>
</div>

Types of inbound calls include the following:

- [Namespace](/namespaces) CRUD
- External events
- Worker polls
- [Visibility](#visibility) requests
- [Temporal CLI](/cli) (the Temporal CLI) operations
- Calls from a remote Temporal Service related to [Multi-Cluster Replication](#multi-cluster-replication)

Every inbound request related to a Workflow Execution must have a Workflow Id, which is hashed for routing purposes.
The Frontend Service has access to the hash rings that maintain service membership information, including how many nodes (instances of each service) are in the Temporal Service.

Inbound call rate limiting is applied per host and per namespace.

The Frontend Service talks to the Matching Service, History Service, Worker Service, the database, and Elasticsearch (if in use).

- It uses the grpcPort 7233 to host the service handler.
- It uses port 6933 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

### What is a History Service? {#history-service}

The History Service is responsible for persisting Workflow Execution state to the Workflow History.
When the Workflow Execution is able to progress, the History Service adds a Task with the Workflow's updated history to the Task Queue.
From there, a Worker can poll for work, receive this updated history, and resume execution.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">
      Block diagram of how the History Service relates to the other services of
      the Temporal Server and to the Temporal Service
    </p>
  </div>
  <div className="tdiiw" height="1040">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-history-service.svg"
      alt="Block diagram of how the History Service relates to the other services of the Temporal Server and to a Temporal Service"
    />
  </div>
</div>

The total number of History Service processes can be between 1 and the total number of [History Shards](#history-shard).
An individual History Service can support many History Shards.
Temporal recommends starting at a ratio of 1 History Service process for every 500 History Shards.

Although the total number of History Shards remains static for the life of the Temporal Service, the number of History Service processes can change.

The History Service talks to the Matching Service and the database.

- It uses grpcPort 7234 to host the service handler.
- It uses port 6934 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

#### What is a History Shard? {#history-shard}

A History Shard is an important unit within a Temporal Service by which concurrent Workflow Execution throughput can be scaled.

Each History Shard maps to a single persistence partition.
A History Shard assumes that only one concurrent operation can be within a partition at a time.
In essence, the number of History Shards represents the number of concurrent database operations that can occur for a Temporal Service.
This means that the number of History Shards in a Temporal Service plays a significant role in the performance of your Temporal Application.

Before integrating a database, the total number of History Shards for the Temporal Service must be chosen and set in the Temporal Service's configuration (see [persistence](/references/configuration#persistence)).
After the Shard count is configured and the database integrated, the total number of History Shards for the Temporal Service cannot be changed.

In theory, a Temporal Service can operate with an unlimited number of History Shards, but each History Shard adds compute overhead to the Temporal Service.
The Temporal Service has operated successfully using anywhere from 1 to 128K History Shards, with each Shard responsible for tens of thousands of Workflow Executions.
One Shard is useful only in small scale setups designed for testing, while 128k Shards is useful only in very large scale production environments.
The correct number of History Shards for any given Temporal Service depends entirely on the Temporal Application that it is supporting and the type of database.

A History Shard is represented as a hashed integer.
Each Workflow Execution is automatically assigned to a History Shard.
The assignment algorithm hashes Workflow Execution metadata such as Workflow Id and Namespace and uses that value to match a History Shard.

Each History Shard maintains the Workflow Execution Event History, Workflow Execution mutable state, and the following internal Task Queues:

- Internal Transfer Task Queue: Transfers internal tasks to the Matching Service.
  Whenever a new Workflow Task needs to be scheduled, the History Service's Transfer Task Queue Processor transactionally dispatches it to the Matching Service.
- Internal Timer Task Queue: Durably persists Timers.
- Internal Replicator Task Queue: Asynchronously replicates Workflow Executions from active Clusters to other passive Clusters.
  (Relies on the experimental Multi-Cluster feature.)
- Internal Visibility Task Queue: Pushes data to the [Advanced Visibility](/visibility#advanced-visibility) index.

### What is a Matching Service? {#matching-service}

The Matching Service is responsible for hosting user-facing [Task Queues](/task-queue) for Task dispatching.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Matching Service</p>
  </div>
  <div className="tdiiw" height="980">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-matching-service.svg"
      alt="Matching Service"
    />
  </div>
</div>

It is responsible for matching Workers to Tasks and routing new Tasks to the appropriate queue.
This service can scale internally by having multiple instances.

It talks to the Frontend Service, History Service, and the database.

- It uses grpcPort 7235 to host the service handler.
- It uses port 6935 for membership related communication.

Ports are configurable in the Temporal Service configuration.

### What is a Worker Service? {#worker-service}

The Worker Service runs background processing for the replication queue, system Workflows, and (in versions older than 1.5.0) the Kafka visibility processor.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Worker Service</p>
  </div>
  <div className="tdiiw" height="740">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-worker-service.svg"
      alt="Worker Service"
    />
  </div>
</div>

It talks to the Frontend Service.

- It uses port 6939 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

### What is a Retention Period? {#retention-period}

Retention Period is the duration for which the Temporal Service stores data associated with closed Workflow Executions on a Namespace in the Persistence store.

- [How to set the Retention Period for a Namespace](/cli/operator#create)
- [How to set the Retention Period for a Namespace using the Go SDK](/develop/go/namespaces)
- [How to set the Retention Period for a Namespace using the Java SDK](/develop/java/namespaces)

A Retention Period applies to all closed Workflow Executions within a [Namespace](/namespaces) and is set when the Namespace is registered.

The Temporal Service triggers a Timer task at the end of the Retention Period that cleans up the data associated with the closed Workflow Execution on that Namespace.

The minimum Retention Period is 1 day.
On Temporal Service version 1.18 and later, the maximum Retention Period value for Namespaces can be set to anything over the minimum requirement of 1 day. Ensure that your Persistence store has enough capacity for the storage.
On Temporal Service versions 1.17 and earlier, the maximum Retention Period you can set is 30 days.
Setting the Retention Period to 0 results in the error _A valid retention period is not set on request_.

If you don't set the Retention Period value when using the [`temporal operator namespace create`](/cli/operator#create) command, it defaults to 3 days.
If you don't set the Retention Period value when using the Register Namespace Request API, it returns an error.

When changing the Retention Period, the new duration applies to Workflow Executions that close after the change is saved.

{/* TODO link up to working API usage examples */}

## What is Persistence? {#persistence}

The Temporal Persistence store is a database used by the [Temporal Server](#temporal-server) to persist events generated and processed in your Temporal Service and SDK.

A Temporal Service's only required dependency for basic operation is the Persistence database.
Multiple types of databases are supported.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Persistence</p>
  </div>
  <div className="tdiiw" height="620">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-database.svg"
      alt="Persistence"
    />
  </div>
</div>

The database stores the following types of data:

- Tasks: Tasks to be dispatched.
- State of Workflow Executions:
  - Execution table: A capture of the mutable state of Workflow Executions.
  - History table: An append-only log of Workflow Execution History Events.
- Namespace metadata: Metadata of each Namespace in the Temporal Service.
- [Visibility](#visibility) data: Enables operations like "show all running Workflow Executions".
  For production environments, we recommend using Elasticsearch as your Visibility store.

An Elasticsearch database must be configured in a self-hosted Temporal Service to enable [advanced Visibility](/visibility#advanced-visibility) on Temporal Server versions 1.19.1 and earlier.

With Temporal Server version 1.20 and later, advanced Visibility features are available on SQL databases like MySQL (version 8.0.17 and later), PostgreSQL (version 12 and later), SQLite (v3.31.0 and later), and Elasticsearch.

#### Dependency versions

Temporal tests compatibility by spanning the minimum and maximum stable major versions for each supported database.
The following versions are used in our test pipelines and actively tested before we release any version of Temporal:

- **Cassandra v3.11 and v4.0**
- **PostgreSQL v10.18 and v13.4**
- **MySQL v5.7 and v8.0** (specifically 8.0.19+ due to a bug)

You can verify supported databases in the [Temporal Server release notes](https://github.com/temporalio/temporal/releases).

- Because Temporal Server primarily relies on core database functionality, we do not expect compatibility to break often.
  {/* Temporal has no opinions on database upgrade paths; as long as you can upgrade your database according to each project's specifications, Temporal should work with any version within supported ranges. */}
- We do not run tests with vendors like Vitess and CockroachDB.
- Temporal also supports SQLite v3.x persistence, but this is meant only for development and testing, not production usage.

## What is Visibility? {#visibility}

:::tip Support, stability, and dependency info

- For Temporal Server v1.19 and earlier, all supported databases for Visibility provide standard Visibility features, and an Elasticsearch database is required for advanced Visibility features.
- For Temporal Server v1.20 and later, advanced Visibility features are enabled on all supported SQL databases, in addition to Elasticsearch.
- In Temporal Server v1.21 and later, standard Visibility is no longer in development, and we recommend migrating to a [database that supports Advanced Visibility features](/self-hosted-guide/visibility). The Visibility configuration for the Temporal Service has been updated and Dual Visibility is enabled. For details, see [Visibility store setup](/self-hosted-guide/visibility).

:::

The term [Visibility](/visibility), within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view, filter, and search for Workflow Executions that currently exist within a Temporal Service.

The [Visibility store](/self-hosted-guide/visibility) in your Temporal Service stores persisted Workflow Execution Event History data and is set up as a part of your [Persistence store](#persistence) to enable listing and filtering details about Workflow Executions that exist on your Temporal Service.

- [How to set up a Visibility store](/self-hosted-guide/visibility)

With Temporal Server v1.21, you can set up [Dual Visibility](/dual-visibility) to migrate your Visibility store from one database to another.

Support for separate standard and advanced Visibility setups will be deprecated from Temporal Server v1.21 onwards. Check [Supported databases](/self-hosted-guide/visibility) for updates. \*/}

## What is Archival? {#archival}

Archival is a feature that automatically backs up [Event Histories](/workflows#event-history) and Visibility records from Temporal Service persistence to a custom blob store.

- [How to create a custom Archiver](/self-hosted-guide/archival#custom-archiver)
- [How to set up Archival](/self-hosted-guide/archival#set-up-archival)

Workflow Execution Event Histories are backed up after the [Retention Period](#retention-period) is reached.
Visibility records are backed up immediately after a Workflow Execution reaches a Closed status.

Archival enables Workflow Execution data to persist as long as needed, while not overwhelming the Temporal Service's persistence store.

This feature is helpful for compliance and debugging.

Temporal's Archival feature is considered **experimental** and not subject to normal [versioning and support policy](/clusters#versions-and-support).

Archival is not supported when running Temporal through Docker.
It's disabled by default when installing the system manually and when deploying through [helm charts](https://github.com/temporalio/helm-charts/blob/main/charts/temporal/templates/server-configmap.yaml).
It can be enabled in the [config](https://github.com/temporalio/temporal/blob/main/config/development.yaml).

## What is Temporal Service configuration? {#cluster-configuration}

Temporal Service configuration is the setup and configuration details of your self-hosted Temporal Service, defined using YAML.
You must define your Temporal Service configuration when setting up your self-hosted Temporal Service.

For details on using Temporal Cloud, see [Temporal Cloud documentation](/cloud).

Temporal Service configuration is composed of two types of configuration: [Static configuration](#static-configuration) and [Dynamic configuration](#dynamic-configuration).

### Static configuration

Static configuration contains details of how the Temporal Service should be set up.
The static configuration is read just once and used to configure service nodes at startup.
Depending on how you want to deploy your self-hosted Temporal Service, your static configuration must contain details for setting up:

- Temporal Services—Frontend, History, Matching, Worker
- Membership ports for the Temporal Services
- Persistence (including History Shard count), Visibility, Archival store setups.
- TLS, authentication, authorization
- Server log level
- Metrics
- Temporal Service metadata
- Dynamic config Client

Static configuration values cannot be changed at runtime.
Some values, such as the Metrics configuration or Server log level can be changed in the static configuration but require restarting the Temporal Service for the changes to take effect.

For details on static configuration keys, see [Temporal Service configuration reference](/references/configuration).

For static configuration examples, see [https://github.com/temporalio/temporal/tree/master/config](https://github.com/temporalio/temporal/tree/master/config).

### Dynamic configuration

Dynamic configuration contains configuration keys that you can update in your Temporal Service setup without having to restart the server processes.

All dynamic configuration keys provided by Temporal have default values that are used by the Temporal Service.
You can override the default values by setting different values for the keys in a YAML file and setting the [dynamic configuration client](/references/configuration#dynamicconfigclient) to poll this file for updates.
Setting dynamic configuration for your Temporal Service is optional.

Setting overrides for some configuration keys updates the Temporal Service configuration immediately.
However, for configuration fields that are checked at startup (such as thread pool size), you must restart the server for the changes to take effect.

Use dynamic configuration keys to fine-tune your self-deployed Temporal Service setup.

For details on dynamic configuration keys, see [Dynamic configuration reference](/references/dynamic-configuration).

For dynamic configuration examples, see [https://github.com/temporalio/temporal/tree/master/config/dynamicconfig](https://github.com/temporalio/temporal/tree/master/config/dynamicconfig).

### What is Temporal Service security configuration? {#temporal-cluster-security-configuration}

Secure your Temporal Service (self-hosted and Temporal Cloud) by encrypting your network communication and setting authentication and authorization protocols for API calls.

For details on setting up your Temporal Service security, see [Temporal Platform security features](/security).

#### mTLS encryption

Temporal supports Mutual Transport Layer Security (mTLS) to encrypt network traffic between services within a Temporal Service, or between application processes and a Temporal Service.

On the self-hosted Temporal Service, configure mTLS in the `tls` section of the [Temporal Service configuration](/references/configuration#tls).
mTLS configuration is a [static configuration](#static-configuration) property.

You can then use either the [`WithConfig`](/references/server-options#withconfig) or [`WithConfigLoader`](/references/server-options#withconfigloader) server option to start your Temporal Service with this configuration.

The mTLS configuration includes two sections that serve to separate communication within a Temporal Service and client calls made from your application to the Temporal Service.

- `internode`: configuration for encrypting communication between nodes within the Temporal Service.
- `frontend`: configuration for encrypting the public endpoints of the Frontend Service.

Setting mTLS for `internode` and `frontend` separately lets you use different certificates and settings to encrypt each section of traffic.

#### Using certificates for Client connections

Use CA certificates to authenticate client connections to your Temporal Service.

On Temporal Cloud, you can [set your CA certificates in your Temporal Cloud settings](/cloud/certificates) and use the end-entity certificates in your client calls.

On the self-hosted Temporal Service, you can restrict access to Temporal Service endpoints by using the `clientCAFiles` or `clientCAData` property and the [`requireClientAuth`](/references/configuration#tls) property in your Temporal Service configuration.
These properties can be specified in both the `internode` and `frontend` sections of the [mTLS configuration](/references/configuration#tls).
For details, see the [tls configuration reference](/references/configuration#tls).

#### Server name specification

On the self-hosted Temporal Service, you can specify `serverName` in the `client` section of your mTLS configuration to prevent spoofing and [MITM attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack).

Entering a value for `serverName` enables established connections to authenticate the endpoint.
This ensures that the server certificate presented to any connected client has the specified server name in its CN property.

This measure can be used for `internode` and `frontend` endpoints.

For more information on mTLS configuration, see [tls configuration reference](/references/configuration#tls).

#### Authentication and authorization

{/* commenting this very generic explanation out. Can include it back in if everyone feels strongly.
**Authentication** is the process of verifying users who want to access your application are actually the users you want accessing it.
**Authorization** is the verification of applications and data that a user on your Temporal Service or application has access to. */}

Temporal provides authentication interfaces that can be set to restrict access to your data.
These protocols address three areas: servers, client connections, and users.

Temporal offers two plugin interfaces for authentication and authorization of API calls.

- [`ClaimMapper`](/self-hosted-guide/security#claim-mapper)
- [`Authorizer`](/self-hosted-guide/security#authorizer-plugin)

The logic of both plugins can be customized to fit a variety of use cases.
When plugins are provided, the Frontend Service invokes their implementation before running the requested operation.

### What is Temporal Service observability? {#monitoring-and-observation}

You can monitor and observe performance with metrics emitted by your self-hosted Temporal Service or by Temporal Cloud.

Temporal emits metrics by default in a format that is supported by Prometheus.
Any metrics software that supports the same format can be used.
Currently, we test with the following Prometheus and Grafana versions:

- **Prometheus >= v2.0**
- **Grafana >= v2.5**

Temporal Cloud emits metrics through a Prometheus HTTP API endpoint, which can be directly used as a Prometheus data source in Grafana or to query and export Cloud metrics to any observability platform.

For details on Cloud metrics and setup, see the following:

- [Temporal Cloud metrics reference](/cloud/metrics/)
- [Set up Grafana with Temporal Cloud observability to view metrics](/cloud/metrics/prometheus-grafana#grafana-data-sources-configuration)

On the self-hosted Temporal Service, expose Prometheus endpoints in your Temporal Service configuration and configure Prometheus to scrape metrics from the endpoints.
You can then set up your observability platform (such as Grafana) to use Prometheus as a data source.

For details on self-hosted Temporal Service metrics and setup, see the following:

- [Temporal Service OSS metrics reference](/references/cluster-metrics)
- [Set up Prometheus and Grafana to view SDK and self-hosted Temporal Service metrics](/self-hosted-guide/monitoring)

## What is Multi-Cluster Replication? {#multi-cluster-replication}

Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.
When necessary, for higher availability, Cluster operators can failover to any of the backup Clusters.

Temporal's Multi-Cluster Replication feature is considered **experimental** and not subject to normal [versioning and support policy](/clusters).

Temporal automatically forwards Start, Signal, and Query requests to the active Cluster.
This feature must be enabled through a Dynamic Config flag per [Global Namespace](/global-namespace).

When the feature is enabled, Tasks are sent to the Parent Task Queue partition that matches that Namespace, if it exists.

All Visibility APIs can be used against active and standby Clusters.
This enables [Temporal UI](https://docs.temporal.io/web-ui) to work seamlessly for Global Namespaces.
Applications making API calls directly to the Temporal Visibility API continue to work even if a Global Namespace is in standby mode.
However, they might see a lag due to replication delay when querying the Workflow Execution state from a standby Cluster.

#### Namespace Versions

A _version_ is a concept in Multi-Cluster Replication that describes the chronological order of events per Namespace.

With Multi-Cluster Replication, all Namespace change events and Workflow Execution History events are replicated asynchronously for high throughput.
This means that data across clusters is **not** strongly consistent.
To guarantee that Namespace data and Workflow Execution data will achieve eventual consistency (especially when there is a data conflict during a failover), a **version** is introduced and attached to Namespaces.
All Workflow Execution History entries generated in a Namespace will also come with the version attached to that Namespace.

All participating Clusters are pre-configured with a unique initial version and a shared version increment:

- `initial version < shared version increment`

When performing failover for a Namespace from one Cluster to another Cluster, the version attached to the Namespace will be changed by the following rule:

- for all versions which follow `version % (shared version increment) == (active cluster's initial version)`, find the smallest version which has `version >= old version in namespace`

When there is a data conflict, a comparison will be made and Workflow Execution History entries with the highest version will be considered the source of truth.

When a cluster is trying to mutate a Workflow Execution History, the version will be checked.
A cluster can mutate a Workflow Execution History only if the following is true:

- The version in the Namespace belongs to this cluster, i.e.
  `(version in namespace) % (shared version increment) == (this cluster's initial version)`
- The version of this Workflow Execution History's last entry (event) is equal or less than the version in the Namespace, i.e.
  `(last event's version) <= (version in namespace)`

<details>
    <summary>
      Namespace version change example
    </summary>

Assuming the following scenario:

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: Namespace α is registered, with active Cluster set to Cluster A

```
namespace α's version is 1
all workflows events generated within this namespace, will come with version 1
```

T = 1: namespace β is registered, with active Cluster set to Cluster B

```
namespace β's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 2: Namespace α is updated to with active Cluster set to Cluster B

```
namespace α's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 3: Namespace β is updated to with active Cluster set to Cluster A

```
namespace β's version is 11
all workflows events generated within this namespace, will come with version 11
```

</details>

#### Version history

Version history is a concept which provides a high level summary of version information in regards to Workflow Execution History.

Whenever there is a new Workflow Execution History entry generated, the version from Namespace will be attached.
The Workflow Executions's mutable state will keep track of all history entries (events) and the corresponding version.

<details>
    <summary>
        Version history example (without data conflict)
    </summary>

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: adding event with event ID == 1 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 1               | 1       |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 2 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: adding event with event ID == 3 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               |                 |         |
| 3        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 3: Namespace failover triggered, Namespace version is now 2
adding event with event ID == 4 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 4: adding event with event ID == 5 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 5               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| 5        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

</details>

Since Temporal is AP, during failover (change of active Temporal Service Namespace), there can exist cases where more than one Cluster can modify a Workflow Execution, causing divergence of Workflow Execution History. Below shows how the version history will look like under such conditions.

<details>
    <summary>
      Version history example (with data conflict)
    </summary>

Below, shows version history of the same Workflow Execution in 2 different Clusters.

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Cluster C comes with initial version: 3
- Shared version increment: 10

T = 0:

View in both Cluster B & C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 4 & version == 2 in Cluster B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 2               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: namespace failover to Cluster C, adding event with event ID == 4 & version == 3 in Cluster C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               | 4               | 3       |
| 4        | 3               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: replication task from Cluster C arrives in Cluster B

Note: below are a tree structures

```
                | -------- | ------------- |
                | Events        |
                | ------------- | ------------- |
                | Event ID      | Event Version |
                | --------      | ------------- |
                | 1             | 1             |
                | 2             | 1             |
                | 3             | 2             |
                | --------      | ------------- |
                |               |
                | ------------- | ------------  |
                |               |
                | --------      | ------------- |  | -------- | ------------- |
                | Event ID      | Event Version |  | Event ID | Event Version |
                | --------      | ------------- |  | -------- | ------------- |
                | 4             | 2             |  | 4        | 3             |
                | --------      | ------------- |  | -------- | ------------- |

          | --------------- | ------- |
          | Version History |
          | --------------- | ------------------- |
          | Event ID        | Version             |
          | --------------- | -------             |
          | 2               | 1                   |
          | 3               | 2                   |
          | --------------- | -------             |
          |                 |
          | -------         | ------------------- |
          |                 |
          | --------------- | -------             |  | --------------- | ------- |
          | Event ID        | Version             |  | Event ID        | Version |
          | --------------- | -------             |  | --------------- | ------- |
          | 4               | 2                   |  | 4               | 3       |
          | --------------- | -------             |  | --------------- | ------- |
```

T = 2: replication task from Cluster B arrives in Cluster C, same as above

</details>

#### Conflict resolution

When a Workflow Execution History diverges, proper conflict resolution is applied.

In Multi-cluster Replication, Workflow Execution History Events are modeled as a tree, as shown in the second example in [Version History](#version-history).

Workflow Execution Histories that diverge will have more than one history branch.
Among all history branches, the history branch with the highest version is considered the `current branch` and the Workflow Execution's mutable state is a summary of the current branch.
Whenever there is a switch between Workflow Execution History branches, a complete rebuild of the Workflow Execution's mutable state will occur.

Temporal Multi-Cluster Replication relies on asynchronous replication of Events across Clusters, so in the case of a failover it is possible to have an Activity Task dispatched again to the newly active Cluster due to a replication task lag.
This also means that whenever a Workflow Execution is updated after a failover by the new Cluster, any previous replication tasks for that Execution cannot be applied.
This results in loss of some progress made by the Workflow Execution in the previous active Cluster.
During such conflict resolution, Temporal re-injects any external Events like Signals in the new Event History before discarding replication tasks.
Even though some progress could roll back during failovers, Temporal provides the guarantee that Workflow Executions won't get stuck and will continue to make forward progress.

Activity Execution completions are not forwarded across Clusters.
Any outstanding Activities will eventually time out based on the configuration.
Your application should have retry logic in place so that the Activity gets retried and dispatched again to a Worker after the failover to the new Cluster.
Handling this is similar to handling an Activity Task timeout caused by a Worker restarting.

#### Zombie Workflows

There is an existing contract that for any Namespace and Workflow Id combination, there can be at most one run (Namespace + Workflow Id + Run Id) open / executing.

Multi-cluster Replication aims to keep the Workflow Execution History as up-to-date as possible among all participating Clusters.

Due to the nature of Multi-cluster Replication (for example, Workflow Execution History events are replicated asynchronously) different Runs (same Namespace and Workflow Id) can arrive at the target Cluster at different times, sometimes out of order, as shown below:

```
| ------------- |          | ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
        |                          |                          |
        | Run 1 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        | Run 2 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        |                          |                          |
        |                          |                          |
        |                          | Run 2 Replication Events |
        |                          | -----------------------> |
        |                          |                          |
        |                          | Run 1 Replication Events |
        |                          | -----------------------> |
        |     |  |
        | --- || ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
```

Because Run 2 appears in Cluster B first, Run 1 cannot be replicated as "runnable" due to the rule `at most one Run open` (see above), thus the "zombie" Workflow Execution state is introduced.
A "zombie" state is one in which a Workflow Execution which cannot be actively mutated by a Cluster (assuming the corresponding Namespace is active in this Cluster). A zombie Workflow Execution can only be changed by a replication Task.

Run 1 will be replicated similar to Run 2, except when Run 1's execution will become a "zombie" before Run 1 reaches completion.

#### Workflow Task processing

In the context of Multi-cluster Replication, a Workflow Execution's mutable state is an entity which tracks all pending tasks.
Prior to the introduction of Multi-cluster Replication, Workflow Execution History entries (events) are from a single branch, and the Temporal Server will only append new entries (events) to the Workflow Execution History.

After the introduction of Multi-cluster Replication, it is possible that a Workflow Execution can have multiple Workflow Execution History branches.
Tasks generated according to one history branch may become invalidated by switching history branches during conflict resolution.

Example:

T = 0: task A is generated according to Event Id: 4, version: 2

```
| -------- | ------------- |
| Events   |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 1        | 1             |
| 2        | 1             |
| 3        | 2             |
| -------- | ------------- |
|          |
|          |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 4        | 2             | <-- task A belongs to this event |
| -------- | ------------- |
```

T = 1: conflict resolution happens, Workflow Execution's mutable state is rebuilt and history Event Id: 4, version: 3 is written down to persistence

```
| -------- | ------------- |
| Events        |
| ------------- | -------------------------------------------- |
| Event ID      | Event Version                                |
| --------      | -------------                                |
| 1             | 1                                            |
| 2             | 1                                            |
| 3             | 2                                            |
| --------      | -------------                                |
|               |
| ------------- | -------------------------------------------- |
|               |
| --------      | -------------                                |                                  | -------- | ------------- |
| Event ID      | Event Version                                |                                  | Event ID | Event Version |
| --------      | -------------                                |                                  | -------- | ------------- |
| 4             | 2                                            | <-- task A belongs to this event | 4        | 3             | <-- current branch / mutable state |
| --------      | -------------                                |                                  | -------- | ------------- |
```

T = 2: task A is loaded.

At this time, due to the rebuild of a Workflow Execution's mutable state (conflict resolution), Task A is no longer relevant (Task A's corresponding Event belongs to non-current branch).
Task processing logic will verify both the Event Id and version of the Task against a corresponding Workflow Execution's mutable state, then discard task A.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/observability.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/observability.mdx</path>
  <content>
---
id: observability
title: Observability - Python SDK
sidebar_label: Observability
description: Discover how to monitor your Temporal Application using metrics, tracing, logging, and visibility APIs. Learn to emit metrics, set up tracing, log from Workflows, and use custom Search Attributes.
slug: /develop/python/observability
toc_max_heading_level: 2
keywords:
  - client
  - code sample
  - developer-guide
  - guide-context
  - how-to
  - logging
  - python
  - python sdk
  - sdk
  - search attribute
  - workflow
tags:
  - Observability
  - Workflows
  - Search Attributes
  - Python SDK
  - Temporal SDKs
---

The observability section of the Temporal Developer's guide covers the many ways to view the current state of your [Temporal Application](/temporal#temporal-application)—that is, ways to view which [Workflow Executions](/workflows#workflow-execution) are tracked by the [Temporal Platform](/temporal#temporal-platform) and the state of any specified Workflow Execution, either currently or at points of an execution.

This section covers features related to viewing the state of the application, including:

- [Emit metrics](#metrics)
- [Set up tracing](#tracing)
- [Log from a Workflow](#logging)
- [Visibility APIs](#visibility)

## Emit metrics {#metrics}

**How to emit metrics**

Each Temporal SDK is capable of emitting an optional set of metrics from either the Client or the Worker process.
For a complete list of metrics capable of being emitted, see the [SDK metrics reference](/references/sdk-metrics).

Metrics can be scraped and stored in time series databases, such as:

- [Prometheus](https://prometheus.io/docs/introduction/overview/)
- [M3db](https://m3db.io/docs/)
- [statsd](https://github.com/statsd/statsd)

Temporal also provides a dashboard you can integrate with graphing services like [Grafana](https://grafana.com/docs/). For more information, see:

- Temporal's implementation of the [Grafana dashboard](https://github.com/temporalio/dashboards)
- [How to export metrics in Grafana](https://github.com/temporalio/helm-charts#exploring-metrics-via-grafana)

Metrics in Python are configured globally; therefore, you should set a Prometheus endpoint before any other Temporal code.

The following example exposes a Prometheus endpoint on port `9000`.

```python
from temporalio.runtime import Runtime, TelemetryConfig, PrometheusConfig

# Create a new runtime that has telemetry enabled. Create this first to avoid
# the default Runtime from being lazily created.
new_runtime = Runtime(telemetry=TelemetryConfig(metrics=PrometheusConfig(bind_address="0.0.0.0:9000")))
my_client = await Client.connect("my.temporal.host:7233", runtime=new_runtime)
```

## Set up tracing {#tracing}

**How to set up tracing**

Tracing allows you to view the call graph of a Workflow along with its Activities and any Child Workflows.

Temporal Web's tracing capabilities mainly track Activity Execution within a Temporal context. If you need custom tracing specific for your use case, you should make use of context propagation to add tracing logic accordingly.

To configure tracing in Python, install the `opentelemetry` dependencies.

```bash
# This command installs the `opentelemetry` dependencies.
pip install temporalio[opentelemetry]
```

Then the [`temporalio.contrib.opentelemetry.TracingInterceptor`](https://python.temporal.io/temporalio.contrib.opentelemetry.TracingInterceptor.html) class can be set as an interceptor as an argument of [`Client.connect()`](https://python.temporal.io/temporalio.client.Client.html#connect).

When your Client is connected, spans are created for all Client calls, Activities, and Workflow invocations on the Worker.
Spans are created and serialized through the server to give one trace for a Workflow Execution.

## Log from a Workflow {#logging}

Logging enables you to record critical information during code execution.
Loggers create an audit trail and capture information about your Workflow's operation.
An appropriate logging level depends on your specific needs.
During development or troubleshooting, you might use debug or even trace.
In production, you might use info or warn to avoid excessive log volume.

The logger supports the following logging levels:

| Level   | Use                                                                                                       |
| ------- | --------------------------------------------------------------------------------------------------------- |
| `TRACE` | The most detailed level of logging, used for very fine-grained information.                               |
| `DEBUG` | Detailed information, typically useful for debugging purposes.                                            |
| `INFO`  | General information about the application's operation.                                                    |
| `WARN`  | Indicates potentially harmful situations or minor issues that don't prevent the application from working. |
| `ERROR` | Indicates error conditions that might still allow the application to continue running.                    |

The Temporal SDK core normally uses `WARN` as its default logging level.

**How to log from a Workflow**

Send logs and errors to a logging service, so that when things go wrong, you can see what happened.

The SDK core uses `WARN` for its default logging level.

You can log from a Workflow using Python's standard library, by importing the logging module `logging`.

Set your logging configuration to a level you want to expose logs to.
The following example sets the logging information level to `INFO`.

```python
logging.basicConfig(level=logging.INFO)
```

Then in your Workflow, set your [`logger`](https://python.temporal.io/temporalio.workflow.html#logger) and level on the Workflow. The following example logs the Workflow.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_loggers/your_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
        workflow.logger.info("Workflow input parameter: %s" % name)
```

### Custom logger {#custom-logger}

Use a custom logger for logging.

Use the built-in [Logging facility for Python](https://docs.python.org/3/library/logging.html) to set a custom logger.

## Visibility APIs {#visibility}

The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Temporal Service.

### Use Search Attributes {#search-attributes}

The typical method of retrieving a Workflow Execution is by its Workflow Id.

However, sometimes you'll want to retrieve one or more Workflow Executions based on another property. For example, imagine you want to get all Workflow Executions of a certain type that have failed within a time range, so that you can start new ones with the same arguments.

You can do this with [Search Attributes](/search-attribute).

- [Default Search Attributes](/search-attribute#default-search-attribute) like `WorkflowType`, `StartTime` and `ExecutionStatus` are automatically added to Workflow Executions.
- _Custom Search Attributes_ can contain their own domain-specific data (like `customerId` or `numItems`).
  - A few [generic Custom Search Attributes](/search-attribute#custom-search-attribute) like `CustomKeywordField` and `CustomIntField` are created by default in Temporal's [Docker Compose](https://github.com/temporalio/docker-compose).

The steps to using custom Search Attributes are:

- Create a new Search Attribute in your Temporal Service in the Temporal CLI or Web UI.
  - For example: `temporal operator search-attribute create --name CustomKeywordField --type Text`
    - Replace `CustomKeywordField` with the name of your Search Attribute.
    - Replace `Text` with a type value associated with your Search Attribute: `Text` | `Keyword` | `Int` | `Double` | `Bool` | `Datetime` | `KeywordList`
- Set the value of the Search Attribute for a Workflow Execution:
  - On the Client by including it as an option when starting the Execution.
  - In the Workflow by calling `upsert_search_attributes`.
- Read the value of the Search Attribute:
  - On the Client by calling `DescribeWorkflow`.
  - In the Workflow by looking at `WorkflowInfo`.
- Query Workflow Executions by the Search Attribute using a [List Filter](/list-filter):
  - [In the Temporal CLI](/cli/operator#list-2)
  - In code by calling `ListWorkflowExecutions`.

Here is how to query Workflow Executions:

Use the [list_workflows()](https://python.temporal.io/temporalio.client.Client.html#list_workflows) method on the Client handle and pass a [List Filter](/list-filter) as an argument to filter the listed Workflows.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_visibility/starter_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
    async for workflow in client.list_workflows('WorkflowType="GreetingWorkflow"'):
        print(f"Workflow: {workflow.id}")
```

### How to set custom Search Attributes {#custom-search-attributes}

After you've created custom Search Attributes in your Temporal Service (using `temporal operator search-attribute create`or the Cloud UI), you can set the values of the custom Search Attributes when starting a Workflow.

Use `SearchAttributeKey` to create your Search Attributes. Then, when starting a Workflow execution using `client.start_workflow()`, include the Custom Search Attributes by passing instances of `SearchAttributePair()` containing each of your keys and starting values to a parameter called `search_attributes`.
If you had Custom Search Attributes `CustomerId` of type `Keyword` and `MiscData` of type `Text`, you could provide these starting values:

```python
customer_id_key = SearchAttributeKey.for_keyword("CustomerId")
misc_data_key = SearchAttributeKey.for_text("MiscData")

handle = await client.start_workflow(
    GreetingWorkflow.run,
    id="search-attributes-workflow-id",
    task_queue="search-attributes-task-queue",
    search_attributes=TypedSearchAttributes([
        SearchAttributePair(customer_id_key, "customer_1"),
        SearchAttributePair(misc_data_key, "customer_1_data")
    ]),
)
```

In this example, `CustomerId` and `MiscData` are set as Search Attributes.
These attributes are useful for querying Workflows based on the customer ID or the date the order was placed.

### Upsert Search Attributes {#upsert-search-attributes}

You can upsert Search Attributes to add or update Search Attributes from within Workflow code.

To upsert custom Search Attributes, use the [`upsert_search_attributes()`](https://python.temporal.io/temporalio.workflow.html#upsert_search_attributes) method to pass instances of `SearchAttributePair()` containing each of your keys and starting values to a parameter to a `TypedSearchAttributes()` object:

```python
workflow.upsert_search_attributes(TypedSearchAttributes([
    SearchAttributePair(customer_id_key, "customer_2")
]))
```

### Remove a Search Attribute from a Workflow {#remove-search-attribute}

To remove a Search Attribute that was previously set, set it to an empty array: `[]`.

```python
workflow.upsert_search_attributes(TypedSearchAttributes([
    SearchAttributePair(customer_id_key, [])
]))
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/overview.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/overview.mdx</path>
  <content>
---
id: overview
title: Overview - Temporal Cloud
sidebar_label: Overview
description: Temporal Cloud is a SaaS platform managing the durability of your Temporal Applications, implemented using Temporal SDK. It supervises workflow histories and supports multiple isolated namespaces.
slug: /cloud/overview
toc_max_heading_level: 4
keywords:
  - explanation
  - term
tags:
  - Temporal Cloud
---

When it comes to running Temporal in production, you have two main options:

**Temporal self-hosted:**
This option involves setting up and managing your own instance of the Temporal Server.
Your Workers and Temporal Application connect directly to this self-hosted instance.
With the self-hosted approach, you have full control over the infrastructure and are responsible for managing the persistence layer, scalability, and availability of the Temporal system.

**Temporal Cloud:**
Temporal Cloud is a fully managed service provided by Temporal.
It offers a hassle-free way to run your Temporal Applications without the need to manage the underlying infrastructure.
Your Workers and Temporal Applications connect to the Temporal Cloud service, which takes care of the persistence layer, scalability, and availability for you.

Temporal Cloud and self-hosted Temporal Services have some similarities, as both require your Temporal Clients and Workers to establish a connection to the Temporal Service.
Additionally, in both cases, you are responsible for managing and hosting your application code and running your Workers.
The choice between self-hosted and Temporal Cloud depends on your specific requirements, resources, and expertise.

### High level system topology of the Temporal Service

There are two major parts of the Temporal Service that work together to create the fully functioning system.
Temporal Cloud is an offering of the Temporal Service.

1. Temporal SDK: The Temporal software development kit (SDK) is available in various languages and can be integrated as a dependency into your new or existing application.
   It offers developers a comprehensive development framework and APIs, facilitating the creation and management of applications.
2. Temporal Cloud: Operating independently from the execution environment, Temporal Cloud oversees the execution process by preserving the source of truth for your Workflow Execution Event Histories.
   This independent supervision ensures the durable execution of your distributed applications and services.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">High-level system topology</p>
  </div>
  <div className="tdiiw" height="761">
    <img
      className="img_ev3q"
      src="/diagrams/high-level-system-topology.svg"
      alt="High-level system topology"
    />
  </div>
</div>

Temporal Cloud is based off of the open source [Temporal Server](/clusters#temporal-server) software and offers a comparable set of features but with out the overhead of setting up and deploying a production level Temporal Service (Temporal Server + all of the auxillary services it depends on).

Temporal Cloud is offered in units of isolation known as [Namespaces](/namespaces).
You can provision and use one or more Cloud Namespaces.
A typical use case is to use separate Namespaces as development, testing, integration, staging, and production environments for an application.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/index.mdx</path>
  <content>
---
id: index
title: Temporal Platform references
sidebar_label: References
description: Explore comprehensive references for SDK Metrics, Commands, Events, Web UI environmental variables, Temporal Service and Web UI configurations, and API guides for Go, Java, Python, TypeScript, .NET, and PHP.
tags:
  - Reference
---

- [SDK metrics reference](/references/sdk-metrics)
- [Commands reference](/references/commands)
- [Events reference](/references/events)
- [Web UI environmental variables reference](/references/web-ui-environment-variables)
- [Temporal Service configuration reference](/references/configuration)
- [Temporal Web UI configuration reference](/references/web-ui-configuration)
- [Go SDK API reference](https://pkg.go.dev/go.temporal.io/sdk)
- [Java SDK API reference](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/index.html)
- [Python SDK API reference](https://python.temporal.io/)
- [TypeScript SDK API reference](https://typescript.temporal.io)
- [.NET SDK API reference](https://dotnet.temporal.io/api/)
- [PHP SDK API reference](https://php.temporal.io/namespaces/temporal.html)
- [Glossary](/glossary)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/versioning.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/versioning.mdx</path>
  <content>
---
id: versioning
title: Versioning - Python SDK
sidebar_label: Versioning
description: Learn how to ensure deterministic Temporal Workflow execution and safely deploy updates using the Python SDK's patching and Worker Versioning APIs, for scalable long-running Workflows.
slug: /develop/python/versioning
toc_max_heading_level: 2
keywords:
  - best practices
  - code sample
  - deployment
  - deployment safety
  - deprecated patches
  - how-to
  - patching
  - python
  - python sdk
  - version
  - versioning
  - workflow completion
  - workflow history
  - workflow transition
tags:
  - Workflows
  - Versioning
  - Patching
  - Python SDK
  - Temporal SDKs
---

The definition code of a Temporal Workflow must be deterministic because Temporal uses event sourcing
to reconstruct the Workflow state by replaying the saved history event data on the Workflow
definition code. This means that any incompatible update to the Workflow Definition code could cause
a non-deterministic issue if not handled correctly.

## Introduction to Versioning

Because we design for potentially long running Workflows at scale, versioning with Temporal works differently. We explain more in this optional 30 minute introduction: [https://www.youtube.com/watch?v=kkP899WxgzY](https://www.youtube.com/watch?v=kkP899WxgzY)

## How to use the Python SDK Patching API {#python-sdk-patching-api}

In principle, the Python SDK's patching mechanism operates similarly to other SDKs in a "feature-flag" fashion. However, the "versioning" API now uses the concept of "patching in" code.

To understand this, you can break it down into three steps, which reflect three stages of migration:

- Running `pre_patch_activity` code while concurrently patching in `post_patch_activity`.
- Running `post_patch_activity` code with deprecation markers for `my-patch` patches.
- Running only the `post_patch_activity` code.

Let's walk through this process in sequence.

Suppose you have an initial Workflow version called `pre_patch_activity`:

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/version_your_workflows/workflow_1_initial_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from datetime import timedelta

from temporalio import workflow

with workflow.unsafe.imports_passed_through():
    from activities import pre_patch_activity
# ...
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> None:
        self._result = await workflow.execute_activity(
            pre_patch_activity,
            schedule_to_close_timeout=timedelta(minutes=5),
        )
```

Now, you want to update your code to run `post_patch_activity` instead. This represents your desired end state.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/version_your_workflows/workflow_4_patch_complete_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from datetime import timedelta

from temporalio import workflow

with workflow.unsafe.imports_passed_through():
    from activities import post_patch_activity
# ...
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> None:
        self._result = await workflow.execute_activity(
            post_patch_activity,
            schedule_to_close_timeout=timedelta(minutes=5),
        )
```

**Problem: You cannot deploy `post_patch_activity` directly until you're certain there are no more running Workflows created using the `pre_patch_activity` code, otherwise you are likely to cause a nondeterminism error.**

Instead, you'll need to deploy `post_patched_activity` and use the [patched](https://python.temporal.io/temporalio.workflow.html#patched) function to determine which version of the code to execute.

Implementing patching involves three steps:

1. Use [patched](https://python.temporal.io/temporalio.workflow.html#patched) to patch in new code and run it alongside the old code.
2. Remove the old code and apply [deprecate_patch](https://python.temporal.io/temporalio.workflow.html#deprecate_patch).
3. Once you're confident that all old Workflows have finished executing, remove `deprecate_patch`.

### Patching in new code {#using-patched-for-workflow-history-markers}

Using `patched` inserts a marker into the Workflow History.

![image](https://user-images.githubusercontent.com/6764957/139673361-35d61b38-ab94-401e-ae7b-feaa52eae8c6.png)

During replay, if a Worker encounters a history with that marker, it will fail the Workflow task when the Workflow code doesn't produce the same patch marker (in this case, `my-patch`). This ensures you can safely deploy code from `post_patch_activity` as a "feature flag" alongside the original version (`pre_patch_activity`).

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/version_your_workflows/workflow_2_patched_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> None:
        if workflow.patched("my-patch"):
            self._result = await workflow.execute_activity(
                post_patch_activity,
                schedule_to_close_timeout=timedelta(minutes=5),
            )
        else:
            self._result = await workflow.execute_activity(
                pre_patch_activity,
                schedule_to_close_timeout=timedelta(minutes=5),
            )
```

### Understanding deprecated Patches in the Python SDK {#deprecated-patches}

After ensuring that all Workflows started with `pre_patch_activity` code have finished, you can [deprecate the patch](https://python.temporal.io/temporalio.workflow.html#deprecate_patch).

Once you're confident that your Workflows are no longer running the pre-patch code paths, you can deploy your code with `deprecate_patch()`.
These Workers will be running the most up-to-date version of the Workflow code, which no longer requires the patch.
The `deprecate_patch()` function works similarly to the `patched()` function by recording a marker in the Workflow history.
This marker does not fail replay when Workflow code does not emit it.
Deprecated patches serve as a bridge between the pre-patch code paths and the post-patch code paths, and are useful for avoiding errors resulting from patched code paths in your Workflow history.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/version_your_workflows/workflow_3_patch_deprecated_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> None:
        workflow.deprecate_patch("my-patch")
        self._result = await workflow.execute_activity(
            post_patch_activity,
            schedule_to_close_timeout=timedelta(minutes=5),
        )
```

### Safe Deployment of post_patch_activity {#deploy-new-code}

Once you're sure that you will no longer need to Query or Replay any of your pre-patch Workflows, you can then safely deploy Workers that no longer use either the `patched()` or `deprecate_patch()` calls:

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/version_your_workflows/workflow_4_patch_complete_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> None:
        self._result = await workflow.execute_activity(
            post_patch_activity,
            schedule_to_close_timeout=timedelta(minutes=5),
        )
```

## How to use Worker Versioning in Python {#worker-versioning}

This feature is coming soon!

For now, please join #safe-deploys in our [Community Slack](https://temporal.io/slack) to find the latest status and pre-release docs.

If you were using a previous pre-release version of Worker Versioning, it's now deprecated.

See [Legacy Worker Versioning](worker-versioning-legacy) if you still need those docs.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/default-custom-data-converter.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/default-custom-data-converter.mdx</path>
  <content>
---
id: default-custom-data-converters
title: Default and Custom Data Converters
sidebar_label: Default and Custom Data Converters
description: Learn about the default Data Converter in Temporal SDKs and how to implement a custom Data Converter for custom serialization and encoding needs.
slug: /default-custom-data-converters
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - default-data-converter
  - custom-data-converter
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses the following: 
- [Default Data Converter](#default-data-converter)
- [Custom Data Converter](#custom-data-converter)

## What is a default Data Converter? {#default-data-converter}

Each Temporal SDK includes and uses a default Data Converter.
The default Data Converter converts objects to bytes using a series of Payload Converters and supports binary, Protobufs, and JSON formats.
It encodes values in the following order:

- Null
- Byte array
- Protobuf JSON
- JSON

In SDKs that cannot determine parameter types at runtime (for example, TypeScript), Protobufs aren't included in the default converter.

For example:

- If a value is an instance of a Protobuf message, it is encoded with [proto3 JSON](https://developers.google.com/protocol-buffers/docs/proto3#json).
- If a value isn't null, binary, or a Protobuf, it is encoded as JSON. Most common input types — including strings, integers, floating point numbers, and booleans — are serializable as JSON. If any part of it is not serializable as JSON, {/* (for example, a Date—see JSON data types) */} an error is thrown.

The default Data Converter serializes objects based on their root type, rather than nested types.
The JSON serializers of some SDKs cannot process lists with Protobuf children objects without implementing a [custom Data Converter](#custom-data-converter).

## What is a custom Data Converter? {#custom-data-converter}

A custom Data Converter extends the default Data Converter with custom logic for [Payload](/dataconversion#payload) conversion or encoding.

You can create a custom Data Converter to alter formats (for example, using [MessagePack](https://msgpack.org/) instead of JSON) or add compression and encryption.

A Payload Codec encodes and decodes [Payloads](/dataconversion#payload), with bytes-to-bytes conversion.
To use custom encryption or compression logic, create a custom Payload Codec with your encryption/compression logic in the `encode` function and your decryption/decompression logic in the `decode` function.
To implement a custom Payload Codec, you can override the default Data Converter, or create a customized Data Converter that defines its own Payload Converter.

Custom Data Converters are not applied to all data; for example, [Search Attributes](/search-attribute) are persisted unencoded so they can be indexed for searching.

A customized Data Converter can have the following three components:

- [Payload Converter](/payload-converter)
- [Payload Codec](/payload-codec)
- [Failure Converter](/failure-converter)

For details on how to implement custom encryption and compression in your SDK, see [Data Encryption](/production-deployment/data-encryption).



  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/data-encryption.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/data-encryption.mdx</path>
  <content>
---
id: data-encryption
title: Data encryption - Temporal feature
description: Learn how to implement data encryption in your Temporal Workflows to ensure the security and confidentiality of your data.
sidebar_label: Data encryption
tags:
  - Codec Server
  - Security
  - Encryption
  - Workflows
keywords:
  - temporal data encryption
  - secure temporal workflows
  - encrypting workflow data
  - temporal encryption
  - temporal encryption features
  - temporal secure workflows
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Data Converters in Temporal are SDK components that handle the serialization and encoding of data transmitted and received by a Temporal Client.
Workflow input and output need to be serialized and deserialized so they can be sent as JSON to the Temporal Service.

Temporal provides its own default Data Converter logic, which is not apparent to a user if payloads contain plain text or JSON data.
For enhanced security, you can implement your own encryption standards using a Codec Server.
Temporal's data encryption capabilities ensures the security and confidentiality of your Workflows and provides protection without compromising performance.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/converters-and-encryption" text="Data Encryption using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/converters-and-encryption" text="Data Encryption using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/converters-and-encryption" text="Data Encryption using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/converters-and-encryption" text="Data Encryption using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/converters-and-encryption" text="Data Encryption using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/use-cases-design-patterns.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/use-cases-design-patterns.mdx</path>
  <content>
---
id: use-cases-design-patterns
title: Temporal Use Cases and Design Patterns 
description: Discover various use cases and architectural design patterns for implementing Workflows with Temporal.
sidebar_label: Use Cases
tags:
  - use-cases
  - design-patterns
keywords:
  - use cases
  - design patterns
  - workflows
---

This page provides an overview of how leading organizations leverage Temporal to solve real-world problems, general use cases, and architectural design patterns. 

## Use Cases of Temporal in Production

Here are some examples where Temporal is most impactful and running in production at large organizations today.  For more examples, see our [Temporal Use Cases](https://temporal.io/in-use) page.

### Transactions

Actions or activities involving two or more parties or things that reciprocally affect or influence each other. For example:

- [Payment processing at Stripe](https://temporal.io/resources/on-demand/stripe)
- [Money movement at Coinbase](https://temporal.io/in-use/coinbase)
- [Content management at Box](https://temporal.io/resources/case-studies/box)

### Business processes

A sequence of tasks that find their end in the delivery of a service or product to a client. For example:

- [Bookings at Turo](https://temporal.io/replay/videos/temporal-adoption-and-integration-at-turo)
- [Orders/logistics at Maersk](https://temporal.io/replay/videos/building-a-time-machine-for-the-logistics-industry)
- [Marketing Campaigns at AirBnb](https://medium.com/airbnb-engineering/journey-platform-a-low-code-tool-for-creating-interactive-user-workflows-9954f51fa3f8)
- [Human-in-the-loop at Checkr](https://temporal.io/in-use/checkr)

### Entity lifecycle

Complex long-running processes that accumulate state over time. For example:

- [Mortgage underwriting applications at ANZ](https://temporal.io/in-use/anz-story)
- [Menu versioning at Yum! Brands](https://temporal.io/replay-2023/videos/synchronizing-concurrent-workflows)

### Operations

An automated method for getting a repeatable, mundane task accomplished. For example:

- [Infrastructure services at DataDog](https://www.youtube.com/watch?v=Hz7ZZzafBoE)
- [Custom CI/CD at Netflix](https://temporal.io/replay-2023/videos/actor-workflows-reliably-orchestrating-thousands-of-flink-clusters-at)

### AI / ML and Data Engineering

AI and ML developers face challenges in system orchestration, such as managing complex data pipelines and job coordination across GPU resources. 
Temporal's code-first approach helps build reliable services faster, making it popular among AI companies. For example:

- [Orchestrating video processing at Descript](https://temporal.io/blog/ai-ml-and-data-engineering-workflows-with-temporal#descript)
- [Automating data pipelines at Neosync](https://temporal.io/blog/ai-ml-and-data-engineering-workflows-with-temporal#neosync)

## General Use Cases

### Human in the Loop

"Human in the Loop" systems require human interaction for certain steps, such as customer onboarding, forms, or invoice approval.
These are event driven system with humans generating events, and may be challenging to implement due to timing or unreliable connections between the human to the rest of the system.
They can use schedules and timers to prompt for user input.

**Example**: [Background checks example using the Go SDK](https://learn.temporal.io/examples/go/background-checks/).

**Code Sample**: [Candidate acceptance example prompting for a response](https://learn.temporal.io/examples/go/background-checks/candidate-acceptance)

### Polyglot Systems

Modern development teams often work with different programming languages based on their expertise and project requirements. Temporal supports this through built-in multi-language capabilities, allowing teams to continue using their preferred languages while working together. 

The example below showcases how Workflow Executions, written in different languages, can send messages to each other. Go, Java, PHP, and TypeScript SDKs are represented in this sample. It also shows how to properly propagate errors, including how to do so across Workflows written in different languages.

**Example**: [Polyglot example](https://github.com/temporalio/temporal-polyglot). 

### Long Running Tasks

This use case is particularly relevant for scenarios like shopping cart Workflows in an eCommerce app, where you can handling long-running tasks efficiently without managing state in a separate database.
It processes one message at a time, ensuring each message is processed only once.

This approach addresses issues that can arise with long message processing times, which in other systems might cause consumer failover (typically with a default 5-minute message poll timeout) and potentially result in duplicate message processing by multiple consumers.
Temporal's ability to handle extended task durations makes it well-suited for such scenarios.
The [heartbeat](/encyclopedia/detecting-activity-failures#activity-heartbeat) feature allows you to know that an activity is still working, providing insight into the progress of long-running processes.

**Example**: [eCommerce example](https://learn.temporal.io/tutorials/go/build-an-ecommerce-app/).

**Code Sample**: [Temporal eCommerce](https://github.com/temporalio/temporal-ecommerce)

## Design Patterns

### Saga

The Saga pattern is a design pattern used to manage and handle failures in complex Workflows by breaking down a transaction into a series of smaller, manageable sub-transactions.
If a step in the Workflow fails, the Saga pattern compensates for this failure by executing specific actions to undo the previous steps.
This ensures that even in the event of a failure, the system can revert to a consistent state.

**Examples:**
  - [Build a trip booking application in Python](https://learn.temporal.io/tutorials/python/trip-booking-app/).
  - [Saga Pattern with Temporal Whitepaper](https://pages.temporal.io/download-saga-pattern-made-easy)
  - [To choreograph or orchestrate your saga, that is the question](https://temporal.io/blog/to-choreograph-or-orchestrate-your-saga-that-is-the-question)
  - [Saga Webinar](https://pages.temporal.io/on-demand-webinar-what-is-a-saga.html)

### State Machine

A state machine is a software design pattern used to modify a system’s behavior in response to changes in its state.
While state machines are widely used in software development, applying them to complex business processes can be a difficult undertaking.
Temporal simplifies the complexity of state machines by providing a structured approach to workflow development, avoiding the intricate state management code required for state machines.

**Example**: [State Machine Simplified Whitepaper](https://pages.temporal.io/download-state-machines-simplified.html)

:::tip

If you're interested in code to help get you started, check out our [Temporal Example Applications](https://learn.temporal.io/examples/), [Getting Starting Tutorials](https://learn.temporal.io/getting_started/), or [Project-based Tutorials](https://learn.temporal.io/tutorials/).

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/sticky-execution.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/sticky-execution.mdx</path>
  <content>
---
id: sticky-execution
title: Sticky Execution
sidebar_label: Sticky Execution
description: Learn about Sticky Execution and how it optimizes Task processing in Temporal by caching Workflow state locally.
slug: /sticky-execution
toc_max_heading_level: 4
keywords:
  - sticky execution
tags:
  - Sticky Execution
  - Worker
---

This page discusses [Sticky Executions](#sticky-execution). 

## What is a Sticky Execution? {#sticky-execution}

A Sticky Execution is when a Worker Entity caches the Workflow in memory and creates a dedicated Task Queue to listen on.

A Sticky Execution occurs after a Worker Entity completes the first Workflow Task in the chain of Workflow Tasks for the Workflow Execution.

The Worker Entity caches the Workflow in memory and begins polling the dedicated Task Queue for Workflow Tasks that contain updates, rather than the entire Event History.

If the Worker Entity does not pick up a Workflow Task from the dedicated Task Queue in an appropriate amount of time, the Temporal Service will resume Scheduling Workflow Tasks on the original Task Queue.
Another Worker Entity can then resume the Workflow Execution, and can set up its own Sticky Execution for future Workflow Tasks.

- [How to set a `StickyScheduleToStartTimeout` on a Worker Entity in Go](/develop/go/core-application#stickyscheduletostarttimeout)

Sticky Executions are the default behavior of the Temporal Platform.
  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/testing-suite.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/testing-suite.mdx</path>
  <content>
---
id: testing-suite
title: Temporal Testing Suite - Temporal feature
description: Explore Temporal's comprehensive testing suite; Frameworks that facilitate Workflow and integration testing across different programming languages with Temporal.
sidebar_label: Testing suite
tags:
  - Testing
keywords:
  - temporal testing suite
  - test temporal workflows
  - temporal activity testing
  - workflow unit testing temporal
  - temporal SDK testing
  - temporal integration testing
  - automated tests for temporal
  - temporal worker validation
  - temporal framework testing
  - best practices for temporal testing
  - temporal testing examples
  - temporal SDK tutorial
  - end-to-end testing temporal
  - temporal performance testing
  - temporal testing strategies
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

In the context of Temporal, you can create these types of automated tests:

1. End-to-end: Running a Temporal Server and Worker with all its Workflows and Activities; starting and interacting with Workflows from a Client.
2. Integration: Anything between end-to-end and unit testing.
   Running Activities with mocked Context and other SDK imports (and usually network requests).
   Running Workers with mock Activities, and using a Client to start Workflows.
   Running Workflows with mocked SDK imports.
3. Unit: Running a piece of Workflow or Activity code and mocking any code it calls.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/testing-suite" text="Testing using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/testing-suite" text="Testing using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/testing-suite" text="Testing using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/testing-suite" text="Testing using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/testing-suite" text="Testing using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/testing-suite" text="Testing using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/aws-privatelink.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/aws-privatelink.mdx</path>
  <content>
---
id: aws-privatelink
title: Private Connectivity - AWS PrivateLink
sidebar_label: AWS PrivateLink
description: Secure your Temporal Cloud connections using AWS PrivateLink.
slug: /cloud/security/aws-privatelink
toc_max_heading_level: 4
keywords:
  - privatelink
  - private connectivity
  - security
  - temporal cloud
  - aws
tags:
  - Security
  - Temporal Cloud
  - AWS
---

#### AWS PrivateLink

[AWS PrivateLink](https://aws.amazon.com/privatelink/) allows you to open a path to Temporal without opening a public egress.
It establishes a private connection between your Amazon Virtual Private Cloud (VPC) and Temporal Cloud.
This one-way connection means Temporal cannot establish a connection back to your service.
This is useful if normally you block traffic egress as part of your security protocols.
If you use a private environment that does not allow external connectivity, you will remain isolated.

:::note

If you are interested in leveraging AWS PrivateLink in your Namespaces, [create a support ticket](/cloud/support#support-ticket) that includes the following information:

- AWS Region: The Region in which your connection will go through.
- AWS Account Id: The account which contains the permissions to enable AWS PrivateLink.
- Temporal Cloud Namespace names: The name of the Namespaces you want to enable AWS PrivateLink with.

:::

Set up PrivateLink connectivity with Temporal Cloud with these steps:

1. Open the AWS console with the region you want to use to establish the PrivateLink.
2. Search for "VPC" in _Services_ and select the option.

   ![AWS console showing services, features, resources](/img/cloud/privatelink/aws-console.png)
3. Select _Virtual private cloud_ > _Endpoints_ from the left menu bar.
4. Click the _Create endpoint_ button to the right of the _Actions_ pulldown menu.
5. Under _Type_ category, select _Endpoint services that use NLBs and GWLBs_.
   This option lets you find services shared with you by service name.
6. Under _Service settings_, fill in the _Service name_ with the PrivateLink Service Name for the region you’re trying to connect from:

   | Region           | PrivateLink Service Name                                       |
   | ---------------- | -------------------------------------------------------------- |
   | `ap-northeast-1` | `com.amazonaws.vpce.ap-northeast-1.vpce-svc-08f34c33f9fb8a48a` |
   | `ap-northeast-2` | `com.amazonaws.vpce.ap-northeast-2.vpce-svc-08c4d5445a5aad308` |
   | `ap-south-1`     | `com.amazonaws.vpce.ap-south-1.vpce-svc-0ad4f8ed56db15662`     |
   | `ap-south-2`     | `com.amazonaws.vpce.ap-south-2.vpce-svc-08bcf602b646c69c1`     |
   | `ap-southeast-1` | `com.amazonaws.vpce.ap-southeast-1.vpce-svc-05c24096fa89b0ccd` |
   | `ap-southeast-2` | `com.amazonaws.vpce.ap-southeast-2.vpce-svc-0634f9628e3c15b08` |
   | `ca-central-1`   | `com.amazonaws.vpce.ca-central-1.vpce-svc-080a781925d0b1d9d`   |
   | `eu-central-1`   | `com.amazonaws.vpce.eu-central-1.vpce-svc-073a419b36663a0f3`   |
   | `eu-west-1`      | `com.amazonaws.vpce.eu-west-1.vpce-svc-04388e89f3479b739`      |
   | `eu-west-2`      | `com.amazonaws.vpce.eu-west-2.vpce-svc-0ac7f9f07e7fb5695`      |
   | `sa-east-1`      | `com.amazonaws.vpce.sa-east-1.vpce-svc-0ca67a102f3ce525a`      |
   | `us-east-1`      | `com.amazonaws.vpce.us-east-1.vpce-svc-0822256b6575ea37f`      |
   | `us-east-2`      | `com.amazonaws.vpce.us-east-2.vpce-svc-01b8dccfc6660d9d4`      |
   | `us-west-2`      | `com.amazonaws.vpce.us-west-2.vpce-svc-0f44b3d7302816b94`      |

7. Confirm your service by clicking on the _Verify service_ button. AWS should respond "Service name verified."

   ![The service name field is filled out and the Verify service button is shown](/img/cloud/privatelink/service-settings.png)
8. Select the VPC and subnets to peer with the Temporal Cloud service endpoint.
9. Select the security group that will control traffic sources for this VPC endpoint.
   The security group must accept TCP ingress traffic to port 7233 for gRPC communication with Temporal Cloud.
10. Click the _Create endpoint_ button at the bottom of the screen.
    If successful, AWS reports "Successfully created VPC endpoint." and lists the new endpoint.
    The new endpoint appears in the Endpoints list, along with its ID.

    ![The created endpoint appears in the Endpoints list](/img/cloud/privatelink/endpoint-created.png)
11. Click on the VPC endpoint ID in the Endpoints list to check its status.
    Wait for the status to be “Available”.
    This can take up to 10 minutes.
12. Once available, you can use AWS PrivateLink.
    Use the first value under “DNS names” as your hostname to connect to Temporal Cloud using port 7233.
    To establish a valid mTLS session, you must override the TLS server name used for the connection to `<namespace_id>.<account_id>.tmprl.cloud`.

    ![Highlighted DNS names section shows your hostname](/img/cloud/privatelink/details.png)

You are ready to start using Private Link with Temporal Cloud.

:::tip

PrivateLink endpoint services are regional.
Individual Namespaces do not use separate services.

:::

Once set up, you can test your PrivateLink connectivity using the following methods.
When connecting, you must override the TLS server name to target your Namespace’s individual hostname (`<namespace_id>.<account_id>.tmprl.cloud`) to establish a valid mTLS session:

- The Temporal CLI, using the `--tls-server-name` parameter to override the TLS server name. For example:

  ```
  temporal workflow count \
      --address <DNS associated with VPC endpoint>:7233 \
      --tls-cert-path /path/to/client.pem \
      --tls-key-path /path/to/client.key \
      --tls-server-name <namespace_id>.<account_id>.tmprl.cloud \
      --namespace <namespace_id>.<account_id>
  ```

- Non-Temporal tools like grpcURL, useful for testing from environments that restrict tool usage, using the `-servername` parameter to override the TLS server name. For example:

  ```
  grpcurl \
      -servername <namespace_id>.<account_id>.tmprl.cloud \
      -cert /path/to/client.pem \
      -key /path/to/client.key \
      <DNS ASSOCIATED WITH VPC ENDPOINT>:7233 \
      temporal.api.workflowservice.v1.WorkflowService/GetSystemInfo
  ```

- Temporal SDKs, by setting the endpoint server address argument to the PrivateLink endpoint (`<DNS associated with VPC endpoint>:7233`) and using the TLS configuration options to override the TLS server name.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/temporal-sdks.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/temporal-sdks.mdx</path>
  <content>
---
id: temporal-sdks
title: About Temporal SDKs
sidebar_label: About the SDKs
description: Temporal SDKs are open-source tools enabling scalable and reliable application development. They feature APIs for Workflow and Activity execution, automatic retries, and resilience mechanisms, making it easier to build fault-tolerant applications.
toc_max_heading_level: 4
keywords:
  - components
  - developers guide
  - event-loop
  - explanation
  - replay
  - temporal application
  - temporal sdk
  - temporal-service
  - temporal-sdk
tags:
  - Concepts
  - Temporal SDKs
  - Durable Execution
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';

Temporal SDKs (software development kits) are an open source collection of tools, libraries, and APIs that enable Temporal Application development.

They offer a [Temporal Client](#temporal-client) to interact with the [Temporal Service](/clusters), APIs to develop your [Temporal Application](#temporal-application), and APIs to run horizontally scalable [Workers](/workers#worker).

SDKs are more than just a development tool, however.
The SDK APIs enable developers to write code in a particular pattern that mirrors real world processes.
The SDK's internal implementation, working in collaboration with the Temporal Service, steps through that code, guaranteeing execution progression during application runtime.

## Temporal Applications {#temporal-application}

A Temporal Application is the code you write, comprised of [Workflow Definitions](/workflows#workflow-definition), [Activity Definitions](/workflows#workflow-definition), code used to configure [Temporal Clients](#temporal-client), and code used to configure and start [Workers](/workers#worker).
Developers create Temporal Applications using an [official Temporal SDK](#official-sdks).

Consider that the Workflow Definition code can be executed repeatedly.
The Temporal Platform can concurrently support millions to billions of Workflow Executions, each of which representing an invoked Workflow Definition.

Additionally, a Temporal Workflow Execution is both resumable and recoverable, and it can react to external events.

- Resumable: The ability of a process to resume execution after suspending on an _awaitable_.
- Recoverable: The ability of a process to resume execution after suspending due to a _failure_.
- Reactive: The ability of a process to respond to external events.

Hence, a Temporal Application can run for seconds or years in the presence of arbitrary load and failures.

## Official SDKs {#official-sdks}

**What are the officially supported SDKs?**

Each Temporal SDK targets a specific programming language.

- [Go SDK feature guides](/develop/go)
- [Java SDK feature guides](/develop/java)
- [PHP SDK feature guides](/develop/php)
- [Python SDK feature guides](/develop/python/)
- [TypeScript SDK feature guides](/develop/typescript/)
- [.NET SDK feature guides](/develop/dotnet)

Despite supporting multiple languages, and supporting many features, Temporal SDKs aim to make developers feel at home in their language.

### Third-party SDKs

The following third-party SDKs exist but are not supported in Temporal's documentation:

- [Clojure](https://github.com/manetu/temporal-clojure-sdk) - from [@Manetu](https://github.com/manetu)
- [Scala](https://github.com/vitaliihonta/zio-temporal) from [@vitaliihonta](https://github.com/vitaliihonta)
- [Ruby](https://github.com/coinbase/temporal-ruby) from [@coinbase](https://github.com/coinbase)

## Why use a Temporal SDK? {#why-use-an-sdk}

Temporal SDKs empowers developers to concentrate on creating dependable and scalable business logic, alleviating the need to build home grown supervisor systems to ensure reliability and fault-tolerance. This is possible because the Temporal SDK provides a unified library that abstracts the intricacies of how Temporal handles distributed systems.

### Development pattern

By abstracting complexities and streamlining boilerplate code, developers can craft straightforward code that directly aligns with their business logic, enhancing code readability and bolstering developer productivity.

Consider a bank loan application.
Developers can design the business logic of a bank loan using the Temporal SDK.
The Workflow defines the overarching business logic, encompassing tasks such as validating applicant information, credit checks, loan approval, and applicant notifications, as Activities.

:::caution Do not copy and use code

The following is pseudocode. For tested samples see your language SDK's developer's guide.

:::

```
func LoanApplicationWorkflow {

    sdk.ExecuteActivity(CreditCheck)

    sdk.ExecuteActivity(AutomatedApproval)

    sdk.ExecuteActivity(NotifyApplicant)

    // ...
}
```

For instance, Temporal SDKs have built-in support for handling failures, timeouts, and retries.
In the event of an Activity failure, the SDK automatically initiates retries according to configurable policies established by the developer within the SDK. This streamlined process simplifies the integration of fault-tolerance mechanisms into applications.

:::caution Do not copy and use code

The following is pseudocode. For tested samples see your language SDK's developer's guide.

:::

```
func LoanApplicationWorkflow {

    options = {
        MaxAttempts: 3,
        StartToCloseTimeout: 30min,
        HeartbeatTimeout: 10min,
    }

    sdk.ExecuteActivity(CreditCheck, options)

    sdk.ExecuteActivity(AutomatedApproval)

    sdk.ExecuteActivity(NotifyApplicant)

    // ...
}
```

### Replays

Another quality of the SDKs lies in their ability to replay Workflow Executions, a complex operation that contributes significantly to the Platform's promised reliability.

<PrettyImage src="/diagrams/replay-basic.svg" title="The SDKs Replay code execution to continue from the last step" />

We will delve into this idea more later, but for now, it signifies that the SDKs can automatically continue a process from the point of interruption, should a failure occur.
This capability stems from the SDK's ability to persist each step the program takes.

{/* - [Developing for Durable Execution using the Go SDK](/develop/go/durable-execution) */}

## Temporal SDKs major components {#major-components}

**What are the major components of Temporal SDKs?**

Temporal SDKs offer developers the following:

- A Temporal Client to communicate with a Temporal Service
- APIs to develop application code (Workflows & Activities)
- APIs to configure and run Workers

<PrettyImage src="/diagrams/temporal-sdk-components.svg" title="Temporal SDK components create a runtime across your environment and a Temporal Service" />

Let's break down each one.

### Temporal Client

A Temporal Client acts as the bridge for communication between your applications and the Temporal Service.
The Client performs key functions that facilitate the execution of, management of, and communication with Workflows.

The most common operations that a Temporal Client enables you to perform are the following:

- Get the result of Workflow Execution.
- List Workflow Executions.
- Query a Workflow Execution.
- Signal a Workflow Execution.
- Start a Workflow Execution.

The following code is an example using the Go SDK.
It showcases how to initialize a Temporal Client, create a connection to a local Temporal Service, and start a Workflow Execution:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

- [Go SDK Temporal Client feature guide](/develop/go/temporal-clients)
- [Java SDK Temporal Client feature guide](/develop/java/temporal-clients)
- [PHP SDK Temporal Client feature guide](/develop/php/temporal-clients#connect-to-a-dev-cluster)
- [Python SDK Temporal Client feature guide](/develop/python/temporal-clients#connect-to-a-dev-cluster)
- [TypeScript SDK Temporal Client feature guide](/develop/typescript/core-application#connect-to-a-dev-cluster)

:::

```go
package main

import (
	"context"

	"go.temporal.io/sdk/client"
)

func main() {
	// Temporal Client setup code
	c, err := client.NewClient(client.Options{})
	if err != nil {
		log.Fatalln("Unable to create client", err)
	}
	defer c.Close()
	// Prepare Workflow option and parameters
	workflowOptions := client.StartWorkflowOptions{
		ID:        "loan-application-1",
		TaskQueue: "loan-application-task-queue",
	}
	applicantDetails := ApplicantDetails{
		// ...
	}
	// Start the Workflow
	workflowRun, err := c.ExecuteWorkflow(context.Background(), workflowOptions, "loan-application-workflow", applicantDetails)
	if err != nil {
		// ...
	}
	// ...
}
```

Developers can then use the Client as the main entry point for interacting with the application through Temporal.
Using that Client, developers may for example start or Signal Workflows, Query a Workflow's state, etc.
We can see in the example above how the developer has used `ExecuteWorkflow` API to start a Workflow.

### APIs to Develop Workflows

Workflows are defined as code: either a function or an object method, depending on the language.

For example, the following is a valid Temporal Workflow in Go:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func LoanApplication(ctx context.Context) (error) {
    // ...
	return nil
}
```

The Workflow code uses Temporal SDK APIs to orchestrate the steps of the application.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func LoanApplication(ctx workflow.Context, input *LoanApplicationWorkflowInput) (*LoanApplicationWorkflowResult, error) {
	// ...
	var result activities.CreditCheckResult
	f := workflow.ExecuteActivity(ctx, a.CreditCheck, CreditCheckInput(*input))
	err := f.Get(ctx, &result)
	// ...
	// Return the results
	return &loanApplicationResults, nil
}
```

A Workflow executes Activities (other functions that interact with external systems), handles and sends messages (Queries, Signals, Updates), and interacts with other Workflows.

This Workflow code, while executing, can be paused, resumed, and migrated across physical machines without losing state.

When a Workflow calls the API to execute an Activity, the Worker sends a [Command](https://docs.temporal.io/references/commands) back to the Temporal Service. The Temporal Service creates Activity Tasks in response which the same or a different Worker can then pick up and begin executing. In this way, the Worker and Temporal Service work together to incrementally execute Workflow code in a reliable way.
We discuss this more in detail in [The SDK and Temporal Service relationship](/encyclopedia/temporal-sdks#sdk-and-cluster-relationship) section.

The SDK APIs also enable developers to write code that more genuinely maps to their process. This is because without a specialized SDK, developers might have to write a lot of boilerplate code. This can lead to code that's hard to maintain, difficult to understand, or that doesn't directly correspond to the underlying business process.

For example, the bank loan application Workflow might actually look like this:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
// LoanApplicationWorkflow is the workflow definition.
func LoanApplicationWorkflow(ctx workflow.Context, applicantName string, loanAmount int) (string, error) {
	// Step 1: Notify the applicant that the application process has started
	err := workflow.ExecuteActivity(ctx, NotifyApplicantActivity, applicantName, "Application process started").Get(ctx, nil)
	if err != nil {
		return "", err
	}

	// Step 2: Perform a credit check
	var creditCheckResult string
	err = workflow.ExecuteActivity(ctx, LoanCreditCheckActivity, loanAmount).Get(ctx, &creditCheckResult)
	if err != nil {
		return "", err
	}

	// Step 3: Perform an automatic approval check
	var approvalCheckResult string
	err = workflow.ExecuteActivity(ctx, AutomaticApprovalCheckActivity, creditCheckResult).Get(ctx, &approvalCheckResult)
	if err != nil {
		return "", err
	}

	// Step 4: Notify the applicant of the decision
	var notificationResult string
	err = workflow.ExecuteActivity(ctx, NotifyApplicantActivity, applicantName, approvalCheckResult).Get(ctx, &notificationResult)
	if err != nil {
		return "", err
	}

	return notificationResult, nil
}
```

The level of abstraction that APIs offer enables the developer to focus on business logic without having to worry about the intricacies of distributed computing such as retries, or having to explicitly maintain a state machine and the intermediate state for each step of the process.

Additionally, the state of the Workflow is automatically persisted so if a failure does occur, it resumes right where it left off.

### APIs to create and manage Worker Processes

Workers are responsible for executing Workflow and Activity code (application code). The SDK provides APIs for configuring and starting Workers, enabling developers to control how the code is executed.
Workers are horizontally scalable, often run with systems like Kubernetes, and configured according to the application's needs.

Here is an example of how you could initialize a Worker using the Go SDK.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func main() {
    // Create the client object just once per process
    c, err := client.NewClient(client.Options{})
    if err != nil {
        log.Fatalln("Unable to create Temporal client", err)
    }
    defer c.Close()

    // Create the Worker instance
    w := worker.New(c, "loan-application-task-queue", worker.Options{})

    // Register the workflow and activity with the worker
    w.RegisterWorkflow(LoanApplicationWorkflow)
    w.RegisterActivity(LoanCreditCheck)

    // Start listening to the Task Queue
    err = w.Run(worker.InterruptCh())
    if err != nil {
        log.Fatalln("Unable to start Worker", err)
    }
}
```

The Worker polls on the specified Task Queue, processing those Tasks, and reporting the results back to the Temporal Service. They execute both the Workflows and Activities, and the SDK ensures that they perform these tasks efficiently and reliably.

### APIs to customize Activity Execution behavior

Activities in Temporal are individual units of work that often represent non-deterministic parts of the code logic, such as querying a database or calling an external service. The SDK provides APIs to customize the behavior of an Activity Execution.

By default, if an Activity attempts to communicate with another system and encounters a transient failure like a network issue, Temporal ensures the Activity is tried again automatically.

However, Temporal enables developers to control a variety of timeouts, a Retry Policy, Heartbeat monitoring, and asynchronous completion.

The following code is an example of a custom set of Activity Execution options that affect the timeout and retry behavior of the execution, should the Activity encounter a failure.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
// LoanApplicationWorkflow is the Workflow Definition.
func LoanApplicationWorkflow(ctx workflow.Context, applicantName string, loanAmount int) (string, error) {
    // ...
    var creditCheckResult string
    // set a Retry Policy
    ao := workflow.ActivityOptions{
		ScheduleToCloseTimeout: time.Hour,
		HeartbeatTimeout:       time.Minute,
		RetryPolicy:            &temporal.RetryPolicy{
			InitialInterval:    time.Second,
			BackoffCoefficient: 2,
			MaximumInterval:    time.Minute,
			MaximumAttempts:    5,
		},
	}
    ctx = workflow.WithActivityOptions(ctx, ao)
    err = workflow.ExecuteActivity(ctx, LoanCreditCheckActivity, loanAmount).Get(ctx, &creditCheckResult)
    if err != nil {
        return "", err
    }
	// ...
    return notificationResult, nil
}

// LoanCreditCheckActivity is an Activity function that performs a credit check.
func LoanCreditCheckActivity(ctx context.Context, loanAmount int) (string, error) {
	// ... your logic here ...
	return "Credit check passed", nil
}
```

## The SDK and Temporal Service relationship {#sdk-and-cluster-relationship}

**How do the Temporal SDKs work with the Temporal Service?**

The Temporal Service functions more as a choreographer than a conductor. Rather than directly assigning tasks to Workers, the Temporal Service arranges the Tasks into a Task Queue while Workers poll the Task Queue. Developers may create a fleet of Workers and tune them so that a Task is picked up as soon as it is available. If a Worker goes down, Tasks can wait until the next Worker is available.

A Workflow might request to execute an Activity, start a Timer, or start a Child Workflow, each of which translates into a Command, dispatched to the Temporal Service.
In addition to acting on these Commands, the Temporal Service documents that interaction by appending their corresponding Events into to the Workflow Execution's Event History.

Take for instance the call to execute an Activity. When a Workflow invokes it, the Worker doesn't immediately execute that Activity code. Instead, it generates a ScheduleActivityTask Command, dispatching it to the Cluster. In response, the Cluster queues up a new Activity Task. Only when a Worker finds itself free, it collects the task and begins executing the Activity code.

The Temporal Service persists Workflow Execution Event History, so that if there is a failure, the SDK Worker is able to Replay the execution and resume where it left off.

This is where the deterministic constraints of the Workflow code comes into play, requiring the use of Activities to create side effects and interact with the outside world.

Let's look at an example Workflow with a single Activity.

```go
func LoanApplication(ctx workflow.Context, input *LoanApplicationWorkflowInput) (*LoanApplicationWorkflowResult, error) {

	ctx = workflow.WithActivityOptions(ctx, workflow.ActivityOptions{
		StartToCloseTimeout: time.Minute,
	})

	var result activities.NotifyApplicantActivityResult
	f := workflow.ExecuteActivity(ctx, a.NotifyApplicantActivity, NotifyApplicantActivityInput(*input))

	err := f.Get(ctx, &result)

	// Return the results
	return &l.LoanApplicationState, nil
}

type Activities struct {}

func (a *Activities) NotifyApplicantActivity(ctx context.Context, input *NotifyApplicantActivityInput) (*NotifyApplicantActivityResult, error) {
	var result NotifyApplicantActivityResult

	// Call the thirdparty API and handle the result

	return &result, err
}
```

The Activity above is performing a single call to an external API. Since the call can fail due to transient issues, we define it outside of the Workflow and provide it with retry options.

When you create a new Worker process, the Worker creates a long-lasting connection to the Temporal Service, polling a Task Queue for Tasks that related to the code it is capable of executing.

<PrettyImage src="/diagrams/how-sdk-works-1.svg" title="A Worker long polls for Tasks" />

Although the Worker is now running, unless a Workflow is explicitly started, the Task Queue doesn't have any Tasks on it and so, no code executes.
We can use a Temporal Client (available in Temporal SDKs and the Temporal CLI) to start a new Workflow.

<PrettyImage src="/diagrams/how-sdk-works-2.svg" title="Start a Workflow using a Temporal Client" />

Starting a Workflow Execution creates a new Event, WorkflowExecutionStarted, and adds it to the Workflow Execution's Event History.

The Temporal Service then schedules a Workflow Task by adding it to the Task Queue.
When the Worker has capacity, it picks up this Task, and begin executing code.

Each step of the Task (e.g. Scheduled, Started, and Completed), gets recorded into the Event History.

- Scheduled means that the Temporal Service has added a Task to the Task Queue.
- Started means that the Worker has dequeued the Task.
- Completed means that the Worker finished executing the Task by responding to the Temporal Service.

When the call to invoke the Activity is evaluated, the Worker suspends executing the code and sends a Command to the Temporal Service to schedule an Activity Task.

<PrettyImage src="/diagrams/how-sdk-works-3.svg" title="Worker suspends code execution and sends a Command to the Temporal Service" />

When the Worker process can perform more work, it picks up the Activity Task and begins executing the Activity code, which includes the call to the external API.

If the Activity fails, say the API goes down, Temporal will automatically retry the Activity with one second between intervals, as the configurations have defined, an infinite amount of times until the Activity succeeds or is canceled.

In the case where the calls succeeds, and the code completes, the Worker tells the Temporal Service the Activity Task completed.

<PrettyImage src="/diagrams/how-sdk-works-activity.svg" title="The Worker reports that the Activity Execution completed" />

Included is any data that was returned from the Activity (results of the API call), which is then persisted in the Workflow Execution Event History, and is now accessible to the Workflow code.

The Temporal Service creates a new Workflow Task which the Worker picks up.

<PrettyImage src="/diagrams/how-sdk-works-1.svg" title="The Worker picks up the new Task" />

This is when the SDK Worker Replays the Workflow code, uses the Event History as guidance on what to expect. If the Replay encounters an Event that doesn't match up with what is expected from the code, a [non-determinism](/references/errors#non-deterministic-error) error gets thrown.

If there is alignment, the Worker continues evaluating code.

Assuming the Activity Execution is successful, the Workflow now has the result of the Activity and the Worker is able to finish evaluating and executing the Workflow code, responding to the Temporal Service when complete.

The result of the Workflow can now be retrieved using a Temporal Client.

<PrettyImage src="/diagrams/how-sdk-works-4.svg" title="The Temporal Client can now access the result of the Workflow" />

And that’s how a Temporal Worker and Temporal Service work together.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/visibility/search-attributes.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/visibility/search-attributes.mdx</path>
  <content>
---
id: search-attribute
title: Search Attributes
sidebar_label: Search Attributes
description: This guide on Temporal Search Attributes explains how to set up, configure, and use default and custom Search Attributes in Temporal Server versions. Learn about supported types, limits, and how to use them to enhance Workflow filtering and querying.
slug: /search-attribute
toc_max_heading_level: 4
keywords:
  - explanation
  - filtered-lists
  - term
  - visibility
  - search attribute
tags:
  - Concepts
  - Visibility
  - Search Attributes
---

This page discusses the following:
- [Search Attributes](#search-attribute)
- [Default Search Attributes](#default-search-attribute)
- [Custom Search Attributes](#custom-search-attribute)

## What is a Search Attribute? {#search-attribute}

A Search Attribute is an indexed field used in a [List Filter](/list-filter) to filter a list of [Workflow Executions](/workflows#workflow-execution) that have the Search Attribute in their metadata.

Each Search Attribute is a key-value pair metadata object included in a Workflow Execution's Visibility information.
This information is available in the Visibility store.

:::note

Search Attribute values are not encrypted because the Temporal Server must be able to read these values from the Visibility store when retrieving Workflow Execution details.

:::

Temporal provides some [default Search Attributes](/search-attribute#default-search-attribute), such as `ExecutionStatus`, the current state of your Workflow Executions.
You can also create [custom Search Attribute](/search-attribute#custom-search-attribute) keys in your Visibility store and assign values when starting a Workflow Execution or in Workflow code.

When using [Continue-As-New](/workflows#continue-as-new) or a [Temporal Cron Job](/workflows#temporal-cron-job), Search Attribute keys are carried over to the new Workflow Run by default.
Search Attribute values are only available for as long as the Workflow is.

Search Attributes are most effective for search purposes or tasks requiring collection-based result sets.
For business logic in which you need to get information about a Workflow Execution, consider one of the following:

- Storing state in a local variable and exposing it with a Query.
- Storing state in an external datastore through Activities and fetching it directly from the store.

If your business logic requires high throughput or low latency, store and fetch the data through Activities.
You might experience lag due to time passing between the Workflow's state change and the Activity updating the Visibility store.

### Default Search Attributes {#default-search-attribute}

A Temporal Service has a set of default Search Attributes already available.
Default Search Attributes are set globally in any Namespace.
These Search Attributes are created when the initial index is created.

| NAME                       | TYPE         | DEFINITION                                                                                                                                                                                                   |
| -------------------------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| BatcherUser                | Keyword      | Used by internal batcher Workflow that runs in `TemporalBatcher` Namespace division to indicate the user who started the batch operation.                                                                    |
| BinaryChecksums            | Keyword List | List of binary Ids of Workers that run the Workflow Execution. Deprecated since server version 1.21 in favor of the `BuildIds` search attribute.                                                             |
| BuildIds                   | Keyword List | List of Worker Build Ids that have processed the Workflow Execution, formatted as `versioned:{BuildId}` or `unversioned:{BuildId}`, or the sentinel `unversioned` value. Available from server version 1.21. |
| CloseTime                  | Datetime     | The time at which the Workflow Execution completed.                                                                                                                                                          |
| ExecutionDuration          | Int          | The time needed to run the Workflow Execution (in nanoseconds). Available only for closed Workflows.                                                                                                         |
| ExecutionStatus            | Keyword      | The current state of the Workflow Execution.                                                                                                                                                                 |
| ExecutionTime              | Datetime     | The time at which the Workflow Execution actually begins running; same as `StartTime` for most cases but different for Cron Workflows and retried Workflows.                                                 |
| HistoryLength              | Int          | The number of events in the history of Workflow Execution. Available only for closed Workflows.                                                                                                              |
| HistorySizeBytes           | Long         | The size of the Event History.                                                                                                                                                                               |
| RunId                      | Keyword      | Identifies the current Workflow Execution Run.                                                                                                                                                               |
| StartTime                  | Datetime     | The time at which the Workflow Execution started.                                                                                                                                                            |
| StateTransitionCount       | Int          | The number of times that Workflow Execution has persisted its state. Available only for closed Workflows.                                                                                                    |
| TaskQueue                  | Keyword      | Task Queue used by Workflow Execution.                                                                                                                                                                       |
| TemporalChangeVersion      | Keyword List | Stores change/version pairs if the GetVersion API is enabled.                                                                                                                                                |
| TemporalScheduledStartTime | Datetime     | The time that the Workflow is schedule to start according to the Schedule Spec. Can be manually triggered. Set on Schedules.                                                                                 |
| TemporalScheduledById      | Keyword      | The Id of the Schedule that started the Workflow.                                                                                                                                                            |
| TemporalSchedulePaused     | Boolean      | Indicates whether the Schedule has been paused. Set on Schedules.                                                                                                                                            |
| WorkflowId                 | Keyword      | Identifies the Workflow Execution.                                                                                                                                                                           |
| WorkflowType               | Keyword      | The type of Workflow.                                                                                                                                                                                        |

- All default Search Attributes are reserved and read-only.
  You cannot create a custom one with the same name or alter the existing one.

- Search attributes are not encrypted in the system.
  Do not use PII as either the search attribute name or the value.

- ExecutionStatus values correspond to Workflow Execution statuses: Running, Completed, Failed, Canceled, Terminated, ContinuedAsNew, TimedOut.

- StartTime, CloseTime, and ExecutionTime are stored as dates but are supported by queries that use either EpochTime in nanoseconds or a string in [RFC3339Nano format](https://pkg.go.dev/time#pkg-constants) (such as "2006-01-02T15:04:05.999999999Z07:00").

- ExecutionDuration is stored in nanoseconds but is supported by queries that use integers in nanoseconds, [Golang duration format](https://pkg.go.dev/time#ParseDuration), or "hh:mm:ss" format.

- CloseTime, HistoryLength, StateTransitionCount, and ExecutionDuration are present only in a closed Workflow Execution.

- ExecutionTime can differ from StartTime in retry and cron use cases.

You can use the default Search Attributes in a List Filter, such as in the Temporal Web UI or with the `temporal workflow list` commands, under the following conditions:

- Without advanced Visibility, you can only use the `=` operator with a single default Search Attribute in your List Filter.
  For example: `temporal workflow list --query "ExecutionStatus = 'Completed'"` or `temporal workflow list --query "WorkflowType = 'YourWorkflow'"`.
- With advanced Visibility, you can combine default Search Attributes in a List Filter to get a list of specific Workflow Executions.
  For example: `temporal workflow list --query "WorkflowType = 'main.YourWorkflowDefinition' and ExecutionStatus != 'Running' and (StartTime > '2022-06-07T16:46:34.236-08:00' or CloseTime < '2022-06-08T16:46:34-08:00')"`

### Custom Search Attributes {#custom-search-attribute}

You can [create custom Search Attributes](/self-hosted-guide/visibility#create-custom-search-attributes) with unique key names that are relevant to your business needs.

Use custom Search Attributes in a List Filter, such as in the Temporal Web UI or with the `temporal workflow list` commands, under the following conditions:

- Without advanced Visibility, you cannot use a custom Search Attribute in your List Filter.
- With advanced Visibility, you can create multiple custom Search Attributes and use them in combinations with List Filters to get a list of specific Workflow Executions.
  For example: `temporal workflow list --query "WorkflowType = 'main.YourWorkflowDefinition' and YourCustomSA = 'YourCustomSAValue' and (StartTime > '2022-06-07T16:46:34.236-08:00' or CloseTime < '2022-06-08T16:46:34-08:00')"`
  - With Temporal Server v1.19 and earlier, you must [integrate Elasticsearch](/self-hosted-guide/visibility#elasticsearch) to use custom Search Attributes with List Filters.
  - With Temporal Server v1.20 and later, custom Search Attribute capabilities are available on MySQL (v8.0.17 or later), PostgreSQL (v12 and later), and SQLite (v3.31.0 and later), in addition to Elasticsearch.

If you use Elasticsearch as your Visibility store, your custom Search Attributes apply globally and can be used across Namespaces.
However, if using any of the [supported SQL databases](/self-hosted-guide/visibility) with Temporal Server v1.20 and later, your custom Search Attributes are associated with a specific Namespace and can be used for Workflow Executions in that Namespace.

See [custom Search Attributes limits](/search-attribute#custom-search-attribute-limits) for limits on the number and size of custom Search Attributes you can create.

#### Supported types {#supported-types}

Custom Search Attributes must be one of the following types:

- Bool
- Datetime
- Double
- Int
- Keyword
- KeywordList
- Text

Note:

- **Double** is backed up by `scaled_float` Elasticsearch type with scale factor 10000 (4 decimal digits).
- **Datetime** is backed up by `date` type with milliseconds precision in Elasticsearch 6 and `date_nanos` type with nanoseconds precision in Elasticsearch 7.
- **Int** is 64-bit integer (`long` Elasticsearch type).
- **Keyword** and **Text** types are concepts taken from Elasticsearch. Each word in a **Text** is considered a searchable keyword.
  For a UUID, that can be problematic because Elasticsearch indexes each portion of the UUID separately.
  To have the whole string considered as a searchable keyword, use the **Keyword** type.
  For example, if the key `ProductId` has the value of `2dd29ab7-2dd8-4668-83e0-89cae261cfb1`:
  - As a **Keyword** it would be matched only by `ProductId = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1`.
  - As a **Text** it would be matched by `ProductId = 2dd8`, which could cause unwanted matches.
- With Temporal Server v1.19 and earlier, the **Keyword** type can store a list of values.
- With Temporal Server v1.20 and later, the **Keyword** type supports only a single value.
  To store a list of values, use **KeywordList**.
- The **Text** type cannot be used in the "Order By" clause.

#### Custom Search Attributes limits {#custom-search-attribute-limits}

{/* TODO - [How to configure maximum number of Search Attribute keys per Cluster](#) */}

The following table lists the maximum number of custom Search Attributes you can create per Namespace by supported Visibility database.

| Search Attribute type | MySQL (v8.0.17 and later) | PostgreSQL (v12 and later) | SQLite (v3.31.0 and later) | Temporal Cloud |
| --------------------- | :-----------------------: | :------------------------: | :------------------------: | :------------: |
| Bool                  |             3             |             3              |             3              |       20       |
| Datetime              |             3             |             3              |             3              |       20       |
| Double                |             3             |             3              |             3              |       20       |
| Int                   |             3             |             3              |             3              |       20       |
| Keyword               |            10             |             10             |             10             |       40       |
| KeywordList           |             3             |             3              |             3              |       5        |
| Text                  |             3             |             3              |             3              |       5        |

Temporal does not impose a limit on the number of custom Search Attributes you can create with Elasticsearch. However, [Elasticsearch sets a default mapping limit](https://www.elastic.co/guide/en/elasticsearch/reference/8.6/mapping-settings-limit.html) that may apply.
Custom Search Attributes are an advanced Visibility feature and are not supported on Cassandra.

Size limits for a custom Search Attribute:

{/*
_This refers to the SA key you create in the visibility store with `tctl search-attribute create`. this value is no longer applicable so commenting out for ref later_
Default total maximum number of Search Attribute **keys** per Temporal Service is 100. */}

- The default single Search Attribute **value** size limit is 2 KB.

{/* TODO - [How to configure Search Attribute value size limit](#) */}

- The maximum total Search Attribute size is 40 KB.

{/* TODO - [How to configure total Search Attribute size limit](#) */}

- The maximum total characters per Search Attribute value is 255.

{/* temp keeping for reference
This is configurable with [`SearchAttributesNumberOfKeysLimit`, `SearchAttributesTotalSizeLimit` and `SearchAttributesSizeOfValueLimit`](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L440-L442), if you know what you are doing.
*/}

For Temporal Cloud specific configurations, see the [Defaults, limits, and configurable settings -Temporal Cloud](/cloud/limits#number-of-custom-search-attributes) guide.

### Usage {#usage}

Search Attributes available in your Visibility store can be used with Workflow Executions for the Temporal Service.
To actually have results from the use of a [List Filter](/list-filter), Search Attributes must be added to a Workflow Execution as metadata.

- To create custom Search Attributes in your Visibility store, see [Create custom Search Attributes](/self-hosted-guide/visibility#create-custom-search-attributes).
- To remove a custom Search Attribute from the Visbility store, see [Remove custom Search Attributes](/self-hosted-guide/visibility#remove-custom-search-attributes).
  Removing custom Search Attributes is not supported on Temporal Cloud.
- To rename a custom Search Attribute on Temporal Cloud, see [`tcld namespace search-attributes rename`](/cloud/tcld/namespace/#rename).

With Workflows you can do the following:

- Set the value of Search Attributes in your Workflow
- Update the value set for a Search Attribute from within the Workflow code
- Remove the value set for a Search Attribute from within the Workflow code


:::info Manage Search Attributes by SDK

- [How to manage Search Attributes using the Go SDK](/develop/go/observability#visibility)
- [How to manage Search Attributes using the Java SDK](/develop/java/observability#visibility)
- [How to manage Search Attributes using the PHP SDK](/develop/php/observability#visibility)
- [How to manage Search Attributes using the Python SDK](/develop/python/observability#visibility)
- [How to manage Search Attributes using the TypeScript SDK](/develop/typescript/observability#visibility)
- [How to manage Search Attributes using the .NET SDK](/develop/dotnet/observability#search-attributes)

::: 

- To get a list of Search Attributes using the Temporal CLI, issue `temporal operator search-attribute list`. See [Search Attributes](/search-attribute).

After you add and set your Search Attributes, use your default or custom Search Attributes in a List Filter.

{/* commenting out this part. added this detail in how to create a custom search attribute under clusters.
The [temporalio/auto-setup](https://hub.docker.com/r/temporalio/auto-setup) Docker image uses a pre-defined set of custom Search Attributes that are handy for testing.
Their names indicate their types:

- CustomBoolField
- CustomDatetimeField
- CustomDoubleField
- CustomIntField
- CustomKeywordField
- CustomTextField
  */}

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/child-workflows.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/child-workflows.mdx</path>
  <content>
---
id: child-workflows
title: Child Workflows - Python SDK
sidebar_label: Child Workflows
description: Learn how to start a Child Workflow Execution and set a Parent Close Policy using the Temporal Python SDK. Ensure proper progress logging and specify Parent Workflow behavior upon closure.
toc_max_heading_level: 2
keywords:
  - child workflow execution
  - spawn child workflow
  - child workflow events
  - parent close policy
  - child workflow options
  - execute child workflow
  - start child workflow
tags:
  - Workflows
  - Child Workflows
  - Python SDK
  - Temporal SDKs
---

This page shows how to do the following:

- [Start a Child Workflow Execution](#child-workflows)
- [Set a Parent Close Policy](#parent-close-policy)

## Start a Child Workflow Execution {#child-workflows}

**How to start a Child Workflow Execution using the Temporal Python SDK.**

A [Child Workflow Execution](/encyclopedia/child-workflows) is a Workflow Execution that is scheduled from within another Workflow using a Child Workflow API.

When using a Child Workflow API, Child Workflow related Events ([StartChildWorkflowExecutionInitiated](/references/events#startchildworkflowexecutioninitiated), [ChildWorkflowExecutionStarted](/references/events#childworkflowexecutionstarted), [ChildWorkflowExecutionCompleted](/references/events#childworkflowexecutioncompleted), etc...) are logged in the Workflow Execution Event History.

Always block progress until the [ChildWorkflowExecutionStarted](/references/events#childworkflowexecutionstarted) Event is logged to the Event History to ensure the Child Workflow Execution has started.
After that, Child Workflow Executions may be abandoned using the _Abandon_ [Parent Close Policy](/encyclopedia/child-workflows#parent-close-policy) set in the Child Workflow Options.

To be sure that the Child Workflow Execution has started, first call the Child Workflow Execution method on the instance of Child Workflow future, which returns a different future.

Then get the value of an object that acts as a proxy for a result that is initially unknown, which is what waits until the Child Workflow Execution has spawned.

To spawn a Child Workflow Execution in Python, use the [`execute_child_workflow()`](https://python.temporal.io/temporalio.workflow.html#execute_child_workflow) function which starts the Child Workflow and waits for completion or
use the [`start_child_workflow()`](https://python.temporal.io/temporalio.workflow.html#start_child_workflow) function to start a Child Workflow and return its handle.
This is useful if you want to do something after it has only started, or to get the Workflow/Run ID, or to be able to signal it while running.

:::note

`execute_child_workflow()` is a helper function for `start_child_workflow()` plus `await handle`.

:::

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_child_workflow/your_child_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@workflow.defn
class ComposeGreetingWorkflow:
    @workflow.run
    async def run(self, input: ComposeGreetingInput) -> str:
        return f"{input.greeting}, {input.name}!"


@workflow.defn
class GreetingWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_child_workflow(
            ComposeGreetingWorkflow.run,
            ComposeGreetingInput("Hello", name),
            id="hello-child-workflow-workflow-child-id",
# ...
        )
```

### Set a Parent Close Policy {#parent-close-policy}

**How to set a Parent Close Policy**

A [Parent Close Policy](/encyclopedia/child-workflows#parent-close-policy) determines what happens to a Child Workflow Execution if its Parent changes to a Closed status (Completed, Failed, or Timed Out).

The default Parent Close Policy option is set to terminate the Child Workflow Execution.

Set the `parent_close_policy` parameter inside the [`start_child_workflow`](https://python.temporal.io/temporalio.workflow.html#start_child_workflow) function or the [`execute_child_workflow()`](https://python.temporal.io/temporalio.workflow.html#execute_child_workflow) function to specify the behavior of the Child Workflow when the Parent Workflow closes.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_child_workflow/your_child_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio.workflow import ParentClosePolicy
# ...
# ...
@workflow.defn
class ComposeGreetingWorkflow:
    @workflow.run
    async def run(self, input: ComposeGreetingInput) -> str:
        return f"{input.greeting}, {input.name}!"


@workflow.defn
class GreetingWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_child_workflow(
            ComposeGreetingWorkflow.run,
            ComposeGreetingInput("Hello", name),
            id="hello-child-workflow-workflow-child-id",
            parent_close_policy=ParentClosePolicy.ABANDON,
        )
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/continue-as-new.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/continue-as-new.mdx</path>
  <content>
---
id: continue-as-new
title: Continue-As-New - Python SDK
sidebar_label: Continue-As-New
description: Learn how to use Temporal's Continue-As-New in Python to manage large Event Histories by atomically creating new Workflow Executions with the same Workflow Id and fresh parameters.
toc_max_heading_level: 2
keywords:
  - continue-as-new workflow
  - restart workflow
  - fresh event history
  - avoid large event histories
  - temporal python continue-as-new
tags:
  - Workflows
  - continue-as-new
  - Python SDK
  - Temporal SDKs
---

**How to Continue-As-New using the Temporal Python SDK.**

[Continue-As-New](/workflows#continue-as-new) enables a Workflow Execution to close successfully and create a new Workflow Execution in a single atomic operation if the number of Events in the Event History is becoming too large.
The Workflow Execution spawned from the use of Continue-As-New has the same Workflow Id, a new Run Id, and a fresh Event History and is passed all the appropriate parameters.

To Continue-As-New in Python, call the [`continue_as_new()`](https://python.temporal.io/temporalio.workflow.html#continue_as_new) function from inside your Workflow, which will stop the Workflow immediately and Continue-As-New.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/continue_as_new/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@workflow.defn
class LoopingWorkflow:
    @workflow.run
    async def run(self, iteration: int) -> None:
        if iteration == 5:
            return
        await asyncio.sleep(10)
        workflow.continue_as_new(iteration + 1)
```

:::warning Using Continue-as-New and Updates

- Temporal _does not_ support Continue-as-New functionality within Update handlers.
- Complete all handlers _before_ using Continue-as-New.
- Use Continue-as-New from your main Workflow Definition method, just as you would complete or fail a Workflow Execution.

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/activity.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/activity.mdx</path>
  <content>
---
id: activity
title: Temporal CLI activity command reference
sidebar_label: activity
description: Learn how to use Temporal Activity commands for completing or failing Activity Executions in your Workflow. Optimize your Temporal Workflow management effectively.
toc_max_heading_level: 4
keywords:
  - activity
  - activity complete
  - activity execution
  - activity fail
  - activity update-options
  - activity pause
  - activity unpause
  - activity reset
  - cli reference
  - cli-feature
  - command-line-interface-cli
  - temporal cli
tags:
  - Activities
  - Temporal CLI
---

# Temporal CLI activity command reference

Activity commands operate on [Activity Executions](/activities#activity-execution).

Activity commands follow this syntax:
`temporal activity [command] [command options]`

## complete

The `temporal activity complete` command completes an [Activity Execution](/activities#activity-execution).
Along with completing the Activity, the result given upon return can be set as well.

`temporal activity complete --activity-id=MyActivity --result=ActivityComplete`

Use the following options to change the behavior of this command.

- [--activity-id](/cli/cmd-options#activity-id)

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--identity](/cli/cmd-options#identity)

- [--namespace](/cli/cmd-options#namespace)

- [--result](/cli/cmd-options#result)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## fail

The `temporal activity fail` command fails an [Activity Execution](/activities#activity-execution).
The Activity must already be running on a valid [Workflow](/workflows).

`temporal fail --workflow-id=meaningful-business-id --activity-id=MyActivity`

Use the following options to change the behavior of this command.

- [--activity-id](/cli/cmd-options#activity-id)

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--detail](/cli/cmd-options#detail)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--identity](/cli/cmd-options#identity)

- [--namespace](/cli/cmd-options#namespace)

- [--reason](/cli/cmd-options#reason)

- [--run-id](/cli/cmd-options#run-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

## update-options

The `temporal activity update-options` command lets you fix running Activities by updating the options that were passed in by the Activity's Parent Workflow.

The Activity must already be running on a valid [Workflow](/workflows).
Updates are incremental, only changing the specified options. Either the Activity Id or Activity Type must be provided.
If Activity Type is provided, and there are multiple pending Activities of the provided type, then all of them will be updated.
The command will return the new Activity options for an [Activity Execution](/activities#activity-execution).

Use the following options to change the behavior of this command.

Routing options:
- [--activity-id](/cli/cmd-options#activity-id)
- [--activity-type](/cli/cmd-options#activity-type)
- [--workflow-id](/cli/cmd-options#workflow-id)
- [--run-id](/cli/cmd-options#run-id)
- [--namespace](/cli/cmd-options#namespace)


You can update the following Activity options:

- [--task-queue](/cli/cmd-options#task-queue)
- [--schedule-to-close-timeout](/cli/cmd-options#schedule-to-close-timeout)
- [--schedule-to-start-timeout](/cli/cmd-options#schedule-to-start-timeout)
- [--start-to-close-timeout](/cli/cmd-options#start-to-close-timeout)
- [--heartbeat-timeout](/cli/cmd-options#heartbeat-timeout)
- [--retry-initial-interval](/cli/cmd-options#retry-initial-interval)
- [--retry-maximum-interval](/cli/cmd-options#retry-maximum-interval)
- [--retry-backoff-coefficient](/cli/cmd-options#retry-backoff-coefficient)
- [--retry-maximum-attempts](/cli/cmd-options#retry-maximum-attempts)

Other options:
- [--identity](/cli/cmd-options#identity)
- [--tls](/cli/cmd-options#tls)
- [--tls-ca-path](/cli/cmd-options#tls-ca-path)
- [--tls-cert-path](/cli/cmd-options#tls-cert-path)
- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)
- [--tls-key-path](/cli/cmd-options#tls-key-path)
- [--tls-server-name](/cli/cmd-options#tls-server-name)
- [--address](/cli/cmd-options#address)
- [--codec-auth](/cli/cmd-options#codec-auth)
- [--codec-endpoint](/cli/cmd-options#codec-endpoint)
- [--color](/cli/cmd-options#color)
- [--command-timeout](/cli/cmd-options#command-timeout)
- [--detail](/cli/cmd-options#detail)
- [--env](/cli/cmd-options#env)
- [--grpc-meta](/cli/cmd-options#grpc-meta)

## pause

The `temporal activity pause` command pauses an [Activity Execution](/activities#activity-execution) specified by its ID or type.
Pausing the Activity can be undone by using the `temporal activity unpause` command.

Pausing an Activity means:
* If the Activity is currently waiting for a retry or is running and subsequently fails, it will not be rescheduled until it is unpaused.
* If the Activity is already paused, calling this method will have no effect.
* If the Activity is running and finishes successfully, the Activity will be completed.
* If the Activity is running and finishes with failure:
  * If no retries remain, the Activity will be completed.
  * If retries remain, the Activity will be paused.

If Activity Type is provided and multiple pending Activities of the provided type exist, all of them will be paused.

For long-running Activities, Activities in a paused state will send a cancellation with `activity_paused` set to `true` as a part of [Activity Heartbeat](/encyclopedia/detecting-activity-failures#activity-heartbeat) response.
You can choose how you would like to handle this case in your Activity.

This command returns a `NotFound` error if there is no pending Activity with the provided ID or type.
Use the following options to change the behavior of this command.

Routing options:
- [--activity-id](/cli/cmd-options#activity-id)
- [--activity-type](/cli/cmd-options#activity-type)
- [--workflow-id](/cli/cmd-options#workflow-id)
- [--run-id](/cli/cmd-options#run-id)
- [--namespace](/cli/cmd-options#namespace)

Other options:
  - [--identity](/cli/cmd-options#identity)
  - [--tls](/cli/cmd-options#tls)
  - [--tls-ca-path](/cli/cmd-options#tls-ca-path)
  - [--tls-cert-path](/cli/cmd-options#tls-cert-path)
  - [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)
  - [--tls-key-path](/cli/cmd-options#tls-key-path)
  - [--tls-server-name](/cli/cmd-options#tls-server-name)
  - [--address](/cli/cmd-options#address)
  - [--codec-auth](/cli/cmd-options#codec-auth)
  - [--codec-endpoint](/cli/cmd-options#codec-endpoint)
  - [--color](/cli/cmd-options#color)
  - [--command-timeout](/cli/cmd-options#command-timeout)
  - [--detail](/cli/cmd-options#detail)
  - [--env](/cli/cmd-options#env)
  - [--grpc-meta](/cli/cmd-options#grpc-meta)

## unpause

The `temporal activity unpause` command unpauses an [Activity Execution](/activities#activity-execution) specified by its ID or type.
If there are multiple pending Activities of the provided type, then all of them will be unpaused.
If Activity is not paused, this call will have no effect.
If the Activity was paused while waiting for retry, it will be scheduled immediately (* see 'jitter' flag).
Once the Activity is unpaused, all Timeout timers will be regenerated.

Command will fail with a `NotFound` error if there is no pending Activity with the provided ID or type.

Activities can be unpaused in bulk via a visibility Query list filter:

```
temporal activity unpause --query YourQuery \
    --reason YourReasonForUnpause
```


Routing options:
- [--activity-id](/cli/cmd-options#activity-id)
- [--activity-type](/cli/cmd-options#activity-type)
- [--workflow-id](/cli/cmd-options#workflow-id)
- [--run-id](/cli/cmd-options#run-id)
- [--namespace](/cli/cmd-options#namespace)

Unpause specific options:
- [--match-all](/cli/cmd-options#match-all)
- [--reset-attempts](/cli/cmd-options#reset-attempts)
- [--reset-heartbeat](/cli/cmd-options#reset-heartbeat)
- [--jitter](/cli/cmd-options#activity-jitter)

Other options:
  - [--identity](/cli/cmd-options#identity)
  - [--tls](/cli/cmd-options#tls)
  - [--tls-ca-path](/cli/cmd-options#tls-ca-path)
  - [--tls-cert-path](/cli/cmd-options#tls-cert-path)
  - [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)
  - [--tls-key-path](/cli/cmd-options#tls-key-path)
  - [--tls-server-name](/cli/cmd-options#tls-server-name)
  - [--address](/cli/cmd-options#address)
  - [--codec-auth](/cli/cmd-options#codec-auth)
  - [--codec-endpoint](/cli/cmd-options#codec-endpoint)
  - [--color](/cli/cmd-options#color)
  - [--command-timeout](/cli/cmd-options#command-timeout)
  - [--detail](/cli/cmd-options#detail)
  - [--env](/cli/cmd-options#env)
  - [--grpc-meta](/cli/cmd-options#grpc-meta)

## reset

The `temporal activity reset` command restarts a running [Activity Execution](/activities#activity-execution) specified by its ID or type.
If there are multiple pending activities of the provided type - all of them will be reset.
Resetting an Activity means:
* The number of attempts will be reset to 0;
* Activity timeouts will be reset;
* If the Activity is waiting for retry, it will be scheduled immediately (* see 'jitter' flag);
* If the Activity is currently executing, it will be reset once/if it completes with failure;
* If the Activity is paused, it will be unpaused. If you want it to stay paused, you can pass --keep-paused flag;

Command will fail with a `NotFound` error if there is no pending Activity with the provided ID or type.
This may happen if the Activity has already completed.

Routing options:
- [--activity-id](/cli/cmd-options#activity-id)
- [--activity-type](/cli/cmd-options#activity-type)
- [--workflow-id](/cli/cmd-options#workflow-id)
- [--run-id](/cli/cmd-options#run-id)
- [--namespace](/cli/cmd-options#namespace)

Reset specific options:
- [--keep-paused](/cli/cmd-options#keep-paused)
- [--reset-heartbeat](/cli/cmd-options#reset-heartbeat)
- [--jitter](/cli/cmd-options#activity-jitter)

Other options:
  - [--identity](/cli/cmd-options#identity)
  - [--tls](/cli/cmd-options#tls)
  - [--tls-ca-path](/cli/cmd-options#tls-ca-path)
  - [--tls-cert-path](/cli/cmd-options#tls-cert-path)
  - [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)
  - [--tls-key-path](/cli/cmd-options#tls-key-path)
  - [--tls-server-name](/cli/cmd-options#tls-server-name)
  - [--address](/cli/cmd-options#address)
  - [--codec-auth](/cli/cmd-options#codec-auth)
  - [--codec-endpoint](/cli/cmd-options#codec-endpoint)
  - [--color](/cli/cmd-options#color)
  - [--command-timeout](/cli/cmd-options#command-timeout)
  - [--detail](/cli/cmd-options#detail)
  - [--env](/cli/cmd-options#env)
  - [--grpc-meta](/cli/cmd-options#grpc-meta)


  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/retry-policies.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/retry-policies.mdx</path>
  <content>
---
id: retry-policies
title: What is a Temporal Retry Policy?
sidebar_label: Retry Policies
description: Optimize your Workflow and Activity Task Executions with a custom Retry Policy on Temporal. Understand default retries, intervals, backoff, and maximum attempts for error handling.
toc_max_heading_level: 4
keywords:
  - activities
  - retry policy
tags:
  - Activities
  - Concepts
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

A Retry Policy works in cooperation with the timeouts to provide fine controls to optimize the execution experience.

A Retry Policy is a collection of attributes that instructs the Temporal Server how to retry a failure of a [Workflow Execution](/workflows#workflow-execution) or an [Activity Task Execution](/tasks#activity-task-execution).
Note that Retry Policies do not apply to [Workflow Task Executions](/tasks#workflow-task-execution), which retry until the Workflow Execution Timeout, which is unlimited by default.

Try out the [Activity retry simulator](/develop/activity-retry-simulator) to visiualize how a Retry Policy works.

---

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Go" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Java" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in PHP" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Python" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in TypeScript" archetype="feature-guide" />
</RelatedReadContainer>

---

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Go" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Java" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in PHP" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Python" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in TypeScript" archetype="feature-guide" />
</RelatedReadContainer>

## Default behavior

- **Workflow Execution:** When a Workflow Execution is spawned, it is not associated with a default Retry Policy and thus does not retry by default.
  The intention is that a Workflow Definition should be written to never fail due to intermittent issues; an Activity is designed to handle such issues.

- **Activity Execution:** When an Activity Execution is spawned, it is associated with a default Retry Policy, and thus Activity Task Executions are retried by default.
  When an Activity Task Execution is retried, the Temporal Service places a new [Activity Task](/tasks#activity-task) into its respective [Activity Task Queue](/task-queue), which results in a new Activity Task Execution.

## Custom Retry Policy

To use a custom Retry Policy, provide it as an options parameter when starting a Workflow Execution or Activity Execution.
Only certain scenarios merit starting a Workflow Execution with a custom Retry Policy, such as the following:

- A [Temporal Cron Job](/workflows#temporal-cron-job) or some other stateless, always-running Workflow Execution that can benefit from retries.
- A file-processing or media-encoding Workflow Execution that downloads files to a host.

## Properties

### Default values for Retry Policy

```
Initial Interval     = 1 second
Backoff Coefficient  = 2.0
Maximum Interval     = 100 × Initial Interval
Maximum Attempts     = ∞
Non-Retryable Errors = []
```

### Initial Interval

- **Description:** Amount of time that must elapse before the first retry occurs.
  - **The default value is 1 second.**
- **Use case:** This is used as the base interval time for the [Backoff Coefficient](#backoff-coefficient) to multiply against.

### Backoff Coefficient

- **Description:** The value dictates how much the _retry interval_ increases.
  - **The default value is 2.0.**
  - A backoff coefficient of 1.0 means that the retry interval always equals the [Initial Interval](#initial-interval).
- **Use case:** Use this attribute to increase the interval between retries.
  By having a backoff coefficient greater than 1.0, the first few retries happen relatively quickly to overcome intermittent failures, but subsequent retries happen farther and farther apart to account for longer outages.
  Use the [Maximum Interval](#maximum-interval) attribute to prevent the coefficient from increasing the retry interval too much.

### Maximum Interval

- **Description:** Specifies the maximum interval between retries.
  - **The default value is 100 times the [Initial Interval](#initial-interval).**
- **Use case:** This attribute is useful for [Backoff Coefficients](#backoff-coefficient) that are greater than 1.0 because it prevents the retry interval from growing infinitely.

### Maximum Attempts

- **Description:** Specifies the maximum number of execution attempts that can be made in the presence of failures.
  - **The default is unlimited.**
  - If this limit is exceeded, the execution fails without retrying again. When this happens an error is returned.
  - Setting the value to 0 also means unlimited.
  - Setting the value to 1 means a single execution attempt and no retries.
  - Setting the value to a negative integer results in an error when the execution is invoked.
- **Use case:** Use this attribute to ensure that retries do not continue indefinitely.
  In most cases, we recommend using the Workflow Execution Timeout for [Workflows](/workflows) or the Schedule-To-Close Timeout for Activities to limit the total duration of retries, rather than using this attribute.

### Non-Retryable Errors

- **Description:** Specifies errors that shouldn't be retried.
  - **Default is none.**
  - Errors are matched against the `type` field of the [Application Failure](/references/failures#application-failure).
  - If one of those errors occurs, a retry does not occur.
- **Use case:** If you know of errors that should not trigger a retry, you can specify that, if they occur, the execution is not retried.

## Retry interval

The wait time before a retry is the _retry interval_. A retry interval is the smaller of two values:

- The [Initial Interval](#initial-interval) multiplied by the [Backoff Coefficient](#backoff-coefficient) raised to the power of the number of retries.
- The [Maximum Interval](#maximum-interval).

<PrettyImage src="/img/info/retry-interval-diagram.png" title="Diagram that shows the retry interval and its formula" />

### Per-error next Retry delay

Sometimes, your Activity or Workflow raises a special exception that needs a different retry interval from the Retry Policy.
To accomplish this, you may throw an [Application Failure](/references/failures#application-failure) with the next Retry delay field set. This value will replace and override whatever the retry interval would be on the Retry Policy.
Note that your retries will still cap out under the Retry Policy's Maximum Attempts, as well as overall timeouts. For an Activity, its Schedule-to-Close Timeout applies. For a Workflow, the Execution Timeout applies.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/java/failure-detection#activity-next-retry-delay" text="Customize retry delays per error in the Java SDK." archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-next-retry-delay" text="Customize retry delays per error in the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

## Event History

There are some subtle nuances to how Events are recorded to an Event History when a Retry Policy comes into play.

- For an Activity Execution, the [ActivityTaskStarted](/references/events#activitytaskstarted) Event will not show up in the Workflow Execution Event History until the Activity Execution has completed or failed (having exhausted all retries).
  This is to avoid filling the Event History with noise.
  Use the Describe API to get a pending Activity Execution's attempt count.

- For a Workflow Execution with a Retry Policy, if the Workflow Execution fails, the Workflow Execution will [Continue-As-New](/workflows#continue-as-new) and the associated Event is written to the Event History.
  The [WorkflowExecutionContinuedAsNew](/references/events#workflowexecutioncontinuedasnew) Event will have an "initiator" field that will specify the Retry Policy as the value and the new Run Id for the next retry attempt.
  The new Workflow Execution is created immediately.
  But the first Workflow Task won't be scheduled until the backoff duration is exhausted.
  That duration is recorded as the `firstWorkflowTaskBackoff` field of the new run's `WorkflowExecutionStartedEventAttributes` event.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/child-workflows.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/child-workflows.mdx</path>
  <content>
---
id: child-workflows
title: Child Workflows
sidebar_label: Child Workflows
description: A Child Workflow Execution in the Temporal platform is initiated from another Workflow within the same Namespace. Learn about the feature guides for Go, Java, PHP, Python, TypeScript, and .NET SDKs. Understand the Parent-Child Workflow relationship, including when to use Child Workflows, Parent Close Policies
toc_max_heading_level: 4
keywords:
  - child workflow execution
  - temporal workflow management
  - parent close policy
  - workflow execution scalability
  - temporal SDK child workflow
  - manage workflows with temporal
  - workflow partitioning
  - asynchronous child workflows
  - child workflow serialization
  - temporal namespace workflows
  - child vs activity execution
  - workflow periodic execution
  - temporal SDK guides
  - parent workflow termination
  - child workflow best practices
tags:
  - Concepts
  - Child Workflows
---

A Child Workflow Execution is a [Workflow Execution](/workflows#workflow-execution) that is spawned from within another Workflow in the same Namespace.

- [Go SDK Child Workflow feature guide](/develop/go/child-workflows)
- [Java SDK Child Workflow feature guide](/develop/java/child-workflows)
- [PHP SDK Child Workflow feature guide](/develop/php/child-workflows)
- [Python SDK Child Workflow feature guide](/develop/python/child-workflows)
- [TypeScript SDK Child Workflow feature guide](/develop/typescript/child-workflows)
- [.NET SDK Child Workflow feature guide](/develop/dotnet/child-workflows)

A Workflow Execution can be both a Parent and a Child Workflow Execution because any Workflow can spawn another Workflow.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Parent and Child Workflow Execution entity relationship</p>
  </div>
  <div className="tdiiw" height="600">
    <img
      className="img_ev3q"
      src="/diagrams/parent-child-workflow-execution-relationship.svg"
      alt="Parent and Child Workflow Execution entity relationship"
    />
  </div>
</div>

A Parent Workflow Execution must await on the Child Workflow Execution to spawn.
The Parent can optionally await on the result of the Child Workflow Execution.
Consider the Child's [Parent Close Policy](#parent-close-policy) if the Parent does not await on the result of the Child, which includes any use of Continue-As-New by the Parent.

:::note

Child Workflows do not carry over when the Parent uses [Continue-As-New](/workflows#continue-as-new).
This means that if a Parent Workflow Execution utilizes Continue-As-New, any ongoing Child Workflow Executions will not be retained in the new continued instance of the Parent.

:::

When a Parent Workflow Execution reaches a Closed status, the Temporal Service propagates Cancellation Requests or Terminations to Child Workflow Executions depending on the Child's [Parent Close Policy](#parent-close-policy).

If a Child Workflow Execution uses Continue-As-New, from the Parent Workflow Execution's perspective the entire chain of Runs is treated as a single execution.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">
      Parent and Child Workflow Execution entity relationship with Continue As
      New
    </p>
  </div>
  <div className="tdiiw" height="700">
    <img
      className="img_ev3q"
      src="/diagrams/parent-child-workflow-execution-with-continue-as-new.svg"
      alt="Parent and Child Workflow Execution entity relationship with Continue As New"
    />
  </div>
</div>

## When to use Child Workflows

There is no reason to use Child Workflows just for code organization.
You can use object oriented structure and other code organization techniques to deal with complexities.
It is typically recommended to start from a single Workflow Definition if your problem has bounded size in terms of the number of Activity Executions and processed Signals.
It is simpler than multiple asynchronously communicating Workflows.

However, there are several valid reasons for using Child Workflows.

### Create a separate service

Because a Child Workflow Execution can be processed by a completely separate set of [Workers](/workers#worker) than the Parent Workflow Execution, it can act as an entirely separate service.
However, this also means that a Parent Workflow Execution and a Child Workflow Execution do not share any local state.
As all Workflow Executions, they can communicate only via asynchronous [Signals](/sending-messages#sending-signals).

### Paritition problems into smaller chunks

An individual Workflow Execution has an [Event History](/workflows#event-history) size limit, which imposes a couple of considerations for using Child Workflows.

On one hand, because Child Workflow Executions have their own Event Histories, they are often used to partition large workloads into smaller chunks.
For example, a single Workflow Execution does not have enough space in its Event History to spawn 100,000 [Activity Executions](/activities#activity-execution).
But a Parent Workflow Execution can spawn 1,000 Child Workflow Executions that each spawn 1,000 Activity Executions to achieve a total of 1,000,000 Activity Executions.

However, because a Parent Workflow Execution Event History contains [Events](/workflows#event) that correspond to the status of the Child Workflow Execution, a single Parent should not spawn more than 1,000 Child Workflow Executions.

In general, however, Child Workflow Executions result in more overall Events recorded in Event Histories than Activities.
Because each entry in an Event History is a _cost_ in terms of compute resources, this could become a factor in very large workloads.
Therefore, we recommend starting with a single Workflow implementation that uses Activities until there is a clear need for Child Workflows.

### Represent a single resource

As all Workflow Executions, a Child Workflow Execution can create a one to one mapping with a resource.
It can be used to manage the resource using its ID to guarantee uniqueness.
For example, a Workflow that manages host upgrades could spawn a Child Workflow Execution per host (hostname being a Workflow ID) and use them to ensure that all operations on the host are serialized.

### Periodic logic execution

A Child Workflow can be used to execute some periodic logic without overwhelming the Parent Workflow Event History.
In this scenario, the Parent Workflow starts a Child Workflow which executes periodic logic calling [Continue-As-New](/workflows#continue-as-new) as many times as needed, then completes.
From the Parent point of view, it is just a single Child Workflow invocation.

### Child Workflow versus an Activity

Child Workflow Executions and Activity Executions are both started from Workflows, so you might feel confused about when to use which.
Here are some important differences:

- A Child Workflow has access to all Workflow APIs but is subject to the same [deterministic constraints](/workflows#deterministic-constraints) as other Workflows.
  An Activity has the inverse pros and cons—no access to Workflow APIs but no Workflow constraints.
- A Child Workflow Execution can continue on if its Parent is canceled with a [Parent Close Policy](#parent-close-policy) of `ABANDON`.
  An Activity Execution is _always_ canceled when its Workflow Execution is canceled.
  (It can react to a cancellation Signal for cleanup.)
  The decision is roughly analogous to spawning a child process in a terminal to do work versus doing work in the same process.
- Temporal tracks all state changes within a Child Workflow Execution in Event History.
  Only the input, output, and retry attempts of an Activity Execution is tracked.

A Workflow models composite operations that consist of multiple Activities or other Child Workflows.
An Activity usually models a single operation on the external world.

Our advice: **When in doubt, use an Activity.**

## Parent Close Policy {#parent-close-policy}

**What is a Parent Close Policy?**

A Parent Close Policy determines what happens to a Child Workflow Execution if its Parent changes to a Closed status (Completed, Failed, or Timed out).

- [How to set a Parent Close Policy using the Go SDK](/develop/go/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the Java SDK](/develop/java/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the PHP SDK](/develop/php/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the Python SDK](/develop/python/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the TypeScript SDK](/develop/typescript/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the .NET SDK](/develop/dotnet/child-workflows#parent-close-policy)

There are three possible values:

- **Abandon:** the Child Workflow Execution is not affected.
- **Request Cancel:** a Cancellation request is sent to the Child Workflow Execution.
- **Terminate** (default): the Child Workflow Execution is forcefully Terminated.

[`ParentClosePolicy`](https://github.com/temporalio/api/blob/c1f04d0856a3ba2995e92717607f83536b5a44f5/temporal/api/enums/v1/workflow.proto#L44) proto definition.

Each Child Workflow Execution may have its own Parent Close Policy.
This policy applies only to Child Workflow Executions and has no effect otherwise.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Parent Close Policy entity relationship</p>
  </div>
  <div className="tdiiw" height="543">
    <img
      className="img_ev3q"
      src="/diagrams/parent-close-policy.svg"
      alt="Parent Close Policy entity relationship"
    />
  </div>
</div>

You can set policies per child, which means you can opt out of propagating terminates / cancels on a per-child basis.
This is useful for starting Child Workflows asynchronously (see [relevant issue here](https://community.temporal.io/t/best-way-to-create-an-async-child-workflow/114) or the corresponding SDK docs).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/index.mdx</path>
  <content>
---
id: index
title: Temporal development and production features
description: Leverage a Temporal SDK to develop robust applications featuring Workflows, Activities, Workers, testing suites, Temporal Clients, Scheduled Workflows, and advanced observability tools.
sidebar_label: Features
keywords:
  - temporal sdk
  - core application primitives
  - workflows in temporal
  - activities and workers
  - temporal testing suite
  - temporal clients
  - scheduled workflows
  - workflow cancellation
  - runtime safeguards
  - failure detection in temporal
  - automatic retries
  - temporal messages
  - business process versioning
  - observability in workflows
  - debugging temporal applications
  - data encryption in applications
  - throughput composability
  - signals
  - queries
---

Through a Temporal SDK, Temporal provides a wide range of features that enable developers to build applications that serve a wide range of use cases.

- **[Core application primitives](/evaluate/development-production-features/core-application)**: Develop and run your application with Workflows, Activities, and Workers.
- **[Testing suite](/evaluate/development-production-features/testing-suite)**: Each Temporal SDK comes with a testing suite that enables developers to test their applications as they would any other.
- **[Scheduled Workflows](/evaluate/development-production-features/schedules)**: Start a business process at a specific time or on a given time interval.
- **[Interrupt a Workflow](/evaluate/development-production-features/interrupt-workflow)**: Cancel or terminate a business process (Workflow) that is already in progress and compensate for any steps already taken.
- **Runtime safeguards**: Prevent avoidable errors and issues from executing during runtime.
- **[Failure detection and mitigation](/evaluate/development-production-features/failure-detection)**: Detect failures with timeouts and configure automatic retries to mitigate them.
- **[Temporal Nexus](/evaluate/nexus)**: Connect Temporal Applications across (and within) isolated Namespaces for improved modularity, security, debugging, and fault isolation. Nexus supports cross-team, cross-domain, and multi-region use cases.
- **[Workflow message passing](/evaluate/development-production-features/workflow-message-passing)**: Build responsive applications that react to events at runtime and enable data retrieval from ongoing Workflows.
- **Versioning**: Support multiple versions of your business logic for long-running business processes.
- **[Observability](/evaluate/development-production-features/observability)**: List business process, view their state, and set up dashboards with metrics.
- **[Debugging](/evaluate/development-production-features/debugging)**: Surface errors and step through code to find issues.
- **[Data encryption](/evaluate/development-production-features/data-encryption)**: Transform data and protect the privacy of the users of your application.
- **[Throughput composability](/evaluate/development-production-features/throughput-composability)**: Breakup business processes by data streams, team ownership, or other organization factors.
- **[Cloud Automation](/evaluate/development-production-features/cloud-automation)**: Simplify cloud management and boost security with Temporal's Cloud Automation.
- **[Low Latency](/evaluate/development-production-features/low-latency)**: Making your applications faster, more performant, and more efficient.
- **[Multi-tenancy](/evaluate/development-production-features/multi-tenancy)**: Enhances efficiency and cost-effectiveness.

For detailed information on Temporal feature release stages and criteria, see this [Product Release Stages Guide](/evaluate/development-production-features/release-stages).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/legacy-pricing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/legacy-pricing.mdx</path>
  <content>
---
id: legacy-pricing
title: Temporal Cloud legacy pricing
sidebar_label: Legacy pricing
description: Temporal Cloud offers flexible, predictable pricing for Workflows, Activities, Workers, and storage. Pay for what you use with volume discounts and credit savings.
slug: /cloud/legacy_pricing
toc_max_heading_level: 4
keywords:
  - explanation
  - faq
  - introduction
  - pricing
  - security
  - storage
  - support
  - temporal cloud
  - term
tags:
  - Temporal Cloud
  - Support
  - Pricing
---

:::tip Support, stability, and dependency info

Temporal Cloud pricing structures [will update](/cloud/pricing) to align with the new pricing plans in February 2025 for existing customers.

:::

Temporal Cloud is a consumption-based service.
You pay only for what you use.
Our pricing reflects your use of [_Actions_](#action), [_Storage_](#storage), and [_Support_](#support).
It is flexible, transparent, and predictable so you know your costs.

This page describes the elements of Temporal Cloud pricing.
It gives you the information you need to understand and estimate costs for your implementation.
For more exact estimates, please reach out to [our team](https://pages.temporal.io/ask-an-expert).

Cost and billing information are available directly in the Temporal Cloud UI.
For more information, visit the [Billing and Cost](/cloud/billing-and-cost) page.

## Temporal Cloud pricing model {#pricing-model}

This section explains the basis of the Temporal Cloud pricing model and how it works.
Your total invoice each calendar month is the combination of Temporal Cloud consumption ([Actions](#action) and [Storage](#storage)) and [Support](#support).

### Actions {#action}

**What are Temporal Actions?**

Actions are the primary unit of consumption-based pricing for Temporal Cloud.
They track billable operations within the Temporal Cloud Service, such as starting Workflows, recording a Heartbeat or sending messages.

<details>

<summary>
[Toggle to View] The following operations result in Actions:
</summary>

**WORKFLOWS**

- **Workflow started**.
  Occurs via client start, client [Signal-With-Start](/sending-messages#signal-with-start), [Continue-As-New](/workflows#continue-as-new), or [Child Workflow](/encyclopedia/child-workflows) start.
  If a Workflow start fails, an Action is not recorded.
- **Workflow reset**.
  Occurs when a [Workflow](/workflows) is reset.
  (Actions that occur before a [Reset](/workflows#reset) are counted even if they are no longer visible in [Event History](/workflows#event-history).)
- **Timer started**.
  Includes implicit Timers that are started by a Temporal SDK when timeouts are set, such as `AwaitWithTimeout` in Go or `condition` in TypeScript.
- **Search Attribute upsert requested**.
  Occurs for each invocation of `UpsertSearchAttributes` command.
- **Signal sent**.
  Includes sending a [Signal](/sending-messages#sending-signals) from a client or from within a Workflow to another Workflow.
- **Query received**. [Queries](/sending-messages#sending-queries) aren't recorded in Event History.
  An operation such as viewing the call stack in the Temporal Cloud UI results in a Query.
- **Side Effect recorded**.
  For a mutable [Side Effect](/workflows#side-effect), an Action occurs only when the value changes.
  (Be aware that some SDKs don't support Side Effects.)
- [**NEW**] **Workflow Update**. [Workflow Updates](/sending-messages#sending-updates) is a primitive that combines a Signal and Query together for a single Action.

**CHILD WORKFLOWS**

- **Child Workflows spawned**.
  The parent Workflow spawning a Child Workflow results in one Action.
- **Child Workflows executed**.
  Execution of the Child Workflow results in one Action.

**ACTIVITIES**

- **Activity started or retried**.
  Occurs each time an Activity is started or retried.
- **Local Activity started**.
  All [Local Activities](/activities#local-activity) associated with one Workflow Task count as a single Action.
  That's because Temporal Cloud counts all [RecordMarkers](https://docs.temporal.io/references/commands#recordmarker) from each Workflow Task as one action, and not _N_ actions.
  Please note:
  - Each additional Workflow Task heartbeat after counts as an additional Action.
  - Local Activities retried following a Workflow Task heartbeat count as one Action (capped at 100 Actions).
- **Activity Heartbeat recorded**.
  A Heartbeat call from Activity code counts as an Action only if it reaches the [Temporal Server](/clusters#temporal-server).
  Temporal SDKs throttle [Activity Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat).
  The default throttle is 80% of the [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout).
  Heartbeats don't apply to Local Activities.

**SCHEDULES**

[Schedules](/workflows#schedule) allows you to "schedule" a Workflow to start at a particular time.
Each execution of a Schedule accrues three actions:

- **Schedule Start**.
  This accounts for two actions.
- **Workflow started**.
  This is a single action to start the target Workflow.
  It includes initial Search Attributes as part of the start request.

**EXPORT**

[Workflow History Export](/cloud/export) enables you to export closed Workflow Histories to a cloud storage sink of your choice.

- **Workflow exported**.
  Each Workflow exported accrues a single action.

**TEMPORAL NEXUS**

- For Nexus Operation scheduled, the caller Workflow starting a Nexus Operation results in one Action on the caller Namespace.
- For Nexus Operation canceled, the caller Workflow canceling a Nexus Operation results in one Action on the caller Namespace.
- The underlying Temporal primitives (such as Workflows, Activities, and Signals) created by a Nexus Operation handler (directly or indirectly) result in the normal Actions for those primitives billed to the handler’s Namespace.
  This includes retries for underlying Temporal primitives like Activities but _not_ for handling the Nexus Operation itself or a retry of the Nexus Operation itself.

</details>

[Reach out](https://pages.temporal.io/contact-us) to our team for more information or to help size your number of Actions.

### Storage {#storage}

**How Workflow Storage works**

A particular Workflow's execution might exist for a few seconds, a day, month, or even forever.
The Temporal Service stores the Workflow Execution's [Event History](/workflows#event-history).
Under this framework, a Workflow Execution has only two states, open (Active Storage) or closed (Retained Storage).

- _Active Storage_ measures the amount of storage used by active Workflows.

- When the execution of a Workflow finishes, Temporal Cloud stores Event History for a defined Retention Period, which is set by the user per Namespace.
  This is _Retained Storage_.
  Typical uses of Retained Storage include compliance, debugging, workload refresh, and business analytics.
  When closed Workflow Histories need to be retained for more than the 90-day maximum period on Temporal Cloud, we recommend using our [**Export**](/cloud/export) feature.

Storage costs are measured in gigabyte-hours (GBh) and they are measured per Namespace.

### Support {#support}

**How Temporal Support tiers work**

Each Temporal Cloud account includes access to expert support.
The Temporal Developer Success team has extensive knowledge of how Temporal operates and how to optimize your deployment.
Our team consists of engineers who are well-versed in Temporal and actively contribute to its development.

Each account is required to have a Support plan.
We offer two Support tiers: Basic and Premium.
Support costs are outlined in the table below.
A complete description of Support plans and response times can be found in our [Support](/cloud/support#support) documentation.

|                     | Basic                                       | Premium                                   |
| ------------------- | ------------------------------------------- | ----------------------------------------- |
| Pricing (per month) | Greater of &#36;200 or 10% of monthly usage | Contact [Sales](mailto:sales@temporal.io) |

### Pricing options {#pricing-options}

**How to Pay for Temporal Cloud**

Temporal Cloud offers two payment options: Pay-As-You-Go and Temporal Commitments.
Both models meter and bill for three components: [Actions](#action), [Storage](#storage), and [Support](#support).

- With Pay-As-You-Go, you are invoiced each calendar month based on your consumption.
  Pay-As-You-Go pricing applies a flat rate for Actions and Storage.
- With Commitments, you pre-purchase your Temporal Cloud spend with Temporal Credits.
  Temporal Credits pay for your Temporal Cloud consumption, including Temporal Cloud Plan charges.

## Pay-As-You-Go {#payg}

**How does Pay-As-You-Go pricing work?**

Pay-As-You-Go uses consumption pricing.
This section explains how you're billed each calendar month and gives examples.

### Action pricing {#payg-action-pricing}

You are only billed for the Actions you use.
Actions are metered and billed on a calendar month for each Namespace.
The Pay-As-You-Go rate is &#36;25 per million Actions per month.
This rate applies across all Namespaces:

| Actions | &#36;25 per million Actions |
| ------- | --------------------------- |

**Example**

If you use fewer than one million Actions per month, your bill for Actions will be less than &#36;25 for that month.
For example, if you use 800,000 Actions in a month, you're billed:

```
0.8M Actions ⨉ $25 Per Million Actions= $20
```

### Storage pricing {#payg-storage-pricing}

You are billed for your Namespace’s Active and Retained Storage each calendar month:

| **Storage** | **Price per GBh (USD)** |
| ----------- | ----------------------- |
| Retained    | &#36;0.00042            |
| Active      | &#36;0.042              |

**Example**

If you have 720 GBh of Active Storage and 3,600 GBh of Retained Storage in one calendar month your bill will be:

```
720 GBh Active Storage ⨉ $0.042 per GBh = $30.24
3,600 GBh Retained Storage ⨉ $0.00042 per GBh = $1.51
Total Storage Bill: $30.24 Active Storage + $1.51 Retained Storage = $31.75
```

### Support pricing {#payg-support-pricing}

Support pricing offers [two tiers](/cloud/support#support):

- Basic Support is priced at the greater of &#36;200/month or 10% of Temporal Cloud consumption.
- Premium Support is priced at the greater of &#36;2,000/month or 10% of Temporal Cloud consumption.

Temporal Cloud consumption is based on the combined cost of [Actions](#action) and [Storage](#storage).

**Example**

If you are signed up for Basic Support, with the above example, your Basic Support will be:

```
Max of $200 or 10% ⨉ ($20 (Actions) + $31.75 (Storage)) = $5.18, so $200.
```

## Commitment Pricing {#commitment-pricing}

**Commitments with Temporal Credits**

Temporal Cloud offers the option to commit to a minimum spend over a given timeframe.
In exchange for this commitment you receive additional discounts.
Key discount levers include:

- Account Action volume over 200M Actions
- Duration of your commitment (1, 2, or 3 years)

Meet your commitments with any Temporal Cloud spend, including Actions, Storage and your Temporal Cloud Plan.
After making a commitment, Temporal locks in your Actions price based on your expected volume and discounts your Active Storage costs.
This price is used to bill your Actions and Active Storage across your account for the timeframe specified in your commitment.

Commitments must be paid for with Temporal Credits.
Temporal Credits are used to pay your Temporal Cloud consumption, including Temporal Cloud Plan charges.
A Temporal Credit is equivalent to &#36;1 USD.
For example, a credit purchase of &#36;20,000 results in 20,000 Temporal Credits.
A minimum credit purchase equivalent to the first year of your commitment is required.
For multi-year deals please contact [Sales](mailto:sales@temporal.io) for the most accurate pricing.

### Commitment Pricing Q&A

**How do multi-year commitments work?**

Our sales team works with you to match annual credit purchases in line with your expected spend.
This aligns your payments to annual terms rather than one up-front expense.

**What happens if I exhaust my commitment-based Temporal Credits before the end of my term?**

You continue to receive the negotiated discounted prices for the remainder of your term.
You'll be invoiced for another credit purchase based on your most recent calendar month's spend.
This amount is multiplied by the months remaining in the annual portion of your term.
If your previous month spend was &#36;5,000, and you're 10 months through your annual term, you'll be invoiced for 10,000 Temporal Credits to cover the remaining two months.

**What happens if I have unused Temporal Credits at the end of my term?**

Commitments can be difficult to estimate.
Temporal Cloud offers two ways to roll-over unused credits:

- When you renew a commitment for the same or larger amount, Temporal Cloud rolls over any unused credits into your new commitment.
- Should you need to downsize your commitment, Temporal Cloud rolls over up to 10% of your initial credit purchase amount into the new commitment.

**How do I make a commitment and purchase Temporal Credits?**

Contact our team at [sales@temporal.io](mailto:sales@temporal.io) or reach out to your dedicated account manager.
You can also purchase Temporal Cloud commitments credits through [AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu).

## Other pricing {#other-pricing}

Temporal Cloud has additional pricing for other elements of the platform.
Following are additional pricing considerations for Multi-region Namespaces and SSO/SAML.

### Multi-region Namespace (MRN) pricing {#multi-region}

**How do MRN costs work?**

For workloads with stringent high-availability requirements, Temporal Cloud provides multi-region Namespaces (MRNs), which add a failover capability.
Each multi-region Namespace automatically replicates Workflow Execution data and metadata to a standby region.
This keeps the standby region in sync, allowing for a near-seamless failover should regional outages occur.

Multi-region Namespace pricing align with the volume of your workloads.
After activation, the new MRN begins replicating data to the standby region.
Due to this replication, MRNs double your current [Action](#action) and [Storage](#storage) costs.
To estimate costs for this deployment model, apply a 2x multiplier to your existing Actions and Storage Namespace costs.

When upgrading an existing Namespace, some points to consider:

- Temporal won't charge for historical Actions completed prior to upgrading to a multi-region Namespace.
  Only ongoing (in-flight) and new Workflow Executions incur the \"2x\" charge, as these are actively replicated.
- Temporal charges for all Actions of existing (ongoing) and new Workflows from the point of adding a new region and provisioning multi-region Namespace service onward.
- Temporal charges for Replicated Storage of retained (historical), running (ongoing), and new Workflow Executions from the point of adding a new region and starting MRN service.

Multi-region Namespace invoice charges will include:

- An Actions row, showing the Action count from the active region.
- A Replicated Actions row, showing the Action count from the standby region.

The invoice follows a similar structure for Replicated Storage.
It breaks out Storage and Replicated Storage into their own line items.

:::tip Action counts for mid-month adoption

- If your multi-region Namespace adoption began mid-month, expect to see more Actions than Replicated Actions and more Storage than Replicated Storage on your invoice.

:::

### Temporal Nexus pricing {#temporal-nexus-pricing}

- For Nexus Operation scheduled, the caller Workflow starting a Nexus Operation results in one Action on the caller Namespace.
- For Nexus Operation canceled, the caller Workflow canceling a Nexus Operation results in one Action on the caller Namespace.
- The underlying Temporal primitives (such as Workflows, Activities, and Signals) created by a Nexus Operation handler (directly or indirectly) result in the normal Actions for those primitives billed to the handler’s Namespace.
  This includes retries for underlying Temporal primitives like Activities.
- No Action results for handling the Nexus Operation itself.
- No Action results for a retry of the Nexus Operation itself.

### SSO and SAML pricing {#sso-and-saml}

**What costs are associated with SSO/SAML use?**

We offer single sign-on (SSO) integration using SAML at a monthly fixed fee based on the number of users registered in Temporal Cloud:

| **Users** | **Cost per month** |
| --------- | ------------------ |
| 0 to 25   | &#36;200           |
| 26 to 50  | &#36;300           |
| 51+       | &#36;500           |

### Use case cost estimates {#pricing-estimates}

Temporal Cloud uses a consumption-based pricing model based primarily on [Actions](#action) and [Storage](#storage).
Each workload is different.
You can estimate the cost of a specific Workflow by running it at a low volume.
Use the resulting Storage and compute measurements to project your production scale cost.

The examples below provide general estimates based on workload size.
You can also use our calculator on the pricing page to build your estimate.
Our team is always happy to [help you estimate costs] (https://pages.temporal.io/contact-us) for your specific workloads and requirements.

| Workload size | Cost (monthly) | Characteristics                            | Actions                                            | Typical use cases                                                                                             |
| ------------- | -------------- | ------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| Small         | < &#36;25.00   | Modest / transient throughput              | < 1M / month  <br /> _(< 0.38 actions per second)_ | General automation <br /> Human dependent processes <br /> Data pipelines <br /> Nightly batch processes      |
| Medium        | < &#36;1K      | Steady or burst throughput                 | < 40M / month <br /> _(< 15 actions per second)_   | Transaction & order systems <br /> Infrastructure automation <br /> Payment Processing <br /> Batch processes |
| Large         | < &#36;10K     | Sustained throughput or multiple use cases | < 400M / month <br /> _(< 150 actions per second)_ | Data processing / sync <br /> Retail order system <br /> KYC & fraud detection                                |
| Web Scale     | &#36;20K+      | "Web scale" and / or numerous use cases    | 1B+ / month <br /> _(400+ actions per second)_     | Social media application <br /> SaaS application service                                                      |

## Billing Questions FAQs {#pricing-faq}

**What payment methods does Temporal accept?**

You can pay with a credit card, ACH, or wire transfer.
To pay for Temporal Cloud with an AWS Account, sign up for [Temporal Cloud Pay-As-You-Go](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu) on the AWS Marketplace.

**How often will I be billed?**

Temporal Cloud issues invoices for the previous month’s usage and costs.
Invoices are issued on the 3rd of the month for the previous month.
For example, invoices for May will be issued at midnight UTC on June 3rd.

**Where can I view my usage and billing information?**
Account Owners and Finance Admin can view their detailed billing data at any time via the [Usage and Billing dashboards](/cloud/billing-and-cost) in Temporal Cloud.

**How do I purchase Temporal Cloud credits?**

You can purchase Temporal Cloud credits by contacting our team at [sales@temporal.io](mailto:sales@temporal.io).

**What's the minimum cost to run Temporal Cloud?**

The Temporal Cloud service is consumption-based.
You pay only for what you need with no minimum usage requirement.
Basic Support has a monthly fee starting from &#36;200.

**Can I purchase Temporal Cloud through my Amazon, Azure, or Google Cloud Platform Marketplace?**

Yes. You’ll enjoy streamlined billing through AWS and GCP.

There are two ways to purchase Temporal Cloud through AWS Marketplace:

- Pay-As-You-Go available [here](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu)
- Credits: available via private offer, please contact our team at [sales@temporal.io](mailto:sales@temporal.io)

To purchase Temporal Cloud on the Google Cloud Marketplace, please contact our team at [sales@temporal.io](mailto:sales@temporal.io).

**How do I see how many Temporal Cloud credits are remaining?**

To view remaining Temporal Cloud credits, log in to Temporal Cloud and go to Settings > Billing.
You need appropriate administrative permissions to access this section.

**What happens if I exceed my available credits?**

Temporal automatically invoices customers who purchased credits to reload their balance.
The invoice amount is based on annualizing the most recent month’s usage.
Customers with free credits from the startup program or from an offer are invoiced once their credit balance is exhausted at the end of that month.

**Do promotional credits expire?**

Credits received through the startup program or an offer have an expiry date.
This date is stated as part of the sign-up process.

**How do I update my payment information?**

To update payment information, [contact Support](https://temporalsupport.zendesk.com/).

**What happens if my payment fails?**

Temporal will periodically send you email reminders to complete the payment.

**How do I view my invoices and billing history?**

Invoices are emailed to Admins of Temporal Cloud.
Admins can view their [detailed billing information](https://cloud.temporal.io/billing) at any time.
See our [billing and cost](/cloud/billing-and-cost) page for details.
Alternatively, to view invoices and billing history, [contact Support](https://temporalsupport.zendesk.com/).

**Does Temporal charge sales tax/VAT?**

We charge applicable sales tax in US jurisdictions as required.

**How do I cancel my account?**

To cancel your Temporal Cloud account, [contact Support](https://temporalsupport.zendesk.com/).

**Will I lose access immediately if I cancel my account?**

Customers will lose access once Temporal completes the off-boarding process.
Billing is independent of this process.

**Can I reactivate my account after cancellation?**

No.
When your account is canceled, your account data is deleted and cannot be restored.
To return to Temporal Cloud, you must sign up again.
You will be assigned a new Temporal account and be treated as a new customer.

**What happens to my credits if I cancel my account?**

Prepaid but unused credits purchased after June 17, 2024 will be refunded if the account is canceled.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/glossary.md</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/glossary.md</path>
  <content>
---
id: glossary
title: Glossary
description: The following terms have specific definitions within the context of the Temporal Platform.
sidebar_label: Glossary
sidebar_position: 13
toc_max_heading_level: 4
tags:
  - Reference
---

The following terms are used in [Temporal Platform](/temporal) documentation.

#### [Action](/cloud/pricing#action)

An Action is the fundamental pricing unit in Temporal Cloud.
Temporal Actions are the building blocks for Workflow Executions.
When you execute a Temporal Workflow, its Actions create the ongoing state and progress of your Temporal Application.

<!-- _Tags: [term](/tags/term), [pricing](/tags/pricing), [temporal-cloud](/tags/temporal-cloud), [explanation](/tags/explanation)_ -->

#### [Actions Per Second (APS)](/cloud/limits#throughput)

APS, or Actions per second, is specific to Temporal Cloud.
Each Temporal Cloud Namespace enforces a rate limit, which is measured in Actions per second (APS).
This is the number of Actions, such as starting or signaling a Workflow, that can be performed per second within a specific Namespace.

<!-- _Tags: [term](/tags/term), [pricing](/tags/pricing), [temporal-cloud](/tags/temporal-cloud), [explanation](/tags/explanation)_ -->

#### [Activity](/activities)

In day-to-day conversation, the term "Activity" denotes an Activity Type, Activity Definition, or Activity Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Definition](/activities#activity-definition)

An Activity Definition is the code that defines the constraints of an Activity Task Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Execution](/activities#activity-execution)

An Activity Execution is the full chain of Activity Task Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Heartbeat](/encyclopedia/detecting-activity-failures#activity-heartbeat)

An Activity Heartbeat is a ping from the Worker that is executing the Activity to the Temporal Service.

Each ping informs the Temporal Service that the Activity Execution is making progress and the Worker has not crashed.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Id](/activities#activity-id)

A unique identifier for an Activity Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Task](/tasks#activity-task)

An Activity Task contains the context needed to make an Activity Task Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Task Execution](/tasks#activity-task-execution)

An Activity Task Execution occurs when a Worker uses the context provided from the Activity Task and executes the Activity Definition.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Activity Type](/activities#activity-type)

An Activity Type is the mapping of a name to an Activity Definition.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Archival](/clusters#archival)

Archival is a feature specific to a Self-hosted Temporal Service that automatically backs up Event Histories from Temporal Service persistence to a custom blob store after the Closed Workflow Execution retention period is reached.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Asynchronous Activity Completion](/activities#asynchronous-activity-completion)

Asynchronous Activity Completion occurs when an external system provides the final result of a computation, started by an Activity, to the Temporal System.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Audit Logging](/cloud/audit-logging)

Audit Logging is a feature that provides forensic access information for accounts, users, and Namespaces.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [temporal-cloud](/tags/temporal-cloud), [operations](/tags/operations)_ -->

#### [Authorizer Plugin](/self-hosted-guide/security#authorizer-plugin)

The `Authorizer` plugin contains a single `Authorize` method, which is invoked for each incoming API call. `Authorize` receives information about the API call, along with the role and permission claims of the caller.

<!-- _Tags: [term](/tags/term)_ -->

#### [Availability Zone](/cloud/high-availability)

An availability zone is a part of the Temporal system where tasks or operations are handled and executed. 
This design helps manage workloads and ensure tasks are completed.
Temporal Cloud Namespaces are automatically distributed across three availability zones, offering the 99.9% uptime outlined in our Cloud [SLA](/cloud/sla). 

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Child Workflow](/encyclopedia/child-workflows)

A Child Workflow Execution is a Workflow Execution that is spawned from within another Workflow.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [child-workflow](/tags/child-workflow)_ -->

#### [Claim Mapper](/self-hosted-guide/security#claim-mapper)

The Claim Mapper component is a pluggable component that extracts Claims from JSON Web Tokens (JWTs).

<!-- _Tags: [term](/tags/term)_ -->

#### [Codec Server](/codec-server)

A Codec Server is an HTTP server that uses your custom Payload Codec to encode and decode your data remotely through endpoints.

<!-- _Tags: [term](/tags/term)_ -->

#### [Command](/workflows#command)

A Command is a requested action issued by a Worker to the Temporal Service after a Workflow Task Execution completes.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Continue-As-New](/workflows#continue-as-new)

Continue-As-New is the mechanism by which all relevant state is passed to a new Workflow Execution with a fresh Event History.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [continue-as-new](/tags/continue-as-new)_ -->

#### [Core SDK](https://temporal.io/blog/why-rust-powers-core-sdk)

The Core SDK is a shared common core library used by several Temporal SDKs.
Written in Rust, the Core SDK provides complex concurrency management and state machine logic among its standout features.
Centralizing development enables the Core SDK to support quick and reliable deployment of new features to existing SDKs, and to more easily add new SDK languages to the Temporal ecosystem.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [continue-as-new](/tags/continue-as-new)_ -->

#### [Custom Data Converter](/default-custom-data-converters#custom-data-converter)

A custom Data Converter extends the default Data Converter with custom logic for Payload conversion or Payload encryption.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Data Converter](/dataconversion)

A Data Converter is a Temporal SDK component that serializes and encodes data entering and exiting a Temporal Service.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Default Data Converter](/default-custom-data-converters#default-data-converter)

The default Data Converter is used by the Temporal SDK to convert objects into bytes using a series of Payload Converters.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Delay Workflow Execution](/workflows#delay-workflow-execution)

Start Delay determines the amount of time to wait before initiating a Workflow Execution. If the Workflow receives a Signal-With-Start during the delay, it dispatches a Workflow Task and the remaining delay is bypassed.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [delay-workflow](/tags/delay-workflow)_ -->

#### [Dual Visibility](/dual-visibility)

Dual Visibility is a feature, specific to a Self-hosted Temporal Service, that lets you set a secondary Visibility store in your Temporal Service to facilitate migrating your Visibility data from one database to another.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [filtered-lists](/tags/filtered-lists), [visibility](/tags/visibility)_ -->

#### [Durable Execution](/temporal#durable-execution)

Durable Execution in the context of Temporal refers to the ability of a Workflow Execution to maintain its state and progress even in the face of failures, crashes, or server outages.

<!-- _Tags: [temporal](/tags/temporal), [durable-execution](/tags/durable-execution), [term](/tags/term)_ -->

#### [Dynamic Handler](/workflows#dynamic-handler)

Dynamic Handlers are Workflows, Activities, Signals, or Queries that are unnamed and invoked when no other named handler matches the call from the Server at runtime.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Event](/workflows#event)

Events are created by a Temporal Service in response to external occurrences and Commands generated by a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Event History](/workflows#event-history)

An append-only log of Events that represents the full state a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Failback](/cloud/high-availability)

After Temporal Cloud has resolved an outage or incident involving a failover, a failback process shifts Workflow Execution processing back to the original region that was active before the incident.

#### [Failover](/cloud/high-availability)

A failover shifts Workflow Execution processing from an active Temporal Namespace region to a standby Temporal Namespace region during outages or other incidents.
Standby Namespace regions use replication to duplicate data and prevent data loss during failover.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Failure](/temporal#failure)

Temporal Failures are representations of various types of errors that occur in the system.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Failure Converter](/failure-converter)

A Failure Converter converts error objects to proto Failures and back.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Failures](/references/failures)

A Failure is Temporal's representation of various types of errors that occur in the system.

<!-- _Tags: [failure](/tags/failure), [explanation](/tags/explanation), [term](/tags/term)_ -->

#### [Frontend Service](/clusters#frontend-service)

The Frontend Service is a stateless gateway service that exposes a strongly typed Proto API. The Frontend Service is responsible for rate limiting, authorizing, validating, and routing all inbound calls.

<!-- _Tags: [term](/tags/term)_ -->

#### [General Availability](/evaluate/development-production-features/release-stages#general-availability)

Learn more about the General Availability release stage

<!-- _Tags: [product-release-stages](/tags/product-release-stages), [term](/tags/term)_ -->

#### [Global Namespace](/global-namespace)

A Global Namespace is a Namespace that duplicates data from an active [Temporal Service](#temporal-cluster) to a standby Service using the replication to keep both Namespaces in sync.
Global Namespaces are designed to respond to service issues like network congestion.
When service to the primary Cluster is compromised, a [failover](#failover) transfers control from the active to the standby cluster.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout)

A Heartbeat Timeout is the maximum time between Activity Heartbeats.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [High Availability](/cloud/high-availability/how-it-works#high-availability)

High availability ensures that a system remains operational with minimal downtime.
It achieves this with redundancy and failover mechanisms that handle failures, so end-users remain unaware of incidents.
Temporal Cloud guarantees this high availability with its Service Level Agreements ([SLA](/cloud/sla))

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [High Availability features](/cloud/high-availability#high-availability-features)

High Availability features automatically synchronize your data between a primary Namespace and its replica, keeping them in sync.
In case of an incident or an outage, Temporal will automatically failover your Namespace from the primary to the replica.
This supports high levels of business continuity, allowing Workflow Executions to continue with minimal interruptions or data loss.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [History Service](/clusters#history-service)

The History Service is responsible for persisting Workflow Execution state and determining what to do next to progress the Workflow Execution through History Shards.

<!-- _Tags: [term](/tags/term)_ -->

#### [History Shard](/clusters#history-shard)

A History Shard is an important unit within a Temporal Service by which the scale of concurrent Workflow Execution throughput can be measured.

<!-- _Tags: [term](/tags/term)_ -->

#### [Idempotency](/activities#idempotency)

An "idempotent" approach avoids process duplication that could withdraw money twice or ship extra orders by mistake.
Idempotency keeps operations from producing additional effects, protecting your processes from accidental or repeated actions, for more reliable execution.
Design your activities to succeed once and only once.
Run-once actions maintain data integrity and prevent costly errors.

<!-- _Tags: [term](/tags/term)_ -->

#### [Isolation Domain](/cloud/high-availability/how-it-works)

An isolation domain is a defined area within Temporal Cloud's infrastructure.
It helps contain failures and prevents them from spreading to other parts of the system, providing redundancy and fault tolerance.

<!-- _Tags: [term](/tags/term)_ -->

#### [List Filter](/list-filter)

A List Filter is the SQL-like string that is provided as the parameter to an advanced Visibility List API.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [filtered-lists](/tags/filtered-lists), [visibility](/tags/visibility)_ -->

#### [Local Activity](/activities#local-activity)

A Local Activity is an Activity Execution that executes in the same process as the Workflow Execution that spawns it.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Matching Service](/clusters#matching-service)

The Matching Service is responsible for hosting external Task Queues for Task dispatching.

<!-- _Tags: [term](/tags/term)_ -->

#### [Memo](/workflows#memo)

A Memo is a non-indexed user-supplied set of Workflow Execution metadata that is returned when you describe or list Workflow Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Multi-Cluster Replication](/self-hosted-guide/multi-cluster-replication)

Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Multi-region Replication](/cloud/high-availability/enable)

Multi-region Replication replicates Workflows and metadata to a different region that is not co-located with the primary Namespace.
This is particularly beneficial for organizations with multi-regional architectures or those required to be highly available across regions for compliance purposes.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Namespace](/namespaces)

A Namespace is a unit of isolation within the Temporal Platform.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Async Completion Callback

A Nexus Async Completion Callback is the completion callback for an asynchronous Nexus Operation.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Endpoint

A Nexus Endpoint is a reverse proxy that can serve one or more Nexus Services.
It routes Nexus requests to a target Namespace and Task Queue, that a Nexus Worker is polling.
This allows service providers to present a clean service contract and hide the underlying implementation, which may consist of many internal Workflows.
Multiple Nexus Endpoints can target the same Namespace, and over time a Nexus Endpoint will be able to span multiple Namespaces with service routing rules.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Machinery

Temporal has built-in Nexus Machinery to guarantee at-least-once execution of Nexus Operations with state-machine-based invocation and completion callbacks.
The Nexus Machinery uses [Nexus RPC](/glossary#nexus-rpc), a protocol designed with Durable Execution in mind, to communicate across Namespace boundaries.
Caller Workflows and Nexus handlers don't have to use Nexus RPC directly, since the Temporal SDK provides a streamlined developer experience to build, run, and use Nexus Services.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Operation

An arbitrary-duration operation that may be synchronous or asynchronous, short-lived, or long-lived, and used to connect durable executions within and across Namespaces, clusters, regions, and clouds.
Unlike a traditional RPC, an asynchronous Nexus Operation has an operation token that can be used to re-attach to a long-lived Nexus Operation, for example, one backed by a Temporal Workflow.
Nexus Operations support a uniform interface to get the status of an operation or its result, receive a completion callback, or cancel the operation – all of which are fully integrated into the Temporal Platform.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Operation Events

Nexus Operations Events are history events that surface in the Caller Workflow to indicate the state of an Operation including `Nexus Operation Scheduled`, `Nexus Operation Started`, `Nexus Operation Completed`.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->


#### Nexus Operation Handler

The Nexus handler code in a Temporal Worker typically created using Temporal SDK builder functions that make it easy to abstract Temporal primitives and expose a clean service contract for others to use.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->


#### Nexus Registry

The Nexus Registry manages Nexus Endpoints and provides lookup services for resolving Nexus requests at runtime.
In the open source version of Temporal, the Registry is scoped to a Cluster, while in Temporal Cloud, it is scoped to an Account.
Endpoint names must be unique within the Registry.
When the Temporal Service dispatches a Nexus request, it resolves the request's Endpoint to a Namespace and Task Queue through the Registry.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->


#### [Nexus RPC](https://github.com/nexus-rpc/api/blob/main/SPEC.md)

Nexus RPC is a protocol designed with durable execution in mind.
It supports arbitrary-duration Operations that extend beyond a traditional RPC — a key underpinning to connect durable executions within and across Namespaces, clusters, regions, and cloud boundaries.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Service

A Nexus Service is a named collection of arbitrary-duration Nexus Operations that provide a microservice contract suitable for sharing across team and application boundaries.
Nexus Services are registered with a Temporal Worker that is polling a Nexus Endpoint's target Namespace and Task Queue.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### Nexus Service Contract

A common code package, schema, or documentation that a Caller can use to obtain Service and Operation names as associated input/output types a Service will accept for a given Operation.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Parent Close Policy](/encyclopedia/child-workflows#parent-close-policy)

If a Workflow Execution is a Child Workflow Execution, a Parent Close Policy determines what happens to the Workflow Execution if its Parent Workflow Execution changes to a Closed status (Completed, Failed, Timed out).

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [child-workflow-executions](/tags/child-workflow-executions)_ -->

#### [Payload](/dataconversion#payload)

A Payload represents binary data such as input and output from Activities and Workflows.

<!-- _Tags: [term](/tags/term), [payloads](/tags/payloads), [explanation](/tags/explanation)_ -->

#### [Payload Codec](/payload-codec)

A Payload Codec transforms an array of Payloads into another array of Payloads.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Payload Converter](/payload-converter)

A Payload Converter serializes data, converting objects or values to bytes and back.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Pre-release](/evaluate/development-production-features/release-stages#pre-release)

Learn more about the Pre-release stage

<!-- _Tags: [product-release-stages](/tags/product-release-stages), [term](/tags/term)_ -->

#### [Public Preview](/evaluate/development-production-features/release-stages#public-preview)

Learn more about the Public Preview release stage

<!-- _Tags: [product-release-stages](/tags/product-release-stages), [term](/tags/term)_ -->

#### [Query](/sending-messages#sending-queries)

A Query is a synchronous operation that is used to report the state of a Workflow Execution.

<!-- _Tags: [term](/tags/term), [queries](/tags/queries), [explanation](/tags/explanation)_ -->

#### [Remote data encoding](/remote-data-encoding)

Remote data encoding is using your custom Data Converter to decode (and encode) your Payloads remotely through endpoints.

<!-- _Tags: [term](/tags/term), [queries](/tags/queries), [explanation](/tags/explanation)_ -->

#### [Replication Lag](/cloud/high-availability/monitor)

The transmission delay of Workflow updates and history events from the active region to the standby region.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Requests Per Second (RPS)](/references/dynamic-configuration#service-level-rps-limits)

RPS, or Requests per second, is used in the Temporal Service (both in self-hosted Temporal and Temporal Cloud).
This is a measure that controls the rate of requests at the service level, such as the Frontend, History, or Matching Service.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [temporal](/tags/temporal)_ -->

#### [Reset](/workflows#reset)

A Reset terminates a Workflow Execution, removes the progress in the Event History up to the reset point, and then creates a new Workflow Execution with the same Workflow Type and Id to continue.

<!-- _Tags: [term](/tags/term), [resets](/tags/resets), [explanation](/tags/explanation)_ -->

#### [Retention Period](/clusters#retention-period)

A Retention Period is the amount of time a Workflow Execution Event History remains in the Temporal Service's persistence store.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Retry Policy](/encyclopedia/retry-policies)

A Retry Policy is a collection of attributes that instructs the Temporal Server how to retry a failure of a Workflow Execution or an Activity Task Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Run Id](/workflows#run-id)

A Run Id is a globally unique, platform-level identifier for a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Same-region Replication](/cloud/high-availability/enable)

Same-region Replication replicates Workflows and metadata to an isolation domain within the same region as the primary Namespace.
It provides a reliable failover mechanism while maintaining deployment simplicity.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Schedule](/workflows#schedule)

A Schedule enables the scheduling of Workflow Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Schedule-To-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout)

A Schedule-To-Close Timeout is the maximum amount of time allowed for the overall Activity Execution, from when the first Activity Task is scheduled to when the last Activity Task, in the chain of Activity Tasks that make up the Activity Execution, reaches a Closed status.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout)

A Schedule-To-Start Timeout is the maximum amount of time that is allowed from when an Activity Task is placed in a Task Queue to when a Worker picks it up from the Task Queue.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [Search Attribute](/search-attribute)

A Search Attribute is an indexed name used in List Filters to filter a list of Workflow Executions that have the Search Attribute in their metadata.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [filtered-lists](/tags/filtered-lists), [visibility](/tags/visibility)_ -->

#### [Side Effect](/workflows#side-effect)

A Side Effect is a way to execute a short, non-deterministic code snippet, such as generating a UUID, that executes the provided function once and records its result into the Workflow Execution Event History.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Signal](/sending-messages#sending-signals)

A Signal is an asynchronous request to a Workflow Execution.

<!-- _Tags: [term](/tags/term), [signals](/tags/signals), [explanation](/tags/explanation)_ -->

#### [Signal-With-Start](/sending-messages#signal-with-start)

Signal-With-Start starts and Signals a Workflow Execution, or just Signals it if it already exists.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout)

A Start-To-Close Timeout is the maximum time allowed for a single Activity Task Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [State Transition](/workflows#state-transition)

A State Transition is a unit of progress by a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Sticky Execution](/sticky-execution)

A Sticky Execution is a when a Worker Entity caches the Workflow Execution Event History and creates a dedicated Task Queue to listen on.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Task](/tasks#task)

A Task is the context needed to make progress with a specific Workflow Execution or Activity Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Task Queue](/task-queue)

A Task Queue is a first-in, first-out queue that a Worker Process polls for Tasks.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Task Routing](/task-routing)

Task Routing is when a Task Queue is paired with one or more Worker Processes, primarily for Activity Task Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Task Token](/activities#task-token)

A Task Token is a unique identifier for an Activity Task Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal](/temporal)

Temporal is a scalable and reliable runtime for Reentrant Processes called Temporal Workflow Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Application](/temporal#temporal-application)

A Temporal Application is a set of Workflow Executions.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal CLI](/cli) {#cli}

The Temporal CLI is the most recent version of Temporal's command-line tool.

<!-- _Tags: [term](/tags/term), [cli](/tags/cli)_ -->

#### [Temporal Client](/encyclopedia/temporal-sdks#temporal-client)

A Temporal Client, provided by a Temporal SDK, provides a set of APIs to communicate with a Temporal Service.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cloud](/cloud/overview)

Temporal Cloud is a managed, hosted Temporal environment that provides a platform for Temporal Applications.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cloud Account Id](/cloud/namespaces#temporal-cloud-account-id)

A Temporal Cloud Account Id is a unique identifier for a customer.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cloud Namespace Id](/cloud/namespaces#temporal-cloud-namespace-id)

A Cloud Namespace Id is a globally unique identifier for a Namespace in Temporal Cloud.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cloud Namespace Name](/cloud/namespaces#temporal-cloud-namespace-name)

A Cloud Namespace Name is a customer-supplied name for a Namespace in Temporal Cloud.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cloud gRPC Endpoint](/cloud/namespaces#temporal-cloud-grpc-endpoint)

A Cloud gRPC Endpoint is a Namespace-specific address used to access Temporal Cloud from your code.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cluster](/clusters)
The term "Temporal Cluster" is being phased out.
Instead the term [Temporal Service](#temporal-service) is now being used.

#### [Temporal Service](/clusters)

A Temporal Service is a Temporal Server paired with Persistence and Visibility stores.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Service configuration](/clusters#cluster-configuration)

Temporal Service configuration is the setup and configuration details of your Temporal Service, defined using YAML.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Cron Job](/workflows#temporal-cron-job)

A Temporal Cron Job is the series of Workflow Executions that occur when a Cron Schedule is provided in the call to spawn a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Platform](/temporal#temporal-platform)

The Temporal Platform consists of a Temporal Service and Worker Processes.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal SDK](/encyclopedia/temporal-sdks)

A Temporal SDK is a language-specific library that offers APIs to construct and use a Temporal Client to communicate with a Temporal Service, develop Workflow Definitions, and develop Worker Programs.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Server](/clusters#temporal-server)

The Temporal Server is a grouping of four horizontally scalable services.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Temporal Web UI](/web-ui)

The Temporal Web UI provides users with Workflow Execution state and metadata for debugging purposes.

<!-- _Tags: [term](/tags/term), [web-ui](/tags/web-ui)_ -->

#### [Timer](/workflows#timer)

Temporal SDKs offer Timer APIs so that Workflow Executions are deterministic in their handling of time values.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Update](/sending-messages#sending-updates)

An Update is a request to and a response from Workflow Execution.

<!-- _Tags: [term](/tags/term), [updates](/tags/updates), [explanation](/tags/explanation)_ -->

#### [Visibility](/clusters#visibility)

The term Visibility, within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view Workflow Executions that currently exist within a Temporal Service.

<!-- _Tags: [term](/tags/term)_ -->

#### [Worker](/workers#worker)

In day-to-day conversations, the term Worker is used to denote both a Worker Program and a Worker Process. Temporal documentation aims to be explicit and differentiate between them.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Worker Entity](/workers#worker-entity)

A Worker Entity is the individual Worker within a Worker Process that listens to a specific Task Queue.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Worker Process](/workers#worker-process)

A Worker Process is responsible for polling a Task Queue, dequeueing a Task, executing your code in response to a Task, and responding to the Temporal Server with the results.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Worker Program](/workers#worker-program)

A Worker Program is the static code that defines the constraints of the Worker Process, developed using the APIs of a Temporal SDK.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Worker Service](/clusters#worker-service)

The Worker Service runs background processing for the replication queue, system Workflows, and (in versions older than 1.5.0) the Kafka visibility processor.

<!-- _Tags: [term](/tags/term)_ -->

#### [Worker Session](/task-routing#worker-session)

A Worker Session is a feature provided by some SDKs that provides a straightforward way to ensure that Activity Tasks are executed with the same Worker without requiring you to manually specify Task Queue names.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow](/workflows)

In day-to-day conversations, the term "Workflow" frequently denotes either a Workflow Type, a Workflow Definition, or a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Definition](/workflows#workflow-definition)

A Workflow Definition is the code that defines the constraints of a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Execution](/workflows#workflow-execution)

A Temporal Workflow Execution is a durable, scalable, reliable, and reactive function execution. It is the main unit of execution of a Temporal Application.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout)

A Workflow Execution Timeout is the maximum time that a Workflow Execution can be executing (have an Open status) including retries and any usage of Continue As New.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [Workflow History Export](/cloud/export)

Workflow History export allows users to export Closed Workflow Histories to a user's Cloud Storage Sink.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [temporal-cloud](/tags/temporal-cloud), [operations](/tags/operations)_ -->

#### [Workflow Id](/workflows#workflow-id)

A Workflow Id is a customizable, application-level identifier for a Workflow Execution that is unique to an Open Workflow Execution within a Namespace.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Id Conflict Policy](/workflows#workflow-id-conflict-policy)

A Workflow Id Conflict Policy determines how to resolve the conflict when spawning a new Workflow Execution with a particular Workflow Id that is used by an Open Workflow Execution already.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Id Reuse Policy](/workflows#workflow-id-reuse-policy)

A Workflow Id Reuse Policy determines whether a Workflow Execution is allowed to spawn with a particular Workflow Id, if that Workflow Id has been used with a previous, and now Closed, Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout)

This is the maximum amount of time that a single Workflow Run is restricted to.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [Workflow Task](/tasks#workflow-task)

A Workflow Task is a Task that contains the context needed to make progress with a Workflow Execution.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Task Execution](/tasks#workflow-task-execution)

A Workflow Task Execution occurs when a Worker picks up a Workflow Task and uses it to make progress on the execution of a Workflow Definition.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

#### [Workflow Task Timeout](/encyclopedia/detecting-workflow-failures#workflow-task-timeout)

A Workflow Task Timeout is the maximum amount of time that the Temporal Server will wait for a Worker to start processing a Workflow Task after the Task has been pulled from the Task Queue.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation), [timeouts](/tags/timeouts)_ -->

#### [Workflow Type](/workflows#workflow-type)

A Workflow Type is a name that maps to a Workflow Definition.

<!-- _Tags: [term](/tags/term), [explanation](/tags/explanation)_ -->

## Deprecated terms

#### tctl (_deprecated_)

tctl is a command-line tool that you can use to interact with a Temporal Service.
It is superseded by the [Temporal CLI utility](#cli).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/errors.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/errors.mdx</path>
  <content>
---
id: errors
title: Errors
sidebar_label: Errors
description: This reference outlines possible Workflow Task errors, causes, and resolution steps in Temporal. It covers various error scenarios such as attribute failures, size limits, and system resource issues.
toc_max_heading_level: 4
keywords:
  - error
  - errors
  - strongly-typed
tags:
  - Reference
---

This reference lists possible [Workflow Task](/tasks#workflow-task) errors and how to resolve them.

> For other types of errors, see [Temporal Failures](https://docs.temporal.io/kb/failures).

Each of the below errors corresponds with a [WorkflowTaskFailedCause](https://api-docs.temporal.io/#temporal.api.enums.v1.WorkflowTaskFailedCause), which appears in [Events](/workflows#event) under `workflow_task_failed_event_attributes`.

## Bad Cancel Timer Attributes {#bad-cancel-timer-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed while attempting to cancel a Timer.

{/* TODO add Timer term definition and link to it */}

Check your Timer attributes for a missing Timer Id value.
Add a valid Timer Id and redeploy the code.

## Bad Cancel Workflow Execution Attributes {#bad-cancel-workflow-execution-attributes}

The [Workflow Task](/tasks#workflow-task) failed due to unset [CancelWorkflowExecution](/references/commands#cancelworkflowexecution) attributes.

Reset any missing attributes and redeploy the Workflow Task.

## Bad Complete Workflow Execution Attributes {#bad-complete-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to unset attributes on [CompleteWorkflowExecution](/references/commands#completeworkflowexecution).

Reset any missing attributes.
Adjust the size of your Payload if it exceeds size limits.

## Bad Continue as New Attributes {#bad-continue-as-new-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate a [ContinueAsNew](/references/commands#continueasnewworkflowexecution) attribute.
The attribute could be unset or invalid.

Reset any missing attributes.
If the payload or memo exceeded size limits, adjust the input size.

Check that the [Workflow](/workflows) is validating search attributes after unaliasing keys.

## Bad Fail Workflow Execution Attributes {#bad-fail-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to unset [FailWorkflowExecution](/references/commands#failworkflowexecution) attributes.

If you encounter this error, make sure that `StartToClostTimeout` or `ScheduleToCloseTimeout` are set.
Restart the [Worker](/workers) that the [Workflow](/workflows) and [Activity](/activities) are registered to.

## Bad Modify Workflow Properties Attributes {#bad-modify-workflow-properties-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes on a property in the Upsert Memo or in a payload.
These attributes are either unset or exceeding size limits.

Reset any unset and empty attributes.
Adjust the size of the [Memo](/workflows#memo) or payload to fit within the system's limits.

## Bad Record Marker Attributes {#bad-record-marker-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to an unset or incorrect [Marker](/references/events#markerrecorded) name.

Enter a valid Marker name and redeploy the Task.

## Bad Request Cancel Activity Attributes {#bad-request-cancel-activity-attributes}

This error either indicates the possibility of unset attributes for [RequestCancelActivity](/references/commands#requestcancelactivitytask), or an invalid History Builder state.

Update the [Temporal SDK](/encyclopedia/temporal-sdks) to the most recent release.
Reset any unset attributes before retrying the [Workflow Task](/tasks#workflow-task).

If you continue to see this error, review your code for [nondeterministic causes](/workflows#non-deterministic-change).

## Bad Request Cancel External Workflow Execution Attributes {#bad-request-cancel-external-workflow-execution}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed while trying to cancel an external Workflow.
Unset or invalid attributes can cause this to occur.

Reset any missing attributes, such as Workflow Id or Run Id.
Adjust any fields that exceed length limits.

If [Child Workflow](/encyclopedia/child-workflows) is set to `Start` and `RequestCancel`, remove one of these attributes.
A Child Workflow cannot perform both actions in the same Workflow Task.

## Bad Schedule Activity Attributes {#bad-schedule-activity-attributes}

This error indicates unset or invalid attributes for [`ScheduleActivityTask`](/references/commands#scheduleactivitytask) or [`CompleteWorkflowExecution`](/references/commands#completeworkflowexecution).

Reset any unset or empty attributes.
Adjust the size of the received payload to stay within the given size limit.

## Bad Schedule Nexus Operation Attributes

This error indicates unset or invalid attributes for ScheduleNexusOperation, for example if the Nexus Endpoint name used in the caller Workflow doesn't exist.

Inspect the reason given in the error for mitigation when possible.

## Bad Search Attributes {#bad-search-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) has unset or invalid [Search Attributes](/search-attribute).
This can cause Workflow Tasks to continue to retry without success.

Make sure that all attributes are defined before retrying the Task.
Adjust the size of the Payload to fit within the system's size limits.

## Bad Signal Input Size {#bad-signal-input-size}

This error indicates that the Payload has exceeded the [Signal's](/sending-messages#sending-signals) available input size.

Adjust the size of the Payload, and redeploy the [Workflow Task](/tasks#workflow-task).

## Bad Signal Workflow Execution Attributes {#bad-signal-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes for [SignalExternalWorkflowExecution](/references/commands#signalexternalworkflowexecution).

Reset any unset, missing, nil, or invalid attributes.
Adjust the input to fit within the system's size limits.

## Bad Start Child Execution Attributes {#bad-start-child-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes for [`StartChildWorkflowExecution`](/references/commands#startchildworkflowexecution)

Adjust the input size of the attributes to fall within the system's size limits.

Make sure that [Search Attribute](/search-attribute) validation is performed after unaliasing keys.

## Bad Start Timer Attributes {#bad-start-timer-attributes}

This error indicates that the scheduled [Event](/workflows#event) is missing a Timer Id.

{/* TODO add Timer Id as anchor for term and link to it */}

Set a valid Timer Id and retry the [Workflow Task](/tasks#workflow-task).

## Cause Bad Binary {#cause-bad-binary}

This error indicates that the [Worker](/workers) deployment returned a bad binary checksum.

{/* TODO: get more information about binary */}

## Cause Bad Update {#cause-bad-update}

{/* TODO: add link to Workflow Update page when written */}

This error indicates that a [Workflow Execution](/workflows#workflow-execution) tried to complete before receiving an Update.

`BadUpdate` can happen when a [Worker](/workers#worker) generates a [Workflow Task Completed](/references/events#workflowtaskcompleted) message with missing fields or an invalid Update response format.

This error might indicate usage of an unsupported SDK.
Make sure you're using a [supported SDK](/encyclopedia/temporal-sdks).

## Cause Reset Workflow {#cause-reset-workflow}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to a request to reset the [Workflow](/workflows).

If the system hasn't started a new Workflow, manually reset the Workflow.

## Cause Unhandled Update {#cause-unhandled-update}

`UnhandledUpdate` occurs when a Workflow Update is received by the Temporal Server while a Workflow Task being processed on a Worker produces a Command that would cause the Workflow to transition to a closed state.

Temporal rejects the Workflow Task completion to guarantee that the Update is eventually handled by Workflow code and rewinds the Workflow so it can handle the pending Update.

This error can happen when the Workflow receives frequent Updates.

## Cause Unspecified {#cause-unspecified}

This error indicates that the [Workflow Task](/tasks#workflow-task) has failed for an unknown reason.

If you see this error, examine your Workflow Definition.

## Failover Close Command {#failover-close-command}

This error indicates that a [Namespace](/namespaces) failover forced the [Workflow Task](/tasks#workflow-task) to close.
The system automatically schedules a retry when this error occurs.

{/* TODO: troubleshooting */}

## Force Close Command {#force-close-command}

This error indicates that the [Workflow Task](/tasks#workflow-task) was forced to close.
A retry will be scheduled if the error is recoverable.

{/* TODO: more info */}

## Nondeterminism Error {#non-deterministic-error}

The [Workflow Task](/tasks#workflow-task) failed due to a [nondeterminism error](/workflows#non-deterministic-change).

{/* TODO: info */}

## Pending Activities Limit Exceeded {#pending-activities-limit-exceeded}

The [Workflow](/workflows) has reached capacity for pending [Activities](/activities).
Therefore, the [Workflow Task](/tasks#workflow-task) was failed to prevent the creation of another Activity.

Let the Workflow complete any current Activities before redeploying the code.

## Pending Child Workflows Limit Exceeded {#pending-child-workflows-limit-exceeded}

This error indicates that the [Workflow](/workflows) has reached capacity for pending [Child Workflows](/encyclopedia/child-workflows).
Therefore, the [Workflow Task](/tasks#workflow-task) was failed to prevent additional Child Workflows from being added.

Wait for the system to finish any currently running Child Workflows before redeploying this Task.

## Pending Nexus Operations Limit Exceeded {#pending-nexus-operations-limit-exceeded}

The Workflow has reached capacity for pending Nexus Operations. Therefore, the Workflow Task was failed to prevent the creation of another Nexus Operation.

Let the Workflow complete any current Nexus Operation before retrying the Task.

See [Per Workflow Nexus Operation Limits](/cloud/limits#per-workflow-nexus-operation-limits) for details.

## Pending Request Cancel Limit Exceeded {#pending-request-cancel-limit-exceeded}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed after attempting to add more cancel requests.
The [Workflow](/workflows) has reached capacity for pending requests to cancel other Workflows, and cannot accept more requests.

If you see this error, give the system time to process pending requests before retrying the Task.

## Pending Signals Limit Exceeded {#pending-signals-limit-exceeded}

The Workflow has reached capacity for pending Signals.
Therefore, the [Workflow Task](/tasks#workflow-task) was failed after attempting to add more [Signals](/sending-messages#sending-signals) to an external Workflow.

Wait for Signals to be processed by the Workflow before retrying the Task.

## Reset Sticky Task Queue {#reset-sticky-task-queue}

This error indicates that the Sticky [Task Queue](/task-queue) needs to be reset.

If you see this error, reset the Sticky Task Queue.
The system will retry automatically.

## Resource Exhausted Cause Concurrent Limit {#resource-exhausted-cause-concurrent-limit}

This error indicates that the concurrent [poller count](/develop/worker-performance#poller-count) has been exhausted.

{/* TODO: more info needed */}

Adjust the poller count per [Worker](/workers).

## Resource Exhausted Cause Persistence Limit {#resource-exhausted-cause-persistence-limit}

This error indicates that the persistence rate limit has been reached.

{/* TODO: more info needed */}

## Resource Exhausted Cause RPS Limit {#resource-exhausted-cause-rps-limit}

This error indicates that the [Workflow](/workflows) has exhausted its RPS limit.

{/* TODO: more info needed */}

## Resource Exhausted Cause System Overload {#resource-exhausted-cause-system-overload}

This error indicates that the system is overloaded and cannot allocate further resources to [Workflow Tasks](/tasks#workflow-task).

{/* TODO: more info needed */}

## Resource Exhausted Cause Unspecified {#resource-exhausted-cause-unspecified}

This error indicates that an unknown cause is preventing resources from being allocated to further [Workflow Tasks](/tasks#workflow-task).

{/* TODO: more info needed */}

## Schedule Activity Duplicate Id {#schedule-activity-duplicate-id}

The [Workflow Task](/tasks#workflow-task) failed because the [Activity](/activities) Id is already in use.

Check your code to see if you've already specified the same Activity Id in your [Workflow](/workflows).
Enter another Activity Id, and try running the Workflow Task again.

## Start Timer Duplicate Id {#start-timer-duplicate-id}

This error indicates that a Timer with the given Timer Id has already started.

{/* TODO link to Timer term when exists */}

Try entering a different Timer Id, and retry the [Workflow Task](/tasks#workflow-task).

## Unhandled Command {#unhandled-command}

This error indicates new available [Events](/references/events) since the last [Workflow Task](/tasks#workflow-task) started.
The Workflow Task was failed because the [Workflow](/workflows) attempted to close itself without handling the new Events.

`UnhandledCommand` can happen when the Workflow is receiving a high number of [Signals](/sending-messages#sending-signals).
If the Workflow doesn't have enough time to handle these Signals, a RetryWorkflow Task is scheduled to handle these new Events.

To prevent this error, drain the Signal Channel with the ReceiveAsync function.

If you continue to see this error, check your logs for failing Workflow Tasks.
The Workflow may have been picked up by a different [Worker](/workers#worker).

## Workflow Worker Unhandled Failure {#workflow-worker-unhandled-failure}

This error indicates that the [Workflow Task](/tasks#workflow-task) encountered an unhandled failure from the [Workflow Definition](/workflows#workflow-definition).

{/* TODO: more info needed */}

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/multi-region-namespace.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/multi-region-namespace.mdx</path>
  <content>
---
id: multi-region-namespace
title: Multi-region Namespace - Temporal Cloud production feature
description: Temporal Cloud's Multi-region Namespaces offer automated failover, synchronized data replication, and high availability for workloads requiring disaster-tolerant deployment and 99.99% uptime.
sidebar_label: Multi-region namespace
tags:
  - Temporal Cloud
  - High availability
keywords:
  - availability
  - explanation
  - failover
  - high-availability
  - multi-region
  - multi-region namespace
  - namespaces
  - temporal-cloud
  - term
---

Temporal Cloud offers disaster-tolerant deployment for workloads with stringent availability requirements.
With the multi-region feature enabled, Temporal Cloud automates [failover](/glossary#failover) and synchronizes data between Namespace regions.
This page introduces Temporal Cloud patterns that support your workload's availability requirements.

## Multi-region Namespaces

Multi-region Namespaces provide failover capabilities to mitigate service outages due to regional failures.
They reduce risk and minimize operational disruption.
This feature seamlessly shif​​ts Workflow execution between regions to maintain service availability.

Your Clients use a single logical Namespace with a single endpoint that operates in two physical regions: one active and one standby.
As Workflows progress in the active region, history events asynchronously replicate to the standby region.
Data replication ensures both regions are in sync so the standby is ready to take over when needed.

Should an incident or outage occur in the active region, Temporal Cloud initiates a "failover" to the standby region.
During a failover, the roles of the active and standby regions reverse.
The standby takes over as the primary region.

### Advantages of multi-region Namespaces {#multi-region-advantages}

**Why choose a multi-region Namespace (MRN)?**

- **Reduce Risk**:
  MRN's protects your operations from unexpected regional outages.
  Its automated disaster recovery features ensure that workloads remain available and continue execution.
- **Minimize Operational Disruption**:
  Seamless failovers shift Workflow Executions to a secondary region during outages.
  MRNs maintain service availability without needing manual synchronization between Namespaces.
  Real-time alerts during failover events keep you informed.
- **No manual deployment or configuration needed:**
  Temporal Cloud simplifies deployment with push-button operation.
  This eliminates the need for manual deployment or configuration.
- **Fault tolerance**.
  Your open Workflows continue their progress in the standby region.
  This minimizes interruption and data loss during regional failures.
- **No code changes**.
  Your Workers and Workflow starter code don't need updates to take advantage of multi-region setup or to respond to failover conditions.
  This allows for a smooth transition and continued operation.

### Service Level Objectives (SLO) and guarantees {#multi-region-SLO}

**What reliability promises does this feature offer?**

- Temporal provides a 99.99% Contractual SLA that provides redress in the event of downtime ([SLA](https://docs.temporal.io/cloud/sla)).
- [RTO](https://csrc.nist.gov/glossary/term/recovery_time_objective): 20 minutes or less.
- [RPO](https://csrc.nist.gov/glossary/term/recovery_point_objective): Near zero.

### Target workloads {#target-workloads}

**Who benefits from this feature?**

Multi-region Namespaces are a great solution for Workloads where a regional cloud outage would cause:

- Revenue loss
- Poor customer experience
- Problems stemming from policy/legal requirements that demand high availability

Some examples: financial services, e-commerce, gaming, global SaaS platforms, bookings & reservations, delivery & shipping, order management.

### Explore {#explore-multi-region}

**Read more about our multi-region features**

- [Multi-region Namespaces](/cloud/high-availability/enable) offer High Availability service for Temporal Cloud customers who need the highest level of availability at all times.
- [Multi-region Pricing](/cloud/pricing) scales to use.
- Multi-region replication supports [PrivateLink routing](/cloud/high-availability/private-link).

## Single-region Namespaces

A typical Temporal Cloud Namespace is deployed into one [AWS region](https://docs.temporal.io/cloud/service-availability), or GCP region.
Temporal Cloud provides [99.99% availability](https://docs.temporal.io/cloud/sla) and a contractual [service level agreement](https://docs.temporal.io/cloud/sla) (SLA) of 99.9% guarantee against service errors.
It provides a great all-around solution that's suitable for most organizations.

### Advantages of single-region Namespaces {#single-region-advantages}

**Why choose single-region Namespaces?**

- This option offers sufficient availability for most use cases and workloads.
- Temporal Cloud provides 99.99% availability and a contractual service level agreement of 99.9% guarantee against service errors.
  Read more on our [SLA page](https://docs.temporal.io/cloud/sla).

Some downsides of single-region Namespaces compared to multi-region Namespaces:

- Stalled work during failures: Open Workflow Executions pause until the region/Namespace recovers.
- Blocked work initiation: No new Workflow Executions will start until the region/Namespace recovers.

### Explore {#explore-temporal-namespaces}

**Read more about Namespaces**

- [Temporal Cloud Namespaces](/cloud/namespaces) offer outstanding reliable service for Temporal Cloud customers.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/gcp-private-service-connect.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/gcp-private-service-connect.mdx</path>
  <content>
---
id: gcp-private-service-connect
title: Private Communication - GCP Private Service Connect
sidebar_label: GCP Private Service Connect
description: Secure your Temporal Cloud connections using GCP Private Service Connect.
slug: /cloud/security/gcp-private-service-connect
toc_max_heading_level: 4
keywords:
  - private service connect
  - private connectivity
  - security
  - temporal cloud
  - gcp
  - google cloud
tags:
  - security
  - temporal-cloud
  - gcp
  - google cloud
  - private service connect
  - private-connectivity
---

#### Google Cloud Private Service Connect

[Google Cloud Private Service Connect](https://cloud.google.com/vpc/docs/private-service-connect) allows you to open a path to Temporal without opening a public egress.
It establishes a private connection between your Google Virtual Private Cloud (VPC) and Temporal Cloud.
This one-way connection means Temporal cannot establish a connection back to your service.
This is useful if normally you block traffic egress as part of your security protocols.
If you use a private environment that does not allow external connectivity, you will remain isolated.

:::note

If you are interested in leveraging Google Cloud Private Service Connect in your Namespaces, [create a support ticket](/cloud/support#support-ticket) that includes the following information:

- Google Cloud Region: The Region in which your connection will go through.
- Google Cloud Project Id: The project that you will establish the private connection from, so it can be allowed on the Temporal side.
- Temporal Cloud Namespace names: The name of the Namespaces you want to enable Google Cloud Private Service Connect with.

:::

Set up Private Service Connect with Temporal Cloud with these steps:

1. Open the Google Cloud console
2. Navigate to **Network Services**, then **Private Service Connect**. If you haven't used **Network Services** recently, you might have to find it by clicking on **View All Products** at the bottom of the left sidebar.

   ![GCP console showing Network Services, and the View All Products button](/img/cloud/gcp/gcp-console.png)

3. Go to the **Endpoints** section. Click on **Connect endpoint**.

   ![GCP console showing the endpoints, and the Connect endpoint button](/img/cloud/gcp/connect-endpoint-button.png)

4. Under **Target**, select **Published service**, this will change the contents of the form to allow you to fill the rest as described below

   ![GCP console showing the endpoints, and the Connect endpoint button](/img/cloud/gcp/connect-endpoint.png)

  - For **Target service**, fill in the **Service name** with the Private Service Connect Service Name for the region you’re trying to connect to:

      | Region                 | Private Service Connect Service Name                                                      |
      | ---------------------- | ----------------------------------------------------------------------------------------- |
      | `asia-south1`          | `projects/prod-d5spc2sfeshws33bg33vwdef7/regions/asia-south1/serviceAttachments/pl-7w7tw` |
      | `us-west1   `          | `projects/prod-rbe76zxxzydz4cbdz2xt5b59q/regions/us-west1/serviceAttachments/pl-94w0x`    |

  - For **Endpoint name**, enter a unique identifier to use for this endpoint. It could be for instance `temporal-api` or `temporal-api-<namespace>` if you want a different endpoint per namespace.
  - For **Network** and **Subnetwork**, choose the network and subnetwork where you want to publish your endpoint.
  - For **IP address**, click the dropdown and select **Create IP address** to create an internal IP from your subnet dedicated to the endpoint. Select this IP.
  - Check **Enable global access** if you intend to connect the endpoint to virtual machines outside of the selected region. We recommend regional connectivity instead of global access, as it can be better in terms of latency for your workers.

5. Click the **Add endpoint** button at the bottom of the screen.
   If successful, the status of your new endpoint will appear as **Accepted**.
   Take note of the **IP address** that has been assigned to your endpoint, as it will be used to connect to Temporal Cloud.

6. You can use GCP Private Service Connect.
    You can use the **IP address** of the previous step to connect to Temporal Cloud using port 7233.
    To establish a valid mTLS session, you must override the TLS server name used for the connection to `<namespace>.<account>.tmprl.cloud`.


:::tip

GCP Private Service Connect services are regional.
Individual Namespaces do not use separate services.

:::

Once set up, you can test your Private Service Connect connectivity using the following methods.
When connecting, you must override the TLS server name to target your Namespace’s individual hostname (`<namespace>.<account>.tmprl.cloud`) to establish a valid mTLS session:

- The Temporal CLI, using the `--tls-server-name` parameter to override the TLS server name. For example:

  ```
  temporal workflow count \
      --address <IP address of the PSC endpoint>:7233 \
      --tls-cert-path /path/to/client.pem \
      --tls-key-path /path/to/client.key \
      --tls-server-name <namespace>.<account>.tmprl.cloud \
      --namespace <namespace>
  ```

- Non-Temporal tools like grpcURL, useful for testing from environments that restrict tool usage, using the `-servername` parameter to override the TLS server name. For example:

  ```
  grpcurl \
      -servername <name>.<account>.tmprl.cloud \
      -cert /path/to/client.pem \
      -key /path/to/client.key \
      <IP address of the PSC endpoint>:7233 \
      temporal.api.workflowservice.v1.WorkflowService/GetSystemInfo
  ```

- Temporal SDKs, by setting the endpoint server address argument to the Private Service Connect endpoint (`<IP address of the PSC endpoint>:7233`) and using the TLS configuration options to override the TLS server name.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/workflow-message-passing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/workflow-message-passing.mdx</path>
  <content>
---
id: workflow-message-passing
title: Workflow message passing - Temporal feature
description: Enhance your Workflows with Signals and Queries, allowing dynamic responses to external events and real-time state access for comprehensive monitoring and tracking.
sidebar_label: Workflow message passing
tags:
  - Signals
  - Queries
  - Updates
  - Workflows
  - Activities
  - Workers
keywords:
  - temporal application
  - workflow design
  - business logic activities
  - temporal workers
  - temporal SDK tutorial
  - learning temporal workflows
  - developing with temporal
  - temporal workflow execution
  - temporal activity management
  - worker process execution
  - signals
  - queries
  - updates
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Need to interact with your Workflow from outside of it? Think about use cases like these:

- Your shipment-tracking Workflow needs to know when the item leaves the warehouse and is loaded into their truck. **Signal** your Workflow when the truck driver scans the barcode.
- Folks in your company want to track the progress of their data migration Workflows. **Query** your running batch Workflow to get the data for the progress bar.
- Your eCommerce shopping cart Workflow needs to know when a new item is added. **Update** it to add the item and receive back the current items to render.

Temporal provides Signals, Queries, and Updates to allow rich interactivity with your running Workflows.

**Signals**: Signal to send messages asynchronously to a running Workflow, changing its state or controlling its flow in real-time.

**Queries**: Query to check the progress of your Workflow or debug the internal state in real-time.

**Updates**: Update to send synchronous requests to your Workflow and track it in real-time.

To learn more about using these powerful primitives, see our encyclopedia Entry:

<RelatedReadContainer>
  <RelatedReadItem path="/encyclopedia/workflow-message-passing" text="Workflow message passing (Signals, Queries, & Updates)" archetype="encyclopedia" />
</RelatedReadContainer>

For a deeper dive into Workflow message passing, enroll in one of [our courses](https://learn.temporal.io/courses/interacting_with_workflows).

If you want to jump to straight to implementation details, see the SDK feature guides.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/message-passing" text="Go SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/message-passing" text="Java SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/message-passing" text="Python SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/message-passing" text="TypeScript SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/message-passing" text=".NET SDK Workflow message passing feature guide" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/troubleshooting/last-connection-error.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/troubleshooting/last-connection-error.mdx</path>
  <content>
---
id: last-connection-error
title: Troubleshoot the failed reaching server error
sidebar_label: Failed reaching server error
description: Troubleshoot server connection errors often caused by expired TLS certificates. Verify, renew, and update server configurations to resolve temporal client request issues effectively.
toc_max_heading_level: 4
keywords:
  - cloud
  - namespaces
tags:
  - Temporal Cloud
  - Namespaces
---

The message `Failed reaching server: last connection error` can often result from an expired TLS certificate or during the Server startup process, in which the Client requests reach the Server before the roles are fully initialized.

This troubleshooting guide shows you how to do the following:

- Verify the certification expiration date
- Renew the certification
- Update the server configuration

### Verify TLS certification expiration date

The first step in troubleshooting this error is to verify the expiration date of the TLS certification.
Then you can renew the certification and update the server configuration.

Choose one of the following methods to verify the expiration date of the TLS certification:

**Verify the expiration date of the TLS certification**

List the expiration date with the following command:

```command
tcld namespace accepted-client-ca list \
    --namespace <namespace_id>.<account_id> | \
    jq -r '.[0].notAfter'
```

If the returned date is in the past, the certificate has expired.

**Existing certificate management infrastructure**

If you are using an existing certificate management infrastructure, use it to verify the TLS connection.
For example, if you are using OpenSSL, run the following command:

```command
openssl s_client -connect <namespace_grpc_endpoint> -showcerts -cert ~/certs/path.pem -key .~/certs/path.key -tls1_2
```

**Self-signed certificate**

If you are using a self-signed certificate, run the following Temporal CLI command:

```command
temporal namespace describe \
    --namespace <namespace_id>.<account_id> \
    --address <namespace_grpc_endpoint> \
    --tls-cert-path <path-to-mTLS-pem-file> \
    --tls-key-path <path-to-mTLS-key-file>
```

Your Namespace gRPC endpoint is available on the details page for your [Temporal Cloud Namespace](https://cloud.temporal.io/namespaces).

### Renew TLS certification

If the certificate has expired or is about to expire, the next step is to renew it.

You can do this by contacting the certificate authority (CA) that issued the certificate and requesting a renewal.

**Existing certificate management infrastructure**

If you are using an existing certificate management infrastructure, contact the administrator of the infrastructure to renew the certificate.

**Self-signed certificate**

If you are using a self-signed certificate or don't have an existing infrastructure, you can generate a new certificate using OpenSSL or [certstrap](https://github.com/square/certstrap).

For information on generating a self-signed certificate, see [Control authorization](/cloud/certificates#control-authorization).

### Update the CA certification in the server configuration

Update the new CA certificate in the Temporal Cloud server configuration.

You can update certificates using any of the following methods:

- [Update certificates using Temporal Cloud UI](/cloud/certificates#update-certificates-using-temporal-cloud-ui)
- [Update certificates using tcld](/cloud/certificates#update-certificates-using-tcld)

After you update the TLS certification in the server configuration, retry your connection.

### Set reminders

Don't let your certificates expire.
Add reminders to your calendar to issue new CA certificates well before the expiration dates of the existing ones.

### Additional resources

The preceding steps should help you troubleshoot the `failed reaching server: last connection error` error caused by an expired TLS certificate.

If this issue persists, verify that the Client you are using to connect to the server is using the correct TLS certification and that the Client requests reach the server after the roles are fully initialized.
If you still need help, [create a support ticket](/cloud/support#support-ticket).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workflow-message-passing/workflow-message-passing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workflow-message-passing/workflow-message-passing.mdx</path>
  <content>
---
id: workflow-message-passing
title: Temporal Workflow message passing - Signals, Queries, & Updates
sidebar_label: Workflow message passing
description: Signals, Queries, and Updates facilitate interactions with Workflow Executions.
tags:
- Concepts
- Signals
- Queries
- Updates
- Messages
keywords:
- temporal workflow signals
- temporal workflow queries
- temporal workflow updates
- temporal workflow execution
- message passing temporal
- signal-with-start temporal
- temporal query handler
- temporal signal handler
- temporal update handler
- temporal update validator
- temporal message passing
- workflow state temporal
- synchronous operation temporal
- asynchronous request temporal
- temporal service events
- temporal client methods
- temporal sdk message passing
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import {RelatedReadContainer, RelatedReadItem} from '@site/src/components/related-read/RelatedRead';

Workflows can be thought of as stateful web services that can receive messages.
The Workflow can have powerful message handlers akin to endpoints that react to the incoming messages in combination with the current state of the Workflow.
Temporal supports three types of messages: Signals, Queries, and Updates:

- Queries are read requests. They can read the current state of the Workflow but cannot block in doing so.
- Signals are asynchronous write requests. They cause changes in the running Workflow, but you cannot await any response or error.
- Updates are synchronous, tracked write requests. The sender of the Update can wait for a response on completion or an error on failure.

## How to choose between Signals, Updates, and Queries as a Workflow author? {#choosing-messages}

This section will help you write Workflows that receive messages.

### For write requests

Unlike Signals, Updates must be synchronous. That is, they must wait for the Worker running the Workflow to acknowledge the request.

Use Signals instead of Updates when:

- The Workflow's clients want to quickly move on after sending an asynchronous message.
- The clients are willing to "fire and forget": they don't want a result or exception from the message.
- The clients don't want to rely on the Worker being available.

Use Updates instead of Signals when:

- The Workflow's clients want to track the completion of the message.
- The clients need a result or an exception from your message without having to query subsequently.
- You’d like to “validate” the Update before accepting it into the Workflow and its history.
- The clients want a low-latency end-to-end operation and are willing to wait for it to finish or be validated.

### For read requests

You normally want to do a Query, because:

- Queries are efficient–they never add entries to the [Workflow Event History](/workflows#event-history), whereas an Update would (if accepted).
- Queries can operate on completed Workflows.

However, because Queries cannot block, sometimes Updates are best.
When your goal is to do a read once the Workflow achieves a certain desired state, you have two options:

- You could poll periodically with Queries until the Workflow is ready.
- You could write your read operation as an Update, which will give you better efficiency and latency, though it will write an entry to the [Workflow Event History](/workflows#event-history).

### For read/write requests

Use an Update for synchronous read/write requests. If your request must be asynchronous, consider sending a Signal followed by polling with a Query.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/index.mdx</path>
  <content>
---
id: index
title: Temporal CLI command reference
sidebar_label: Temporal CLI
description: The Temporal CLI offers terminal access to Temporal Services for managing, monitoring, and debugging Workflows and Activities, including Namespace and Task Queue management, with embedded development support.
slug: /cli
toc_max_heading_level: 4
keywords:
  - cli
  - dev server
  - install
  - temporal cli
  - term
tags:
  - Temporal CLI
---

:::tip Support, stability, and dependency info

Temporal CLI 1.1 is now available.
See the [release notes](https://github.com/temporalio/cli/releases/tag/v1.1.0) or view the latest command information from the utility:

```
temporal [command] --help
```

:::

The Temporal CLI provides direct access to a Temporal Service via the terminal.
It's a powerful tool for managing, monitoring, and debugging Temporal Applications.
You can use it to start, stop, inspect and operate on Workflows and Activities, and perform administrative tasks such as Namespace, Schedule, and Task Queue management.

The Temporal CLI also includes an embedded Temporal Service suitable for use in development and CI/CD.
It includes the [Temporal Server](/clusters#temporal-server), SQLite persistence, and the [Temporal Web UI](/web-ui).

:::note

When upgrading from [tctl](/tctl-v1) to the Temporal CLI, make sure to update your environment variables and use updated commands.
For details, see [CLI release notes](https://github.com/temporalio/cli/releases/).

:::

## Install the Temporal CLI {#install}

**How to download and install the Temporal CLI**

The Temporal CLI is available on macOS, Windows, and Linux.

### How to install the Temporal CLI on macOS

Choose one of the following install methods to install the Temporal CLI on macOS:

- Install the Temporal CLI with Homebrew.

```shell
brew install temporal
```

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed.

  - Download for Darwin amd64: https://temporal.download/cli/archive/latest?platform=darwin&arch=amd64
  - Download for Darwin arm64: https://temporal.download/cli/archive/latest?platform=darwin&arch=arm64

  2. Extract the downloaded archive.

  3. Add the Temporal CLI binary to your PATH.

### How to install the Temporal CLI on Linux

Choose one of the following install methods to install the Temporal CLI on Linux:

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed.

  - Download for Linux amd64: https://temporal.download/cli/archive/latest?platform=linux&arch=amd64
  - Download for Linux arm64: https://temporal.download/cli/archive/latest?platform=linux&arch=arm64

  2. Extract the downloaded archive.

  3. Add the `temporal` binary to your PATH.

### How to install the Temporal CLI on Windows

Choose one of the following methods to install the Temporal CLI on Windows:

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed and download the binary.

  - Download for Windows amd64: https://temporal.download/cli/archive/latest?platform=windows&arch=amd64
  - Download for Windows arm64: https://temporal.download/cli/archive/latest?platform=windows&arch=arm64

  2. Extract the downloaded archive.

  3. Add the `temporal.exe` binary to your PATH.

## Command set

- [temporal activity](/cli/activity/)
- [temporal batch](/cli/batch/)
- [temporal env](/cli/env/)
- [temporal operator](/cli/operator/)
- [temporal schedule](/cli/schedule/)
- [temporal server](/cli/server)
- [temporal task-queue](/cli/task-queue/)
- [temporal workflow](/cli/workflow/)

## Configuration

The following information provides important configuration details.

### Namespace registration

Namespaces are pre-registered at startup for immediate use.
Customize pre-registered Namespaces with the following command:

```shell
temporal server start-dev --namespace foo --namespace bar
```

Register Namespaces with `namespace create`:

```shell
temporal operator namespace create --namespace foo
```

### Enable or disable Temporal UI

By default, the Temporal UI is enabled when running the development server using the Temporal CLI.
To disable the UI, use the `--headless` modifier:

```shell
temporal server start-dev --headless
```

### Dynamic configuration

Advanced Temporal CLI configuration requires a dynamic configuration file.

To set values on the command line, use `--dynamic-config-value KEY=JSON_VALUE`.
For example, enable the Search Attribute cache:

```bash
temporal server start-dev --dynamic-config-value system.forceSearchAttributesCacheRefreshOnRead=false
```

This setting makes created Search Attributes immediately available.

## Environment variables

The following table describes the environment variables you can set for the Temporal CLI.

| Variable                                 | Definition                                                                | Client Option                   |
| ---------------------------------------- | ------------------------------------------------------------------------- | ------------------------------- |
| `TEMPORAL_ADDRESS`                       | Host and port (formatted as host:port) for the Temporal Frontend Service. | --address                       |
| `TEMPORAL_CODEC_AUTH`                    | Authorization header for requests to Codec Server.                        | --codec-auth                    |
| `TEMPORAL_CODEC_ENDPOINT`                | Endpoint for remote Codec Server.                                         | --codec-endpoint                |
| `TEMPORAL_NAMESPACE`                     | Namespace in Temporal Workflow. Default: "default".                       | --namespace                     |
| `TEMPORAL_TLS_CA`                        | Path to server CA certificate.                                            | --tls-ca-path                   |
| `TEMPORAL_TLS_CERT`                      | Path to x509 certificate.                                                 | --tls-cert-path                 |
| `TEMPORAL_TLS_DISABLE_HOST_VERIFICATION` | Disables TLS host name verification. Default: false.                      | --tls-disable-host-verification |
| `TEMPORAL_TLS_KEY`                       | Path to private certificate key.                                          | --tls-key-path                  |
| `TEMPORAL_TLS_SERVER_NAME`               | Override for target TLS server name.                                      | --tls-server-name               |
| `TEMPORAL_CLOUD_API_KEY`                 | API key used for authentication.                                          | --api-key                       |

## Proxy support

The Temporal CLI provides support for users who are operating behind a proxy.
This feature ensures seamless communication even in network-restricted environments.

#### Setting up proxy support

If you are behind a proxy, you'll need to instruct the Temporal CLI to route its requests via that proxy.
You can achieve this by setting the `HTTPS_PROXY` environment variable.

```command
export HTTPS_PROXY=<host>:<port>
```

Replace `<host>` with the proxy's hostname or IP address, and `<port>` with the proxy's port number.

Once set, you can run the Temporal CLI commands as you normally would.

:::note

Temporal CLI uses the gRPC library which natively supports HTTP CONNECT proxies. The gRPC library checks for the `HTTPS_PROXY` (and its case-insensitive variants) environment variable to determine if it should route requests through a proxy.

:::

In addition to `HTTPS_PROXY`, gRPC also respects the `NO_PROXY` environment variable.
This can be useful if there are specific addresses or domains you wish to exclude from proxying.

For more information, see [Proxy](https://github.com/grpc/grpc-go/blob/master/Documentation/proxy.md) in the gRPC documentation.

## Auto-completion

Enable auto-completion using the following commands.

### zsh auto-completion

1. Add the following line to your `~/.zshrc` startup script:

   ```sh
   eval "$(temporal completion zsh)"
   ```

2. Re-launch your shell or run:

   ```sh
   source ~/.zshrc
   ```

### Bash auto-completion

1. Install [bash-completion](https://github.com/scop/bash-completion#installation) and add the software to your `~/.bashrc`.

2. Add the following line to your `~/.bashrc` startup script:

   ```sh
   eval "$(temporal completion bash)"
   ```

3. Re-launch your shell or run:

   ```sh
   source ~/.bashrc
   ```

:::note

If auto-completion fails with the error: `bash: _get_comp_words_by_ref: command not found`, you did not successfully install [bash-completion](https://github.com/scop/bash-completion#installation). This package must be loaded into your shell for `temporal` auto-completion to work.

:::

### Fish auto-completion

1. Create the Fish custom completions directory if it does not already exist:

   ```fish
   mkdir -p ~/.config/fish/completions
   ```

2. Configure the completions to load when needed. Note: the file name must be `temporal.fish` or the completions will not be found:

   ```fish
   echo 'eval "$(temporal completion fish)"' >~/.config/fish/completions/temporal.fish
   ```

3. Re-launch your shell or run:

   ```fish
   source ~/.config/fish/completions/temporal.fish
   ```

## Temporal dev server {#start-dev-server}

**How to start the Temporal development server**

To start the Temporal development server run the following command:

```bash
temporal server start-dev
```

This command automatically starts the Web UI, creates the `default` [Namespace](/namespaces), and uses an in-memory database.

The Temporal Server should be available on `localhost:7233` and the Temporal Web UI should be available at [`http://localhost:8233`](http://localhost:8233/).

The in-memory SQLite database does not persist if you stop the dev server.
Use the `--db-filename` option to specify a database file, persisting application state.
This is helpful if you plan on stopping and re-starting the dev server.

```shell
temporal server start-dev --db-filename temporal.db
```

:::note

Local databases created with `--db-filename` may not be compatible with newer versions of the Temporal CLI.
The `temporal server` command is only intended for development environments.

:::

For the full list of dev server options use the `--help` flag:

```shell
temporal server start-dev --help
```

## Common CLI operations {#common-operations}

The following are some of the more common operations you can perform with the Temporal CLI.

### Start a Workflow

In another terminal, use the following commands to interact with the Server.
The following command starts a Workflow:

```shell
$ temporal workflow start \
  --task-queue hello-world \
  --type MyWorkflow \
  --workflow-id 123 \
  --input 456

Running execution:
  WorkflowId                                   123
  RunId       357074e4-0dd8-4c44-8367-d92536dd0943
  Type        MyWorkflow
  Namespace   default
  TaskQueue   hello-world
  Args        [456]
```

Shorthand options are available:

```shell
temporal workflow start --task-queue hello-world --type MyWorkflow --workflow-id 123 --input 456
```

You can also list and describe Workflows:

```shell
$ temporal workflow list

  Status   WorkflowId     Name       StartTime
  Running         123  MyWorkflow  14 seconds ago

$ temporal workflow describe --workflow-id 123

{
  "executionConfig": {
    "taskQueue": {
      "name": "hello-world",
      "kind": "Normal"
    },
    "workflowExecutionTimeout": "0s",
    "workflowRunTimeout": "0s",
    "defaultWorkflowTaskTimeout": "10s"
  },
  "workflowExecutionInfo": {
    "execution": {
      "workflowId": "123",
      "runId": "357074e4-0dd8-4c44-8367-d92536dd0943"
    },
    "type": {
      "name": "MyWorkflow"
    },
    "startTime": "2023-04-15T06:42:31.191137Z",
    "status": "Running",
    "historyLength": "2",
    "executionTime": "2023-04-15T06:42:31.191137Z",
    "memo": {

    },
    "autoResetPoints": {

    },
    "stateTransitionCount": "1"
  },
  "pendingWorkflowTask": {
    "state": "Scheduled",
    "scheduledTime": "2023-04-15T06:42:31.191173Z",
    "originalScheduledTime": "2023-04-15T06:42:31.191173Z",
    "attempt": 1
  }
}
```

For more detailed output in JSON format, use the following command:

```shell
$ temporal workflow list --fields long --output json

[
  {
    "execution": {
      "workflow_id": "123",
      "run_id": "357074e4-0dd8-4c44-8367-d92536dd0943"
    },
    "type": {
      "name": "MyWorkflow"
    },
    "start_time": "2023-04-15T06:42:31.191137Z",
    "status": 1,
    "execution_time": "2023-04-15T06:42:31.191137Z",
    "memo": {},
    "task_queue": "hello-world"
  }
]
```

Filter out Workflows based on Workflow Type with [jq](https://stedolan.github.io/jq/):

```shell
$ temporal workflow list --fields long --output json | jq '.[].type.name'

"OtherWorkflow"
"MyWorkflow"
"MyWorkflow"
```

To count the number of Workflows, use the following command:

```shell
$ temporal workflow list --fields long --output json | jq '.[].type.name' | uniq -c

   1 "OtherWorkflow"
   2 "MyWorkflow"
```

To see the full range of Workflow-related commands, run `temporal workflow` or see the [Temporal CLI workflow command reference](/cli/workflow).

For a full list of available commands, run `temporal` without arguments or see [Available commands](#command-set).

### Customize your environment variables

To communicate with a different Server, like a production Namespace on Temporal Cloud:

1. Create an environment named `prod`.
2. Pass `--env prod` to commands, like `temporal workflow list --env prod`.

To create a new environment and set its properties:

```shell
temporal env set prod.namespace production.f45a2
temporal env set prod.address production.f45a2.tmprl.cloud:7233
temporal env set prod.tls-cert-path /temporal/certs/prod.pem
temporal env set prod.tls-key-path /temporal/certs/prod.key
```

Check your settings:

```shell
$ temporal env get prod

  address        production.f45a2.tmprl.cloud:7233
  namespace      production.f45a2
  tls-cert-path  /temporal/certs/prod.pem
  tls-key-path   /temporal/certs/prod.key
```

Run a command to test the connection:

```shell
$ temporal workflow list --env prod
```

For a full list of properties, use `temporal env set -h`.

```shell
$ temporal env set -h

OPTIONS:
   Client Options:

   --address value                          The host and port (formatted as host:port) for the Temporal Frontend Service. [$TEMPORAL_CLI_ADDRESS]
   --codec-auth value                       Sets the authorization header on requests to the Codec Server. [$TEMPORAL_CLI_CODEC_AUTH]
   --codec-endpoint value                   Endpoint for a remote Codec Server. [$TEMPORAL_CLI_CODEC_ENDPOINT]
   --command-timeout duration               Timeout for the span of a command. (default 0s)
   --env value                              Name of the environment to read environmental variables from. (default: "default")
   --grpc-meta value [ --grpc-meta value ]  Contains gRPC metadata to send with requests (format: key=value). Values must be in a valid JSON format.
   --namespace value, -n value              Identifies a Namespace in the Temporal Workflow. (default: "default") [$TEMPORAL_CLI_NAMESPACE]
   --tls-ca-path value                      Path to server CA certificate. [$TEMPORAL_CLI_TLS_CA]
   --tls-cert-path value                    Path to x509 certificate. [$TEMPORAL_CLI_TLS_CERT]
   --tls-disable-host-verification          Disables TLS host name verification if already enabled. (default: false) [$TEMPORAL_CLI_TLS_DISABLE_HOST_VERIFICATION]
   --tls-key-path value                     Path to private certificate key. [$TEMPORAL_CLI_TLS_KEY]
   --tls-server-name value                  Provides an override for the target TLS server name. [$TEMPORAL_CLI_TLS_SERVER_NAME]

   Display Options:

   --color value  when to use color: auto, always, never. (default: "auto")
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/sdk-metrics.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/sdk-metrics.mdx</path>
  <content>
---
id: sdk-metrics
title: Temporal SDK metrics reference
sidebar_label: SDK metrics
description: Temporal SDKs emit metrics covering Client usage and Worker Processes. Metrics can be tuned to improve Worker performance and are prefixed with temporal_ before export.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
  - Metrics
---

:::info SDK metrics

The information on this page is relevant to [Temporal SDKs](/encyclopedia/temporal-sdks).

See [Cloud metrics](/cloud/metrics/) for metrics emitted by [Temporal Cloud](/cloud/overview).

See [Cluster metrics](/references/cluster-metrics) for metrics emitted by the [OSS Cluster](/clusters).

Some SDKs may emit metrics beyond what is listed in this SDK Metrics reference.
Only metrics included in this Metrics reference have guaranteed, defined behavior.
Other metrics are considered deprecated, inconsistent or experimental.

:::

The Temporal SDKs emit a set of metrics from Temporal Client usage and Worker Processes.

- [How to emit metrics using the Go SDK](/develop/go/observability#metrics)
- [How to emit metrics using the Java SDK](/develop/java/observability#metrics)
- [How to emit metrics using the Python SDK](/develop/python/observability#metrics)
- [How to emit metrics using the TypeScript SDK](/develop/typescript/observability#metrics)
- [How to emit metrics using the .NET SDK](/develop/dotnet/observability#metrics)

- [How to tune Worker performance based on metrics](/develop/worker-performance)

All metrics are prefixed with `temporal_` before being exported to their configured destination.
(The prefix has been removed in the following reference.)
Currently, some metrics are specific to certain SDKs.

TypeScript, Python, and .NET SDKs metrics are defined in the Core SDK.

PHP and Go metrics are defined in the Go SDK.

Java metrics are defined in the Java SDK
Metrics are defined in the following locations.

- [Core SDK Worker metrics](https://github.com/temporalio/sdk-core/blob/master/core/src/telemetry/metrics.rs)
- [Core SDK Client metrics](https://github.com/temporalio/sdk-core/blob/master/client/src/metrics.rs)
- [Java SDK Worker metrics](https://github.com/temporalio/sdk-java/blob/master/temporal-sdk/src/main/java/io/temporal/worker/MetricsType.java)
- [Java SDK Client metrics](https://github.com/temporalio/sdk-java/blob/master/temporal-serviceclient/src/main/java/io/temporal/serviceclient/MetricsType.java)
- [Go SDK Worker and Client metrics](https://github.com/temporalio/sdk-go/blob/c32b04729cc7691f80c16f80eed7f323ee5ce24f/internal/common/metrics/constants.go)

:::note Metric units across SDKs

The unit of measurement for metrics can vary based on which SDK they are being reported from:

**Core-based SDKs:** Metrics of the type Histogram are measured in _milliseconds_ by default.
This can be customized to use seconds for SDKs using [Core SDK](/glossary#core-sdk).
The Core SDK is a shared common core library used by several Temporal SDKs, including TypeScript, Python, and .NET.

**Java and Go SDKs:** Metrics of the type Histogram are measured in _seconds_.

:::

Each metric may have some combination of the following keys attached to them:

- `task-queue`: Task Queue that the Worker Entity is polling
- `namespace`: Namespace the Worker is bound to
- `poller_type`: One of the following:
  - `workflow_task`
  - `activity_task`
  - `nexus_task` (Go and Java only)
  - `sticky_workflow_task`
- `worker_type`: One of the following:
  - `ActivityWorker`
  - `WorkflowWorker`
  - `LocalActivityWorker` (Go and Java only)
  - `NexusWorker` (Go and Java only)
- `activity_type`: The name of the Activity Function the metric is associated with
- `workflow_type`: The name of the Workflow Function the metric is associated with
- `operation`: RPC method name; available for metrics related to Temporal Client gRPC requests

Some keys may not be available in every SDK, and Histogram metrics may have different buckets in each SDK.

| Metric name                                                                             | Emitted by     | Metric type | Availability   |
| --------------------------------------------------------------------------------------- | -------------- | ----------- | -------------- |
| [activity_execution_cancelled](#activity_execution_cancelled)                           | Worker         | Counter     | Java           |
| [activity_execution_failed](#activity_execution_failed)                                 | Worker         | Counter     | Core, Go, Java |
| [activity_execution_latency](#activity_execution_latency)                               | Worker         | Histogram   | Core, Go, Java |
| [activity_poll_no_task](#activity_poll_no_task)                                         | Worker         | Counter     | Core, Go, Java |
| [activity_schedule_to_start_latency](#activity_schedule_to_start_latency)               | Worker         | Histogram   | Core, Go, Java |
| [activity_succeed_endtoend_latency](#activity_succeed_endtoend_latency)                 | Worker         | Histogram   | Core, Go, Java |
| [activity_task_error](#activity_task_error)                                             | Worker         | Counter     | Go             |
| [corrupted_signals](#corrupted_signals)                                                 | Worker         | Counter     | Go, Java       |
| [local_activity_execution_cancelled](#local_activity_execution_cancelled)               | Worker         | Counter     | Core, Go, Java |
| [local_activity_execution_failed](#local_activity_execution_failed)                     | Worker         | Counter     | Core, Go, Java |
| [local_activity_execution_latency](#local_activity_execution_latency)                   | Worker         | Histogram   | Core, Go, Java |
| [local_activity_succeeded_endtoend_latency](#local_activity_succeeded_endtoend_latency) | Worker         | Histogram   | Core, Go, Java |
| [local_activity_total](#local_activity_total)                                           | Worker         | Counter     | Core, Go, Java |
| [long_request](#long_request)                                                           | Service Client | Counter     | Core, Go, Java |
| [long_request_failure](#long_request_failure)                                           | Service Client | Counter     | Core, Go, Java |
| [long_request_latency](#long_request_latency)                                           | Service Client | Histogram   | Core, Go, Java |
| [num_pollers](#num_pollers)                                                             | Worker         | Gauge       | Core           |
| [poller_start](#poller_start)                                                           | Worker         | Counter     | Go, Java       |
| [request](#request)                                                                     | Service Client | Counter     | Core, Go, Java |
| [request_failure](#request_failure)                                                     | Service Client | Counter     | Core, Go, Java |
| [request_latency](#request_latency)                                                     | Service Client | Histogram   | Core, Go, Java |
| [sticky_cache_hit](#sticky_cache_hit)                                                   | Worker         | Counter     | Core, Go, Java |
| [sticky_cache_miss](#sticky_cache_miss)                                                 | Worker         | Counter     | Core, Go, Java |
| [sticky_cache_size](#sticky_cache_size)                                                 | Worker         | Gauge       | Core, Go, Java |
| [sticky_cache_total_forced_eviction](#sticky_cache_total_forced_eviction)               | Worker         | Counter     | Go, Java       |
| [unregistered_activity_invocation](#unregistered_activity_invocation)                   | Worker         | Counter     | Go             |
| [worker_start](#worker_start)                                                           | Worker         | Counter     | Core, Go, Java |
| [worker_task_slots_available](#worker_task_slots_available)                             | Worker         | Gauge       | Core, Go, Java |
| [worker_task_slots_used](#worker_task_slots_used)                                       | Worker         | Gauge       | Core, Go, Java |
| [workflow_active_thread_count](#workflow_active_thread_count)                           | Worker         | Gauge       | Java           |
| [workflow_cancelled](#workflow_cancelled)                                               | Worker         | Counter     | Core, Go, Java |
| [workflow_completed](#workflow_completed)                                               | Worker         | Counter     | Core, Go, Java |
| [workflow_continue_as_new](#workflow_continue_as_new)                                   | Worker         | Counter     | Core, Go, Java |
| [workflow_endtoend_latency](#workflow_endtoend_latency)                                 | Worker         | Histogram   | Core, Go, Java |
| [workflow_failed](#workflow_failed)                                                     | Worker         | Counter     | Core, Go, Java |
| [workflow_task_execution_failed](#workflow_task_execution_failed)                       | Worker         | Counter     | Core, Go, Java |
| [workflow_task_execution_latency](#workflow_task_execution_latency)                     | Worker         | Histogram   | Core, Go, Java |
| [workflow_task_queue_poll_empty](#workflow_task_queue_poll_empty)                       | Worker         | Counter     | Core, Go, Java |
| [workflow_task_queue_poll_succeed](#workflow_task_queue_poll_succeed)                   | Worker         | Counter     | Core, Go, Java |
| [workflow_task_replay_latency](#workflow_task_replay_latency)                           | Worker         | Histogram   | Core, Go, Java |
| [workflow_task_schedule_to_start_latency](#workflow_task_schedule_to_start_latency)     | Worker         | Histogram   | Core, Go, Java |
| [nexus_poll_no_task](#nexus_poll_no_task)                                               | Worker         | Counter     | Go, Java       |
| [nexus_task_schedule_to_start_latency](#nexus_task_schedule_to_start_latency)           | Worker         | Histogram   | Go, Java       |
| [nexus_task_execution_failed](#nexus_task_execution_failed)                             | Worker         | Counter     | Go, Java       |
| [nexus_task_execution_latency](#nexus_task_execution_latency)                           | Worker         | Histogram   | Go, Java       |
| [nexus_task_endtoend_latency](#nexus_task_endtoend_latency)                             | Worker         | Histogram   | Go, Java       |

### activity_execution_cancelled

An Activity Execution was canceled.

- Type: Counter
- Available in: Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_execution_failed

An Activity Execution failed.
This does not include local Activity Failures in the Go and Java SDKs (see [local_activity_execution_failed](#local_activity_execution_failed)).

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_execution_latency

Time to complete an Activity Execution, from the time the Activity Task is generated to the time the language SDK responded with a completion (failure or success).

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_poll_no_task

An Activity Worker poll for an Activity Task timed out, and no Activity Task is available to pick from the Task Queue.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### activity_schedule_to_start_latency

The Schedule-To-Start time of an Activity Task in seconds.
A [Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout) can be set when an Activity Execution is spawned.
This metric is useful for ensuring Activity Tasks are being processed from the queue in a timely manner. Some SDKs may include
the `activity_type` label, but the metric should not vary by type, as it does not influence the rate at which tasks are pulled
from the queue.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### activity_succeed_endtoend_latency

Total latency of successfully finished Activity Executions from the time they are scheduled to the time they are completed.
This metric is not recorded for async Activity completion.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_task_error

An internal error or panic occurred during Activity Task handling or execution.

- Type: Counter
- Available in: Go,
- Tags: `activity_type`, `namespace`, `task_queue`, `workflow_type`

### corrupted_signals

Number of Signals whose payload could not be deserialized.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### local_activity_execution_cancelled

A Local Activity Execution was canceled.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_execution_failed

A Local Activity Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_execution_latency

Time to complete a Local Activity Execution, from the time the first Activity Task is generated to the time the SDK responds that the execution is complete.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_succeeded_endtoend_latency

Total latency of successfully finished Local Activity Executions (from schedule to completion).

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_total

Total number of [Local Activity Executions](/activities#local-activity).

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### long_request

Temporal Client made an RPC long poll request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### long_request_failure

Temporal Client made an RPC long poll request that failed.
This number is included into the total `long_request` counter for long poll RPC requests.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### long_request_latency

Latency of a Temporal Client gRPC long poll request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### num_pollers

Current number of Worker Entities that are polling.

- Type: Gauge
- Available in: Core
- Tags: `namespace`, `poller_type`, `task_queue`

### poller_start

A Worker Entity poller was started.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### request

Temporal Client made an RPC request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### request_failure

Temporal Client made an RPC request that failed.
This number is included into the total `request` counter for RPC requests.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### request_latency

Latency of a Temporal Client gRPC request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### sticky_cache_hit

A Workflow Task found a cached Workflow Execution Event History to run against.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### sticky_cache_miss

A Workflow Task did not find a cached Workflow Worker.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### sticky_cache_size

Current cache size, expressed in number of Workflow Executions.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace` (TypeScript, Java), `task_queue` (TypeScript)

### sticky_cache_total_forced_eviction

A Workflow Execution has been forced from the cache intentionally.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### unregistered_activity_invocation

A request to spawn an Activity Execution is not registered with the Worker.

- Type: Counter
- Available in: Go,
- Tags: `activity_type`, `namespace`, `task_queue`, `workflow_type`

### worker_start

A Worker Entity has been registered, created, or started.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### worker_task_slots_available

The total number of Workflow, Activity, Local Activity, or Nexus Task execution slots that are currently available.
Use the `worker_type` key to differentiate execution slots.
The Worker type specifies an ability to perform certain tasks.
For example, Workflow Workers execute Workflow Tasks, Activity Workers execute Activity Tasks, and so forth.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### worker_task_slots_used

The total number of Workflow, Activity, Local Activity, or Nexus Tasks execution slots in current use.
Use the `worker_type` key to differentiate execution slots.
The Worker type specifies an ability to perform certain tasks.
For example, Workflow Workers execute Workflow Tasks, Activity Workers execute Activity Tasks, and so forth.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### workflow_active_thread_count

Total amount of Workflow threads in the Worker Process.

- Type: Gauge
- Available in: Java

### workflow_cancelled

Workflow Execution ended because of a cancellation request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_completed

A Workflow Execution completed successfully.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_continue_as_new

A Workflow ended with Continue-As-New.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_endtoend_latency

Total Workflow Execution time from schedule to completion for a single Workflow Run. (A retried Workflow Execution is a separate Run.)

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_failed

A Workflow Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_execution_failed

A Workflow Task Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_execution_latency

Workflow Task Execution time.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_queue_poll_empty

A Workflow Worker polled a Task Queue and timed out without picking up a Workflow Task.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### workflow_task_queue_poll_succeed

A Workflow Worker polled a Task Queue and successfully picked up a Workflow Task.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### workflow_task_replay_latency

Time to catch up on replaying a Workflow Task.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_schedule_to_start_latency

The Schedule-To-Start time of a Workflow Task.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### nexus_poll_no_task

A Nexus Worker poll for a Nexus Task timed out, and no Nexus Task is available to pick from the Task Queue.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### nexus_task_schedule_to_start_latency

The Schedule-To-Start time of a Nexus Task in seconds. The schedule time is taken from when the corresponding request
hit the Frontend service to when the SDK started processing the task.

This time is limited by the `Request-Timeout` header given to the Frontend when handling this request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### nexus_task_execution_failed

Handling of a Nexus Task resulted in an error. This includes any error returned from a user handler and unexpected
internal errors in the SDK.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`, `failure_reason`

Valid values for the `failure_reason` tag:

- `internal_sdk_error`: There was an unexpected internal error within the SDK while handling the Nexus task. Indicates a
  bug in the SDK.
- `handler_error_{TYPE}`: The user handler code returned a predefined error, as specified in the [Nexus spec](https://github.com/nexus-rpc/api/blob/main/SPEC.md#predefined-handler-errors).
  If the handler returns an unexpected error, the TYPE is set to `INTERNAL`.
- `timeout`: The user handler code did not return within the request timeout.
- `operation_failed`: The user handler code has indicated that the operation has failed. In Go, this maps to an
  `UnsuccessfulOperationError` with a `failed` state.
- `operation_canceled`: The user handler code has indicated that the operation has completed as canceled. In Go, this maps
  to an `UnsuccessfulOperationError` with a `canceled` state.

### nexus_task_execution_latency

Time to complete a Nexus Task, from the time the Nexus Task processing starts in the SDK to the time the user handler
completes.

- Type: Histogram
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`

### nexus_task_endtoend_latency

Total latency of Nexus Tasks from the time the corresponding request hit the Frontend to after the SDK gets
acknowledgment from the server for task completion.

- Type: Histogram
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/visibility/list-filter.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/visibility/list-filter.mdx</path>
  <content>
---
id: list-filter
title: List Filter
sidebar_label: List Filter
description: This guide on Temporal List Filters explains how to set up, configure, and use the List Filter API in Temporal Server versions. Learn how to filter and retrieve Workflow Executions, apply supported operators, and optimize queries for efficiency.
slug: /list-filter
toc_max_heading_level: 4
keywords:
  - explanation
  - filtered-lists
  - term
  - visibility
  - list filter
tags:
  - Concepts
  - Visibility
---

This page discusses [List Filter](#list-filter).

## What is a List Filter? {#list-filter}

The [Visibility](/clusters#visibility) List API requires you to provide a List Filter as an SQL-like string parameter.

A List Filter includes [Search Attribute](/search-attribute) names, Search Attribute values, and [operators](#supported-operators) so that it can retrieve a filtered list of Workflow Executions from the Visibility Store.

List Filter [Search Attribute](/search-attribute) names are case sensitive.
A single [Namespace](/namespaces) scopes each List Filter.

A List Filter using a time range provides a resolution of 1 ns on [Elasticsearch](/self-hosted-guide/visibility#elasticsearch) and 1 µs for [SQL databases](/self-hosted-guide/visibility).

### Supported operators

List Filters support the following operators:

- **`=, !=, >, >=, <, <=`**
- **`AND, OR, ()`**
- **`BETWEEN ... AND`**
- **`IN`**
- **STARTS_WITH**

{/* - **ORDER BY** */}

The **ORDER BY** operator is currently not supported in Temporal Cloud.

Custom Search Attributes of the `Text` type cannot be used in **ORDER BY** clauses.

### Partial string match

There are different options for partial string matching when the type of the Search Attribute is [Text](#text) versus [Keyword](#keyword).

#### Text

Search Attributes of type `Text` are [broken up into words](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenizer.html) that match with the `=` operator.

For example, if you have a custom `Text` Search Attribute named `Description` with either of the following values—

```
my-business-id-foobar
my business id foobar
```

—then the following List Filter matches—

```
Description = 'foobar'
```

—but a partial word does not:

```
// Doesn't match
Description = 'foo'
```

#### Keyword

For Search Attributes of type `Keyword` like `WorkflowId`, perform partial string matching using STARTS_WITH for prefixes and BETWEEN for suffixes.

* `WorkflowId STARTS_WITH "order-"` matches Workflow Ids with the "order-" prefix, regardless of the following text.

  ```
  order-
  order-1234
  order-abracadabra
  order-~~~abracadabra
  ```

* `WorkflowId BETWEEN "order-" AND "order-~"` matches Workflow Ids that have characters after `order-` with ASCII values lower than `~` (126, the highest-value printable character), such as the following:

  ```
  order-
  order-1234
  order-abracadabra
  ```

  It does not match `order-~~`.

:::note Filter Composition Quick Reference

**Composition**

- Data types:
  - String literals with single or double quotes
  - Numbers (Integer and Floating Point)
  - Booleans
- Comparison: `=`, `!=`, `>`, `>=`, `<`, `<=`
- Expressions/Operators:
  - `IN array`
  - `BETWEEN value AND value`
  - `STARTS_WITH string`
  - `IS NULL`, `IS NOT NULL`
  - `expr AND expr`, `expr OR expr`, `( expr )`
- Array: `( comma-separated-values )`

**Please note**

- Wrap attributes with backticks if it contains characters not in
  `[a-zA-Z0-9]`.
- `STARTS_WITH` is only available for Keyword search attributes.

:::

### Efficient API usage

If the Advanced List Filter API retrieves a substantial number of Workflow Executions (more than 10,000), the response time might be longer.

Beginning with Temporal Server v1.20, you can employ the `CountWorkflow` API to efficiently count the number of [Workflow Executions](/workflows#workflow-execution).

To paginate the results using the `ListWorkflow` API, use the page token to retrieve the next page.
Continue until the page token becomes `null`/`nil`.

#### List Filter examples

Here are examples of List Filters set with the [Temporal CLI](/cli/workflow#list):

```
WorkflowType = "main.YourWorkflowDefinition" and ExecutionStatus != "Running" and (StartTime > "2021-06-07T16:46:34.236-08:00" or CloseTime > "2021-06-07T16:46:34-08:00")
```

When you use the preceding example, you receive a list of Workflows fulfilling the following criteria:

- Workflow Type is `main.YourWorkflowDefinition`.
- Workflow isn't in a running state.
- Workflow either started after "2021-06-07T16:46:34.236-08:00" or closed after "2021-06-07T16:46:34-08:00".

The following are additional examples of List Filters.

```sql
WorkflowId = '<workflow-id>'
```

```sql
WorkflowId = '<workflow-id>' or WorkflowId = '<another-workflow-id>'
```

```sql
WorkflowId IN ('<workflow-id>', '<another-workflow-id>')
```

```sql
WorkflowId = '<workflow-id>' and ExecutionStatus = 'Running'
```

```sql
WorkflowId = '<workflow-id>' or ExecutionStatus = 'Running'
```

```sql
WorkflowId = '<workflow-id>' and StartTime > '2021-08-22T15:04:05+00:00'
```

```sql
ExecutionTime between '2021-08-22T15:04:05+00:00' and '2021-08-28T15:04:05+00:00'
```

```sql
ExecutionTime < '2021-08-28T15:04:05+00:00' or ExecutionTime > '2021-08-22T15:04:05+00:00'
```

```sql
WorkflowType STARTS_WITH '<workflow-type-prefix>'
```

{/*

```sql
order by ExecutionTime
```

```sql
order by StartTime desc, CloseTime asc
```

```sql
order by CustomIntField asc
```

*/}
  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/troubleshooting/deadline-exceeded-error.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/troubleshooting/deadline-exceeded-error.mdx</path>
  <content>
---
id: deadline-exceeded-error
title: Troubleshoot the deadline-exceeded error
sidebar_label: Deadline-exceeded error
description: Troubleshoot Temporal Service's Context deadline exceeded errors caused by network issues, server overload, and timing skews. Sync system clocks, check Frontend logs, metrics, Workflow logic, and service health after configurations or restarts. For unresolved issues, contact support.
toc_max_heading_level: 4
keywords:
  - error
  - troubleshooting
tags:
  - Failures
  - Errors
---

All requests made to the [Temporal Service](/clusters) by the Client or Worker are [gRPC requests](https://grpc.io/docs/what-is-grpc/core-concepts/#deadlines).
Sometimes, when these frontend requests can't be completed, you'll see this particular error message: `Context: deadline exceeded`.
Network interruptions, timeouts, server overload, and Query errors are some of the causes of this error.

The following sections discuss the nature of this error and how to troubleshoot it.

### Check system clocks

Timing skew can cause the system clock on a Worker to drift behind the system clock of the Temporal Service.
If the difference between the two clocks exceeds an Activity's Start-To-Close Timeout, an `Activity complete after timeout` error occurs.

If you receive an `Activity complete after timeout` error alongside `Context: deadline exceeded`, check the clocks on the Temporal Service's system and the system of the Worker sending that error.
If the Worker's clock doesn't match the Temporal Service, synchronize all clocks to an NTP server.

### Check Frontend Service logs

:::note

Cloud users cannot access some of the logs needed to diagnose the source of the error.

If you're using Temporal Cloud, create a [support ticket](/cloud/support#support-ticket) with as much information as possible, including the Namespace Name and the Workflow Ids of some Workflow Executions in which the issue occurs.

:::

[Frontend Service](/clusters#frontend-service) logs can show which parts of the Temporal Service aren't working.
For the error to appear, a service pod or container must be up and running.

OSS users can verify that the Frontend Service is connected and running by using the Temporal CLI.

```
temporal operator cluster health --address 127.0.0.1:7233
```

Use [`grpc-health-probe`](https://github.com/grpc-ecosystem/grpc-health-probe) to check the Frontend Service, [Matching Service](/clusters#matching-service), and [History Service](/clusters#history-service).

```
./grpc-health-probe -addr=frontendAddress:frontendPort -service=temporal.api.workflowservice.v1.WorkflowService

./grpc-health-probe -addr=matchingAddress:matchingPort -service=temporal.api.workflowservice.v1.MatchingService

./grpc-health-probe -addr=historyAddress:historyPort -service=temporal.api.workflowservice.v1.HistoryService
```

Logs can also be used to find failed Client [Query](/sending-messages#sending-queries) requests.

### Check your Temporal Service metrics

Temporal Service metrics can be used to detect issues (such as `resource exhausted`) that impact Temporal Service health.
A `resource exhausted` error can cause your client request to fail, which prompts the `deadline exceeded` error.

Use the following query to check for errors in `RpsLimit`, `ConcurrentLimit` and `SystemOverloaded` on your metrics dashboard.

```
sum(rate(service_errors_resource_exhausted{}[1m])) by (resource_exhausted_cause)
```

Look for high latencies, short timeouts, and other abnormal [Temporal Service metrics](/references/cluster-metrics).
If the metrics come from a specific service (such as History Service), check the service's health and performance.

### Check Workflow logic

Check your [Client and Worker configuration](/references/configuration) files for missing or invalid target values, such as the following:

- Server names
- Network or host addresses
- Certificates

Invalid targets also cause `connection refused` errors alongside `deadline exceeded`.
Check that the Client connects after updating your files.

### Advanced troubleshooting

In addition to the steps listed in the previous sections, check the areas mentioned in each of the following scenarios.

### After enabling mTLS

Check the health of the Temporal Service with `temporal operator cluster health`.

```
temporal operator cluster health --address [SERVER_ADDRESS]
```

Add any missing [environment variables](/references/web-ui-environment-variables) to the configuration files, and correct any incorrect values.
Server names and certificates must match between Frontend and internode.

### After restarting the Temporal Service

You might not be giving the Temporal Service enough time to respond and reconnect.
Restart the Server, wait, and then check all services for connectivity and further errors.

If the error persists, review your Workflow Execution History and server logs for more specific causes before continuing to troubleshoot.

### When executing or scheduling Workflows

One or more services might be unable to connect to the [Frontend Service](/clusters#frontend-service).
The Workflow might be unable to complete requests within the given connection time.

Increase the value of `frontend.keepAliveMaxConnectionAge` so that requests can be finished before the connection terminates.

:::note

If you increase `frontend.keepAliveMaxConnectionAge` values, consider monitoring your server performance for load.

:::

---

Still unable to resolve your issue?

- If you use Temporal Cloud, create a [support ticket](/cloud/support#support-ticket).
- If you use our open source software or Temporal Cloud, check for similar questions and possible solutions in our [community forum](https://community.temporal.io) or [community Slack](https://temporal.io/slack).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/cmd-options.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/cmd-options.mdx</path>
  <content>
---
id: cmd-options
title: Temporal CLI command options reference
sidebar_label: cmd options
description: Discover how to manage Temporal Workflows, from Activity Execution to Workflow Ids, using clusters, cron schedules, dynamic configurations, and logging. Perfect for developers.
toc_max_heading_level: 4
keywords:
  - actions
  - active cluster
  - activity
  - activity execution
  - activity id
  - address
  - archival
  - backfill
  - batch job
  - build
  - build id
  - ca-certificate
  - calendar
  - certificate key
  - child workflows
  - cli reference
  - cluster
  - codec server
  - command-line-interface-cli
  - command-line-interface-cli,
  - concurrency control
  - configuration
  - context
  - continue-as-new
  - cron
  - cross-cluster-connection
  - data converters
  - endpoint
  - environment
  - event
  - event id
  - event type
  - events
  - external temporal and state events
  - failures
  - frontend
  - frontend address
  - frontend service
  - goroutine
  - grpc
  - history
  - http
  - interval
  - ip address
  - job id
  - log-feature
  - logging
  - logging and metrics
  - memo
  - metrics
  - namespace
  - namespace description
  - namespace id
  - namespace management
  - nondeterministic
  - notes
  - operation
  - operator
  - options-feature
  - overlap policy
  - pager
  - port
  - pragma
  - queries-feature
  - query
  - requests
  - reset point
  - resets-feature
  - retention policy
  - retries
  - reuse policy
  - schedule
  - schedule backfill
  - schedule id
  - schedule pause
  - schedule unpause
  - schedules
  - search attribute
  - search attributes
  - server
  - server options and configurations
  - sqlite
  - start-to-close
  - task queue
  - task queue type
  - temporal cli
  - temporal ui
  - time
  - time zone
  - timeout
  - timeouts and heartbeats
  - tls
  - tls server
  - uri
  - verification
  - visibility
  - web ui
  - workflow
  - workflow execution
  - workflow id
  - workflow run
  - workflow state
  - workflow task
  - workflow task failure
  - workflow type
  - workflow visibility
  - x509-certificate
tags:
  - Temporal CLI
---

## active-cluster

Active cluster name.

## activity-id

Identifies the Activity Execution.

## activity-jitter

If set, the Activity will start at a random time within the specified jitter duration.

## activity-type

Command is applied to the all running activities with of this type.

## address

The host and port (formatted as host:port) for the Temporal Frontend Service.

## api-key

API key for request.

## archived

List archived Workflow Executions.

:::note

Caution: `--archived` is experimental.

:::

## build-id

Identifies the build to retrieve reachability information for.
Can be specified multiple times.

## calendar

Calendar specification in JSON `({"dayOfWeek":"Fri","hour":"17","minute":"5"})` or as a Cron string `("30 2 \* \* 5" or "@daily")`.

## catchup-window

Maximum allowed catch-up time if server is down.

## cluster

Cluster name.

## codec-auth

Sets the authorization header on requests to the Codec Server.

## codec-endpoint

Endpoint for a remote Codec Server.

## color

When to use color: auto, always, never. (default: auto)

## command-timeout

The command execution timeout. 0s means no timeout.

## concurrency

Request concurrency.

## cron

The Cron schedule can be formatted like the following:

```text
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
* * * * *
```

## data

Namespace data in a key=value format.

Values must be in JSON format.

## db-filename

File in which to persist Temporal state.
By default, Workflows are lost when the process dies.

## depth

The number of Child Workflows to fetch and expand.
Use `-1` to fetch Child Workflows at any depth.

## description

Namespace description or Nexus Endpoint description.
You may use Markdown formatting in the Nexus Endpoint description.

## description-file

Path to the Nexus Endpoint description file.
The contents of the description file may use Markdown formatting.

## detail

A provided reason for failing an Activity.

## dry-run

Simulate reset without resetting any Workflow Executions.

## dynamic-config-value

Dynamic config value, formatted as `KEY=JSON_VALUE`.
String values require quotation marks.

## email

Owner email.

## enable-connection

Enable cross-cluster connection.

## end-time

Backfill end time.

## env

Name of the environment to read environmental variables from.

## env-file

Path to environment settings file.
Defaults to `$HOME/.config/temporalio/temporal.yaml`.

## event-id

The Event Id for any Event after WorkflowTaskStarted you want to reset to (exclusive).
It can be WorkflowTaskCompleted, WorkflowTaskFailed or others.

## exclude-file

Input file that specifies Workflow Executions to exclude from resetting.

## execution-timeout

Timeout (in seconds) for a [Workflow Execution](/workflows#workflow-execution), including retries and `ContinueAsNew` tasks.

## existing-compatible-build-id

A Build Id that already exists in the version sets known by the Task Queue.
New Build Ids are stored in the version set containing this Id, making them compatible with the versions in that set.

## fields

Customize fields to print.
Set to 'long' to automatically print more of main fields.

## first-execution-run-id

Run update on the last execution in the chain that started with this Run Id.

## fold

Statuses for which Child Workflows will be folded in (this will reduce the number of information fetched and displayed).
Case-insensitive and ignored if `--no-fold` is supplied.

## follow

Follow the progress of a Workflow Execution.

## frontend-address

Frontend address of the remote Cluster.

## global

Flag to indicate whether a Namespace is a Global Namespace.

## grpc-meta

Contains gRPC metadata to send with requests (format: `key=value`).
Values must be in a valid JSON format.

## headless

Disable the Web UI.

## heartbeat-timeout

Maximum permitted time between successful Worker Heartbeats.

## history-archival-state

Sets the history archival state.
Valid values are "disabled" and "enabled".

## history-uri

Optionally specify history archival URI (cannot be changed after first time archival is enabled).

## id-reuse-policy

Allows the same Workflow Id to be used in a new Workflow Execution.
Options: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

## identity

Specify operator's identity.

## input

Use the `--input` command option to include data in the command.

This command option accepts a valid JSON string.
If the entity that the command is acting on accepts multiple parameters, pass "null" for null values within the JSON string.

The following is an example of starting a Workflow with the `--input` command option.
This Workflow expects a single string as a parameter:

```shell
temporal workflow start --input '"+1 555-555-5555"'
```

## input-file

Passes optional input for the Workflow from a JSON file.
If there are multiple JSON files, concatenate them and separate by space or newline.
Input from the command line will overwrite file input.

## input-parallelism

Number of goroutines to run in parallel.
Each goroutine processes one line for every second.

## input-separator

Separator for the input file. The default is a tab (`\t`).

## interval

Interval duration, such as 90m, or 90m/13m to include phase offset.

## ip

IPv4 address to bind the frontend service to.
(default: 127.0.0.1)

## jitter

Jitter duration.

## job-id

Batch Job Id.

## keep-paused

If this flag is provided and Activity was paused, it will stay paused after reset.

## limit

Number of items to print on a page.

## log-format

Set the log formatting.
Options: ["json", "pretty"].

## log-level

Set the log level.
Options: ["debug" "info" "warn" "error" "fatal"].

## match-all

If set, all currently running activities will be unpaused.

## max-field-length

Maximum length for each attribute field.

## max-sets

Limits how many compatible sets will be returned.
Specify 1 to return only the current default major version set.
0 returns all sets.

## memo

Set a memo on a schedule (format: key=value).
Use valid JSON formats for value.

## memo-file

Set a memo from a file.
Each line should follow the format key=value.
Use valid JSON formats for value.

## metrics-port

Port for `/metrics`.
Enabled by default with a randomly assigned port.

## name

Frontend address of the remote Cluster or the Endpoint name.

## namespace

Identifies a Namespace in the Temporal Workflow.

## namespace-id

Namespace Id.

## no-fold

Disable folding.
All Child Workflows within the set depth will be fetched and displayed.

## no-json-shorthand-payloads

Raw payload output, even if the JSON option was used.

## no-pager

Disables the interactive pager.

## non-deterministic

Reset Workflow Execution only if its last Event is `WorkflowTaskFailed` with a nondeterminism error.

## notes

Initial value of notes field.

## output

Format of output.
Options: table, json, card.

## overlap-policy

Overlap policy.
Options: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll.

## pager

Sets the pager for the Temporal CLI to use.
Options are less, more, and favoritePager.

## pause

Pauses the Schedule.

## pause-on-failure

Pause schedule after any Workflow failure.

## port

Port for the frontend gRPC service.

## promote-global

Promote local Namespace to Global Namespace.

## query

Provides a SQL-like Query of Search Attributes to return Workflow Executions to reset.
For more information, refer to the [`temporal workflow list`](/cli/workflow#list) command.

## raw

Print raw data in a JSON format.
For scripting, we recommend using this option instead of `-o json`.

## reachability-type

Specify how you'd like to filter the reachability of Build IDs.
The following are valid choices:

- `open`: reachable by one or more open Workflows.
- `closed`: reachable by one or more closed Workflows.
- `existing`: reachable by either open or closed Workflows.

Build IDs that are reachable by new Workflows are always reported.

## reapply-type

Event types to reapply after the reset point.
Options: Signal, None.

## reason

Reason for the operation.

## reject-condition

Optional flag for rejecting Queries based on Workflow state.
Valid values are "not_open" and "not_completed_cleanly".

## remaining-actions

Total number of actions allowed.

## reset-attempts

Providing this flag will reset the number of attempts.

## reset-heartbeat

Providing this flag will reset the heartbeat details.

## reset-points

Only show Workflow Events that are eligible for reset.

## result

Set the result value of Activity completion.

## retention

Workflow Execution retention.

## retry-backoff-coefficient

Coefficient used to calculate the next retry interval.
The next retry interval is previous interval multiplied by the coefficient.
Must be 1 or larger.

## retry-initial-interval

Interval of the first retry. If retryBackoffCoefficient is 1.0 then it is used for all retries.

## retry-maximum-attempts

Maximum number of attempts. When exceeded the retries stop even if not expired yet.
1 disables retries. 0 means unlimited (up to the timeouts).

## retry-maximum-interval

Maximum interval between retries. Exponential backoff leads to interval increase.
This value is the cap of the increase. Default is 100x of the initial interval.

## run-id

Identifies the current Workflow Run.

## run-timeout

Timeout (in seconds) of a single Workflow run.

## schedule-id

Schedule Id.

## schedule-to-close-timeout

Indicates how long the caller is willing to wait for an Activity completion.
Limits how long retries will be attempted.

## schedule-to-start-timeout

Limits time an Activity Task can stay in a task queue before a Worker picks it up.
This timeout is always non retryable, as all a retry would achieve is to put it back into the same queue.
Defaults to `schedule_to_close_timeout` or workflow execution timeout if not specified.

## search-attribute

Set Search Attribute on a Schedule (formatted as `key=value`).
Use valid JSON formats for value.

## set-as-default

When set, establishes the compatible set being targeted as the default for the Task Queue.

If a different set is the current default, the targeted set replaces it.

## skip-base-is-not-current

Skip a Workflow Execution if the base Workflow Run is not the current Workflow Run.

## skip-current-open

Skip a Workflow Execution if the current Run is open for the same Workflow Id as the base Run.

## sqlite-pragma

Specify sqlite pragma statements in pragma=value format.
Pragma options: ["journal_mode" "synchronous"].

## start-delay

Specify a delay before the workflow starts.

## start-time

Backfill start time.

## start-to-close-timeout

Maximum time an Activity is allowed to execute after being picked up by a Worker.
This Timeout is always retryable.

## target-namespace

Namespace in which a handler Worker will poll for Nexus tasks.

## target-task-queue

Task Queue in which a handler Worker will poll for Nexus tasks.

## target-url

An external Nexus Endpoint where Nexus requests are forwarded to.
May be used as an alternative to `--target-namespace` and `--target-task-queue`.

:::note

Caution: `--target-url` is experimental.

:::

## task-queue

Task Queue.

## task-queue-type

Task Queue type, which can be either Workflow or Activity.
The default type is Workflow.

## task-timeout

Start-to-close timeout for a Workflow Task (in seconds).

## time-format

Format time as: relative, iso, raw.

## time-zone

Time zone (IANA name).

## tls

Enable TLS encryption without additional options such as mTLS or client certificates.

## tls-ca-data

Data for server CA certificate. Can't be used with --tls-ca-path.

## tls-ca-path

Path to server CA certificate.

## tls-cert-data

Data for x509 certificate. Can't be used with --tls-cert-path.

## tls-cert-path

Path to x509 certificate.

## tls-disable-host-verification

Disables TLS host name verification.

## tls-key-data

Private certificate key data. Can't be used with --tls-key-path.

## tls-key-path

Path to private certificate key.

## tls-server-name

Overrides the target TLS server name.

## type

Search attribute type.
Options: Text, Keyword, Int, Double, Bool, Datetime, KeywordList.

## ui-asset-path

UI Custom Assets path.

## ui-codec-endpoint

UI Remote data converter HTTP endpoint.

## ui-ip

IPv4 address to bind the Web UI to.

## ui-port

Port for the Web UI.
Default: `--port` + 1000 (for example, 4000).

## unpause

Unpauses the Schedule.

## unset-description

Unset the description.

## verbose

Print applied Namespace changes.

## visibility-archival-state

Visibility Archival state.
Valid values: "disabled", "enabled".

## visibility-uri

Specify URI for Visibility Archival.
This cannot be changed after Archival is enabled.

## workflow-id

Workflow Id.

## workflow-type

Workflow type name.

## yes

Confirm all prompts.
  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/events.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/events.mdx</path>
  <content>
---
id: events
title: Temporal Events reference
sidebar_label: Events
description: Events in a Temporal Service respond to external occurrences and Workflow Commands. Workflow Execution Event History includes WorkflowExecutionStarted, WorkflowExecutionCompleted, WorkflowExecutionFailed, and many more.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
---

[Events](/workflows#event) are created by the [Temporal Service](/clusters) in response to external occurrences and [Commands](/workflows#command) generated by a [Workflow Execution](/workflows#workflow-execution).
All possible Events that could appear in a Workflow Execution [Event History](/workflows#event-history) are listed below.

### WorkflowExecutionStarted

This is always the first [Event](/workflows#event) in a Workflow Execution Event History.
It indicates that the Temporal Service received a request to spawn the Workflow Execution.

| Field                              | Description                                                                                                                                                    |
| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| workflow_type                      | The [Name](/workflows#workflow-type) of [Workflow](/workflows) that was initiated.                                                                             |
| parent_workflow_namespace          | The [Namespace](/namespaces) of the Parent [Workflow Execution](/workflows#workflow-execution), if applicable.                                                 |
| parent_workflow_execution          | Identifies the parent Workflow and the execution run.                                                                                                          |
| parent_initiated_event_id          | Id of the [StartWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to.                                            |
| task_queue                         | The [Task Queue](/task-queue) that this [Workflow Task](/tasks#workflow-task) was enqueued in.                                                                 |
| input                              | Information that is deserialized by the SDK to provide arguments to the Workflow.                                                                              |
| workflow_execution_timeout         | The total timeout period for a [Workflow Execution](/workflows#workflow-execution), including retries and continue-as-new.                                     |
| workflow_run_timeout               | Timeout of a single Workflow run.                                                                                                                              |
| workflow_task_timeout              | Timeout of a single Workflow Task.                                                                                                                             |
| continued_execution_run_id         | [Run Id](/workflows#run-id) of the previous Workflow which continued-as-new, retried or was executed by Cron into this Workflow.                               |
| initiator                          | Allows the Workflow to continue as a new Workflow Execution.                                                                                                   |
| continued_failure                  | Serialized result of a failure.                                                                                                                                |
| last_completion_result             | Information from the previously completed [Task](/tasks#task), if applicable.                                                                                  |
| original_execution_run_id          | The [Run Id](/workflows#run-id) of the original Workflow started.                                                                                              |
| identity                           | The Id of the [Client](/self-hosted-guide/security#client-connections) or parent Workflow [Worker](/workers#worker) that requested the start of this Workflow. |
| first_execution_run_id             | The first [Run Id](/workflows#run-id), along the chain of [Continue-As-New](/workflows#continue-as-new) Runs and Reset.                                        |
| retry_policy                       | The amount of retries as determined by the service's dynamic configuration. Retries will happen until 'schedule_to_close_timeout' is reached.                  |
| attempt                            | The number of attempts that have been made to complete this Task.                                                                                              |
| workflow_execution_expiration_time | The absolute time at which the Workflow Execution will [time out](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout).                       |
| cron_schedule                      | Displays the Workflow's [Cron Schedule](/workflows#temporal-cron-job), if applicable.                                                                          |
| first_workflow_task_backoff        | Contains the amount of time between when this iteration of the Workflow was scheduled, and when it should run next. Applies to Cron Scheduling.                |
| memo                               | Non-indexed information to show in the Workflow.                                                                                                               |
| search_attributes                  | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).                                                                              |
| prev_auto_reset_points             |                                                                                                                                                                |
| header                             | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the [Workflow Task](/tasks#workflow-task).             |

### WorkflowExecutionCompleted

This indicates that the [Workflow Execution](/workflows#workflow-execution) has successfully completed. The [Event](/workflows#event) contains Workflow Execution results.

| Field                            | Description                                                                                                                           |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| result                           | Serialized result of completed [Workflow](/workflows).                                                                                |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                       |
| new_execution_run_id             | The [Run Id](/workflows#run-id) of the new Workflow Execution started as a result of a [Cron Schedule](/workflows#temporal-cron-job). |

### WorkflowExecutionFailed

This [Event](/workflows#event) indicates that the [Workflow Execution](/workflows#workflow-execution) has unsuccessfully completed and contains the Workflow Execution error.

| Field                            | Description                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| failure                          | Serialized result of a [Workflow](/workflows) failure.                                                                   |
| retry_state                      | The reason provided for whether the [Task](/tasks#task) should or shouldn't be retried.                                  |
| workflow_task_completed_event_id | The [Run Id](/workflows#run-id) of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| new_execution_run_id             | The [Run Id](/workflows#run-id) of the new Workflow started by Cron or [Retry](/encyclopedia/retry-policies).            |

### WorkflowExecutionTimedOut

This [Event](/workflows#event) type indicates that the [Workflow Execution](/workflows#workflow-execution) has timed out by the [Temporal Server](/clusters#temporal-server) due to the [Workflow](/workflows) having not been completed within [timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) settings.

| Field                | Description                                                                                                   |
| -------------------- | ------------------------------------------------------------------------------------------------------------- |
| retry_state          | The reason provided for whether the [Task](/tasks#task) should or shouldn't be retried.                       |
| new_execution_run_id | The [Run Id](/workflows#run-id) of the new Workflow started by Cron or [Retry](/encyclopedia/retry-policies). |

### WorkflowExecutionCancelRequested

This [Event](/workflows#event) type indicates that a request has been made to cancel the [Workflow Execution](/workflows#workflow-execution).

| Field                       | Description                                                                                                           |
| --------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| cause                       | The user-provided reason for the cancelation request.                                                                 |
| external_initiated_event_id | The [Run Id](/workflows#run-id) of the Event in the [Workflow](/workflows) that requested cancelation, if applicable. |
| external_workflow_execution | Identifies the external Workflow and the run of the its execution.                                                    |
| identity                    | Id of the [Worker](/workers#worker) that requested cancelation.                                                       |

### WorkflowExecutionCanceled

This [Event](/workflows#event) type indicates that the client has confirmed the cancelation request and the [Workflow Execution](/workflows#workflow-execution) has been canceled.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| details                          | Additional information reported by the [Workflow](/workflows) upon cancelation.                 |

### WorkflowExecutionSignaled

This [Event](/workflows#event) type indicates the [Workflow](/workflows) has received a [Signal](/sending-messages#sending-signals) Event.
The Event type contains the Signal name and a Signal payload.

| Field       | Description                                                                                                   |
| ----------- | ------------------------------------------------------------------------------------------------------------- |
| signal_name | The name/type of Signal to be fired.                                                                          |
| input       | Information that is deserialized by the SDK to provide arguments to the Workflow function.                    |
| identity    | Identifies the [Worker](/workers#worker) that signaled to the Workflow.                                       |
| header      | Information passed by the sender of the Signal that is copied into the [Workflow Task](/tasks#workflow-task). |

### WorkflowExecutionTerminated

This [Event](/workflows#event) type indicates that the [Workflow Execution](/workflows#workflow-execution) has been forcefully terminated and that likely the terminate Workflow API was called.

| Field    | Description                                                          |
| -------- | -------------------------------------------------------------------- |
| reason   | Information provided by the user or client for Workflow termination. |
| details  | Additional information reported by the Workflow upon termination.    |
| identity | Identifies the Worker that requested termination.                    |

### WorkflowExecutionContinuedAsNew

This [Event](/workflows#event) type indicates that the Workflow has successfully completed, and a new Workflow has been started within the same transaction.
This Event type contains last [Workflow Execution](/workflows#workflow-execution) results as well as new Workflow Execution inputs.

| Field                            | Description                                                                                                   |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| new_execution_run_id             | The [Run Id](/workflows#run-id) of the new Workflow started by this Continue-As-New Event.                    |
| workflow_type                    | The name/type of Workflow that was started by this Event.                                                     |
| task_queue                       | The [Task Queue](/task-queue) that this [Workflow Task](/tasks#workflow-task) was enqueued in.                |
| input                            | Information that is deserialized by the SDK to provide arguments to the Workflow.                             |
| workflow_run_timeout             | Timeout of a single Workflow run.                                                                             |
| workflow_task_timeout            | Timeout of a single Workflow Task.                                                                            |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event command was reported with.       |
| backoff_start_interval           | The amount of time to delay the beginning of the [ContinuedAsNew](#workflowexecutioncontinuedasnew) Workflow. |
| initiator                        | Allows the Workflow to continue as a new execution.                                                           |
| last_completion_result           | Information passed by the previously completed Task to the ongoing execution.                                 |
| header                           | Information passed by the sender of the Signal that is copied into the Workflow Task.                         |
| memo                             | Non-indexed information to show in the Workflow.                                                              |
| search_attributes                | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).                             |

### WorkflowTaskScheduled

This [Event](/workflows#event) type indicates that the [Workflow Task](/tasks#workflow-task) has been scheduled.
The SDK client should now be able to process any new history events.

| Field                  | Description                                                                                |
| ---------------------- | ------------------------------------------------------------------------------------------ |
| task_queue             | The [Task Queue](/task-queue) that this Workflow Task was enqueued in.                     |
| start_to_close_timeout | The time that the [Worker](/workers#worker) takes to process this Task once it's received. |
| attempt                | The number of attempts that have been made to complete this Task.                          |

### WorkflowTaskStarted

This [Event](/workflows#event) type indicates that the [Workflow Task](/tasks#workflow-task) has started.
The SDK client has picked up the Workflow Task and is processing new history events.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| identity           | Identifies the [Worker](/workers#worker) that started this Task.                                            |
| request_id         | Identifies the Workflow Task request.                                                                       |

### WorkflowTaskCompleted

This [Event](/workflows#event) type indicates that the [Workflow Task](/tasks#workflow-task) completed.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Task corresponds to.              |
| identity           | Identity of the [Worker](/workers#worker) that completed this Task.                                         |
| binary_checksum    | Binary Id of the Worker that completed this Task.                                                           |

The SDK client picked up the Workflow Task, processed new history events, and may or may not ask the [Temporal Server](/clusters#temporal-server) to do additional work.
It is possible for the following events to still occur:

- [ActivityTaskScheduled](#activitytaskscheduled)
- [TimerStarted](#timerstarted)
- [UpsertWorkflowSearchAttributes](#upsertworkflowsearchattributes)
- [MarkerRecorded](#markerrecorded)
- [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated)
- [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated)
- [SignalExternalWorkflowExecutionInitiated](#signalexternalworkflowexecutioninitiated)
- [WorkflowExecutionCompleted](#workflowexecutioncompleted)
- [WorkflowExecutionFailed](#workflowexecutionfailed)
- [WorkflowExecutionCanceled](#workflowexecutioncanceled)
- [WorkflowExecutionContinuedAsNew](#workflowexecutioncontinuedasnew)

### WorkflowTaskTimedOut

This [Event](/workflows#event) type indicates that the [Workflow Task](/tasks#workflow-task) encountered a [timeout](/encyclopedia/detecting-workflow-failures#workflow-task-timeout).
Either an SDK client with a local cache was not available at the time, or it took too long for the SDK client to process the Task.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Task corresponds to.              |
| timeout_type       | The type of timeout that has occurred.                                                                      |

### WorkflowTaskFailed

This [Event](/workflows#event) type indicates that the [Workflow Task](/tasks#workflow-task) encountered a failure.
Usually this means that the Workflow was non-deterministic.
However, the Workflow reset functionality also uses this Event.

| Field              | Description                                                                                                                                  |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to.                                  |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Workflow Task corresponds to.                                      |
| failure            | Details for the Workflow Task's failure.                                                                                                     |
| identity           | The identity of the [Worker](/workers#worker) that failed this Task. The Worker must be explicitly defined to return a value for this field. |
| base_run_id        | The original [Run Id](/workflows#run-id) of the Workflow.                                                                                    |
| new_run_id         | The Run Id of the reset Workflow.                                                                                                            |
| fork_event_version | Identifies the Event version that was forked off to the reset Workflow.                                                                      |
| binary_checksum    | The Binary Id of the Worker that failed this Task. The Worker must be explicitly defined to return a value for this field.                   |

### ActivityTaskScheduled

This [Event](/workflows#event) type indicates that an [Activity Task](/tasks#activity-task) was scheduled.
The SDK client should pick up this Activity Task and execute.
This Event type contains Activity inputs, as well as Activity Timeout configurations.

| Field                            | Description                                                                                                                                        |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| activity_id                      | The identifier assigned to this Activity by a [Worker](/workers#worker) or user.                                                                   |
| activity_type                    | The [type of Activity](/activities#activity-type) that was scheduled.                                                                              |
| namespace                        | Namespace of the Workflow that the [Activity](/activities) resides in.                                                                             |
| task_queue                       | The [Task Queue](/task-queue) that this Activity Task was enqueued in.                                                                             |
| header                           | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the [Workflow Task](/tasks#workflow-task). |
| input                            | Information that is deserialized by the SDK to provide arguments to the [Workflow](/workflows) function.                                           |
| schedule_to_close_timeout        | The amount of time that a caller will wait for Activity completion. Limits the amount of time that retries will be attempted for this Activity.    |
| schedule_to_start_timeout        | Limits the time that an Activity Task can stay in a Task Queue. This timeout cannot be retried.                                                    |
| start_to_close_timeout           | Maximum amount of execution time that an Activity is allowed after being picked up by a Worker. This timeout is retryable.                         |
| heartbeat_timeout                | Maximum amount of time allowed between successful Worker heartbeats.                                                                               |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                                    |
| retry_policy                     | The amount of retries as determined by the service's dynamic configuration. Retries will happen until `schedule_to_close_timeout` is reached.      |

### ActivityTaskStarted

This [Event](/workflows#event) type indicates that an [Activity Task Execution](/tasks#activity-task-execution) was started.
The SDK Worker picked up the Activity Task and started processing the [Activity](/activities) invocation.
Note, however, that this Event is not written to History until the terminal Event (like [ActivityTaskCompleted](#activitytaskcompleted) or [ActivityTaskFailed](#activitytaskfailed)) occurs.

| Field              | Description                                                                                                          |
| ------------------ | -------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this Task corresponds to.                   |
| identity           | Identifies the [Worker](/workers#worker) that started the Task.                                                      |
| request_id         | Identifies the Activity Task request.                                                                                |
| attempt            | The number of attempts that have been made to complete this Task.                                                    |
| last_failure       | Details from the most recent failure Event. Only assigned values if the Task has previously failed and been retried. |

### ActivityTaskCompleted

This [Event](/workflows#event) type indicates that the [Activity Task](/tasks#activity-task) has completed.
The SDK client has picked up and successfully completed the Activity Task.
This Event type contains [Activity Execution](/activities#activity-execution) results.

| Field              | Description                                                                                                    |
| ------------------ | -------------------------------------------------------------------------------------------------------------- |
| result             | Serialized result of a completed [Activity](/activities).                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this completion Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this Task corresponds to.                 |
| identity           | Identity of the [Worker](/workers#worker) that completed this Task.                                            |

### ActivityTaskFailed

This [Event](/workflows#event) type indicates that the [Activity Task](/tasks#activity-task) has failed.
The SDK client picked up the Activity Task but unsuccessfully completed it.
This Event type contains [Activity Execution](/activities#activity-execution) errors.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this failure Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this failure corresponds to.           |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                    |

### ActivityTaskTimedOut

This [Event](/workflows#event) type indicates that the Activity has timed out according to the [Temporal Server](/clusters#temporal-server), due to one of these [Activity](/activities) timeouts: [Schedule-to-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout) and [Schedule-to-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout).

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this timeout Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this timeout corresponds to.           |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                    |
| timeout_type       | The type of timeout that led to this Event, e.g., Start-to-Close, Schedule-to-Close, Schedule-to-Start.     |

You can run a Workflow containing an Activity Execution that takes longer than the Start-to-Close Timeout you set and use a RetryPolicy that sets MaxAttempts to 1 so it does not retry indefinitely.
When the Activity times out, you will observe that the `ActivityTaskTimedOut` Event contains other attributes missing from the documentation, including the type of timeout that led to the Event.

### ActivityTaskCancelRequested

This [Event](/workflows#event) type indicates that a request to [cancel](/activities#cancellation) the [Activity](/activities) has occurred.

| Field                            | Description                                                                                                |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| scheduled_event_id               | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this cancel Event corresponds to. |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.            |

### ActivityTaskCanceled

This [Event](/workflows#event) type indicates that the [Activity](/activities) has been [canceled](/activities#cancellation).

| Field                            | Description                                                                                                                |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| details                          | Additional information reported by the Activity upon confirming cancelation.                                               |
| latest_cancel_requested_event_id | Id of the most recent [ActivityTaskCancelRequested](#activitytaskcancelrequested) Event which refers to the same Activity. |
| scheduled_event_id               | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this cancelation corresponds to.                  |
| started_event_id                 | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this cancelation corresponds to.                      |
| identity                         | Identifies the [Worker](/workers#worker) that requested cancelation.                                                       |

### TimerStarted

This [Event](/workflows#event) type indicates a timer has started.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| timer_id                         | The Id assigned for the timer by a [Worker](/workers#worker) or user.                           |
| start_to_fire_timeout            | Amount of time to elapse before the timer fires.                                                |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |

### TimerFired

This [Event](/workflows#event) type indicates a timer has fired.

| Field            | Description                                                           |
| ---------------- | --------------------------------------------------------------------- |
| timer_id         | The Id assigned for the timer by a [Worker](/workers#worker) or user. |
| started_event_id | The Id of the [TimerStarted](#timerstarted) Event itself.             |

### TimerCanceled

This [Event](/workflows#event) type indicates a Timer has been canceled.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| timer_id                         | The Id assigned for the timer by a [Worker](/workers#worker) or user.                           |
| started_event_id                 | The Id of the [TimerStarted](#timerstarted) Event itself.                                       |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |

### RequestCancelExternalWorkflowExecutionInitiated

This [Event](/workflows#event) type indicates that a [Workflow](/workflows) has requested that the [Temporal Server](/clusters#temporal-server) try to cancel another Workflow.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that`s going to be signaled for execution.             |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution). |
| child_workflow_only              | Set to true if this Workflow is a child of the Workflow which issued the cancelation request.   |
| reason                           | Information provided by the user or client for Workflow cancelation.                            |

### RequestCancelExternalWorkflowExecutionFailed

This [Event](/workflows#event) type indicates that [Temporal Server](/clusters#temporal-server) could not cancel the targeted [Workflow](/workflows).
This is usually because the target Workflow could not be found.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that failed to cancel.                                 |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution). |
| initiated_event_id               | Id of the [RequestCancelExternalWorkflowExecutionInitiated] Event this failure corresponds to.  |

### ExternalWorkflowExecutionCancelRequested

This [Event](/workflows#event) type indicates that the [Temporal Server](/clusters#temporal-server) has successfully requested the cancelation of the target [Workflow](/workflows).

| Field              | Description                                                                                                                                                       |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| initiated_event_id | Id of the [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated) Event that this cancelation request corresponds to. |
| namespace          | [Namespace](/namespaces) of the Workflow that was requested to cancel.                                                                                            |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                                                                   |

### ExternalWorkflowExecutionSignaled

This [Event](/workflows#event) type indicates that the [Temporal Server](/clusters#temporal-server) has successfully [Signaled](/sending-messages#sending-signals) the targeted [Workflow](/workflows).

| Field              | Description                                                                                                                      |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------- |
| initiated_event_id | Id of the [SignalExternalWorkflowExecutionInitiated](#signalexternalworkflowexecutioninitiated) Event this Event corresponds to. |
| namespace          | [Namespace](/namespaces) of the Workflow that was signaled to.                                                                   |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                                  |

### MarkerRecorded

This [Event](/workflows#event) type is transparent to the [Temporal Server](/clusters#temporal-server) .
The Server will only store it and will not try to understand it.
The SDK client may use it for local activities or side effects.

| Field                            | Description                                                                                                         |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| marker_name                      | Identifies various markers.                                                                                         |
| details                          | Serialized information recorded in the marker.                                                                      |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                     |
| header                           | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the marker. |
| failure                          | Serialized result of a [Workflow](/workflows) failure.                                                              |

### StartChildWorkflowExecutionInitiated

This [Event](/workflows#event) type indicates that the [Temporal Server](/clusters#temporal-server) will try to start a Child Workflow.

| Field         | Description                                     |
| ------------- | ----------------------------------------------- |
| namespace     | [Namespace](/namespaces) of the Child Workflow. |
| workflow_id   | Identifies the Child Workflow.                  |
| workflow_type | The name/type of Workflow that was initiated.   |

### StartChildWorkflowExecutionFailed

This [Event](/workflows#event) type indicates a [Child Workflow Execution](/encyclopedia/child-workflows) cannot be started / triggered.
It is usually due to a Child Workflow Id collision.

| Field                            | Description                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| namespace                        | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_id                      | Identifies the Child Workflow.                                                                                           |
| workflow_type                    | The name/type of Workflow that has failed.                                                                               |
| initiated_event_id               | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                          |

### ChildWorkflowExecutionStarted

This [Event](/workflows#event) type indicates a [Child Workflow Execution](/encyclopedia/child-workflows) has successfully started / triggered.
This would also cause the [WorkflowExecutionStarted](#workflowexecutionstarted) to be recorded for the Workflow that has started.

| Field              | Description                                                                                                                      |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------- |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                                  |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to.         |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                                   |
| workflow_type      | The name/type of Workflow that has started execution.                                                                            |
| header             | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the Child Workflow Task. |

### ChildWorkflowExecutionCompleted

This [Event](/workflows#event) type indicates that the [Child Workflow Execution](/encyclopedia/child-workflows) has successfully completed.
This would also cause the [WorkflowExecutionCompleted](#workflowexecutioncompleted) to be recorded for the [Workflow](/workflows) that has completed.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| result             | Serialized result of the completed Child Workflow.                                                                       |
| namespace          | [Namespace](/namespaces) of the completed Child Workflow.                                                                |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                          |
| workflow_type      | The name/type of Workflow that was completed.                                                                            |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this Event corresponds to.               |

### ChildWorkflowExecutionFailed

This [Event](/workflows#event) type indicates that the [Child Workflow Execution](/encyclopedia/child-workflows) has unsuccessfully completed.
This would also cause the [WorkflowExecutionFailed](#workflowexecutionfailed) to be recorded for the Workflow that has failed.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                                   |
| namespace          | [Namespace](/namespaces) of the Child Workflow that failed.                                                              |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                          |
| workflow_type      | The name/type of Workflow that has failed.                                                                               |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this failure corresponds to.             |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### ChildWorkflowExecutionCanceled

This [Event](/workflows#event) type indicates that the Child Workflow Execution has been canceled.
This would also cause the [WorkflowExecutionCanceled](#workflowexecutioncanceled) to be recorded for the Workflow that was canceled.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| details            | Additional information reported by the Child Workflow upon cancelation.                                                  |
| namespace          | [Namespace](/namespaces) of the Child Workflow that was canceled.                                                        |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                          |
| workflow_type      | The name/type of Workflow that was canceled.                                                                             |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this cancelation corresponds to.         |

### ChildWorkflowExecutionTimedOut

This Event type indicates that the [Child Workflow Execution](/encyclopedia/child-workflows) has timed out by the [Temporal Server](/clusters#temporal-server).
This would also cause the [WorkflowExecutionTimeOut](#workflowexecutiontimedout) to be recorded for the Workflow that timed out.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                           |
| workflow_type      | The name/type of Workflow that has timed out.                                                                            |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event that this timeout corresponds to.        |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### ChildWorkflowExecutionTerminated

This [Event](/workflows#event) type indicates that the Child Workflow Execution has been terminated.
This would also cause the [WorkflowExecutionTerminated](#workflowexecutionterminated) to be recorded for the Workflow that was terminated.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                           |
| workflow_type      | The name/type of Workflow that was terminated.                                                                           |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event that this termination corresponds to.    |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### SignalExternalWorkflowExecutionInitiated

This [Event](/workflows#event) type indicates that the [Temporal Server](/clusters#temporal-server) will try to [Signal](/sending-messages#sending-signals) the targeted [Workflow](/workflows).
This Event type contains the Signal name, as well as a Signal payload.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that's to be signaled.                                 |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution). |
| signal_name                      | The name/type of Signal to be fired.                                                            |
| input                            | Information that is deserialized by the SDK to provide arguments to the Workflow Function.      |
| child_workflow_only              | Set to true if this Workflow is a child of the Workflow which issued the cancelation request.   |
| header                           | Information to be passed from the Signal to the targeted Workflow.                              |

### SignalExternalWorkflowExecutionFailed

This [Event](/workflows#event) type indicates that the [Temporal Server](/clusters#temporal-server) cannot Signal the targeted [Workflow](/workflows), usually because the Workflow could not be found.

| Field                            | Description                                                                                                                                                                                  |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                                                                              |
| namespace                        | [Namespace](/namespaces) of the Workflow that failed to execute.                                                                                                                             |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflows#workflow-execution).                                                                                              |
| initiated_event_id               | Id of the [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated) Event this failure [signal](/sending-messages#sending-signals) corresponds to. |

### UpsertWorkflowSearchAttributes

This [Event](/workflows#event) type indicates that the Workflow [Search Attributes](/search-attribute) should be updated and synchronized with the visibility store.

| Field                            | Description                                                                                |
| -------------------------------- | ------------------------------------------------------------------------------------------ |
| workflow_task_completed_event_id | The [WorkflowTaskCompleted](#workflowtaskcompleted) Event reported the Event with this Id. |
| search_attributes                | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).          |

### WorkflowExecutionUpdateAcceptedEvent

This [Event](/workflows#event) type indicates that a [Workflow Execution](/workflows#workflow-execution) has accepted an [Update](/sending-messages#sending-updates) for execution.
The original request input payload is both indicated and stored by this Event, as it generates no Event when initially requesting an Update.

| Field                                | Description                                                                                                                                                            |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| protocol_instance_id                 | The instance of the Update protocol with this Id is executing this Update.                                                                                             |
| accepted_request_message_id          | The Id of the request message sent by [Temporal Server](/clusters#temporal-server) to the [Worker](/workers#worker).                                                   |
| accepted_request_sequencing_event_id | Execute this Update after the Event with this Id.                                                                                                                      |
| accepted_request                     | The request input and metadata initially provided by the invoker of the Update and subsequently relayed by Temporal Server to the Worker for acceptance and execution. |

### WorkflowExecutionUpdateCompletedEvent

This [Event](/workflows#event) type indicates that a [Workflow Execution](/workflows#workflow-execution) has executed an [Update](/sending-messages#sending-updates) to completion.

| Field             | Description                                                                                                                                  |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| meta              | The metadata associated with this Update, sourced from the initial request.                                                                  |
| accepted_event_id | The Id of the [WorkflowExecutionUpdateAcceptedEvent](#workflowexecutionupdateacceptedevent) The Platform accepted this Update for execution. |
| outcome           | The outcome of execution of this Update whether the execution resulted in a success or a failure.                                            |

### NexusOperationScheduled

This Event type indicates that a Nexus Operation scheduled by a caller Workflow.
The caller's [Nexus Machinery](/glossary#nexus-machinery) will attempt to start the Nexus Operation.
This Event type contains Nexus Operation input and the Operation request ID.

| Field                            | Description                                                                                                                                                                                                                                                                                               |
| :------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| endpoint                         | Endpoint name, must exist in the endpoint registry.                                                                                                                                                                                                                                                       |
| service                          | Service name.                                                                                                                                                                                                                                                                                             |
| operation                        | Operation name.                                                                                                                                                                                                                                                                                           |
| input                            | Input for the operation. The server converts this into Nexus request content and the appropriate content headers internally when sending the StartOperation request. On the handler side, if it is also backed by Temporal, the content is transformed back to the original Payload stored in this event. |
| schedule_to_close_timeout        | Schedule-to-close timeout for this operation. Indicates how long the caller is willing to wait for operation completion. Calls are retried internally by the server.                                                                                                                                      |
| nexus_header                     | Header to attach to the Nexus request. Note these headers are not the same as Temporal headers on internal activities and child Workflows, these are transmitted to Nexus operations that may be external and are not traditional payloads.                                                               |
| workflow_task_completed_event_id | The ID of the [WorkflowTaskCompleted](#workflowtaskcompleted) event that the corresponding ScheduleNexusOperation command was reported with.                                                                                                                                                              |
| request_id                       | A unique ID generated by the History Service upon creation of this event. The ID will be transmitted with all Nexus StartOperation requests and is used as an idempotency key.                                                                                                                            |
| endpoint_id                      | Endpoint ID as resolved in the endpoint registry at the time this event was generated. This is stored on the event and used internally by the server in case the endpoint is renamed from the time the event was originally scheduled.                                                                    |

### NexusOperationStarted

This Event type indicates that a Nexus Operation Execution was started.
This Event is added to the caller's Workflow History for Asynchronous Nexus Operations, for example those that are backed by a Workflow.
The Event is not added to the caller's Workflow History for Synchronous Nexus Operations, since they transition directly to [NexusOperationCompleted](#nexusoperationcompleted) or another final state such as [NexusOperationFailed](#nexusoperationfailed) when the response is provided synchronously by the Nexus handler.

| Field              | Description                                                                                                                                       |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------ |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled) event this task corresponds to.                                                 |
| operation_token    | The operation token returned by the Nexus handler in the response to the StartOperation request. This token is used when canceling the operation. |
| request_id         | The request ID allocated at schedule time.                                                                                                        |

### NexusOperationCompleted

This Event type indicates that a Nexus Operation has completed successfully.
The caller's Workflow History records the result of a successful Nexus Operation with this event for synchronous and asynchronous Nexus Operations.
This Event type contains Nexus Operation results.

| Field              | Description                                                                                                                                                          |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled) event. Uniquely identifies this operation.                                                         |
| result             | Serialized result of the Nexus operation. The response of the Nexus handler. Delivered either via a completion callback or as a response to a synchronous operation. |
| request_id         | The request ID allocated at schedule time.                                                                                                                           |

### NexusOperationFailed

This Event type indicates that a Nexus Operation has failed.
The caller's Workflow History records a failed Nexus Operation with this event both for synchronous and asynchronous Nexus Operations.
For example, when a Nexus Handler responds synchronously with a non-retryable error or when a Workflow that backs an Operation fails, resulting in a [WorkflowExecutionFailed](#workflowexecutionfailed) Event.
When an SDK client picks up a Nexus Operation, the Nexus handler asynchronously starts an underlying Workflow, which subsequently results in [WorkflowExecutionFailed](#workflowexecutionfailed).
This Event type contains a Nexus Operation failure.

| Field              | Description                                                                                                   |
| :----------------- | :------------------------------------------------------------------------------------------------------------ |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure            | Failure details. A NexusOperationFailureInfo wrapping an ApplicationFailureInfo.                              |
| request_id         | The request ID allocated at schedule time.                                                                    |

### NexusOperationTimedOut

This Event type indicates that a Nexus Operation has timed out according to the Temporal Server, due to one of these Nexus Operation timeouts: Schedule-to-Close Timeout.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure | Failure details. A NexusOperationFailureInfo wrapping a CanceledFailureInfo. |
| request_id | The request ID allocated at schedule time. |

### NexusOperationCancelRequested

This Event type indicates that the Workflow that scheduled a Nexus Operation requested to cancel it.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The id of the [NexusOperationScheduled](#nexusoperationscheduled)` event this cancel request corresponds to. |
| workflow_task_completed_event_id | The [WorkflowTaskCompleted](#workflowtaskcompleted) event that the corresponding RequestCancelNexusOperation command was reported with. |

### NexusOperationCanceled

This Event type indicates that a Nexus Operation has resolved as canceled.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure | Cancellation details. |
| request_id | The request ID allocated at schedule time. |

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/debugging.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/debugging.mdx</path>
  <content>
---
id: debugging
title: Debugging - Python SDK
sidebar_label: Debugging
description: Learn how to debug Workflows in development and production environments using the Temporal Python SDK, Web UI, Temporal CLI, replay, tracing, logging, and performance metrics.
toc_max_heading_level: 2
keywords:
  - debugging temporal python
  - temporal web ui
  - temporal cli
  - workflow replay
  - tracing workflows
  - logging workflows
  - worker performance metrics
  - server performance metrics
tags:
  - Debugging
  - Python SDK
  - Temporal SDKs
---

This page shows how to do the following:

- [Debug in a development environment](#debug-in-a-development-environment)
- [Debug in a production environment](#debug-in-a-production-environment)

### Debug in a development environment {#debug-in-a-development-environment}

**How to debug in a development environment using the Temporal Python SDK.**

When developing Workflows, you can use the normal development tools of logging and a debugger to see what’s happening in your Workflow.
In addition to the normal development tools of logging and a debugger, you can also see what’s happening in your Workflow by using the [Web UI](/web-ui) or [Temporal CLI](/cli).

### How to debug in a production environment {#debug-in-a-production-environment}

**How to debug in a production environment using the Temporal Python SDK.**

You can debug production Workflows using:

- [Web UI](/web-ui)
- [Temporal CLI](/cli)
- [Replay](/develop/python/testing-suite#replay)
- [Tracing](/develop/python/observability#tracing)
- [Logging](/develop/python/observability#logging)

You can debug and tune Worker performance with metrics and the [Worker performance guide](/develop/worker-performance).
For more information, see [Observability ▶️ Metrics](/develop/python/observability#metrics) for setting up SDK metrics.

Debug Server performance with [Cloud metrics](/cloud/metrics/) or [self-hosted Server metrics](/self-hosted-guide/production-checklist#scaling-and-metrics).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/visibility/visibility.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/visibility/visibility.mdx</path>
  <content>
---
id: visibility
title: Temporal Visibility
sidebar_label: Visibility
description: This comprehensive guide on Temporal Visibility explains how to set up, configure, and use Visibility features in Temporal Server versions. Learn about standard and advanced Visibility, Dual Visibility, supported databases, and custom Search Attributes.
slug: /visibility
toc_max_heading_level: 4
keywords:
  - explanation
  - filtered-lists
  - term
  - visibility
tags:
  - Concepts
  - Visibility
  - Search Attributes
---

This page provides an overview of Temporal Visibility.

:::tip Support, stability, and dependency info

- For Temporal Server v1.19 and earlier, all supported databases for Visibility provide standard Visibility features, and an Elasticsearch database is required for advanced Visibility features.
- For Temporal Server v1.20 and later, advanced Visibility features are enabled on all supported SQL databases, in addition to Elasticsearch.
- In Temporal Server v1.21 and later, standard Visibility is no longer in development, and we recommend migrating to a [database that supports Advanced Visibility features](/self-hosted-guide/visibility). The Visibility configuration for the Temporal Service has been updated and Dual Visibility is enabled. For details, see [Visibility store setup](/self-hosted-guide/visibility).

:::

The term [Visibility](/visibility), within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view, filter, and search for Workflow Executions that currently exist within a Temporal Service.

The [Visibility store](/self-hosted-guide/visibility) in your Temporal Service stores persisted Workflow Execution Event History data and is set up as a part of your [Persistence store](/clusters#persistence) to enable listing and filtering details about Workflow Executions that exist on your Temporal Service.

- [How to set up a Visibility store](/self-hosted-guide/visibility)

With Temporal Server v1.21, you can set up [Dual Visibility](/dual-visibility) to migrate your Visibility store from one database to another.

Support for separate standard and advanced Visibility setups will be deprecated from Temporal Server v1.21 onwards. Check [Supported databases](/self-hosted-guide/visibility) for updates.

## What is standard Visibility? {#standard-visibility}

Standard Visibility, within the Temporal Platform, is the subsystem and APIs that list Workflow Executions by a predefined set of filters.

Open Workflow Executions can be filtered by a time constraint and either a Workflow Type, Workflow Id, or Run Id.

Closed Workflow Executions can be filtered by a time constraint and either a Workflow Type, Workflow Id, Run Id, or Execution Status (Completed, Failed, Timed Out, Terminated, Canceled, or Continued-As-New).

[Custom Search Attributes](https://docs.temporal.io/search-attribute#custom-search-attribute) are not supported with Standard Visibility.

Support for standard Visibility is deprecated beginning with Temporal Server v1.21.
For updates, check [Supported databases](/self-hosted-guide/visibility).

## What is advanced Visibility? {#advanced-visibility}

Visibility, within the Temporal Platform, is the subsystem and APIs that enable the listing, filtering, and sorting of [Workflow Executions](/workflows#workflow-execution) through a custom SQL-like [List Filter](/list-filter).

- In Temporal Service version 1.20 and later, advanced Visibility is available on SQL databases like MySQL (version 8.0.17 and later) and PostgreSQL (version 12 and later), in addition to support for Elasticsearch.
- For Temporal Server versions 1.19.1 and earlier, you must [integrate with ElasticSearch](/self-hosted-guide/visibility#elasticsearch) to use advanced Visibility.
  Elasticsearch takes on the Visibility request load, relieving potential performance issues.
  We highly recommend operating a Temporal Service with Elasticsearch for any use case that spawns more than just a few Workflow Executions.
- On Temporal Cloud, advanced Visibility is enabled by default for [all users](/cloud/users#invite-users).



  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/core-application.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/core-application.mdx</path>
  <content>
---
id: core-application
title: Core application - Temporal feature
description: Discover Temporal's Workflow, Activity, and Worker framework; orchestrate steps, encapsulate business logic, and execute code efficiently using the Temporal SDK in your favorite language.
sidebar_label: Core application
tags:
  - Workflows
  - Activities
  - Workers
  - Temporal SDKs
keywords:
  - temporal application
  - workflow design
  - business logic activities
  - temporal workers
  - temporal SDK tutorial
  - go sdk temporal guide
  - java sdk temporal guide
  - php sdk temporal guide
  - python sdk temporal guide
  - typescript sdk temporal guide
  - learning temporal workflows
  - developing with temporal
  - temporal workflow execution
  - temporal activity management
  - worker process execution
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

**Workflows**, **Activities**, and **Workers** form the core parts of a Temporal Application.

**Workflows**: A Workflow defines the overall flow of the application.
You write it in your programming language of choice using the Temporal SDK.
Conceptually, a Workflow specifies a sequence of steps and orchestrates the execution of Activities.

**Activities**: An Activity is a method or function that encapsulates business logic prone to failure (e.g., calling a service that may go down).
The system can automatically retry these Activities upon some failures.
Activities perform a single, well-defined action, such as calling another service, transcoding a media file, or sending an email message.

**Workers**: A Worker executes your Workflow and Activity code.

**Follow one of our tutorials to [Get started](https://learn.temporal.io/getting_started/) learning how to develop Workflows and Activities and run them in Worker Processes.**

Or jump straight to a Temporal SDK feature guide:

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/core-application" text="Go SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/core-application" text="Java SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/core-application" text="PHP SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/core-application" text="Python SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/core-application#connect-to-a-dev-cluster" text="TypeScript SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/core-application" text=".NET SDK Core application feature guide" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into Temporal Workflows, Activities, and Workers, visit the following Temporal Encyclopedia pages or enroll in one of [our courses](https://learn.temporal.io/courses/).

- [Temporal Workflows](/workflows)
- [Temporal Activities](/activities)
- [Temporal Workers](/workers)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/codec-server.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/codec-server.mdx</path>
  <content>
---
id: codec-server
title: Codec Server
sidebar_label: Codec Server
description: A Codec Server is an HTTP server that provides remote encoding and decoding for Temporal Payloads.
slug: /codec-server
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - codec-server
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Codec Server](#codec-server). 

## What is a Codec Server? {#codec-server}

A Codec Server is an HTTP/HTTPS server that uses a [custom Payload Codec](/production-deployment/data-encryption) to decode your data remotely through endpoints.

{/* This should not have changed with tctl-to-temporal */}

![](/diagrams/tctl-diagram-codec-server.svg)

A Codec Server follows the Temporal [Codec Server Protocol](https://github.com/temporalio/samples-go/tree/main/codec-server#codec-server-protocol).
It implements two endpoints:

- `/encode`
- `/decode`

Each endpoint receives and responds with a JSON body that has a `payloads` property with an array of [Payloads](/dataconversion#payload).
The endpoints run the Payloads through a [Payload Codec](/payload-codec) before returning them.

Most SDKs provide example Codec Server implementation samples, listed here:

- [Go](https://github.com/temporalio/samples-go/tree/main/codec-server)
- [Java](https://github.com/temporalio/sdk-java/tree/master/temporal-remote-data-encoder)
- [.NET](https://github.com/temporalio/samples-dotnet/tree/main/src/Encryption)
- [Python](https://github.com/temporalio/samples-python/blob/main/encryption/codec_server.py)
- [TypeScript](https://github.com/temporalio/samples-typescript/blob/main/encryption/src/codec-server.ts)

#### Usage

When you apply custom encoding with encryption or compression on your Workflow data, it is stored in the encrypted/compressed format on the Temporal Server. For details on what data is encoded, see [Securing your data](/production-deployment/data-encryption).

To see decoded data when using the Temporal CLI or Web UI to perform some operations on a Workflow Execution, configure the Codec Server endpoint in the Web UI and the Temporal CLI.
When you configure the Codec Server endpoints, the Temporal CLI and Web UI send the encoded data to the Codec Server, and display the decoded data received from the Codec Server.

For details on creating your Codec Server, see [Codec Server Setup](/production-deployment/data-encryption#codec-server-setup).


  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/schedule.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/schedule.mdx</path>
  <content>
---
id: schedule
title: Temporal CLI schedule command reference
sidebar_label: schedule
description: Temporal's Schedule commands allow users to create, update, and manage Workflow Executions seamlessly for automation, supporting commands for creation, backfill, deletion, and more.
toc_max_heading_level: 4
keywords:
  - backfill
  - cli reference
  - command-line-interface-cli
  - schedule
  - schedule backfill
  - schedule create
  - schedule delete
  - schedule describe
  - schedule list
  - schedule toggle
  - schedule trigger
  - schedule update
  - temporal cli
  - updates
tags:
  - Temporal CLI
  - Schedules
---

Schedule commands allow the user to create, use, and update [Schedules](/workflows#schedule).
Schedules control when certain Actions for a [Workflow Execution](/workflows#workflow-execution) are performed, making it a useful tool for automation.

To run a Schedule command, run `temporal schedule [command] [command options]`.

## backfill

The `temporal schedule backfill` command executes Actions ahead of their specified time range.
Backfilling adds [Workflow Runs](/workflows#run-id) from a time period when the Schedule was paused, or from before the Schedule was created.

Schedule backfills require a valid Schedule ID, along with the time in which to run the Schedule and a change to the overlap policy.
The following example fills in Workflow Runs from a point when the Schedule was paused.

```
temporal schedule backfill --schedule-id 'your-schedule-id' \
--overlap-policy 'BufferAll' 				\
--start-time '2022-05-0101T00:00:00Z'		\
--end-time '2022-05-31T23:59:59Z'
```

Temporal recommends setting the Overlap Policy to `BufferAll` to run backfilled Workflows sequentially.

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--end-time](/cli/cmd-options#end-time)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--overlap-policy](/cli/cmd-options#overlap-policy)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--start-time](/cli/cmd-options#start-time)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## create

The `temporal schedule create` command creates a new [Schedule](/workflows#schedule).
Newly created Schedules return a Schedule ID to be used in other Schedule commands.

Schedules use the following format:

```
temporal schedule create \
    --schedule-id 'your-schedule-id' \
    --workflow-id 'your-workflow-id' \
    --task-queue 'your-task-queue' \
    --workflow-type 'YourWorkflowType'
```

Actions are executed at the times specified in the Schedule.
For example, the following Schedule starts a Workflow every 5 hours at 15 minutes past the hour.
A Workflow is also started at 11:03 on Fridays.

```
temporal schedule create \
    --schedule-id 'your-schedule-id' \
    --interval '5h/15m' \
    --calendar '{"dayOfWeek":"Fri","hour":"11","minute":"3"}' \
    --overlap-policy 'BufferAll' \
    --workflow-id 'your-workflow-id' \
    --task-queue 'your-task-queue' \
    --workflow-type 'YourWorkflowType'
```

Workflows don't run in parallel.
Setting the `--overlap-policy` to `BufferAll` allows Workflows to run sequentially if they would overlap.

Any combination of `--calendar`, `--interval`, and `--cron` is supported.
Traditional cron strings, along with `CronSchedule` features, are also supported.

```
temporal schedule create \
    --schedule-id 'your-schedule-id' \
    --cron '3 11 * * Fri' \
    --workflow-id 'your-workflow-id' \
    --task-queue 'your-task-queue' \
    --workflow-type 'YourWorkflowType'
```

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--calendar](/cli/cmd-options#calendar)

- [--catchup-window](/cli/cmd-options#catchup-window)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--cron](/cli/cmd-options#cron)

- [--end-time](/cli/cmd-options#end-time)

- [--env](/cli/cmd-options#env)

- [--execution-timeout](/cli/cmd-options#execution-timeout)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--interval](/cli/cmd-options#interval)

- [--jitter](/cli/cmd-options#jitter)

- [--max-field-length](/cli/cmd-options#max-field-length)

- [--memo](/cli/cmd-options#memo)

- [--memo-file](/cli/cmd-options#memo-file)

- [--namespace](/cli/cmd-options#namespace)

- [--notes](/cli/cmd-options#notes)

- [--overlap-policy](/cli/cmd-options#overlap-policy)

- [--pause](/cli/cmd-options#pause)

- [--pause-on-failure](/cli/cmd-options#pause-on-failure)

- [--remaining-actions](/cli/cmd-options#remaining-actions)

- [--run-timeout](/cli/cmd-options#run-timeout)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--search-attribute](/cli/cmd-options#search-attribute)

- [--start-time](/cli/cmd-options#start-time)

- [--task-queue](/cli/cmd-options#task-queue)

- [--task-timeout](/cli/cmd-options#task-timeout)

- [--time-zone](/cli/cmd-options#time-zone)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--workflow-type](/cli/cmd-options#workflow-type)

## delete

The `temporal schedule delete` command deletes a [Schedule](/workflows#schedule).
Deleting a Schedule does not affect any [Workflows](/workflows) started by the Schedule.

[Workflow Executions](/workflows#workflow-execution) started by Schedules can be cancelled or terminated like other Workflow Executions.
However, Workflow Executions started by a Schedule can be identified by their [Search Attributes](/search-attribute), making them targetable by batch command for termination.

`temporal schedule delete --schedule-id 'your-schedule-id' [command options]`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## describe

The `temporal schedule describe` command shows the current [Schedule](/workflows#schedule) configuration.
This command also provides information about past, current, and future [Workflow Runs](/workflows#run-id).

`temporal schedule describe --schedule-id 'your-schedule-id' [command options]`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--raw](/cli/cmd-options#raw)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## list

The `temporal schedule list` command lists all [Schedule](/workflows#schedule) configurations.
Listing Schedules in [Standard Visibility](/visibility#standard-visibility) will only provide Schedule IDs.

`temporal schedule list`

Use the options below to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--limit](/cli/cmd-options#limit)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## toggle

The `temporal schedule toggle` command can pause and unpause a [Schedule](/workflows#schedule).

Toggling a Schedule requires a reason to be entered on the command line.
Use `--reason` to note the issue leading to the pause or unpause.

Schedule toggles are passed in this format:
`temporal schedule toggle --schedule-id 'your-schedule-id' --pause --reason "paused because the database is down"`
`temporal schedule toggle --schedule-id 'your-schedule-id' --unpause --reason "the database is back up"`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--pause](/cli/cmd-options#pause)

- [--reason](/cli/cmd-options#reason)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--unpause](/cli/cmd-options#unpause)

## trigger

The `temporal schedule trigger` command triggers an immediate action with a given [Schedule](/workflows#schedule).
By default, this action is subject to the Overlap Policy of the Schedule.

Schedule triggers are passed in this format:
`temporal schedule trigger` can be used to start a Workflow Run immediately.
`temporal schedule trigger --schedule-id 'your-schedule-id'`

The Overlap Policy of the Schedule can be overridden as well.
`temporal schedule trigger --schedule-id 'your-schedule-id' --overlap-policy 'AllowAll'`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--overlap-policy](/cli/cmd-options#overlap-policy)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## update

The `temporal schedule update` command updates an existing [Schedule](/workflows#schedule).

Like `temporal schedule create`, updated Schedules need to follow a certain format:

```
temporal schedule update 			    \
    --schedule-id 'your-schedule-id' 	\
    --workflow-id 'your-workflow-id' 	\
    --task-queue 'your-task-queue' 		\
    --workflow-type 'YourWorkflowType'
```

Updating a Schedule takes the given options and replaces the entire configuration of the Schedule with what's provided.
If you only change one value of the Schedule, be sure to provide the other unchanged fields to prevent them from being overwritten.

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--calendar](/cli/cmd-options#calendar)

- [--catchup-window](/cli/cmd-options#catchup-window)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--cron](/cli/cmd-options#cron)

- [--end-time](/cli/cmd-options#end-time)

- [--env](/cli/cmd-options#env)

- [--execution-timeout](/cli/cmd-options#execution-timeout)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--input](/cli/cmd-options#input)

- [--input-file](/cli/cmd-options#input-file)

- [--interval](/cli/cmd-options#interval)

- [--jitter](/cli/cmd-options#jitter)

- [--max-field-length](/cli/cmd-options#max-field-length)

- [--memo](/cli/cmd-options#memo)

- [--memo-file](/cli/cmd-options#memo-file)

- [--namespace](/cli/cmd-options#namespace)

- [--notes](/cli/cmd-options#notes)

- [--overlap-policy](/cli/cmd-options#overlap-policy)

- [--pause](/cli/cmd-options#pause)

- [--pause-on-failure](/cli/cmd-options#pause-on-failure)

- [--remaining-actions](/cli/cmd-options#remaining-actions)

- [--run-timeout](/cli/cmd-options#run-timeout)

- [--schedule-id](/cli/cmd-options#schedule-id)

- [--search-attribute](/cli/cmd-options#search-attribute)

- [--start-time](/cli/cmd-options#start-time)

- [--task-queue](/cli/cmd-options#task-queue)

- [--task-timeout](/cli/cmd-options#task-timeout)

- [--time-zone](/cli/cmd-options#time-zone)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--workflow-id](/cli/cmd-options#workflow-id)

- [--workflow-type](/cli/cmd-options#workflow-type)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/core-application.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/core-application.mdx</path>
  <content>
---
id: core-application
title: Core application - Python SDK
sidebar_label: Core application
description: Learn to develop and customize Workflows and Activities using the Temporal Python SDK, manage parameters, set timeouts, execute Activities, and run a Worker Process efficiently.
toc_max_heading_level: 2
keywords:
  - temporal python core
  - develop temporal workflow
  - temporal python activities
  - workflow logic requirements
  - customizing workflow type
  - activity parameters
  - activity return values
  - activity execution in workflow
  - activity timeouts
  - getting activity results
  - temporal python worker
  - registering workflow types
tags:
  - Activities
  - Temporal Client
  - Task Queues
  - Workers
  - Workflows
  - Python SDK
  - Temporal SDKs
---

This page shows how to do the following:

- [Develop a basic Workflow](#develop-workflows)
- [Define Workflow parameters](#workflow-parameters)
- [Define Workflow return parameters](#workflow-return-values)
- [Customize your Workflow Type](#workflow-type)
- [Develop Workflow logic](#workflow-logic-requirements)
- [Develop a basic Activity](#develop-activities)
- [Develop Activity Parameters](#activity-parameters)
- [Define Activity return values](#activity-return-values)
- [Customize your Activity Type](#activity-type)
- [Start an Activity Execution](#activity-execution)
- [Set the required Activity Timeouts](#required-timeout)
- [Get the results of an Activity Execution](#get-activity-results)
- [Run a Worker Process](#run-a-dev-worker)
- [Register types](#register-types)

## Develop a basic Workflow {#develop-workflows}

**How to develop a basic Workflow using the Temporal Python SDK.**

Workflows are the fundamental unit of a Temporal Application, and it all starts with the development of a [Workflow Definition](/workflows#workflow-definition).

In the Temporal Python SDK programming model, Workflows are defined as classes.

Specify the `@workflow.defn` decorator on the Workflow class to identify a Workflow.

Use the `@workflow.run` to mark the entry point method to be invoked. This must be set on one asynchronous method defined on the same class as `@workflow.defn`. Run methods have positional parameters.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import workflow
# ...
# ...
@workflow.defn(name="YourWorkflow")
class YourWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            your_activity,
            YourParams("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

### Define Workflow parameters {#workflow-parameters}

**How to define Workflow parameters using the Temporal Python SDK.**

Temporal Workflows may have any number of custom parameters.
However, we strongly recommend that objects are used as parameters, so that the object's individual fields may be altered without breaking the signature of the Workflow.
All Workflow Definition parameters must be serializable.

Workflow parameters are the method parameters of the singular method decorated with `@workflow.run`.
These can be any data type Temporal can convert, including [`dataclasses`](https://docs.python.org/3/library/dataclasses.html) when properly type-annotated.
Technically this can be multiple parameters, but Temporal strongly encourages a single `dataclass` parameter containing all input fields.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_dataobject_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from dataclasses import dataclass
# ...
# ...
@dataclass
class YourParams:
    greeting: str
    name: str
```

### Define Workflow return parameters {#workflow-return-values}

**How to define Workflow return parameters using the Temporal Python SDK.**

Workflow return values must also be serializable.
Returning results, returning errors, or throwing exceptions is fairly idiomatic in each language that is supported.
However, Temporal APIs that must be used to get the result of a Workflow Execution will only ever receive one of either the result or the error.

To return a value of the Workflow, use `return` to return an object.

To return the results of a Workflow Execution, use either `start_workflow()` or `execute_workflow()` asynchronous methods.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import workflow
# ...
# ...
@workflow.defn(name="YourWorkflow")
class YourWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            your_activity,
            YourParams("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

### Customize your Workflow Type {#workflow-type}

**How to customize your Workflow Type using the Temporal Python SDK.**

Workflows have a Type that are referred to as the Workflow name.

The following examples demonstrate how to set a custom name for your Workflow Type.

You can customize the Workflow name with a custom name in the decorator argument. For example, `@workflow.defn(name="your-workflow-name")`. If the name parameter is not specified, the Workflow name defaults to the unqualified class name.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import workflow
# ...
# ...
@workflow.defn(name="YourWorkflow")
class YourWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            your_activity,
            YourParams("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

### Develop Workflow logic {#workflow-logic-requirements}

**How to develop Workflow logic using the Temporal Python SDK.**

Workflow logic is constrained by [deterministic execution requirements](/workflows#deterministic-constraints).
Therefore, each language is limited to the use of certain idiomatic techniques.
However, each Temporal SDK provides a set of APIs that can be used inside your Workflow to interact with external (to the Workflow) application code.

Workflow code must be deterministic. This means:

- no threading
- no randomness
- no external calls to processes
- no network I/O
- no global state mutation
- no system date or time

All API safe for Workflows used in the [`temporalio.workflow`](https://python.temporal.io/temporalio.workflow.html) must run in the implicit [`asyncio` event loop](https://docs.python.org/3/library/asyncio-eventloop.html) and be _deterministic_.

## Develop a basic Activity {#develop-activities}

**How to develop a basic Activity using the Temporal Python SDK.**

One of the primary things that Workflows do is orchestrate the execution of Activities.
An Activity is a normal function or method execution that's intended to execute a single, well-defined action (either short or long-running), such as querying a database, calling a third-party API, or transcoding a media file.
An Activity can interact with world outside the Temporal Platform or use a Temporal Client to interact with a Temporal Service.
For the Workflow to be able to execute the Activity, we must define the [Activity Definition](/activities#activity-definition).

You can develop an Activity Definition by using the `@activity.defn` decorator.
Register the function as an Activity with a custom name through a decorator argument, for example `@activity.defn(name="your_activity")`.

:::note

The Temporal Python SDK supports multiple ways of implementing an Activity:

- Asynchronously using [`asyncio`](https://docs.python.org/3/library/asyncio.html)
- Synchronously multithreaded using [`concurrent.futures.ThreadPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#threadpoolexecutor)
- Synchronously multiprocess using [`concurrent.futures.ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#processpoolexecutor) and [`multiprocessing.managers.SyncManager`](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager)

Blocking the async event loop in Python would turn your asynchronous program into a synchronous program that executes serially, defeating the entire purpose of using `asyncio`.
This can also lead to potential deadlock, and unpredictable behavior that causes tasks to be unable to execute.
Debugging these issues can be difficult and time consuming, as locating the source of the blocking call might not always be immediately obvious.

Due to this, consider not make blocking calls from within an asynchronous Activity, or use an async safe library to perform
these actions.
If you must use a blocking library, consider using a synchronous Activity instead.

:::

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_activities_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import activity
# ...
# ...
@activity.defn(name="your_activity")
async def your_activity(input: YourParams) -> str:
    return f"{input.greeting}, {input.name}!"
```

### Develop Activity Parameters {#activity-parameters}

**How to develop Activity Parameters using the Temporal Python SDK.**

There is no explicit limit to the total number of parameters that an [Activity Definition](/activities#activity-definition) may support.
However, there is a limit to the total size of the data that ends up encoded into a gRPC message Payload.

A single argument is limited to a maximum size of 2 MB.
And the total size of a gRPC message, which includes all the arguments, is limited to a maximum of 4 MB.

Also, keep in mind that all Payload data is recorded in the [Workflow Execution Event History](/workflows#event-history) and large Event Histories can affect Worker performance.
This is because the entire Event History could be transferred to a Worker Process with a [Workflow Task](/tasks#workflow-task).

{/* TODO link to gRPC limit section when available */}

Some SDKs require that you pass context objects, others do not.
When it comes to your application data—that is, data that is serialized and encoded into a Payload—we recommend that you use a single object as an argument that wraps the application data passed to Activities.
This is so that you can change what data is passed to the Activity without breaking a function or method signature.

Activity parameters are the function parameters of the function decorated with `@activity.defn`.
These can be any data type Temporal can convert, including dataclasses when properly type-annotated.
Technically this can be multiple parameters, but Temporal strongly encourages a single dataclass parameter containing all input fields.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_activities_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import activity
from your_dataobject_dacx import YourParams

# ...
# ...
@activity.defn(name="your_activity")
async def your_activity(input: YourParams) -> str:
    return f"{input.greeting}, {input.name}!"
```

### Define Activity return values {#activity-return-values}

**How to define Activity return values using the Temporal Python SDK.**

All data returned from an Activity must be serializable.

There is no explicit limit to the amount of data that can be returned by an Activity, but keep in mind that all return values are recorded in a [Workflow Execution Event History](/workflows#event-history).

An Activity Execution can return inputs and other Activity values.

The following example defines an Activity that takes a string as input and returns a string.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_activities_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@activity.defn(name="your_activity")
async def your_activity(input: YourParams) -> str:
    return f"{input.greeting}, {input.name}!"
```

### Customize your Activity Type {#activity-type}

**How to customize your Activity Type**

Activities have a Type that are referred to as the Activity name.
The following examples demonstrate how to set a custom name for your Activity Type.

You can customize the Activity name with a custom name in the decorator argument. For example, `@activity.defn(name="your-activity")`.
If the name parameter is not specified, the Activity name defaults to the function name.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_activities_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
@activity.defn(name="your_activity")
async def your_activity(input: YourParams) -> str:
    return f"{input.greeting}, {input.name}!"
```

## Start an Activity Execution {#activity-execution}

**How to start an Activity Execution using the Temporal Python SDK.**

Calls to spawn [Activity Executions](/activities#activity-execution) are written within a [Workflow Definition](/workflows#workflow-definition).
The call to spawn an Activity Execution generates the [ScheduleActivityTask](/references/commands#scheduleactivitytask) Command.
This results in the set of three [Activity Task](/tasks#activity-task) related Events ([ActivityTaskScheduled](/references/events#activitytaskscheduled), [ActivityTaskStarted](/references/events#activitytaskstarted), and ActivityTask[Closed])in your Workflow Execution Event History.

A single instance of the Activities implementation is shared across multiple simultaneous Activity invocations.
Activity implementation code should be _idempotent_.

The values passed to Activities through invocation parameters or returned through a result value are recorded in the Execution history.
The entire Execution history is transferred from the Temporal service to Workflow Workers when a Workflow state needs to recover.
A large Execution history can thus adversely impact the performance of your Workflow.

Therefore, be mindful of the amount of data you transfer through Activity invocation parameters or Return Values.
Otherwise, no additional limitations exist on Activity implementations.

To spawn an Activity Execution, use the [`execute_activity()`](https://python.temporal.io/temporalio.workflow.html#execute_activity) operation from within your Workflow Definition.

`execute_activity()` is a shortcut for [`start_activity()`](https://python.temporal.io/temporalio.workflow.html#start_activity) that waits on its result.

To get just the handle to wait and cancel separately, use `start_activity()`.
In most cases, use `execute_activity()` unless advanced task capabilities are needed.

A single argument to the Activity is positional. Multiple arguments are not supported in the type-safe form of `start_activity()` or `execute_activity()` and must be supplied by the `args` keyword argument.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import workflow
# ...
# ...
@workflow.defn(name="YourWorkflow")
class YourWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            your_activity,
            YourParams("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

### Set the required Activity Timeouts {#required-timeout}

**How to set the required Activity Timeouts using the Temporal Python SDK.**

Activity Execution semantics rely on several parameters.
The only required value that needs to be set is either a [Schedule-To-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout) or a [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout).
These values are set in the Activity Options.

Activity options are set as keyword arguments after the Activity arguments.

Available timeouts are:

- schedule_to_close_timeout
- schedule_to_start_timeout
- start_to_close_timeout

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/activity_timeouts_retires/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
        activity_timeout_result = await workflow.execute_activity(
            your_activity,
            YourParams(greeting, "Activity Timeout option"),
            # Activity Execution Timeout
            start_to_close_timeout=timedelta(seconds=10),
            # schedule_to_start_timeout=timedelta(seconds=10),
            # schedule_to_close_timeout=timedelta(seconds=10),
        )
```

### Get the results of an Activity Execution {#get-activity-results}

**How to get the results of an Activity Execution using the Temporal Python SDK.**

The call to spawn an [Activity Execution](/activities#activity-execution) generates the [ScheduleActivityTask](/references/commands#scheduleactivitytask) Command and provides the Workflow with an Awaitable.
Workflow Executions can either block progress until the result is available through the Awaitable or continue progressing, making use of the result when it becomes available.

Use [`start_activity()`](https://python.temporal.io/temporalio.workflow.html#start_activity) to start an Activity and return its handle, [`ActivityHandle`](https://python.temporal.io/temporalio.workflow.ActivityHandle.html). Use [`execute_activity()`](https://python.temporal.io/temporalio.workflow.html#execute_activity) to return the results.

You must provide either `schedule_to_close_timeout` or `start_to_close_timeout`.

`execute_activity()` is a shortcut for `await start_activity()`. An asynchronous `execute_activity()` helper is provided which takes the same arguments as `start_activity()` and `await`s on the result. `execute_activity()` should be used in most cases unless advanced task capabilities are needed.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio import workflow
# ...
# ...
@workflow.defn(name="YourWorkflow")
class YourWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            your_activity,
            YourParams("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

## Run a Worker Processes {#run-a-dev-worker}

**How to run a Worker Process using the Temporal Python SDK.**

The [Worker Process](/workers#worker-process) is where Workflow Functions and Activity Functions are executed.

- Each [Worker Entity](/workers#worker-entity) in the Worker Process must register the exact Workflow Types and Activity Types it may execute.
- Each Worker Entity must also associate itself with exactly one [Task Queue](/task-queue).
- Each Worker Entity polling the same Task Queue must be registered with the same Workflow Types and Activity Types.

A [Worker Entity](/workers#worker-entity) is the component within a Worker Process that listens to a specific Task Queue.

Although multiple Worker Entities can be in a single Worker Process, a single Worker Entity Worker Process may be perfectly sufficient.
For more information, see the [Worker tuning guide](/develop/worker-performance).

A Worker Entity contains a Workflow Worker and/or an Activity Worker, which makes progress on Workflow Executions and Activity Executions, respectively.

To develop a Worker, use the `Worker()` constructor and add your Client, Task Queue, Workflows, and Activities as arguments.
The following code example creates a Worker that polls for tasks from the Task Queue and executes the Workflow.
When a Worker is created, it accepts a list of Workflows in the workflows parameter, a list of Activities in the activities parameter, or both.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_worker_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio.client import Client
from temporalio.worker import Worker
# ...
# ...
async def main():
    client = await Client.connect("localhost:7233")
    worker = Worker(
        client,
        task_queue="your-task-queue",
        workflows=[YourWorkflow],
        activities=[your_activity],
    )
    await worker.run()

if __name__ == "__main__":
    asyncio.run(main())
```

### Register types {#register-types}

**How to register types using the Temporal Python SDK.**

All Workers listening to the same Task Queue name must be registered to handle the exact same Workflows Types and Activity Types.

If a Worker polls a Task for a Workflow Type or Activity Type it does not know about, it fails that Task.
However, the failure of the Task does not cause the associated Workflow Execution to fail.

When a `Worker` is created, it accepts a list of Workflows in the `workflows` parameter, a list of Activities in the `activities` parameter, or both.

<div className="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_worker_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")
    worker = Worker(
        client,
        task_queue="your-task-queue",
        workflows=[YourWorkflow],
        activities=[your_activity],
    )
    await worker.run()

if __name__ == "__main__":
    asyncio.run(main())
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/dynamic-configuration.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/dynamic-configuration.mdx</path>
  <content>
---
id: dynamic-configuration
title: Temporal Cluster dynamic configuration reference
sidebar_label: Dynamic configuration
description: Temporal Cluster offers dynamic configuration keys that you can update on the fly to optimize performance without service interruption. Customize these settings to meet specific Workflow, Activity, Namespace, or Task Queue requirements, and test thoroughly before deploying to production. For more details, visit the Temporal GitHub repository.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
---

Temporal Cluster provides [dynamic configuration](/clusters#dynamic-configuration) keys that you can update and apply to a running Cluster without restarting your services.

The dynamic configuration keys are set with default values when you create your Cluster configuration.
You can override these values as you test your Cluster setup for optimal performance according to your workload requirements.

For the complete list of dynamic configuration keys, see [https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go).
Ensure that you check server release notes for any changes to these keys and values.

For the default values of dynamic configuration keys, check the following links:

- [Frontend Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/frontend/service.go#L176)
- [History Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/history/configs/config.go#L309)
- [Matching Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/matching/config.go#L125)
- [Worker Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/worker/service.go#L193)

Setting dynamic configuration is optional.
Change these values only if you need to override the default values to achieve better performance on your Temporal Cluster.
Also, ensure that you test your changes before setting these in production.

## Format

To override the default dynamic configuration values, specify your custom values and constraints for the dynamic configuration keys that you want to change in a YAML configuration file.
Use the following format when creating your dynamic configuration file.

```yaml
testGetBoolPropertyKey:
  - value: false
  - value: true
    constraints:
      namespace: 'your-namespace'
  - value: false
    constraints:
      namespace: 'your-other-namespace'
testGetDurationPropertyKey:
  - value: '1m'
    constraints:
      namespace: 'your-namespace'
      taskQueueName: 'longIdleTimeTaskqueue'
testGetFloat64PropertyKey:
  - value: 12.0
    constraints:
      namespace: 'your-namespace'
testGetMapPropertyKey:
  - value:
      key1: 1
      key2: 'value 2'
      key3:
        - false
        - key4: true
          key5: 2.0
```

### Constraints

You can define constraints on some dynamic configuration keys to set specific values that apply on a Namespace or Task Queue level.
Not defining constraints on a dynamic configuration key sets the values across the Cluster.

- To set global values for the configuration key with no constraints, use the following:

  ```yaml
  frontend.globalNamespaceRPS: # Total per-Namespace RPC rate limit applied across the Cluster.
    - value: 5000
  ```

- For keys that can be customized at Namespace level, you can specify multiple values for different Namespaces in addition to one default value that applies globally to all Namespaces.
  To set values at a Namespace level, use `namespace` (String) as shown in the following example.

  ```yaml
  frontend.persistenceNamespaceMaxQPS: # Rate limit on the number of queries the Frontend sends to the Persistence store.
    - constraints: {} # Sets default value that applies to all Namespaces
      value: 2000 # The default value for this key is 0.
    - constraints: { namespace: 'namespace1' } # Sets limit on number of queries that can be sent from "namespace1" Namespace to the Persistence store.
      value: 4000
    - constraints: { namespace: 'namespace2' }
      value: 1000
  ```

- For keys that can be customized at a Task Queue level, you can specify Task Queue name and Task type in addition to Namespace.
  To set values at a Task Queue level, use `taskQueueName` (String) with `taskType` (optional; supported values: `Workflow` and `Activity`).

  For example if you have Workflow Executions creating a large number of Workflow and Activity tasks per second, you can add more partitions to your Task Queues (default is 4) to handle the high throughput of tasks.
  To do this, add the following to your dynamic configuration file.
  Note that if changing the number of partitions, you must set the same count for both read and write operations on Task Queues.

  ```yaml
  matching.numTaskqueueReadPartitions: # Number of Task Queue partitions for read operations.
    - constraints: { namespace: 'namespace1', taskQueueName: 'tq' } # Applies to the "tq" Task Queue for both Workflows and Activities.
      value: 8 # The default value for this key is 4. Task Queues that need to support high traffic require higher number of partitions. Set these values in accordance to your poller count.
    - constraints: {
          namespace: 'namespace1',
          taskQueueName: 'other-tq',
          taskType: 'Activity',
        } # Applies to the "other_tq" Task Queue for Activities specifically.
      value: 20
    - constraints: { namespace: 'namespace2' } # Applies to all task queues in "namespace2".
      value: 10
    - constraints: {} # Applies to all other task queues in "namespace1" and all other Namespaces.
      value: 16
  matching.numTaskqueueWritePartitions: # Number of Task Queue partitions for write operations.
    - constraints: { namespace: 'namespace1', taskQueueName: 'tq' } # Applies to the "tq" Task Queue for both Workflows and Activities.
      value: 8 # The default value for this key is 4. Task Queues that need to support high traffic require higher number of partitions. Set these values in accordance to your poller count.
    - constraints: {
          namespace: 'namespace1',
          taskQueueName: 'other-tq',
          taskType: 'Activity',
        } # Applies to the "other_tq" Task Queue for Activities specifically.
      value: 20
    - constraints: { namespace: 'namespace2' } # Applies to all task queues in "namespace2".
      value: 10
    - constraints: {} # Applies to all other task queues in "namespace1" and all other Namespaces.
      value: 16
  ```

{/* Note that the values set with most constraints take priority over values that are set with fewer constraints, regardless of the order in which they are set in the dynamic configuration key. */}

For more examples on how dynamic configuration is set, see:

- [docker-compose](https://github.com/temporalio/docker-compose/tree/main/dynamicconfig)
- [samples-server](https://github.com/temporalio/samples-server/blob/main/tls/config/dynamicconfig/development.yaml)

## Commonly used dynamic configuration keys

The following table lists commonly used dynamic configuration keys that can be used for rate limiting requests to the Temporal Cluster.

Setting dynamic configuration keys is optional.
If you choose to update these values for your Temporal Cluster, ensure that you are provisioning enough resources to handle the load.

All values listed here are for Temporal server v1.21.
Check [server release notes](https://github.com/temporalio/temporal/releases) to verify any potential breaking changes when upgrading your versions.

### Service-level RPS limits

The Requests Per Second (RPS) dynamic configuration keys set the rate at which requests can be made to each service in your Cluster.

When scaling your services, tune the RPS to test your workload and set acceptable provisioning benchmarks.
Exceeding these limits results in `ResourceExhaustedError`.

| Dynamic configuration key              | Type | Description                                                                                                                                                                                                                                          | Default value |
| -------------------------------------- | ---- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| Frontend                               |      |                                                                                                                                                                                                                                                      |               |
| `frontend.rps`                         | Int  | Rate limit (requests/second) for requests accepted by each Frontend Service host.                                                                                                                                                                    | 2400          |
| `frontend.namespaceRPS`                | Int  | Rate limit (requests/second) for requests accepted by each Namespace on the Frontend Service.                                                                                                                                                        | 2400          |
| `frontend.namespaceCount`              | Int  | Limit on the number of concurrent Task Queue polls per Namespace per Frontend Service host.                                                                                                                                                          | 1200          |
| `frontend.globalNamespaceRPS`          | Int  | Rate limit (requests/second) for requests accepted per Namespace, applied across Cluster. The limit is evenly distributed among available Frontend Service instances. If this is set, it overrides the per-instance limit (`frontend.namespaceRPS`). | 0             |
| `internal-frontend.globalNamespaceRPS` | Int  | Rate limit (requests/second) for requests accepted on each Internal-Frontend Service host applied across the Cluster.                                                                                                                                | 0             |
| History                                |      |                                                                                                                                                                                                                                                      |               |
| `history.rps`                          | Int  | Rate limit (requests/second) for requests accepted by each History Service host.                                                                                                                                                                     | 3000          |
| Matching                               |      |                                                                                                                                                                                                                                                      |               |
| `matching.rps`                         | Int  | Rate limit (requests/second) for requests accepted by each Matching Service host.                                                                                                                                                                    | 1200          |
| `matching.numTaskqueueReadPartitions`  | Int  | Number of read partitions for a Task Queue. Must be set with `matching.numTaskqueueWritePartitions`.                                                                                                                                                 | 4             |
| `matching.numTaskqueueWritePartitions` | Int  | Number of write partitions for a Task Queue.                                                                                                                                                                                                         | 4             |

### QPS limits for Persistence store

The Queries Per Second (QPS) dynamic configuration keys set the maximum number of queries a service can make per second to the Persistence store.

Persistence store rate limits are evaluated synchronously.
Adjust these keys according to your database capacity and workload.
If the number of queries made to the Persistence store exceeds the dynamic configuration value, you will see latencies and timeouts on your tasks.

| Dynamic configuration key                 | Type | Description                                                                                                                                                                                                                                             | Default value |
| ----------------------------------------- | ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| Frontend                                  |      |                                                                                                                                                                                                                                                         |               |
| `frontend.persistenceMaxQPS`              | Int  | Maximum number queries per second that the Frontend Service host can send to the Persistence store.                                                                                                                                                     | 2000          |
| `frontend.persistenceNamespaceMaxQPS`     | Int  | Maximum number of queries per second that each Namespace on the Frontend Service host can send to the Persistence store. <br /> If the value set for this config is less than or equal to 0, the value set for `frontend.persistenceMaxQPS` will apply. | 0             |
| History                                   |      |                                                                                                                                                                                                                                                         |               |
| `history.persistenceMaxQPS`               | Int  | Maximum number of queries per second that the History host can send to the Persistence store.                                                                                                                                                           | 9000          |
| `history.persistenceNamespaceMaxQPS`      | Int  | Maximum number of queries per second for each Namespace that the History host can send to the Persistence store. <br /> If the value set for this config is less than or equal to 0, then the value set for `history.persistenceMaxQPS` will apply.     | 0             |
| Matching                                  |      |                                                                                                                                                                                                                                                         |               |
| `matching.persistenceMaxQPS`              | Int  | Maximum number of queries per second that the Matching Service host can send to the Persistence store.                                                                                                                                                  | 9000          |
| `matching.persistenceNamespaceMaxQPS`     | Int  | Maximum number of queries per second that the Matching host can send to the Persistence store for each Namespace.<br /> If the value set for this config is less than or equal to 0, the value set for `matching.persistenceMaxQPS` will apply.         | 0             |
| Worker                                    |      |                                                                                                                                                                                                                                                         |               |
| `worker.persistenceMaxQPS`                | Int  | Maximum number of queries per second that the Worker Service host can send to the Persistence store.                                                                                                                                                    | 100           |
| `worker.persistenceNamespaceMaxQPS`       | Int  | Maximum number of queries per second that the Worker host can send to the Persistence store for each Namespace. <br /> If the value set for this config is less than or equal to 0, the value set for `worker.persistenceMaxQPS` will apply.            | 0             |
| Visibility                                |      |                                                                                                                                                                                                                                                         |               |
| `system.visibilityPersistenceMaxReadQPS`  | Int  | Maximum number queries per second that Visibility database can receive for read operations.                                                                                                                                                             | 9000          |
| `system.visibilityPersistenceMaxWriteQPS` | Int  | Maximum number of queries per second that Visibility database can receive for write operations.                                                                                                                                                         | 9000          |

### Activity and Workflow default policy setting

You can define default values for Activity and Workflow [Retry Policies](/encyclopedia/retry-policies) at the Cluster level with the following dynamic configuration keys.

| Dynamic configuration key            | Type                          | Description                                                                                                       | Default value                                                                                   |
| ------------------------------------ | ----------------------------- | ----------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| `history.defaultActivityRetryPolicy` | Map (key-value pair elements) | Server configuration for an Activity Retry Policy when it is not explicitly set for the Activity in your code.    | [Default values for retry Policy](/encyclopedia/retry-policies#default-values-for-retry-policy) |
| `history.defaultWorkflowRetryPolicy` | Map (key-value pair elements) | Retry Policy for unset fields where the user has set an explicit `RetryPolicy`, but not specified all the fields. | [Default values for retry Policy](/encyclopedia/retry-policies#default-values-for-retry-policy) |

### Size limit settings

The Persistence store in the Cluster has default size limits set for optimal performance. The dynamic configuration keys relating to some of these are listed below.

The default values on these keys are based on extensive testing.
You can change these values, but ensure that you are provisioning enough database resources to handle the changed values.

For details on platform limits, see the [Temporal Platform limits sheet](/self-hosted-guide/defaults).

| Dynamic configuration key               | Type | Description                                                                                                                                                                                                                                     | Default value            |
| --------------------------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------ |
| `limit.maxIDLength`                     | Int  | Length limit for various Ids, including: `Namespace`, `TaskQueue`, `WorkflowID`, `ActivityID`, `TimerID`, `WorkflowType`, `ActivityType`, `SignalName`, `MarkerName`, `ErrorReason`/`FailureReason`/`CancelCause`, `Identity`, and `RequestID`. | 1000                     |
| `limit.blobSize.warn`                   | Int  | Limit, in bytes, for BLOBs size in an Event when a warning is thrown in the server logs.                                                                                                                                                          | 512 KB (512 × 1024)      |
| `limit.blobSize.error`                  | Int  | Limit, in bytes, for BLOBs size in an Event when an error occurs in the transaction.                                                                                                                                                              | 2 MB (2 × 1024 × 1024)   |
| `limit.historySize.warn`                | Int  | Limit, in bytes, at which a warning is thrown for the Workflow Execution Event History size.                                                                                                                                                      | 10 MB (10 × 1024 × 1024) |
| `limit.historySize.error`               | Int  | Limit, in bytes, at which an error occurs in the Workflow Execution for exceeding allowed size.                                                                                                                                                   | 50 MB (50 × 1024 × 1024) |
| `limit.historyCount.warn`               | Int  | Limit, in count, at which a warning is thrown for the Workflow Execution Event History size.                                                                                                                                                    | 10,240 Events            |
| `limit.historyCount.error`              | Int  | Limit, in count, at which an error occurs in the Workflow Execution for exceeding allowed number of Events.                                                                                                                                     | 51,200 events            |
| `limit.numPendingActivities.error`      | Int  | Maximum number of pending Activities that a Workflow Execution can have before the `ScheduleActivityTask` fails with an error.                                                                                                                  | 2000                     |
| `limit.numPendingSignals.error`         | Int  | Maximum number of pending Signals that a Workflow Execution can have before the `SignalExternalWorkflowExecution` commands from this Workflow fail with an error.                                                                               | 2000                     |
| `history.maximumSignalsPerExecution`    | Int  | Maximum number of Signals that a Workflow Execution can receive before it throws an `Invalid Argument` error.                                                                                                                                   | 10000                    |
| `limit.numPendingCancelRequests.error`  | Int  | Maximum number of pending requests to cancel other Workflows that a Workflow Execution can have before the `RequestCancelExternalWorkflowExecution` commands fail with an error.                                                                | 2000                     |
| `limit.numPendingChildExecutions.error` | Int  | Maximum number of pending Child Workflows that a Workflow Execution can have before the `StartChildWorkflowExecution` commands fail with an error.                                                                                              | 2000                     |
| `frontend.visibilityMaxPageSize`        | Int  | Maximum number of Workflow Executions shown from the ListWorkflowExecutions API in one page.                                                                                                                                                    | 1000                     |

### Secondary Visibility settings

Secondary Visibility configuration keys enable Dual Visibility on your Temporal Cluster.
This can be useful when migrating a Visibility database or creating a backup Visibility store.

| Dynamic configuration key                  | Type    | Description                                                                                                                                                                                                                                                                                                                                                                                                          | Default value |
| ------------------------------------------ | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| `system.enableReadFromSecondaryVisibility` | Boolean | Enables reading from the [secondary Visibility store](/dual-visibility), and can be set per Namespace. Allowed values are `true` or `false`.                                                                                                                                                                                                                                                              | `false`       |
| `system.secondaryVisibilityWritingMode`    |         | Enables writing Visibility data to the secondary Visibility store and can be set per Namespace. Setting this value to `on` disables write operations to the primary Visibility store. Allowed values:<br /> `off`: Enables writing to primary Visibility store only. <br /> `on`: Enables writing to secondary Visibility store only.<br /> `dual`: Enables writing to both primary and secondary Visibility stores. | `off`         |

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/failure-detection.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/failure-detection.mdx</path>
  <content>
---
id: failure-detection
title: Failure detection - Python SDK
sidebar_label: Failure detection
Description: Guidance on setting timeouts, retries, and heartbeat functionality for Workflows and Activities in Python with Temporal.
slug: /develop/python/failure-detection
toc_max_heading_level: 2
keywords:
  - workflow timeouts
  - workflow retries
  - activity timeouts
  - activity retry policy
  - activity heartbeats
  - heartbeat timeout
tags:
  - Activities
  - Workflows
  - Errors
  - Failures
  - Python SDK
  - Temporal SDKs
description: Learn how to set Workflow and Activity timeouts, retries, retry policies, and heartbeats using the Temporal Python SDK to optimize execution and ensure reliability.
---

This page shows how to do the following:

- [Set Workflow timeouts](#workflow-timeouts)
- [set Workflow retries](#workflow-retries)
- [Set Activity timeouts](#activity-timeouts)
- [Set an Activity Retry Policy](#activity-retries)
- [Heartbeat an Activity](#activity-heartbeats)

## Workflow timeouts {#workflow-timeouts}

**How to set Workflow timeouts using the Temporal Python SDK.**

Each Workflow timeout controls the maximum duration of a different aspect of a Workflow Execution.

Workflow timeouts are set when [starting the Workflow Execution](#workflow-timeouts).

- **[Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout)** - restricts the maximum amount of time that a single Workflow Execution can be executed.
- **[Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout):** restricts the maximum amount of time that a single Workflow Run can last.
- **[Workflow Task Timeout](/encyclopedia/detecting-workflow-failures#workflow-task-timeout):** restricts the maximum amount of time that a Worker can execute a Workflow Task.

Set the timeout to either the [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) asynchronous methods.

Available timeouts are:

- `execution_timeout`
- `run_timeout`
- `task_timeout`

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/workflow_timeouts_retries/workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
    result = await client.execute_workflow(
        YourWorkflow.run,
        "your timeout argument",
        id="your-workflow-id",
        task_queue="your-task-queue",
        # Set Workflow Timeout duration
        execution_timeout=timedelta(seconds=2),
        # run_timeout=timedelta(seconds=2),
        # task_timeout=timedelta(seconds=2),
    )
```

### Workflow retries {#workflow-retries}

**How to set a Workflow Retry Policy using the Temporal Python SDK.**

A Retry Policy can work in cooperation with the timeouts to provide fine controls to optimize the execution experience.

Use a [Retry Policy](/encyclopedia/retry-policies) to retry a Workflow Execution in the event of a failure.

Workflow Executions do not retry by default, and Retry Policies should be used with Workflow Executions only in certain situations.

Set the Retry Policy to either the [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) asynchronous methods.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/workflow_timeouts_retries/workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
    handle = await client.execute_workflow(
        YourWorkflow.run,
        "your retry policy argument",
        id="your-workflow-id",
        task_queue="your-task-queue",
        retry_policy=RetryPolicy(maximum_interval=timedelta(seconds=2)),
    )
```

## Set Activity timeouts {#activity-timeouts}

**How to set an Activity Execution Timeout using the Temporal Python SDK.**

Each Activity timeout controls the maximum duration of a different aspect of an Activity Execution.

The following timeouts are available in the Activity Options.

- **[Schedule-To-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout):** is the maximum amount of time allowed for the overall [Activity Execution](/activities#activity-execution).
- **[Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout):** is the maximum time allowed for a single [Activity Task Execution](/tasks#activity-task-execution).
- **[Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout):** is the maximum amount of time that is allowed from when an [Activity Task](/tasks#activity-task) is scheduled to when a [Worker](/workers#worker) starts that Activity Task.

An Activity Execution must have either the Start-To-Close or the Schedule-To-Close Timeout set.

Activity options are set as keyword arguments after the Activity arguments.

Available timeouts are:

- schedule_to_close_timeout
- schedule_to_start_timeout
- start_to_close_timeout

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/activity_timeouts_retires/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
        activity_timeout_result = await workflow.execute_activity(
            your_activity,
            YourParams(greeting, "Activity Timeout option"),
            # Activity Execution Timeout
            start_to_close_timeout=timedelta(seconds=10),
            # schedule_to_start_timeout=timedelta(seconds=10),
            # schedule_to_close_timeout=timedelta(seconds=10),
        )
```

### Set an Activity Retry Policy {#activity-retries}

**How to set an Activity Retry Policy using the Temporal Python SDK.**

A Retry Policy works in cooperation with the timeouts to provide fine controls to optimize the execution experience.

Activity Executions are automatically associated with a default [Retry Policy](/encyclopedia/retry-policies) if a custom one is not provided.

To create an Activity Retry Policy in Python, set the [RetryPolicy](https://python.temporal.io/temporalio.common.RetryPolicy.html) class within the [`start_activity()`](https://python.temporal.io/temporalio.workflow.html#start_activity) or [`execute_activity()`](https://python.temporal.io/temporalio.workflow.html#execute_activity) function.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/activity_timeouts_retires/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio.common import RetryPolicy
# ...
        activity_result = await workflow.execute_activity(
            your_activity,
            YourParams(greeting, "Retry Policy options"),
            start_to_close_timeout=timedelta(seconds=10),
            # Retry Policy
            retry_policy=RetryPolicy(
                backoff_coefficient=2.0,
                maximum_attempts=5,
                initial_interval=timedelta(seconds=1),
                maximum_interval=timedelta(seconds=2),
                # non_retryable_error_types=["ValueError"],
            ),
        )
```

### Override the retry interval with `next_retry_delay` {#next-retry-delay}

To override the next retry interval set by the current policy, pass `next_retry_delay` when raising an [ApplicationError](/references/failures#application-failure) in an Activity.
This value replaces and overrides whatever the retry interval would normally be on the retry policy.

For example, you can set the delay interval based on an Activity's attempt count.
In the following example, the retry delay starts at 3 seconds after the first attempt.
It increases to 6 seconds for the second attempt, 9 seconds for the third attempt, and so forth.
This creates a steadily increasing backoff, versus the exponential approach used by [backoff coefficients](/encyclopedia/retry-policies#backoff-coefficient):

```python
from temporalio.exceptions import ApplicationError
from datetime import timedelta

@activity.defn
async def my_activity(input: MyActivityInput):
    try:
        # Your activity logic goes here
    except Exception as e:
        attempt = activity.info().attempt
        raise ApplicationError(
            f"Error encountered on attempt {attempt}",
            next_retry_delay=timedelta(seconds=3 * attempt),
        ) from e
```

## Heartbeat an Activity {#activity-heartbeats}

**How to Heartbeat an Activity using the Temporal Python SDK.**

An [Activity Heartbeat](/encyclopedia/detecting-activity-failures#activity-heartbeat) is a ping from the [Worker Process](/workers#worker-process) that is executing the Activity to the [Temporal Service](/clusters).
Each Heartbeat informs the Temporal Service that the [Activity Execution](/activities#activity-execution) is making progress and the Worker has not crashed.
If the Temporal Service does not receive a Heartbeat within a [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout) time period, the Activity will be considered failed and another [Activity Task Execution](/tasks#activity-task-execution) may be scheduled according to the Retry Policy.

Heartbeats may not always be sent to the Temporal Service—they may be [throttled](/encyclopedia/detecting-activity-failures#throttling) by the Worker.

Activity Cancellations are delivered to Activities from the Temporal Service when they Heartbeat. Activities that don't Heartbeat can't receive a Cancellation.
Heartbeat throttling may lead to Cancellation getting delivered later than expected.

Heartbeats can contain a `details` field describing the Activity's current progress.
If an Activity gets retried, the Activity can access the `details` from the last Heartbeat that was sent to the Temporal Service.

To Heartbeat an Activity Execution in Python, use the [`heartbeat()`](https://python.temporal.io/temporalio.activity.html#heartbeat) API.

```python
@activity.defn
async def your_activity_definition() -> str:
    activity.heartbeat("heartbeat details!")
```

In addition to obtaining cancellation information, Heartbeats also support detail data that persists on the server for retrieval during Activity retry.
If an Activity calls `heartbeat(123, 456)` and then fails and is retried, `heartbeat_details` returns an iterable containing `123` and `456` on the next Run.

#### Set a Heartbeat Timeout {#heartbeat-timeout}

**How to set a Heartbeat Timeout using the Temporal Python SDK.**

A [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout) works in conjunction with [Activity Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat).

[`heartbeat_timeout`](https://python.temporal.io/temporalio.worker.StartActivityInput.html#heartbeat_timeout) is a class variable for the [`start_activity()`](https://python.temporal.io/temporalio.workflow.html#start_activity) function used to set the maximum time between Activity Heartbeats.

```python
workflow.start_activity(
    activity="your-activity",
    schedule_to_close_timeout=timedelta(seconds=5),
    heartbeat_timeout=timedelta(seconds=1),
)
```

`execute_activity()` is a shortcut for [`start_activity()`](https://python.temporal.io/temporalio.workflow.html#start_activity) that waits on its result.

To get just the handle to wait and cancel separately, use `start_activity()`. `execute_activity()` should be used in most cases unless advanced task capabilities are needed.

```python
workflow.execute_activity(
    activity="your-activity",
    name,
    schedule_to_close_timeout=timedelta(seconds=5),
    heartbeat_timeout=timedelta(seconds=1),
)
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/throughput-composability.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/throughput-composability.mdx</path>
  <content>
---
id: throughput-composability
title: Child Workflows - Temporal feature
description: Leverage Temporal Child Workflows for enhanced composability and efficiency. Partition steps, manage resources, invoke multiple services, and execute periodic logic seamlessly.
sidebar_label: Composability
tags:
  - Child Workflows
keywords:
  - child workflows in temporal
  - workflow composability
  - temporal SDK child workflows
  - child workflow services
  - workflow partitioning
  - resource management in workflows
  - periodic task execution
  - temporal throughput enhancement
  - child workflow implementation
  - throughput composability
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

In Temporal, **Child Workflows** enable applications to achieve another level of composability when it comes to throughput.

The following example scenarios are a few reasons to use this feature:

- To create a separate service that can be invoked from multiple other services or applications.
- To partition a step into smaller smaller chunks.
- To manage a dedicated resource and guarantee uniqueness.
- To execute logic periodically without overwhelming the parent business process.

See the SDK feature guides for implementation details:

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/child-workflows" text="Go SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/child-workflows" text="Java SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/child-workflows" text="PHP SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/child-workflows" text="Python SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/child-workflows" text="TypeScript SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/child-workflows" text=".NET SDK Child Workflow feature guide" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into Child Workflows see the [Child Workflows Encyclopedia page](/encyclopedia/child-workflows).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/web-ui-configuration.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/web-ui-configuration.mdx</path>
  <content>
---
id: web-ui-configuration
title: Temporal Web UI configuration reference
sidebar_label: Web UI config
description:  Manage your Temporal Server efficiently with development.yaml. Set parameters for Auth, TLS, ports, and more.
toc_max_heading_level: 4
keywords:
  - reference
  - web-ui
tags:
  - Reference
  - Temporal Web UI
---

The Temporal Web UI Server uses a configuration file for many of the UI's settings.

An example development.yaml file can be found in the [temporalio/ui-server repo](https://github.com/temporalio/ui-server/blob/main/config/development.yaml).

Multiple configuration files can be created for configuring specific areas of the UI, such as Auth or TLS.

## temporalGrpcAddress

The frontend address for the Temporal Cluster.

The default address is localhost (127.0.0.1:7233).

```yaml
temporalGrpcAddress: default
```

## port

The port used by the Temporal Web UI Server and any APIs.

```yaml
port: 8080
```

## publicPath

The path used by the Temporal Web UI Server and any APIs.

```yaml
publicPath: ''
```

## enableUi

Enables the browser UI.
This configuration can be set dynamically with the [TEMPORAL_UI_ENABLED](/references/web-ui-environment-variables#temporal_ui_enabled) environment variable.
If disabled—that is, set to `false`—the UI server APIs remain available.

```yaml
enableUi: true
```

## cloudUi

Enables the Cloud UI.

```yaml
cloudUi: false
```

## defaultNamespace

The default Namespace that the UI loads data for.
Defaults to `default`.

```yaml
defaultNamespace: default
```

## feedbackUrl

The URL to direct users to when they click on the Feedback button in the UI.
If not specified, it defaults to the UI's GitHub Issue page.

```yaml
feedbackUrl: https://github.com/temporalio/ui/issues/new/choose
```

## notifyOnNewVersion

When enabled—that is, when set to `true`—a notification appears in the UI when a newer version of the [Temporal Server](/clusters#temporal-server) is available.

```yaml
notifyOnNewVersion: true
```

## refreshInterval

How often the configuration UI Server reads the configuration file for new values.
Currently, only [tls](#tls) configuration values are propagated during a refresh.

```yaml
refreshInterval: 1m
```

## showTemporalSystemNamespace

When enabled—that is, when set to `true`—the Temporal System Namespace becomes visible in the UI.
The Temporal System Namespace lists Workflow Executions used by the Temporal Platform.

```yaml
showTemporalSystemNamespace: false
```

## disableWriteActions

Prevents the user from executing Workflow Actions on the Web UI.

This option affects Bulk Actions for Recent Workflows as well as Workflow Actions on the Workflow Details page.

```yaml
disableWriteActions: false
```

:::note
`disableWriteActions` overrides the configuration values of each individual Workflow Action.
Setting this variable to `true` disables all Workflow Actions on the Web UI.
:::

## workflowTerminateDisabled

Prevents the user from terminating Workflow Executions from the Web UI.

```yaml
workflowTerminateDisabled: false
```

## workflowCancelDisabled

Prevents the user from canceling Workflow Executions from the Web UI.

```yaml
workflowCancelDisabled: false
```

## workflowSignalDisabled

Prevents the user from signaling Workflow Executions from the Web UI.

```yaml
workflowSignalDisabled: false
```

## workflowResetDisabled

Prevents the user from resetting Workflows from the Web UI.

```yaml
workflowResetDisabled: false
```

## batchActionsDisabled

Prevents the execution of Batch actions.

```yaml
batchActionsDisabled: false
```

## hideWorkflowQueryErrors

Hides any errors resulting from a Query to the Workflow.

```yaml
hideWorkflowQueryErrors: false
```

## cors

The name of the `cors` field stands for Cross-Origin Resource Sharing.
Use this field to provide a list of domains that are authorized to access the UI Server APIs.

```yaml
cors:
  cookieInsecure: false
  allowOrigins:
    - http://localhost:3000 # used at development by https://github.com/temporalio/ui
```

## tls

Transport Layer Security (TLS) configuration for the Temporal Server.
Settings apply when TLS is enabled.

```yaml
tls:
  caFile: ../ca.cert
  certFile: ../cluster.pem
  keyFile: ../cluster.key
  caData:
  certData:
  keyData:
  enableHostVerification: true
  serverName: tls-server
```

## auth

Configures authorization for the Temporal Server.
Settings apply when Auth is enabled.

```yaml
auth:
  enabled: true
  providers:
    label: sso # for internal use; in future may expose as button text
    type: oidc
    providerUrl: https://accounts.google.com
    issuerUrl:
    clientId: xxxxx-xxxx.apps.googleusercontent.com
    clientSecret: xxxxxxxxxxxxxxxxxxxx
    callbackUrl: https://xxxx.com:8080/auth/sso/callback
    scopes:
      - openid
      - profile
      - email
```

## codec

Codec Server configuration.

```yaml
codec:
  endpoint: http://your-codec-server-endpoint
  passAccessToken: false
  includeCredentials: false
  decodeEventHistoryDownload: false
```

## forwardHeaders

Configures headers for forwarding.

```yaml
forwardHeaders:
  -
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/task-queues.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/task-queues.mdx</path>
  <content>
---
id: task-queues
title: Task Queues
sidebar_label: Task Queues
description: Explore the role of Worker Processes in polling Task Queues and executing Tasks.
slug: /task-queue
toc_max_heading_level: 4
keywords:
  - task queues
tags:
  - Workers
  - Task Queues
---

This page discusses [Task Queues](#task-queue) including [where to set Task Queues](#set-task-queue) and [Task Ordering](#task-ordering).

## What is a Task Queue? {#task-queue}

A Task Queue is a lightweight, dynamically allocated queue that one or more [Worker Entities](/workers#worker-entity) poll for [Tasks](/tasks).
There are three types of Task Queues: Activity Task Queues, Workflow Task Queues, and Nexus Task Queues.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Task Queue component</p>
  </div>
  <div className="tdiiw" height="500">
    <img
      className="img_ev3q"
      src="/diagrams/task-queue.svg"
      alt="Task Queue component"
    />
  </div>
</div>

A Nexus Endpoint creates an entry point that separates callers from the underlying Nexus Task Queue.
The Nexus callers only interact with the Nexus Endpoint.
This endpoint routes Nexus Requests to a target Task Queue that's polled by a Nexus Worker.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Nexus Endpoint component</p>
  </div>
  <div className="tdiiw" height="500">
    <img
      className="img_ev3q"
      src="/img/encyclopedia/workers/nexus-task-queue.png"
      alt="Task Queue component"
    />
  </div>
</div>

Task Queues are lightweight components that don’t require explicit registration.
They’re created on demand when a Workflow Execution, Activity, or Nexus Operation is invoked, and/or when a Worker Process subscribes to start polling.
When a named Task Queue is created, individual Task Queues for Workflows, Activities, and Nexus are created using the same name.
A Temporal Application can use, and the Temporal Service can maintain, an unlimited number of Task Queues.

Workers poll for Tasks in Task Queues via synchronous RPC.
This implementation offers several benefits:

- A Worker Process polls for a message only when it has spare capacity, avoiding overloading itself.
- In effect, Task Queues enable load balancing across many Worker Processes.
- Task Queues enable [Task Routing](/task-routing), which is the routing of specific Tasks to specific Worker Processes or even a specific process.
- Activity Task Queues support server-side throttling, which enables you to limit the Task dispatching rate to the pool of Worker Processes while still supporting Task dispatching at higher rates when spikes happen.
- Workflow and Activity Tasks persist in a Task Queue.
  When a Worker Process goes down, the messages remain until the Worker recovers and can process the Tasks.
- Nexus and Query Tasks are not persisted.
  Instead, they are sync matched when, and only when, polled by a Worker.
  Sync matching immediately matches and delivers a Task to an available Worker without persisting a Task to the Service database.
  The caller is responsible to retry failed operations.
  Caller Workflows that invoke Nexus Operations will automatically retry Nexus Tasks until exceeding the Schedule-to-Close timeout.
- Worker Processes do not need to advertise themselves through DNS or any other network discovery mechanism.
- Worker Processes connect directly to the Temporal Service for secure communication without needing to open exposed ports.

Any Worker can pick up any Task on a given Task Queue.
You must ensure that if a Worker accepts a Task that it can process that task using one of its registered Workflows, Activities, or Nexus Operation handlers.
This means that all Workers listening to a Task Queue must register all Workflows, Activities, and Nexus Operations that live on that Queue.

There are two exceptions to this "Task Queue Workers with identical registrations" rule.
First, Worker Versioning may be used.
During a Worker upgrade binary rollouts, it's okay to have temporarily misaligned registrations.
Second, dynamic Workflows or Activity components may be used.
If a Task arrives with a recognized method signature, the Worker can use a pre-registered dynamic stand-in.

When Workers don't have a registered Workflow, Activity, Nexus Operation, or dynamic Workflow or Activity component for a given Task, the Task will fail with a "Not Found" error.

- "Not Found" Workflow Tasks and Activity Tasks are treated as _retryable_ errors.
- "Not Found" Nexus Operation handlers are _non-retryable_ and must be manually retried from the caller Workflow.

#### Where to set Task Queues {#set-task-queue}

There are five places where the name of the Task Queue can be set by the developer.

1. A Task Queue must be set when spawning a Workflow Execution:

   - [How to start a Workflow Execution using the Temporal CLI](/cli/workflow#start)
   - [How to start a Workflow Execution using the Go SDK](/develop/go/temporal-clients#start-workflow-execution)
   - [How to start a Workflow Execution using the Java SDK](/develop/java/temporal-clients#start-workflow-execution)
   - [How to start a Workflow Execution using the PHP SDK](/develop/php/temporal-clients#start-workflow-execution)
   - [How to start a Workflow Execution using the Python SDK](/develop/python/temporal-clients#start-workflow-execution)
   - [How to start a Workflow Execution using the TypeScript SDK](/develop/typescript/temporal-clients#start-workflow-execution)
   - [How to start a Workflow Execution using the .NET SDK](/develop/dotnet/temporal-client#start-workflow)

2. A Task Queue name must be set when creating a Worker Entity and when running a Worker Process:

   - [How to run a development Worker using the Go SDK](/develop/go/core-application#develop-worker)
   - [How to run a development Worker using the Java SDK](/develop/java/core-application#run-a-dev-worker)
   - [How to run a development Worker using the PHP SDK](/develop/php/core-application#run-a-dev-worker)
   - [How to run a development Worker using the Python SDK](/develop/python/core-application#run-a-dev-worker)
   - [How to run a development Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-dev-worker)
   - [How to run a development Worker using the .NET SDK](/develop/dotnet/core-application#run-worker-process)<br /><br />
   - [How to run a Temporal Cloud Worker using the Go SDK](/develop/go/core-application#run-a-temporal-cloud-worker)
   - [How to run a Temporal Cloud Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-temporal-cloud-worker)

   Note that all Worker Entities listening to the same Task Queue name must be registered to handle the exact same Workflows Types, Activity Types, and Nexus Operations.

   If a Worker Entity polls a Task for a Workflow Type or Activity Type it does not know about, it will fail that Task.
   However, the failure of the Task will not cause the associated Workflow Execution to fail.

3. A Task Queue name can be provided when spawning an Activity Execution:

   This is optional.
   An Activity Execution inherits the Task Queue name from its Workflow Execution if one is not provided.

   - [How to start an Activity Execution using the Go SDK](/develop/go/core-application#activity-execution)
   - [How to start an Activity Execution using the Java SDK](/develop/java/core-application#activity-execution)
   - [How to start an Activity Execution using the PHP SDK](/develop/php/core-application#activity-execution)
   - [How to start an Activity Execution using the Python SDK](/develop/python/core-application#activity-execution)
   - [How to start an Activity Execution using the TypeScript SDK](/develop/typescript/core-application#activity-execution)
   - [How to start an Activity Execution using the .NET SDK](/develop/dotnet/core-application#activity-execution)

4. A Task Queue name can be provided when spawning a Child Workflow Execution:

   This is optional.
   A Child Workflow Execution inherits the Task Queue name from its Parent Workflow Execution if one is not provided.

   - [How to start a Child Workflow Execution using the Go SDK](/develop/go/child-workflows)
   - [How to start a Child Workflow Execution using the Java SDK](/develop/java/child-workflows)
   - [How to start a Child Workflow Execution using the PHP SDK](/develop/php/continue-as-new)
   - [How to start a Child Workflow Execution using the Python SDK](/develop/python/child-workflows)
   - [How to start a Child Workflow Execution using the TypeScript SDK](/develop/typescript/child-workflows)
   - [How to start a Child Workflow Execution using the .NET SDK](/develop/dotnet/child-workflows)

5. A Task Queue name can be provided when creating a Nexus Endpoint.
   Nexus Endpoints route requests to the target Task Queue.
   Nexus Workers poll the target Task Queue to handle the Nexus Tasks, such as starting or cancelling a Nexus Operation.

   - [How to run a Nexus Worker using the Go SDK](https://docs.temporal.io/develop/go/nexus#register-a-nexus-service-in-a-worker)
   - [How to run a Nexus Worker using the Java SDK](https://docs.temporal.io/develop/java/nexus#register-a-nexus-service-in-a-worker)

#### Task ordering

Task Queues can be scaled by adding partitions.
The [default](/references/dynamic-configuration#service-level-rps-limits) number of partitions is 4.

Task Queues with multiple partitions do not have any ordering guarantees.
Once there is a backlog of Tasks that have been written to disk, Tasks that can be dispatched immediately (“sync matches”) are delivered before tasks from the backlog (“async matches”).
This approach optimizes throughput.

Task Queues with a single partition are almost always first-in, first-out, with rare edge case exceptions.
However, using a single partition limits you to low- and medium-throughput use cases.

:::note

This section is on the ordering of individual Tasks, and does not apply to the ordering of Workflow Executions, Activity Executions, or [Events](/workflows#event) in a single Workflow Execution.
The order of Events in a Workflow Execution is guaranteed to remain constant once they have been written to that Workflow Execution's [History](/workflows#event-history).

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/remote-data-encoding.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/remote-data-encoding.mdx</path>
  <content>
---
id: remote-data-encoding
title: Remote Data Encoding
sidebar_label: Remote Data Encoding
description: Learn how to use remote encoding to transform data for the Temporal CLI and Web UI.
slug: /remote-data-encoding
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - remote-data-encoding
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Remote Data Encoding](#remote-data-encoding). 

## What is remote data encoding? {#remote-data-encoding}

Remote data encoding is exposing your Payload Codec via HTTP endpoints to support remote encoding and decoding.

Running your encoding remotely allows you to use it with the [Temporal CLI](/cli) to encode/decode data for several commands including `temporal workflow show` and with Temporal Web UI to decode data in your Workflow Execution details view.

To run data encoding/decoding remotely, use a [Codec Server](/codec-server). A Codec Server is an HTTP server that uses your custom Codec logic to decode your data remotely.
The Codec Server is independent of the Temporal Service and decodes your encrypted payloads through predefined endpoints.
You create, operate, and manage access to your Codec Server in your own environment.
The Temporal CLI and the Web UI in turn provide built-in hooks to call the Codec Server to decode encrypted payloads on demand.

### Encoding data on the Web UI and CLI

You can perform some operations on your Workflow Execution using the Temporal CLI and the Web UI.
For example. you can start or signal an active Workflow Execution from the Temporal CLI or cancel a Workflow Execution from the Web UI, which might require inputs that contain sensitive data.

To encode this data, specify your [Codec Server endpoints](/codec-server) with the `codec-endpoint` parameter in [the Temporal CLI](/cli) and configure your Web UI to use the Codec Server endpoints.

### Decoding data on the Web UI and CLI

If you use custom encoding, Payload data handled by the Temporal Service is stored encoded. Since the Web UI uses the [Visibility](/clusters#visibility) database to show events and data stored on the Temporal Server, all data in the Workflow Execution History in your Web UI is displayed in the encoded format.

To decode output when using the Web UI and the Temporal CLI, use a [Codec Server](/codec-server).

Note that a remote data encoder is a separate system with access to your encryption keys and exposes APIs to encode and decode any data.
Evaluate and ensure that your remote data encoder endpoints are secured and only authorized users have access to them.

Samples:

- [Go](https://github.com/temporalio/samples-go/tree/main/codec-server)
- [Java](https://github.com/temporalio/sdk-java/tree/master/temporal-remote-data-encoder)
- [Python](https://github.com/temporalio/samples-python/tree/main/encryption)
- [TypeScript](https://github.com/temporalio/samples-typescript/tree/main/encryption)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/namespaces/global-namespaces.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/namespaces/global-namespaces.mdx</path>
  <content>
---
id: global-namespaces
title: Global Namespace
sidebar_label: Global Namespace
description: This guide covers everything about Global Namespaces within the Temporal Platform.
slug: /global-namespace
toc_max_heading_level: 4
keywords:
  - namespaces
tags:
  - Concepts
  - Namespaces
---

This page provides an overview of Global Namespace.

## What is a Global Namespace? {#global-namespace}

A Global Namespace is a [Namespace](/namespaces) that exists across Clusters when [Multi-Cluster Replication](/clusters#multi-cluster-replication) is set up.

- [How to register a Global Namespace](/cli/operator#create)
- [How to change the active Cluster for a Global Namespace](/cli/operator#update)

The Global Namespace feature enables Workflow Executions to progress through another Cluster in the event of a failover.

A Global Namespace may be replicated to any number of Clusters, but is active in only one Cluster at any given time.

For a failover to be successful, Worker Processes must be polling for Tasks for the Global Namespace on all Clusters.

A Global Namespace has a failover version.
Because a failover can be triggered from any Cluster, the failover version prevents certain conflicts from occurring if a failover is mistakenly triggered simultaneously on two Clusters.

Only the active Cluster dispatches [Tasks](/tasks#task); however, certain conflicts are possible.
Unlike regular Namespaces, which provide at-most-once semantics for an Activity Execution, Global Namespaces can support only at-least-once semantics (see [Conflict resolution](/clusters#conflict-resolution)).
Worker Processes on the standby Clusters are idle until a failover occurs and their Cluster becomes active.

Temporal Application API calls made to a non-active Cluster are rejected with a **NamespaceNotActiveError** which contains the name of the current active Cluster.
It is the responsibility of the Temporal Application to call the Cluster that is currently active.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/temporal.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/temporal.mdx</path>
  <content>
---
id: temporal
title: What is Temporal?
sidebar_label: Temporal
description: Temporal is a scalable platform that ensures the Durable Execution of application code, allowing reliable and resilient Workflow Executions even in the face of failures like network outages or server crashes.
slug: /temporal
toc_max_heading_level: 4
keywords:
  - durable execution
  - explanation
  - temporal
  - term
tags:
  - Durable Execution
  - Temporal
  - Concepts
---

Temporal is a scalable and reliable runtime for durable function executions called [Temporal Workflow Executions](/workflows#workflow-execution).

Said another way, it's a platform that guarantees the [Durable Execution](#durable-execution) of your application code.

It enables you to develop as if failures don't even exist.
Your application will run reliably even if it encounters problems, such as network outages or server crashes, which would be catastrophic for a typical application.
The Temporal Platform handles these types of problems, allowing you to focus on the business logic, instead of writing application code to detect and recover from failures.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">The Temporal System</p>
  </div>
  <div className="tdiiw" height="740">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-system-simple.svg"
      alt="The Temporal System"
    />
  </div>
</div>

## Durable Execution {#durable-execution}

Durable Execution in the context of Temporal refers to the ability of a Workflow Execution to maintain its state and progress even in the face of failures, crashes, or server outages.
This is achieved through Temporal's use of an [Event History](/workflows#event-history), which records the state of a Workflow Execution at each step.
If a failure occurs, the Workflow Execution can resume from the last recorded event, ensuring that progress isn't lost.
This durability is a key feature of Temporal Workflow Executions, making them reliable and resilient.
It enables application code to execute effectively once and to completion, regardless of whether it takes seconds or years.

## What is the Temporal Platform? {#temporal-platform}

The Temporal Platform consists of a [Temporal Service](/clusters) and [Worker Processes](/workers#worker-process).
Together these components create a runtime for Workflow Executions.

The Temporal Platform consists of a supervising software typically called the [Temporal Service](/clusters) and application code bundled as Worker Processes.
Together these components create a runtime for your application.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">The Temporal Platform</p>
  </div>
  <div className="tdiiw" height="740">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-platform-simple.svg"
      alt="The Temporal Platform"
    />
  </div>
</div>

A Temporal Service consists of the Temporal Server and a database.

Our software as a service (SaaS) offering, Temporal Cloud, offers an alternative to hosting the Temporal Service yourself.

Worker Processes are hosted and operated by you and execute your code. Workers run using one of our SDKs.

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Basic component topology of the Temporal Platform</p>
  </div>
  <div className="tdiiw" height="1121">
    <img
      className="img_ev3q"
      src="/diagrams/temporal-platform-component-topology.svg"
      alt="Basic component topology of the Temporal Platform"
    />
  </div>
</div>

## What is a Temporal Application? {#temporal-application}

A Temporal Application is a set of [Temporal Workflow Executions](/workflows#workflow-execution).
Each Temporal Workflow Execution has exclusive access to its local state, executes concurrently to all other Workflow Executions, and communicates with other Workflow Executions and the environment via message passing.

A Temporal Application can consist of millions to billions of Workflow Executions.
Workflow Executions are lightweight components.
A Workflow Execution consumes few compute resources; in fact, if a Workflow Execution is suspended, such as when it is in a waiting state, the Workflow Execution consumes no compute resources at all.

**Reentrant Process**

A Temporal Workflow Execution is a Reentrant Process. A Reentrant Process is resumable, recoverable, and reactive.

- Resumable: Ability of a process to continue execution after execution was suspended on an _awaitable_.
- Recoverable: Ability of a process to continue execution after execution was suspended on a _failure_.
- Reactive: Ability of a process to react to external events.

Therefore, a Temporal Workflow Execution executes a [Temporal Workflow Definition](/workflows#workflow-definition), also called a Temporal Workflow Function, your application code, exactly once and to completion—whether your code executes for seconds or years, in the presence of arbitrary load and arbitrary failures.

## What is a Failure? {#failure}

[Temporal Failures](/references/failures) are representations (in the SDKs and Event History) of various types of errors that occur in the system.

Failure handling is an essential part of development.
For more information, including the difference between application-level and platform-level failures, see [Handling Failure From First Principles](https://dominik-tornow.medium.com/handling-failures-from-first-principles-1ed976b1b869).
For the practical application of those concepts in Temporal, see [Failure Handling in Practice](https://temporal.io/blog/failure-handling-in-practice).

For languages that throw (or raise) errors (or exceptions), throwing an error that is not a Temporal Failure from a Workflow fails the Workflow Task (and the Task will be retried until it succeeds), whereas throwing a Temporal Failure (or letting a Temporal Failure propagate from Temporal calls, like an [Activity Failure](/references/failures#activity-failure) from an Activity call) fails the Workflow Execution.
For more information, see [Application Failure](/references/failures#application-failure).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/temporal-clients.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/temporal-clients.mdx</path>
  <content>
---
id: temporal-clients
title: Temporal Client - Python SDK
sidebar_label: Temporal Client
toc_max_heading_level: 4
description: Discover how to connect and use Temporal Clients with Python. Learn to link your Client to Temporal Service, Temporal Cloud, start Workflow Executions, set Task Queues, Workflow Ids, and get Workflow results.
keywords:
  - temporal python client
  - connect python client to temporal service
  - initialize temporal client
  - temporal SDK python guide
  - start workflow execution python
  - temporal cloud connection
  - python client for temporal cli
  - custom namespace configuration
  - temporal workflow management
  - temporal client setup
  - python workflow execution
  - temporal cloud integration
  - temporal client options
  - managing temporal namespaces
tags:
  - Temporal Client
  - Python SDK
  - Temporal SDKs
  - Certificates
---

This guide introduces Temporal Clients.
It explains the role and use of Clients and shows you how to configure your Python Client code to connect to the Temporal Service.

The pages shows how to do the following:

- [Connect to a local development Temporal Service](#connect-to-development-service)
- [Connect to Temporal Cloud](#connect-to-temporal-cloud)
- [Start a Workflow Execution](#start-workflow-execution)

## Connect to development Temporal Service {#connect-to-development-service}

**How to connect to the local Temporal CLI development Temporal Service using the Python SDK**

A [Temporal Client](/encyclopedia/temporal-sdks#temporal-client) enables you to communicate with the [Temporal Service](/clusters).
Communication with a Temporal Service includes, but isn't limited to, the following:

- Starting Workflow Executions.
- Sending Signals to Workflow Executions.
- Sending Queries to Workflow Executions.
- Getting the results of a Workflow Execution.
- Providing an Activity Task Token.

:::caution

A Temporal Client cannot be initialized and used inside a Workflow.
However, it is acceptable and common to use a Temporal Client inside an Activity to communicate with a Temporal Service.

:::

When you are running a Temporal Service locally (such as the [Temporal CLI](https://docs.temporal.io/cli/server#start-dev)), the number of connection options you must provide is minimal.
Many SDKs default to the local host or IP address and port that Temporalite and [Docker Compose](https://github.com/temporalio/docker-compose) serve (`127.0.0.1:7233`).

Use the `connect()` method on the Client class to create and connect to a Temporal Client to the Temporal Service.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

## Connect a Temporal Client to a Temporal Service {#connect-to-a-dev-cluster}

**How to connect to a Temporal Service**

A [Temporal Client](/encyclopedia/temporal-sdks#temporal-client) enables you to communicate with the [Temporal Service](/clusters).
Communication with a Temporal Service includes, but isn't limited to, the following:

- Starting Workflow Executions.
- Sending Signals to Workflow Executions.
- Sending Queries to Workflow Executions.
- Getting the results of a Workflow Execution.
- Providing an Activity Task Token.

:::caution

A Temporal Client cannot be initialized and used inside a Workflow.
However, it is acceptable and common to use a Temporal Client inside an Activity to communicate with a Temporal Service.

:::

When you are running a Temporal Service locally (such as the [Temporal CLI](https://docs.temporal.io/cli/server#start-dev)), the number of connection options you must provide is minimal.
Many SDKs default to the local host or IP address and port that Temporalite and [Docker Compose](https://github.com/temporalio/docker-compose) serve (`127.0.0.1:7233`).

Use the `connect()` method on the Client class to create and connect to a Temporal Client to the Temporal Service.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

## Connect to Temporal Cloud {#connect-to-temporal-cloud}

**How to connect to Temporal Cloud using the Python SDK**

When you connect to [Temporal Cloud](/cloud), you need to provide additional connection and client options that include the following:

- The [Temporal Cloud Namespace Id](/cloud/namespaces#temporal-cloud-namespace-id).
   A Namespace Id is made up of a Namespace name appended by your unique five- or six-digit [Temporal Cloud Account Id](/cloud/namespaces#temporal-cloud-account-id).
   You can find this Account Id in the URL of your Namespace and on the "Namespaces" page on the Temporal Cloud website.
   For example, in  `https://cloud.temporal.io/namespaces/yournamespacename.a2fx6/`, your Account Id is `a2fx6`.
   The fully qualified Namespace Id for your client with this Namespace is `yournamespacename.a2fx6`.
- The [Namespace's gRPC endpoint](/cloud/namespaces#temporal-cloud-grpc-endpoint).
  An endpoint listing is available at the [Temporal Cloud Website](https://cloud.temporal.io/namespaces) on each Namespace detail page.
  The endpoint contains the Namespace Id and port.
- mTLS CA certificate.
- mTLS private key.

For more information about managing and generating client certificates for Temporal Cloud, see [How to manage certificates in Temporal Cloud](/cloud/certificates).

For more information about configuring TLS to secure inter- and intra-network communication for a Temporal Service, see [Temporal Customization Samples](https://github.com/temporalio/samples-server).

Use the `connect()` method on the Client class to create and connect to a Temporal Client to the Temporal Service.
Then specify the [TLSConfig](https://python.temporal.io/temporalio.service.TLSConfig.html) arguments to connect to a Temporal Service with TLS enabled.
The `client_cert` must be combined with `client_private_key` to authenticate the Client.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/connect_cloud_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
from temporalio.client import Client, TLSConfig
# ...
# ...
async def main():
    with open("client-cert.pem", "rb") as f:
        client_cert = f.read()
    with open("client-private-key.pem", "rb") as f:
        client_private_key = f.read()
    client = await Client.connect(
        "your-custom-namespace.tmprl.cloud:7233",
        namespace="<your-custom-namespace>.<account-id>",
        tls=TLSConfig(
            client_cert=client_cert,
            client_private_key=client_private_key,
            # domain=domain, # TLS domain
            # server_root_ca_cert=server_root_ca_cert, # ROOT CA to validate the server cert
        ),
    )
```

## Start a Workflow Execution {#start-workflow-execution}

**How to start a Workflow Execution using the Python SDK**

[Workflow Execution](/workflows#workflow-execution) semantics rely on several parameters—that is, to start a Workflow Execution you must supply a Task Queue that will be used for the Tasks (one that a Worker is polling), the Workflow Type, language-specific contextual data, and Workflow Function parameters.

In the examples below, all Workflow Executions are started using a Temporal Client.
To spawn Workflow Executions from within another Workflow Execution, use either the [Child Workflow](/develop/python/child-workflows) or External Workflow APIs.

See the [Customize Workflow Type](/develop/python/core-application#workflow-type) section to see how to customize the name of the Workflow Type.

A request to spawn a Workflow Execution causes the Temporal Service to create the first Event ([WorkflowExecutionStarted](/references/events#workflowexecutionstarted)) in the Workflow Execution Event History.
The Temporal Service then creates the first Workflow Task, resulting in the first [WorkflowTaskScheduled](/references/events#workflowtaskscheduled) Event.

To start a Workflow Execution in Python, use either the [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) asynchronous methods in the Client.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

### Set a Workflow's Task Queue {#set-task-queue}

**How to set a Workflow's Task Queue using the Python SDK**

In most SDKs, the only Workflow Option that must be set is the name of the [Task Queue](/task-queue).

For any code to execute, a Worker Process must be running that contains a Worker Entity that is polling the same Task Queue name.

To set a Task Queue in Python, specify the `task_queue` argument when executing a Workflow with either [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) methods.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

### Set a Workflow Id {#workflow-id}

**How to set a Workflow Id using the Python SDK**

You must set a [Workflow Id](/workflows#workflow-id).

When setting a Workflow Id, we recommended mapping it to a business process or business entity identifier, such as an order identifier or customer identifier.

To set a Workflow Id in Python, specify the `id` argument when executing a Workflow with either [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) methods.

The `id` argument should be a unique identifier for the Workflow Execution.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/run_workflow_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

### Get the results of a Workflow Execution {#get-workflow-results}

**How to get the results of a Workflow Execution using the Python SDK**

If the call to start a Workflow Execution is successful, you will gain access to the Workflow Execution's Run Id.

The Workflow Id, Run Id, and Namespace may be used to uniquely identify a Workflow Execution in the system and get its result.

It's possible to both block progress on the result (synchronous execution) or get the result at some other point in time (asynchronous execution).

In the Temporal Platform, it's also acceptable to use Queries as the preferred method for accessing the state and results of Workflow Executions.

Use [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`get_workflow_handle()`](https://python.temporal.io/temporalio.client.Client.html#get_workflow_handle) to return a Workflow handle.
Then use the [`result`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#result) method to await on the result of the Workflow.

To get a handle for an existing Workflow by its Id, you can use [`get_workflow_handle()`](https://python.temporal.io/temporalio.client.Client.html#get_workflow_handle), or use [`get_workflow_handle_for()`](https://python.temporal.io/temporalio.client.Client.html#get_workflow_handle_for) for type safety.

Then use [`describe()`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#describe) to get the current status of the Workflow.
If the Workflow does not exist, this call fails.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_app/get_workflow_results_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    handle = client.get_workflow_handle(
        workflow_id="your-workflow-id",
    )
    results = await handle.result()
    print(f"Result: {results}")


if __name__ == "__main__":
    asyncio.run(main())
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/cloud-vs-self-hosted.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/cloud-vs-self-hosted.mdx</path>
  <content>
---
id: cloud-vs-self-hosted-features
title: Temporal's production deployment features
description: Transform your Temporal apps into production-ready systems by deploying Workflows, Activities, and Workers with either our managed Temporal Cloud or self-hosted service solutions.
sidebar_label: Production features
tags:
  - Temporal Service
  - Temporal Cloud
keywords:
  - temporal service deployment
  - self-host temporal service
  - temporal cloud benefits
  - production traffic management
  - high availability workflows
  - multi-tenant temporal service
  - workflow state retention
  - temporal community support
  - temporal cloud vs self-hosted
  - workflow history export
---

Transform your Temporal applications into production-ready systems by deploying your application code, Workflows, Activities, and Workers for operational use.
When your application is ready to start serving production traffic, we offer two Temporal Service options:

- **[Choose Temporal Cloud for your Temporal Service](/cloud)**
  Let us handle the Temporal Service operations so you can focus on your applications.
- **[Self-host a Temporal Service](/self-hosted-guide)**
  Deploy your own production level Temporal Service to orchestrate your durable applications.

| Feature                            | Temporal Cloud                                                            | Self-hosted                                      |
| ---------------------------------- | ------------------------------------------------------------------------- | ------------------------------------------------ |
| **Multi-tenant**                   | ✅ Up to 100 Namespaces                                                   | ✅ Unlimited Namespaces                          |
| **High availability and failover** | ✅ [Namespaces with High Availability features](/cloud/high-availability) | ✅ Global Namespaces & Multi-Cluster Replication |
| **Application state persistence**  | ✅ 30-90 day Retention                                                    | ✅ Unlimited                                     |
| **Long term state retention**      | ✅ Workflow History Export                                                | ✅ Archival                                      |
| **Community support**              | ✅ Slack, Forum                                                           | ✅ Slack, Forum                                  |
| **Paid support**                   | ✅ Prioritized responses                                                  | ✖️                                                |

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/security.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/security.mdx</path>
  <content>
---
id: security
title: Temporal Platform security
sidebar_label: Security
description: Discover general security practices of Temporal Technologies, SaaS security with Temporal Cloud, and how to self-host a secure Temporal Platform on our security pages.
slug: /security
toc_max_heading_level: 4
keywords:
  - security
tags:
  - Security
---

:::info Temporal Technologies' general company security

For information about the general security habits of Temporal Technologies, see our [trust page](https://trust.temporal.io).

:::

:::info Temporal Cloud (SaaS) security

For information about the security features of our SaaS offering, Temporal Cloud, see our [Cloud security page](/cloud/security).

:::

:::info Self-hosted security

For information about how to self-host a secure Temporal Platform, see the [Self-hosted security page](/self-hosted-guide/security).

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/why-temporal.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/why-temporal.mdx</path>
  <content>
---
id: why-temporal
title: Why Temporal?
sidebar_label: Why Temporal
description: Temporal enhances Workflow reliability, productivity, and state visibility for developers by offering Durable Execution, simplified code structures, and robust monitoring tools.
toc_max_heading_level: 4
keywords:
  - temporal
  - evaluate-temporal
  - why-temporal
tags:
  - Temporal
  - Durable Execution
---

# Why Temporal?

Temporal solves many problems that developers face while building distributed applications.
But most of them revolve around these three themes:

- Reliable distributed applications
- Productive development paradigms and code structure
- Visible distributed application state

:::tip See Temporal in action
Watch the following video to see how Temporal ensures an order-fulfillment system can recover from various failures, from process crashes to unreachable APIs.

<div style={{ display: 'flex', justifyContent: 'center' }}>
    <iframe width="560" height="315"
        src="https://www.youtube.com/embed/dNVmRfWsNkM?si=cfwAJgr2zaoro97P"
        title="YouTube video player"
        frameborder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
</div>
:::

## Reliable execution

**How does Temporal make applications reliable?**

Temporal makes it easier for developers to build and operate reliable, scalable applications without sacrificing productivity.
The design of the system ensures that, once started, an application's main function executes to completion, whether that takes minutes, hours, days, weeks, or even years.
Temporal calls this _Durable Execution._

## Code structure

**How does Temporal simplify application code for software developers?**

By shifting the burden of failure handling from the application to the platform, there is less code for application developers to write, test, and maintain.
Temporal's programming model offers developers a way to express their business logic into coherent _Workflows_ that are much easier to develop than distributed code bases.

Choose the SDK that best suits your preferred programming language and start writing your business logic.
Integrate your favorite IDE, libraries, and tools into your development process.
Temporal also supports polyglot and idiomatic programming - which enables developers to leverage the strengths of various programming languages and integrate Temporal into existing codebases.
Developers achieve all of this without having to manage queues or complex state machines.

## State visibility

**How does Temporal make it easier to view the state of the application?**

Temporal provides out-of-the-box tooling that enables developers to see the state of their applications whenever they need to.
The Temporal CLI allows developers to manage, monitor, and debug Temporal applications effectively.
The browser-based Web UI lets you to quickly isolate, debug, and resolve production problems.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/application-message-passing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/application-message-passing.mdx</path>
  <content>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/index.mdx</path>
  <content>
---
id: index
title: Introduction to Temporal Cloud
sidebar_label: Introduction
description: Discover Temporal Cloud with an overview of its Security, Service Availability, Defaults, Limits, Configurable Settings, SLA, Pricing, and Support. Learn more today!
slug: /cloud/introduction
toc_max_heading_level: 4
keywords:
  - Introduction
  - Temporal Cloud
tags:
  - Temporal Cloud
---

In this introduction to Temporal Cloud you'll find the following information:

- [Overview of Temporal Cloud](/cloud/overview)
- [Security](/cloud/security)
- [Service availability](/cloud/service-availability)
- [Defaults, limits, and configurable settings](/cloud/limits)
- [SLA](/cloud/sla)
- [Pricing](/cloud/pricing)
- [Support](/cloud/support)

[Temporal Cloud](https://temporal.io/cloud) serves as a software as a service (SaaS) infrastructure platform, specifically designed to manage the durability of your Temporal Applications.

Temporal Cloud offers developers a hassle-free way to leverage the power of Temporal without the operational overhead. Here's what you get:

- Scalability: Start small and grow seamlessly. Handles anything from modest workloads to 100B+ actions/month.
- Reliability: 99.99% uptime guarantee, with automatic updates and maintenance.
- Security: Built-in encryption and compliance (SOC2, HIPAA), saving you time on security implementations.
- Cost-effective: Often more economical than self-hosting, especially when factoring in operational costs.
- Expertise on tap: Built and supported by Temporal's core team, ensuring you're always running an optimized setup.
- Focus on development: Spend your time building Workflows, not managing infrastructure.

**Importantly, it does not execute your code directly.** Users of Temporal Cloud must have their own environment to run Temporal Applications.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/task-queue.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/task-queue.mdx</path>
  <content>
---
id: task-queue
title: Temporal CLI task-queue command reference
sidebar_label: task-queue
description: Temporal Task Queue commands facilitate operations like describing poller info, displaying partitions, fetching compatible Build IDs, and determining Build ID reachability for effective Workflow and Activity management.
toc_max_heading_level: 4
keywords:
  - cli reference
  - command-line-interface-cli
  - list partitions
  - task queue
  - task queue describe
  - temporal cli
tags:
  - Temporal CLI
---

Task Queue commands allow operations to be performed on [Task Queues](/task-queue).
To run a Task Queue command, run `temporal task-queue [command] [command options]`

## describe

The `temporal task-queue describe` command provides [poller](/develop/worker-performance#poller-count) information for a given [Task Queue](/task-queue).

The [Server](/clusters#temporal-server) records the last time of each poll request.
A `LastAccessTime` value in excess of one minute can indicate the Worker is at capacity (all Workflow and Activity slots are full) or that the Worker has shut down.
[Workers](/workers#worker) are removed if 5 minutes have passed since the last poll request.

Information about the Task Queue can be returned to troubleshoot server issues.

`temporal task-queue describe --task-queue=MyTaskQueue --task-queue-type="activity"`

Use the following options to change the behavior of this command.

- [--fields](/cli/cmd-options#fields)
- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--task-queue](/cli/cmd-options#task-queue)

- [--task-queue-type](/cli/cmd-options#task-queue-type)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## list-partition

The `temporal task-queue list-partition` command displays the partitions of a [Task Queue](/task-queue), along with the matching node they are assigned to.

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--task-queue](/cli/cmd-options#task-queue)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## get-build-ids

Fetch the sets of compatible build IDs associated with a Task Queue and associated information.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--max-sets](/cli/cmd-options#max-sets)

- [--namespace](/cli/cmd-options#namespace)

- [--task-queue](/cli/cmd-options#task-queue)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## get-build-id-reachability

Determines whether Build IDs can be used for new, existing, or closed Workflows.
Both the `--build-id` and `--task-queue` options can be specified multiple times.
If a Task Queue isn't provided, reachability for the provided Build IDs is checked against all Task Queues.

- [--address](/cli/cmd-options#address)

- [--build-id](/cli/cmd-options#build-id)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--reachability-type](/cli/cmd-options#reachability-type)

- [--task-queue](/cli/cmd-options#task-queue)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## update-build-ids

Provides various commands for adding or changing the sets of compatible build IDs associated with a Task Queue.
See the help text provided for each sub-command for more.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workflows.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workflows.mdx</path>
  <content>
---
id: workflows
title: What is a Temporal Workflow?
sidebar_label: Workflows
description: This comprehensive guide provides insights into Temporal Workflows, covering Workflow Definitions in various programming languages, deterministic constraints, handling code changes, and ensuring reliability, durability, and scalability in a Temporal Application, with examples and best practices for Workflow Versioning and development.
slug: /workflows
toc_max_heading_level: 4
keywords:
  - child-workflow
  - child-workflow-executions
  - continue-as-new
  - delay-workflow
  - queries
  - resets
  - signals
  - timeouts
  - updates
tags:
  - Concepts
  - Workflows

---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';

This guide provides a comprehensive overview of Temporal Workflows.

A Temporal Workflow defines the overall flow of the application.
Conceptually, a Workflow is a sequence of steps written in a general-purpose programming language.
With Temporal, those steps are defined by writing code, known as a Workflow Definition, and are carried out by running that code, which results in a Workflow Execution.

In day-to-day conversations, the term _Workflow_ might refer to [Workflow Type](#workflow-type), a [Workflow Definition](#workflow-definition), or a [Workflow Execution](#workflow-execution).
Temporal documentation aims to be explicit and differentiate between them.

## What is a Workflow Definition? {#workflow-definition}

A Workflow Definition is the code that defines the Workflow.
It is written with a programming language and corresponding Temporal SDK.
Depending on the programming language, it's typically implemented as a function or an object method and encompasses the end-to-end series of steps of a Temporal application.

Below are different ways to develop a basic Workflow Definition.

<Tabs groupId="basic-workflow-definition" queryString>
<TabItem value="go" label="Go">

**[Workflow Definition in Go](/develop/go/core-application#develop-workflows)**

```go
func YourBasicWorkflow(ctx workflow.Context) error {
    // ...
    return nil
}
```

</TabItem>
<TabItem value="java" label="Java">

**[Workflow Definition in Java (Interface)](/develop/java/core-application#develop-workflows)**

```java
// Workflow interface
@WorkflowInterface
public interface YourBasicWorkflow {

    @WorkflowMethod
    String workflowMethod(Arguments args);
}
```

**[Workflow Definition in Java (Implementation)](/develop/java/core-application#develop-workflows)**

```java
// Workflow implementation
public class YourBasicWorkflowImpl implements YourBasicWorkflow {
    // ...
}
```

</TabItem>
<TabItem value="php" label="PHP">

**[Workflow Definition in PHP (Interface)](/develop/php/core-application#develop-workflows)**

```php
#[WorkflowInterface]
interface YourBasicWorkflow {
    #[WorkflowMethod]
    public function workflowMethod(Arguments args);
}
```

**[Workflow Definition in PHP (Implementation)](/develop/php/core-application#develop-workflows)**

```php
class YourBasicWorkflowImpl implements YourBasicWorkflow {
    // ...
}
```

</TabItem>
<TabItem value="python" label="Python">

**[Workflow Definition in Python](/develop/python/core-application#develop-workflows)**

```Python
@workflow.defn
class YourWorkflow:
    @workflow.run
    async def YourBasicWorkflow(self, input: str) -> str:
        # ...
```

</TabItem>
<TabItem value="typescript" label="Typescript">

**[Workflow Definition in Typescript](/develop/typescript/core-application#develop-workflows)**

```Typescript
type BasicWorkflowArgs = {
  param: string;
};

export async function WorkflowExample(
  args: BasicWorkflowArgs,
): Promise<{ result: string }> {
  // ...
}
```

</TabItem>
<TabItem value="dotnet" label=".NET">

**[Workflow Definition in C# and .NET](/develop/dotnet/core-application#develop-workflow)**

```csharp
[Workflow]
public class YourBasicWorkflow {

    [WorkflowRun]
    public async Task<string> workflowExample(string param) {
        // ...
    }
}
```

</TabItem>

</Tabs>

A Workflow Definition may be also referred to as a Workflow Function.
In Temporal's documentation, a Workflow Definition refers to the source for the instance of a Workflow Execution, while a Workflow Function refers to the source for the instance of a Workflow Function Execution.

A Workflow Execution effectively executes once to completion, while a Workflow Function Execution occurs many times during the life of a Workflow Execution.

We strongly recommend that you write a Workflow Definition in a language that has a corresponding Temporal SDK.

### Deterministic constraints

A critical aspect of developing Workflow Definitions is ensuring they exhibit certain deterministic traits – that is, making sure that the same Commands are emitted in the same sequence, whenever a corresponding Workflow Function Execution (instance of the Function Definition) is re-executed.

The execution semantics of a Workflow Execution include the re-execution of a Workflow Function, which is called a [Replay](#replays).
The use of Workflow APIs in the function is what generates [Commands](#command).
Commands tell the Temporal Service which Events to create and add to the Workflow Execution's [Event History](#event-history).
When a Workflow Function executes, the Commands that are emitted are compared with the existing Event History.
If a corresponding Event already exists within the Event History that maps to the generation of that Command in the same sequence, and some specific metadata of that Command matches with some specific metadata of the Event, then the Function Execution progresses.

For example, using an SDK's "Execute Activity" API generates the [ScheduleActivityTask](/references/commands#scheduleactivitytask) Command.
When this API is called upon re-execution, that Command is compared with the Event that is in the same location within the sequence.
The Event in the sequence must be an [ActivityTaskScheduled](/references/events#activitytaskscheduled) Event, where the Activity name is the same as what is in the Command.

If a generated Command doesn't match what it needs to in the existing Event History, then the Workflow Execution returns a _non-deterministic_ error.

The following are the two reasons why a Command might be generated out of sequence or the wrong Command might be generated altogether:

1. Code changes are made to a Workflow Definition that is in use by a running Workflow Execution.
2. There is intrinsic non-deterministic logic (such as inline random branching).

### Code changes can cause non-deterministic behavior {#non-deterministic-change}

The Workflow Definition can change in very limited ways once there is a Workflow Execution depending on it.
To alleviate non-deterministic issues that arise from code changes, we recommend using [Workflow Versioning](#workflow-versioning).

For example, let's say we have a Workflow Definition that defines the following sequence:

1. Start and wait on a Timer/sleep.
2. Spawn and wait on an Activity Execution.
3. Complete.

We start a Worker and spawn a Workflow Execution that uses that Workflow Definition.
The Worker would emit the [StartTimer](/references/commands#starttimer) Command and the Workflow Execution would become suspended.

Before the Timer is up, we change the Workflow Definition to the following sequence:

1. Spawn and wait on an Activity Execution.
2. Start and wait on a Timer/sleep.
3. Complete.

When the Timer fires, the next Workflow Task will cause the Workflow Function to re-execute.
The first Command the Worker sees would be ScheduleActivityTask Command, which wouldn't match up to the expected [TimerStarted](/references/events#timerstarted) Event.

The Workflow Execution would fail and return a nondeterminism error.

The following are examples of minor changes that would not result in non-determinism errors when re-executing a History which already contain the Events:

- Changing the duration of a Timer, with the following exceptions:
  - In Java, Python, and Go, changing a Timer's duration from or to 0 is a non-deterministic behavior.
  - In .NET, changing a Timer's duration from or to -1 (which means "infinite") is a non-deterministic behavior.
- Changing the arguments to:
  - The Activity Options in a call to spawn an Activity Execution (local or nonlocal).
  - The Child Workflow Options in a call to spawn a Child Workflow Execution.
  - Call to Signal an External Workflow Execution.
- Adding a Signal Handler for a Signal Type that has not been sent to this Workflow Execution.

### Intrinsic non-deterministic logic

Intrinsic non-determinism is when a Workflow Function Execution might emit a different sequence of Commands on re-execution, regardless of whether all the input parameters are the same.

For example, a Workflow Definition can not have inline logic that branches (emits a different Command sequence) based off a local time setting or a random number.
In the representative pseudocode below, the `local_clock()` function returns the local time, rather than Temporal-defined time:

```text
fn your_workflow() {
  if local_clock().is_before("12pm") {
    await workflow.sleep(duration_until("12pm"))
  } else {
    await your_afternoon_activity()
  }
}
```

Each Temporal SDK offers APIs that enable Workflow Definitions to have logic that gets and uses time, random numbers, and data from unreliable resources.
When those APIs are used, the results are stored as part of the Event History, which means that a re-executed Workflow Function will issue the same sequence of Commands, even if there is branching involved.

In other words, all operations that do not purely mutate the Workflow Execution's state should occur through a Temporal SDK API.

### Versioning Workflow code {#workflow-versioning}

The Temporal Platform requires that Workflow code (Workflow Definitions) be deterministic in nature.
This requirement means that developers should consider how they plan to handle changes to Workflow code over time.

A versioning strategy is even more important if your Workflow Executions live long enough that a Worker must be able to execute multiple versions of the same Workflow Type.

Apart from the ability to create new Task Queues for Workflow Types with the same name, the Temporal Platform provides Workflow Patching APIs and Worker Build Id–based versioning features.

#### Patching

Patching APIs enable the creation of logical branching inside a Workflow Definition based on a developer-specified version identifier.
This feature is useful for Workflow Definition logic that needs to be updated but still has running Workflow Executions that depend on it.

- [How to patch Workflow code in Go](/develop/go/versioning#patching)
- [How to patch Workflow code in Java](/develop/java/versioning#patching)
- [How to patch Workflow code in Python](/develop/python/versioning#python-sdk-patching-api)
- [How to patch Workflow code in PHP](/develop/php/versioning#php-sdk-patching-api)
- [How to patch Workflow code in TypeScript](/develop/typescript/versioning#patching)
- [How to patch Workflow code in .NET](/develop/dotnet/versioning#dotnet-sdk-patching-api)

You can also use [Worker Versioning](/worker-versioning) instead of Patching.

### Handling unreliable Worker Processes

You do not handle Worker Process failure or restarts in a Workflow Definition.

Workflow Function Executions are completely oblivious to the Worker Process in terms of failures or downtime.
The Temporal Platform ensures that the state of a Workflow Execution is recovered and progress resumes if there is an outage of either Worker Processes or the Temporal Service itself.
The only reason a Workflow Execution might fail is due to the code throwing an error or exception, not because of underlying infrastructure outages.

### What is a Workflow Type? {#workflow-type}

A Workflow Type is a name that maps to a Workflow Definition.

- A single Workflow Type can be instantiated as multiple Workflow Executions.
- A Workflow Type is scoped by a Task Queue.
  It is acceptable to have the same Workflow Type name map to different Workflow Definitions if they are using completely different Workers.

<PrettyImage src="/diagrams/workflow-type-cardinality.svg" title="Workflow Type cardinality with Workflow Definitions and Workflow Executions" />

## What is a Workflow Execution? {#workflow-execution}

While the Workflow Definition is the code that defines the Workflow, the Workflow Execution is created by executing that code.
A Temporal Workflow Execution is a durable, reliable, and scalable function execution.
It is the main unit of execution of a [Temporal Application](/temporal#temporal-application).

- [How to start a Workflow Execution using temporal](/cli/workflow#start)
- [How to start a Workflow Execution using the Go SDK](/develop/go/temporal-clients#start-workflow-execution)
- [How to start a Workflow Execution using the Java SDK](/develop/java/temporal-clients#start-workflow-execution)
- [How to start a Workflow Execution using the PHP SDK](/develop/php/temporal-clients#start-workflow-execution)
- [How to start a Workflow Execution using the Python SDK](/develop/python/temporal-clients#start-workflow-execution)
- [How to start a Workflow Execution using the TypeScript SDK](/develop/typescript/temporal-clients#start-workflow-execution)
- [How to start a Workflow Execution using the .NET SDK](/develop/dotnet/temporal-client#start-workflow)

Each Temporal Workflow Execution has exclusive access to its local state.
It executes concurrently to all other Workflow Executions, and communicates with other Workflow Executions through [Signals](/sending-messages#sending-signals) and the environment through [Activities](/activities).
While a single Workflow Execution has limits on size and throughput, a Temporal Application can consist of millions to billions of Workflow Executions.

**Durability**

Durability is the absence of an imposed time limit.

A Workflow Execution is durable because it executes a Temporal Workflow Definition (also called a Temporal Workflow Function), your application code, effectively once and to completion—whether your code executes for seconds or years.

**Reliability**

Reliability is responsiveness in the presence of failure.

A Workflow Execution is reliable, because it is fully recoverable after a failure.
The Temporal Platform ensures the state of the Workflow Execution persists in the face of failures and outages and resumes execution from the latest state.

**Scalability**

Scalability is responsiveness in the presence of load.

A single Workflow Execution is limited in size and throughput but is scalable because it can [Continue-As-New](#continue-as-new) in response to load.
A Temporal Application is scalable because the Temporal Platform is capable of supporting millions to billions of Workflow Executions executing concurrently, which is realized by the design and nature of the [Temporal Service](/clusters) and [Worker Processes](/workers#worker-process).

### Replays

A Replay is the method by which a Workflow Execution resumes making progress. During a Replay the Commands that are generated are checked against an existing Event History. Replays are necessary and often happen to give the effect that Workflow Executions are resumable, reliable, and durable.

For more information, see [Deterministic constraints](#deterministic-constraints).

If a failure occurs, the Workflow Execution picks up where the last recorded event occurred in the Event History.

- [How to use Replay APIs using the Go SDK](/develop/go/testing-suite#replay)
- [How to use Replay APIs using the Java SDK](/develop/java/testing-suite#replay)
- [How to use Replay APIs using the Python SDK](/develop/python/testing-suite#replay)
- [How to use Replay APIs using the TypeScript SDK](/develop/typescript/testing-suite#replay)
- [How to use Replay APIs using the .NET SDK](/develop/dotnet/testing-suite#replay-test)

### Commands and awaitables

A Workflow Execution does two things:

1. Issue [Commands](#command).
2. Wait on an Awaitables (often called Futures).

<PrettyImage src="/diagrams/workflow-execution-progession-simple.svg" title="Command generation and waiting" />

Commands are issued and Awaitables are provided by the use of Workflow APIs in the [Workflow Definition](#workflow-definition).

Commands are generated whenever the Workflow Function is executed.
The Worker Process supervises the Command generation and makes sure that it maps to the current Event History.
(For more information, see [Deterministic constraints](#deterministic-constraints).)
The Worker Process batches the Commands and then suspends progress to send the Commands to the Temporal Service whenever the Workflow Function reaches a place where it can no longer progress without a result from an Awaitable.

A Workflow Execution may only ever block progress on an Awaitable that is provided through a Temporal SDK API.
Awaitables are provided when using APIs for the following:

- Awaiting: Progress can block using explicit "Await" APIs.
- Requesting cancellation of another Workflow Execution: Progress can block on confirmation that the other Workflow Execution is cancelled.
- Sending a [Signal](/sending-messages#sending-signals): Progress can block on confirmation that the Signal sent.
- Spawning a [Child Workflow Execution](/encyclopedia/child-workflows): Progress can block on confirmation that the Child Workflow Execution started, and on the result of the Child Workflow Execution.
- Spawning an [Activity Execution](/activities#activity-execution): Progress can block on the result of the Activity Execution.
- Starting a Timer: Progress can block until the Timer fires.

### Status

A Workflow Execution can be either _Open_ or _Closed_.

<PrettyImage src="/diagrams/workflow-execution-statuses.svg" title="Workflow Execution statuses" />

#### Open

An _Open_ status means that the Workflow Execution is able to make progress.

- Running: The only Open status for a Workflow Execution.
  When the Workflow Execution is Running, it is either actively progressing or is waiting on something.

#### Closed

A _Closed_ status means that the Workflow Execution cannot make further progress because of one of the following reasons:

- Cancelled: The Workflow Execution successfully handled a cancellation request.
- Completed: The Workflow Execution has completed successfully.
- Continued-As-New: The Workflow Execution [Continued-As-New](#continue-as-new).
- Failed: The Workflow Execution returned an error and failed.
- Terminated: The Workflow Execution was terminated.
- Timed Out: The Workflow Execution reached a timeout limit.

### Workflow Execution Chain

A Workflow Execution Chain is a sequence of Workflow Executions that share the same Workflow Id.
Each link in the Chain is often called a Workflow Run.
Each Workflow Run in the sequence is connected by one of the following:

- [Continue-As-New](#continue-as-new)
- [Retries](/encyclopedia/retry-policies)
- [Temporal Cron Job](#temporal-cron-job)

A Workflow Execution is uniquely identified by its [Namespace](/namespaces), [Workflow Id](#workflow-id), and [Run Id](#run-id).

The [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) applies to a Workflow Execution Chain.
The [Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout) applies to a single Workflow Execution (Workflow Run).

### Event loop

A Workflow Execution is made up of a sequence of [Events](#event) called an [Event History](#event-history).
Events are created by the Temporal Service in response to either Commands or actions requested by a Temporal Client (such as a request to spawn a Workflow Execution).

<PrettyImage src="/diagrams/workflow-execution-swim-lane-01.svg" title="Workflow Execution" />

### Time constraints

**Is there a limit to how long Workflows can run?**

No, there is no time constraint on how long a Workflow Execution can be Running.

However, Workflow Executions intended to run indefinitely should be written with some care.
The Temporal Service stores the complete Event History for the entire lifecycle of a Workflow Execution.
The Temporal Service logs a warning after 10Ki (10,240) Events and periodically logs additional warnings as new Events are added.
If the Event History exceeds 50Ki (51,200) Events, the Workflow Execution is terminated.

To prevent _runaway_ Workflow Executions, you can use the Workflow Execution Timeout, the Workflow Run Timeout, or both.
A Workflow Execution Timeout can be used to limit the duration of Workflow Execution Chain, and a Workflow Run Timeout can be used to limit the duration an individual Workflow Execution (Run).

You can use the [Continue-As-New](#continue-as-new) feature to close the current Workflow Execution and create a new Workflow Execution in a single atomic operation.
The Workflow Execution spawned from Continue-As-New has the same Workflow Id, a new Run Id, and a fresh Event History and is passed all the appropriate parameters.
For example, it may be reasonable to use Continue-As-New once per day for a long-running Workflow Execution that is generating a large Event History.

### Limits

There is no limit to the number of concurrent Workflow Executions, albeit you must abide by the Workflow Execution's Event History limit.

:::caution

As a precautionary measure, the Workflow Execution's Event History is limited to [51,200 Events](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L382) or [50 MB](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L380) and will warn you after 10,240 Events or 10 MB.

:::

There is also a limit to the number of certain types of incomplete operations.

Each in-progress Activity generates a metadata entry in the Workflow Execution's mutable state.
Too many entries in a single Workflow Execution's mutable state causes unstable persistence.
To protect the system, Temporal enforces a maximum number of incomplete Activities, Child Workflows, Signals, or Cancellation requests per Workflow Execution (by default, 2,000 for each type of operation).
Once the limit is reached for a type of operation, if the Workflow Execution attempts to start another operation of that type (by producing a `ScheduleActivityTask`, `StartChildWorkflowExecution`, `SignalExternalWorkflowExecution`, or `RequestCancelExternalWorkflowExecution` Command), it will be unable to (the Workflow Task Execution will fail and get retried).

These limits are set with the following [dynamic configuration keys](https://github.com/temporalio/temporal/blob/main/service/history/configs/config.go):

- `NumPendingActivitiesLimit`
- `NumPendingChildExecutionsLimit`
- `NumPendingSignalsLimit`
- `NumPendingCancelRequestsLimit`

#### Workflow Execution Nexus Operation Limits {#workflow-execution-nexus-operation-limits}

There is a limit to the maximum number of Nexus Operations in a Workflow before Continue-As-New is required.
Each in-progress Nexus Operation generates a metadata entry in the Workflow Execution's mutable state.
Too many entries in a single Workflow Execution's mutable state causes unstable persistence.
To protect the system, Temporal enforces a maximum number of incomplete Nexus Operation requests per Workflow Execution (by default, 30 Nexus Operations).
Once the limit is reached for a type of operation, if the Workflow Execution attempts to start another Nexus operation (by producing a ScheduleNexusOperation), it will be unable to do so (the Workflow Task Execution will fail and get retried).

These limits are set with the following [dynamic configuration keys](https://github.com/temporalio/temporal/blob/de7c8879e103be666a7b067cc1b247f0ac63c25c/components/nexusoperations/config.go#L38):

- MaxConcurrentOperations

### What is a Command? {#command}

A Command is a requested action issued by a [Worker](/workers#worker) to the [Temporal Service](/clusters) after a [Workflow Task Execution](/tasks#workflow-task-execution) completes.

The action that the Temporal Service takes is recorded in the [Workflow Execution's](#workflow-execution) [Event History](#event-history) as an [Event](#event).
The Workflow Execution can await on some of the Events that come as a result from some of the Commands.

Commands are generated by the use of Workflow APIs in your code. During a Workflow Task Execution there may be several Commands that are generated.
The Commands are batched and sent to the Temporal Service as part of the Workflow Task Execution completion request, after the Workflow Task has progressed as far as it can with the Workflow function.
There will always be [WorkflowTaskStarted](/references/events#workflowtaskstarted) and [WorkflowTaskCompleted](/references/events#workflowtaskcompleted) Events in the Event History when there is a Workflow Task Execution completion request.

<PrettyImage src="/diagrams/commands.svg" title="Commands are generated by the use of Workflow APIs in your code" />

Commands are described in the [Command reference](/references/commands) and are defined in the [Temporal gRPC API](https://github.com/temporalio/api/blob/master/temporal/api/command/v1/message.proto).

### What is an Event? {#event}

Events are created by the Temporal Service in response to external occurrences and Commands generated by a Workflow Execution. Each Event corresponds to an `enum` that is defined in the [Server API](https://github.com/temporalio/api/blob/master/temporal/api/enums/v1/event_type.proto).

All Events are recorded in the [Event History](#event-history).

A list of all possible Events that could appear in a Workflow Execution Event History is provided in the [Event reference](/references/events).

#### Activity Events

Seven Activity-related Events are added to Event History at various points in an Activity Execution:

- After a [Workflow Task Execution](/tasks#activity-task-execution) reaches a line of code that starts/executes an Activity, the Worker sends the Activity Type and arguments to the Temporal Service, and the Temporal Service adds an [ActivityTaskScheduled](/references/events#activitytaskscheduled) Event to Event History.
- When `ActivityTaskScheduled` is added to History, the Temporal Service adds a corresponding Activity Task to the Task Queue.
- A Worker polling that Task Queue picks up the Activity Task and runs the Activity function or method.
- If the Activity function returns, the Worker reports completion to the Temporal Service, and the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskCompleted](/references/events#activitytaskcompleted) to Event History.
- If the Activity function throws a [non-retryable Failure](/references/failures#non-retryable), the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskFailed](/references/events#activitytaskfailed) to Event History.
- If the Activity function throws an error or retryable Failure, the Temporal Service schedules an Activity Task retry to be added to the Task Queue (unless you’ve reached the Maximum Attempts value of the [Retry Policy](/encyclopedia/retry-policies), in which case the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskFailed](/references/events#activitytaskfailed) to Event History).
- If the Activity’s [Start-to-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) passes before the Activity function returns or throws, the Temporal Service schedules a retry.
- If the Activity’s [Schedule-to-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout) passes before Activity Execution is complete, or if [Schedule-to-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout) passes before a Worker gets the Activity Task, the Temporal Service writes [ActivityTaskTimedOut](/references/events#activitytasktimedout) to Event History.
- If the Activity is [canceled](/activities#cancellation), the Temporal Service writes [ActivityTaskCancelRequested](/references/events#activitytaskcancelrequested) to Event History, and if the Activity accepts cancellation, the Temporal Service writes [ActivityTaskCanceled](/references/events#activitytaskcanceled).

:::note

While the Activity is running and retrying, [ActivityTaskScheduled](/references/events#activitytaskscheduled) is the only Activity-related Event in History: [ActivityTaskStarted](/references/events#activitytaskstarted) is written along with a terminal Event like [ActivityTaskCompleted](/references/events#activitytaskcompleted) or [ActivityTaskFailed](/references/events#activitytaskfailed).

:::

### What is an Event History? {#event-history}

An append-only log of [Events](#event) for your application.

- Event History is durably persisted by the Temporal service, enabling seamless recovery of your application state from crashes or failures.
- It also serves as an audit log for debugging.

**Event History limits**

The Temporal Service stores the complete Event History for the entire lifecycle of a Workflow Execution.

The Temporal Service logs a [warning after 10Ki (10,240) Events](/workflows#limits) and periodically logs additional warnings as new Events are added.
If the Event History exceeds 50Ki (51,200) Events, the Workflow Execution is terminated.

#### What is Continue-As-New? {#continue-as-new}

Continue-As-New is a mechanism by which the latest relevant state is passed to a new Workflow Execution, with a fresh Event History.

:::caution

As a precautionary measure, the Workflow Execution's Event History is limited to [51,200 Events](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L382) or [50 MB](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L380) and will warn you after 10,240 Events or 10 MB.

:::

To prevent a Workflow Execution Event History from exceeding this limit and failing, use Continue-As-New to start a new Workflow Execution with a fresh Event History.

All values passed to a Workflow Execution through parameters or returned through a result value are recorded into the Event History.
The Temporal Service stores the full Event History of a Workflow Execution for the duration of a Namespace's retention period.
A Workflow Execution that periodically executes many Activities has the potential of hitting the size limit.

A very large Event History can adversely affect the performance of a Workflow Execution.
For example, in the case of a Workflow Worker failure, the full Event History must be pulled from the Temporal Service and given to another Worker via a Workflow Task.
If the Event history is very large, it may take some time to load it.

The Continue-As-New feature enables developers to complete the current Workflow Execution and start a new one atomically.

The new Workflow Execution has the same Workflow Id, but a different Run Id, and has its own Event History.

In the case of [Temporal Cron Jobs](#temporal-cron-job), Continue-As-New is actually used internally for the same effect.

- [How to Continue-As-New using the Go SDK](/develop/go/continue-as-new)
- [How to Continue-As-New using the Java SDK](/develop/java/continue-as-new)
- [How to Continue-As-New using the PHP SDK](/develop/php/continue-as-new)
- [How to Continue-As-New using the Python SDK](/develop/python/continue-as-new)
- [How to Continue-As-New using the TypeScript SDK](/develop/typescript/continue-as-new)
- [How to Continue-As-New using the .NET SDK](/develop/dotnet/continue-as-new)

### What is a Reset? {#reset}

A Reset terminates a [Workflow Execution](#workflow-execution) and creates a new Workflow Execution with the same [Workflow Type](/workflows#workflow-type) and [Workflow ID](#workflow-id).
The [Event History](/workflows#event-history) is copied from the original execution up to and including the reset point.
The new execution continues from the reset point.
Signals in the original history can be optionally copied to the new history, whether they appear after the reset point or not.

### What is a Run Id? {#run-id}

A Run Id is a globally unique, platform-level identifier for a [Workflow Execution](#workflow-execution).

The current Run Id is mutable and can change during a [Workflow Retry](/encyclopedia/retry-policies). You shouldn't rely on storing the current Run Id, or using it for any logical choices, because a Workflow Retry changes the Run Id and can lead to non-determinism issues.

Temporal guarantees that only one Workflow Execution with a given [Workflow Id](#workflow-id) can be in an Open state at any given time.
But when a Workflow Execution reaches a Closed state, it is possible to have another Workflow Execution in an Open state with the same Workflow Id.
For example, a Temporal Cron Job is a chain of Workflow Executions that all have the same Workflow Id.
Each Workflow Execution within the chain is considered a _Run_.

A Run Id uniquely identifies a Workflow Execution even if it shares a Workflow Id with other Workflow Executions.

#### Which operations lead to non-determinism issues?

An operation like `ContinueAsNew`, `Retry`, `Cron`, and `Reset` creates a [Workflow Execution Chain](#workflow-execution-chain) as identified by the [`first_execution_run_id`](https://github.com/temporalio/api/blob/master/temporal/api/history/v1/message.proto).

Each operation creates a new Workflow Execution inside a chain run and saves its information as `first_execution_run_id`.
Thus, the Run Id is updated during each operation on a Workflow Execution.

- The `first_execution_run_id` is the Run Id of the first Workflow Execution in a Chain run.
- The `original_execution_run_id` is the Run Id when the `WorkflowExecutionStarted` Event occurs.

A Workflow `Reset` changes the first execution Run Id, but preserves the original execution Run Id.
For example, when a new Workflow Execution in the chain starts, it stores its Run Id in `original_execution_run_id`.
A reset doesn't change that field, but the current Run Id is updated.

:::caution

Because of this behavior, you shouldn't rely on the current Run Id in your code to make logical choices.

:::

**Learn more**

For more information, see the following link.

- [`message.proto`](https://github.com/temporalio/api/blob/master/temporal/api/history/v1/message.proto#L75-L82)

### What is a Workflow Id? {#workflow-id}

A Workflow Id is a customizable, application-level identifier for a [Workflow Execution](#workflow-execution) that is unique to an Open Workflow Execution within a [Namespace](/namespaces).

- [How to set a Workflow Id](/develop/go/temporal-clients#workflow-id)

A Workflow Id is meant to be a business-process identifier such as customer identifier or order identifier.

The Temporal Platform guarantees uniqueness of the Workflow Id within a [Namespace](/namespaces) based on the Workflow Id Reuse Policy.

A [Workflow Id Reuse Policy](#workflow-id-reuse-policy) can be used to manage whether a Workflow Id from a Closed Workflow can be re-used.

A [Workflow Id Conflict Policy](#workflow-id-conflict-policy) can be used to decide how to resolve a Workflow Id conflict with a Running Workflow.

A Workflow Execution can be uniquely identified across all Namespaces by its [Namespace](/namespaces), Workflow Id, and [Run Id](#run-id).

#### What is a Workflow Id Reuse Policy? {#workflow-id-reuse-policy}

A Workflow Id Reuse Policy determines whether a Workflow Execution is allowed to spawn with a particular Workflow Id, if that Workflow Id has been used with a previous, and now Closed, Workflow Execution.

It is not possible for a new Workflow Execution to spawn with the same Workflow Id as another Open Workflow Execution, regardless of the Workflow Id Reuse Policy.

See [Workflow Id Conflict Policy](#workflow-id-conflict-policy) for resolving a Workflow Id conflict.

The Workflow Id Reuse Policy can have one of the following values:

- **Allow Duplicate:** The Workflow Execution is allowed to exist regardless of the Closed status of a previous Workflow Execution with the same Workflow Id.
  **This is the default policy, if one is not specified.**
  Use this when it is OK to have a Workflow Execution with the same Workflow Id as a previous, but now Closed, Workflow Execution.
- **Allow Duplicate Failed Only:** The Workflow Execution is allowed to exist only if a previous Workflow Execution with the same Workflow Id does not have a Completed status.
  Use this policy when there is a need to re-execute a Failed, Timed Out, Terminated or Cancelled Workflow Execution and guarantee that the Completed Workflow Execution will not be re-executed.
- **Reject Duplicate:** The Workflow Execution cannot exist if a previous Workflow Execution has the same Workflow Id, regardless of the Closed status.
  Use this when there can only be one Workflow Execution per Workflow Id within a Namespace for the given retention period.
- **Terminate if Running:** Specifies that if a Workflow Execution with the same Workflow Id is already running, it should be terminated and a new Workflow Execution with the same Workflow Id should be started. This policy allows for only one Workflow Execution with a specific Workflow Id to be running at any given time.

The first three values (Allow Duplicate, Allow Duplicate Failed Only, and Reject Duplicate) of the Workflow Id Reuse Policy apply to Closed Workflow Executions that are retained within the Namespace.
For example, given a default Retention Period, the Temporal Service can only check the Workflow Id of the spawning Workflow Execution based on the Workflow Id Reuse Policy against the Closed Workflow Executions for the last _30 days_.

If you need to start a Workflow for a particular implementation only if it hasn't started yet, ensure that your Retention Period is long enough to check against.
If this becomes unwieldy, consider using [Workflow message passing](/encyclopedia/workflow-message-passing) instead of trying to start Workflows atomically.

The fourth value of the Workflow Id Reuse Policy, Terminate if Running, only applies to a Workflow Execution that is currently open within the Namespace.
For Terminate if Running, the Retention Period is not a consideration for this policy.

If there is an attempt to spawn a Workflow Execution with a Workflow Id Reuse Policy that won't allow it, the Server will prevent the Workflow Execution from spawning.

#### What is a Workflow Id Conflict Policy? {#workflow-id-conflict-policy}

A Workflow Id Conflict Policy determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution.
See [Workflow Id Reuse Policy](#workflow-id-reuse-policy) for managing the reuse of a Workflow Id of a Closed Workflow.

By default, this results in a `Workflow execution already started` error.

:::note

The default [StartWorkflowOptions](https://pkg.go.dev/go.temporal.io/sdk/internal#StartWorkflowOptions) behavior in the Go SDK is to not return an error when a new Workflow Execution is attempted with the same Workflow Id as an Open Workflow Execution.
Instead, it returns a WorkflowRun instance representing the current or last run of the Open Workflow Execution.

To return the `Workflow execution already started` error, set `WorkflowExecutionErrorWhenAlreadyStarted` to `true`.

:::

The Workflow Id Conflict Policy can have one of the following values:

- **Fail:** Prevents the Workflow Execution from spawning and returns a `Workflow execution already started` error.
  **This is the default policy, if one isn't specified.**
- **Use Existing:** Prevents the Workflow Execution from spawning and returns a successful response with the Open Workflow Execution's Run Id.
- **Terminate Existing:** Terminates the Open Workflow Execution then spawns the new Workflow Execution with the same Workflow Id.

### What is a Timer? {#timer}

Temporal SDKs offer Timer APIs so that Workflow Executions are deterministic in their handling of time values.

Timers in Temporal are persisted, meaning that even if your Worker or Temporal Service is down when the time period completes, as soon as your Worker and Temporal Service become available, the call that is awaiting the Timer in your Workflow code will resolve, causing execution to proceed.
Timers are reliable and efficient.
Workers consume no additional resources while waiting for a Timer to fire, so a single Worker can await millions of Timers concurrently.

- [How to set Timers in Go](/develop/go/timers)
- [How to set Timers in Java](/develop/java/timers)
- [How to set Timers in PHP](/develop/php/timers)
- [How to set Timers in Python](/develop/python/timers)
- [How to set Timers in TypeScript](/develop/typescript/timers)
- [How to set Timers in .NET](/develop/dotnet/durable-timers)

The duration of a Timer is fixed, and your Workflow might specify a value as short as one second or as long as several years.
Although it's possible to specify an extremely precise duration, such as 36 milliseconds or 15.072 minutes, your Workflows should not rely on sub-second accuracy for Timers.
We recommend that you consider the duration as a minimum time, one which will be rounded up slightly due to the latency involved with scheduling and firing the Timer.
For example, setting a Timer for 11.97 seconds is guaranteed to delay execution for at least that long, but will likely be closer to 12 seconds in practice.

### What is a Memo? {#memo}

A Memo is a non-indexed set of Workflow Execution metadata that developers supply at start time or in Workflow code and that is returned when you describe or list Workflow Executions.

The primary purpose of using a Memo is to enhance the organization and management of Workflow Executions.
Add your own metadata, such as notes or descriptions, to a Workflow Execution, which lets you annotate and categorize Workflow Executions based on developer-defined criteria.
This feature is particularly useful when dealing with numerous Workflow Executions because it facilitates the addition of context, reminders, or any other relevant information that aids in understanding or tracking the Workflow Execution.

:::note Use Memos judiciously

Memos shouldn't store data that's critical to the execution of a Workflow, for some of the following reasons:

- Unlike Workflow inputs, Memos lack type safety
- Memos are subject to eventual consistency and may not be immediately available
- Excessive reliance on Memos hides mutable state from the Workflow Execution History

:::

## What is a Dynamic Handler? {#dynamic-handler}

Temporal supports Dynamic Workflows, Activities, Signals, and Queries.

:::note

Currently, the Temporal SDKs that support Dynamic Handlers are:

- [Java](/develop/java/message-passing#dynamic-handler)
- [Python](/develop/python/message-passing#dynamic-handler)
- [.NET](/develop/dotnet/message-passing#dynamic-handler)

The Go SDK supports Dynamic Signals through the [GetUnhandledSignalNames](https://pkg.go.dev/go.temporal.io/sdk/workflow#GetUnhandledSignalNames) function.

:::

These are unnamed handlers that are invoked if no other statically defined handler with the given name exists.

Dynamic Handlers provide flexibility to handle cases where the names of Workflows, Activities, Signals, or Queries aren't known at run time.

:::caution

Dynamic Handlers should be used judiciously as a fallback mechanism rather than the primary approach.
Overusing them can lead to maintainability and debugging issues down the line.

Instead, Workflows, Activities, Signals, and Queries should be defined statically whenever possible, with clear names that indicate their purpose.
Use static definitions as the primary way of structuring your Workflows.

Reserve Dynamic Handlers for cases where the handler names are not known at compile time and need to be looked up dynamically at runtime.
They are meant to handle edge cases and act as a catch-all, not as the main way of invoking logic.

:::

## What is a Side Effect? {#side-effect}

:::note

Side Effects are included in the Go, Java, and PHP SDKs.
They are not included in other SDKs.
[Local Activities](/activities#local-activity) fit the same use case and are slightly less resource intensive.

:::

A Side Effect is a way to execute a short, non-deterministic code snippet, such as generating a UUID, that executes the provided function once and records its result into the Workflow Execution Event History.

A Side Effect does not re-execute upon replay, but instead returns the recorded result.

Do not ever have a Side Effect that could fail, because failure could result in the Side Effect function executing more than once.
If there is any chance that the code provided to the Side Effect could fail, use an Activity.

## What is a Schedule? {#schedule}

:::tip Support, stability, and dependency info

- Is [Generally Available](https://docs.temporal.io/evaluate/development-production-features/release-stages#general-availability) as of Nov 2023
- Introduced in Temporal Server version [1.17.0](https://github.com/temporalio/temporal/releases/tag/v1.17.0)
- Available in the Temporal CLI
- Available in Temporal Cloud
- Available in [Go SDK](/develop/go/schedules#schedule-a-workflow) since [v1.22.0](https://github.com/temporalio/sdk-go/releases/tag/v1.22.0)
- Available in [Java SDK](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/client/schedules/package-summary.html) since [v1.20.0](https://github.com/temporalio/sdk-java/releases/tag/v1.20.0)
- Available in [Python SDK](/develop/python/schedules#schedule-a-workflow) since [v1.1.0](https://github.com/temporalio/sdk-python/releases/tag/1.1.0)
- Available in [TypeScript SDK](https://github.com/temporalio/samples-typescript/tree/main/schedules#schedules) since [v1.5.0](https://github.com/temporalio/sdk-typescript/blob/main/CHANGELOG.md#150---2022-12-07)
- Available in [.NET SDK](https://dotnet.temporal.io/api/Temporalio.Client.Schedules.html) since [v0.1.0](https://github.com/temporalio/sdk-dotnet/releases/tag/0.1.0-alpha4)
- Available in [PHP SDK](https://php.temporal.io/classes/Temporal-Client-ScheduleClient.html) since [v2.7.0](https://github.com/temporalio/sdk-php/releases/tag/v2.7.0)
- Available in [gRPC API](https://api-docs.temporal.io/#temporal.api.workflowservice.v1.CreateScheduleRequest)

:::

A Schedule contains instructions for starting a [Workflow Execution](#workflow-execution) at specific times.
Schedules provide a more flexible and user-friendly approach than [Temporal Cron Jobs](#temporal-cron-job).

- [How to enable Schedules](#limitations)
- [How to operate Schedules using the Temporal CLI](/cli/schedule)

A Schedule has an identity and is independent of a Workflow Execution.
This differs from a Temporal Cron Job, which relies on a cron schedule as a property of the Workflow Execution.

:::info

For triggering a Workflow Execution at a specific one-time future point rather than on a recurring schedule, the [Start Delay](#delay-workflow-execution) option should be used instead of a Schedule.

:::

### Action

The Action of a Schedule is where the Workflow Execution properties are established, such as Workflow Type, Task Queue, parameters, and timeouts.

Workflow Executions started by a Schedule have the following additional properties:

- The Action's timestamp is appended to the Workflow Id.
- The `TemporalScheduledStartTime` [Search Attribute](/search-attribute) is added to the Workflow Execution.
  The value is the Action's timestamp.
- The `TemporalScheduledById` Search Attribute is added to the Workflow Execution.
  The value is the Schedule Id.

### Spec

The Schedule Spec defines when the Action should be taken.
Unless many Schedules have Actions scheduled at the same time, Actions should generally start within 1 second of the specified time.
There are two kinds of Schedule Spec:

- A simple interval, like "every 30 minutes" (aligned to start at the Unix epoch, and optionally including a phase offset).
- A calendar-based expression, similar to the "cron expressions" supported by lots of software, including the older Temporal Cron feature.

These two kinds have multiple representations, depending on the interface or SDK you're using, but they all support the same features.

In the Temporal CLI, for example, an interval is specified as a string like `45m` to mean every 45 minutes, or `6h/5h` to mean every 6 hours but at the start of the fifth hour within each period.

In the Temporal CLI, a calendar expression can be specified as either a traditional cron string with five (or six or seven) positional fields, or as JSON with named fields:

```json
{
  "year": "2022",
  "month": "Jan,Apr,Jul,Oct",
  "dayOfMonth": "1,15",
  "hour": "11-14"
}
```

The following calendar JSON fields are available:

- `year`
- `month`
- `dayOfMonth`
- `dayOfWeek`
- `hour`
- `minute`
- `second`
- `comment`

Each field can contain a comma-separated list of ranges (or the `*` wildcard), and each range can include a slash followed by a skip value.
The `hour`, `minute`, and `second` fields default to `0` while the others default to `*`, so you can describe many useful specs with only a few fields.

For `month`, names of months may be used instead of integers (case-insensitive, abbreviations permitted).
For `dayOfWeek`, day-of-week names may be used.

The `comment` field is optional and can be used to include a free-form description of the intent of the calendar spec, useful for complicated specs.

No matter which form you supply, calendar and interval specs are converted to canonical representations.
What you see when you "describe" or "list" a Schedule might not look exactly like what you entered, but it has the same meaning.

Other Spec features:

**Multiple intervals/calendar expressions:** A Spec can have combinations of multiple intervals and/or calendar expressions to define a specific Schedule.

**Time bounds:** Provide an absolute start or end time (or both) with a Spec to ensure that no actions are taken before the start time or after the end time.

**Exclusions:** A Spec can contain exclusions in the form of zero or more calendar expressions.
This can be used to express scheduling like "each Monday at noon except for holidays.
You'll have to provide your own set of exclusions and include it in each schedule; there are no pre-defined sets.
(This feature isn't currently exposed in the Temporal CLI or the Temporal Web UI.)

**Jitter:** If given, a random offset between zero and the maximum jitter is added to each Action time (but bounded by the time until the next scheduled Action).

**Time zones:** By default, calendar-based expressions are interpreted in UTC.
Temporal recommends using UTC to avoid various surprising properties of time zones.
If you don't want to use UTC, you can provide the name of a time zone.
The time zone definition is loaded on the Temporal Server Worker Service from either disk or the fallback embedded in the binary.

For more operational control, embed the contents of the time zone database file in the Schedule Spec itself.
(Note: this isn't currently exposed in the Temporal CLI or the web UI.)

### Pause

A Schedule can be Paused.
When a Schedule is Paused, the Spec has no effect.
However, you can still force manual actions by using the [temporal schedule trigger](/cli/schedule#trigger) command.

To assist communication among developers and operators, a “notes” field can be updated on pause or resume to store an explanation for the current state.

### Backfill

A Schedule can be Backfilled.
When a Schedule is Backfilled, all the Actions that would have been taken over a specified time period are taken now (in parallel if the `AllowAll` [Overlap Policy](#overlap-policy) is used; sequentially if `BufferAll` is used).
You might use this to fill in runs from a time period when the Schedule was paused due to an external condition that's now resolved, or a period before the Schedule was created.

### Limit number of Actions

A Schedule can be limited to a certain number of scheduled Actions (that is, not trigger immediately).
After that it will act as if it were paused.

### Policies

A Schedule supports a set of Policies that enable customizing behavior.

#### Overlap Policy

The Overlap Policy controls what happens when it is time to start a Workflow Execution but a previously started Workflow Execution is still running.
The following options are available:

- `Skip`: **Default**.
  Nothing happens; the Workflow Execution is not started.
- `BufferOne`: Starts the Workflow Execution as soon as the current one completes.
  The buffer is limited to one.
  If another Workflow Execution is supposed to start, but one is already in the buffer, only the one in the buffer eventually starts.
- `BufferAll`: Allows an unlimited number of Workflows to buffer.
  They are started sequentially.
- `CancelOther`: Cancels the running Workflow Execution, and then starts the new one after the old one completes cancellation.
- `TerminateOther`: Terminates the running Workflow Execution and starts the new one immediately.
- `AllowAll` Starts any number of concurrent Workflow Executions.
  With this policy (and only this policy), more than one Workflow Execution, started by the Schedule, can run simultaneously.

#### Catchup Window

The Temporal Service might be down or unavailable at the time when a Schedule should take an Action.
When it comes back up, the Catchup Window controls which missed Actions should be taken at that point.
The default is one year, meaning Actions will be taken unless over one year late.
If your Actions are more time-sensitive, you can set the Catchup Window to a smaller value (minimum ten seconds), accepting that an outage longer than the window could lead to missed Actions.
(But you can always [Backfill](#backfill).)

#### Pause-on-failure

If this policy is set, a Workflow Execution started by a Schedule that ends with a failure or timeout (but not Cancellation or Termination) causes the Schedule to automatically pause.

Note that with the `AllowAll` Overlap Policy, this pause might not apply to the next Workflow Execution, because the next Workflow Execution might have started before the failed one finished.
It applies only to Workflow Executions that were scheduled to start after the failed one finished.

### Last completion result

A Workflow started by a Schedule can obtain the completion result from the most recent successful run.
(How you do this depends on the SDK you're using.)

For overlap policies that don't allow overlap, “the most recent successful run” is straightforward to define.
For the `AllowAll` policy, it refers to the run that completed most recently, at the time that the run in question is started.
Consider the following overlapping runs:

```
time -------------------------------------------->
 A     |----------------------|
 B               |-------|
 C                          |---------------|
 D                                |--------------T
```

If D asks for the last completion result at time T, it gets the result of A.
Not B, even though B started more recently, because A completed later.
And not C, even though C completed after A, because the result for D is captured when D is started, not when it's queried.

Failures and timeouts do not affect the last completion result.

:::note

When a Schedule triggers a Workflow that completes successfully and yields a result, the result from the initial Schedule execution can be accessed by the subsequent scheduled execution through `LastCompletionResult`.

Be aware that if, during the subsequent run, the Workflow employs the [Continue-As-New](#continue-as-new) feature, `LastCompletionResult` won't be accessible for this new Workflow iteration.

It is important to note that the [status](#status) of the subsequent run is marked as `Continued-As-New` and not as `Completed`.

:::

:::caution

A scheduled Workflow Execution may complete with a result up to the maximum blob size (2 MiB by default).
However, due to internal limitations, results that are within 1 KiB of this limit cannot be passed to the next execution.
So, for example, a Workflow Execution that returns a result of size 2,096,640 bytes (which is above 2MiB - 1KiB limit)
will be allowed to compete successfully, but that value will not be available as a last completion result.
This limitation may be lifted in the future.

:::

### Last failure

A Workflow started by a Schedule can obtain the details of the failure of the most recent run that ended at the time when the Workflow in question was started. Unlike last completion result, a _successful_ run _does_ reset the last failure.

### Limitations

Internally, a Schedule is implemented as a Workflow.
If you're using Advanced Visibility (Elasticsearch), these Workflow Executions are hidden from normal views.
If you're using Standard Visibility, they are visible, though there's no need to interact with them directly.

## What is a Temporal Cron Job? {#temporal-cron-job}

:::note

We recommend using [Schedules](#schedule) instead of Cron Jobs.
Schedules were built to provide a better developer experience, including more configuration options and the ability to update or pause running Schedules.

:::

A Temporal Cron Job is the series of Workflow Executions that occur when a Cron Schedule is provided in the call to spawn a Workflow Execution.

- [How to set a Cron Schedule using the Go SDK](/develop/go/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the Java SDK](/develop/java/schedules#cron-schedule)
- [How to set a Cron Schedule using the PHP SDK](/develop/php/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the Python SDK](/develop/python/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the TypeScript SDK](/develop/typescript/schedules#temporal-cron-jobs)

<PrettyImage src="/diagrams/temporal-cron-job.svg" title="Temporal Cron Job timeline" />

A Temporal Cron Job is similar to a classic unix cron job.
Just as a unix cron job accepts a command and a schedule on which to execute that command, a Cron Schedule can be provided with the call to spawn a Workflow Execution.
If a Cron Schedule is provided, the Temporal Server will spawn an execution for the associated Workflow Type per the schedule.

Each Workflow Execution within the series is considered a Run.

- Each Run receives the same input parameters as the initial Run.
- Each Run inherits the same Workflow Options as the initial Run.

The Temporal Server spawns the first Workflow Execution in the chain of Runs immediately.
However, it calculates and applies a backoff (`firstWorkflowTaskBackoff`) so that the first Workflow Task of the Workflow Execution does not get placed into a Task Queue until the scheduled time.
After each Run Completes, Fails, or reaches the [Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout), the same thing happens: the next run will be created immediately with a new `firstWorkflowTaskBackoff` that is calculated based on the current Server time and the defined Cron Schedule.

The Temporal Server spawns the next Run only after the current Run has Completed, Failed, or has reached the Workflow Run Timeout.
This means that, if a Retry Policy has also been provided, and a Run Fails or reaches the Workflow Run Timeout, the Run will first be retried per the Retry Policy until the Run Completes or the Retry Policy has been exhausted.
If the next Run, per the Cron Schedule, is due to spawn while the current Run is still Open (including retries), the Server automatically starts the new Run after the current Run completes successfully.
The start time for this new Run and the Cron definitions are used to calculate the `firstWorkflowTaskBackoff` that is applied to the new Run.

A [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) is used to limit how long a Workflow can be executing (have an Open status), including retries and any usage of Continue As New.
The Cron Schedule runs until the Workflow Execution Timeout is reached or you terminate the Workflow.

<PrettyImage src="/diagrams/temporal-cron-job-failure-with-retry.svg" title="Temporal Cron Job Run Failure with a Retry Policy" />

### Cron Schedules

Cron Schedules are interpreted in UTC time by default.

The Cron Schedule is provided as a string and must follow one of two specifications:

**Classic specification**

This is what the "classic" specification looks like:

```
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
│ │ │ │ │
* * * * *
```

For example, `15 8 * * *` causes a Workflow Execution to spawn daily at 8:15 AM UTC.
Use the [crontab guru site](https://crontab.guru/) to test your cron expressions.

### `robfig` predefined schedules and intervals

You can also pass any of the [predefined schedules](https://pkg.go.dev/github.com/robfig/cron/v3#hdr-Predefined_schedules) or [intervals](https://pkg.go.dev/github.com/robfig/cron/v3#hdr-Intervals) described in the [`robfig/cron` documentation](https://pkg.go.dev/github.com/robfig/cron/v3).

```
| Schedules              | Description                                | Equivalent To |
| ---------------------- | ------------------------------------------ | ------------- |
| @yearly (or @annually) | Run once a year, midnight, Jan. 1st        | 0 0 1 1 *     |
| @monthly               | Run once a month, midnight, first of month | 0 0 1 * *     |
| @weekly                | Run once a week, midnight between Sat/Sun  | 0 0 * * 0     |
| @daily (or @midnight)  | Run once a day, midnight                   | 0 0 * * *     |
| @hourly                | Run once an hour, beginning of hour        | 0 * * * *     |
```

For example, "@weekly" causes a Workflow Execution to spawn once a week at midnight between Saturday and Sunday.

Intervals just take a string that can be accepted by [time.ParseDuration](http://golang.org/pkg/time/#ParseDuration).

```
@every <duration>
```

### Time zones

_This feature only applies in Temporal 1.15 and up_

You can change the time zone that a Cron Schedule is interpreted in by prefixing the specification with `CRON_TZ=America/New_York` (or your [desired time zone from tz](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)). `CRON_TZ=America/New_York 15 8 * * *` therefore spawns a Workflow Execution every day at 8:15 AM New York time, subject to caveats listed below.

Consider that using time zones in production introduces a surprising amount of complexity and failure modes!
**If at all possible, we recommend specifying Cron Schedules in UTC (the default)**.

If you need to use time zones, here are a few edge cases to keep in mind:

- **Beware Daylight Saving Time:** If a Temporal Cron Job is scheduled around the time when daylight saving time (DST) begins or ends (for example, `30 2 * * *`), **it might run zero, one, or two times in a day**! The Cron library that we use does not do any special handling of DST transitions. Avoid schedules that include times that fall within DST transition periods.
  - For example, in the US, DST begins at 2 AM. When you "fall back," the clock goes `1:59 … 1:00 … 1:01 … 1:59 … 2:00 … 2:01 AM` and any Cron jobs that fall in that 1 AM hour are fired again. The inverse happens when clocks "spring forward" for DST, and Cron jobs that fall in the 2 AM hour are skipped.
  - In other time zones like Chile and Iran, DST "spring forward" is at midnight. 11:59 PM is followed by 1 AM, which means `00:00:00` never happens.
- **Self Hosting note:** If you manage your own Temporal Service, you are responsible for ensuring that it has access to current `tzdata` files. The official Docker images are built with [tzdata](https://docs.w3cub.com/go/time/tzdata/index) installed (provided by Alpine Linux), but ultimately you should be aware of how tzdata is deployed and updated in your infrastructure.
- **Updating Temporal:** If you use the official Docker images, note that an upgrade of the Temporal Service may include an update to the tzdata files, which may change the meaning of your Cron Schedule. You should be aware of upcoming changes to the definitions of the time zones you use, particularly around daylight saving time start/end dates.
- **Absolute Time Fixed at Start:** The absolute start time of the next Run is computed and stored in the database when the previous Run completes, and is not recomputed. This means that if you have a Cron Schedule that runs very infrequently, and the definition of the time zone changes between one Run and the next, the Run might happen at the wrong time. For example, `CRON_TZ=America/Los_Angeles 0 12 11 11 *` means "noon in Los Angeles on November 11" (normally not in DST). If at some point the government makes any changes (for example, move the end of DST one week later, or stay on permanent DST year-round), the meaning of that specification changes. In that first year, the Run happens at the wrong time, because it was computed using the older definition.

### How to stop a Temporal Cron Job

A Temporal Cron Job does not stop spawning Runs until it has been Terminated or until the [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) is reached.

A Cancellation Request affects only the current Run.

Use the Workflow Id in any requests to Cancel or Terminate.

## What is a Start Delay? {#delay-workflow-execution}

:::tip Support, stability, and dependency info

- Available in the [Go SDK](https://pkg.go.dev/go.temporal.io/sdk/internal#StartWorkflowOptions.StartDelay) since [v1.25.0](https://github.com/temporalio/sdk-go/releases/tag/v1.25.0)
- Available in the [Java SDK](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/client/WorkflowOptions.Builder.html#setStartDelay(java.time.Duration)) since [v1.25.0](https://github.com/temporalio/sdk-java/releases/tag/v1.22.1)
- Available in the [Python SDK](https://python.temporal.io/temporalio.client.Client.html#start_workflow) since [v1.4.0](https://github.com/temporalio/sdk-python/releases/tag/1.4.0)
- Available in the [.NET SDK](https://dotnet.temporal.io/api/Temporalio.Client.WorkflowOptions.html#Temporalio_Client_WorkflowOptions_StartDelay) since [v1.0.0](https://github.com/temporalio/sdk-dotnet/releases/tag/1.0.0)
- Available in the [TypeScript SDK](https://typescript.temporal.io/api/interfaces/client.WorkflowOptions#startdelay) since [v1.9.0](https://github.com/temporalio/sdk-typescript/releases/tag/v1.9.0)
- Available in the [PHP SDK](https://php.temporal.io/classes/Temporal-Client-WorkflowOptions.html#property_workflowStartDelay) since [v2.7.0](https://github.com/temporalio/sdk-php/releases/tag/v2.7.0)

:::

Start Delay determines the amount of time to wait before initiating a Workflow Execution.

:::note

Start Delay Workflow Execution is incompatible with both [Schedules](#schedule) and [Cron Jobs](#temporal-cron-job).

:::

This is useful if you have a Workflow you want to schedule out in the future, but only want it to execute once: in comparison to reoccurring Workflows using Schedules.

If the Workflow receives a Signal-With-Start during the delay, it dispatches a Workflow Task and the remaining delay is bypassed.
If the Workflow receives a Signal during the delay that is not a Signal-With-Start, the Signal does not interrupt the delay, and the Workflow continues to be delayed until the delay expires or a Signal-With-Start is received.

You can delay the dispatch of the initial Workflow Execution by setting this option in the Workflow Options field of the SDK of your choice.

## What is a State Transition? {#state-transition}

A State Transition is a unit of progress made by a [Workflow Execution](#workflow-execution).
Each State Transition is recorded in a persistence store.

Some operations, such as [Activity Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat), require only one or two State Transitions each. With an Activity Heartbeat, there are two: the Activity Heartbeat and a Timer.

Most operations require multiple State Transitions.

For example, a simple Workflow with two sequential [Activity Tasks](/tasks#activity-task) (and no retries) produces 11 State Transitions: two for Workflow start, four for each Activity, and one for Workflow completion.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workflow-message-passing/sending-messages.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workflow-message-passing/sending-messages.mdx</path>
  <content>
---
id: sending-messages
title: Sending Signals, Queries, & Updates
sidebar_label: Sending Signals, Queries, & Updates
description: Signals, Queries, and Updates facilitate interactions with Workflow Executions.
slug: /sending-messages
tags:
- Concepts
- Signals
- Queries
- Updates
- Messages
keywords:
- temporal workflow signals
- temporal workflow queries
- temporal workflow updates
- temporal workflow execution
- message passing temporal
- signal-with-start temporal
- temporal query handler
- temporal signal handler
- temporal update handler
- temporal update validator
- temporal message passing
- workflow state temporal
- synchronous operation temporal
- asynchronous request temporal
- temporal service events
- temporal client methods
- temporal sdk message passing
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import {RelatedReadContainer, RelatedReadItem} from '@site/src/components/related-read/RelatedRead';

This section will help you write clients that send messages to Workflows which includes:

- [Sending Signals](#sending-signals)
- [Sending Updates](#sending-updates)
- [Sending Queries](#sending-queries)

### Sending Signals {#sending-signals}

You can send Signals from any Temporal Client, the Temporal CLI, or you can Signal one Workflow to another.

You can also Signal-With-Start to lazily initialize a Workflow while sending a Signal.

#### Send a Signal from a Temporal Client or the CLI

<RelatedReadContainer>
    <RelatedReadItem path="/cli/workflow#signal" text="Send a Signal using the Temporal CLI" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#send-signal-from-client" text="Send Signals with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-signal-from-client" text="Send Signals with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-signal-from-client" text="Send Signals with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-signal-from-client" text="Send Signals with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-signal-from-client" text="Send Signals with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-signal-from-client" text="Send Signals with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Send a Signal from one Workflow to another

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Signal-With-Start {#signal-with-start}

Signal-With-Start is a great tool for lazily initializing Workflows. When you send this operation, if there is a running Workflow Execution with the given Workflow Id, it will be Signaled. Otherwise, a new Workflow Execution starts and is immediately sent the Signal.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#signal-with-start" text="Signal-With-Start using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#signal-with-start" text="Signal-With-Start using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#signal-with-start" text="Signal-With-Start using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#signal-with-start" text="Signal-With-Start using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#signal-with-start" text="Signal-With-Start using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#signal-with-start" text="Signal-With-Start using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Sending Updates {#sending-updates}

:::tip Support, stability, and dependency info

- Available in [Go SDK](https://pkg.go.dev/go.temporal.io/sdk@v1.28.0/client#Client.UpdateWorkflow) since [v1.28.0](https://github.com/temporalio/sdk-go/releases/tag/v1.28.0)
- Available in [Java SDK](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/client/WorkflowStub.html#startUpdate(io.temporal.client.UpdateOptions,java.lang.Object...)) since [v1.25.0](https://github.com/temporalio/sdk-java/releases/tag/v1.25.0)
- Available in [Python SDK](/develop/python/message-passing#send-update-from-client) since [v1.7.0](https://github.com/temporalio/sdk-python/releases/tag/1.7.0)
- Available in [.NET SDK](https://dotnet.temporal.io/api/Temporalio.Client.WorkflowHandle.html#Temporalio_Client_WorkflowHandle_ExecuteUpdateAsync_System_String_System_Collections_Generic_IReadOnlyCollection_System_Object__Temporalio_Client_WorkflowUpdateOptions_) since [v0.1.0-beta2](https://github.com/temporalio/sdk-dotnet/releases/tag/1.3.0)
- Available in [TypeScript SDK](https://typescript.temporal.io/api/interfaces/client.WorkflowHandle#executeupdate) since [v1.11.0](https://github.com/temporalio/sdk-typescript/releases/tag/v1.11.0)
- Available in [PHP SDK](https://php.temporal.io/classes/Temporal-Client-WorkflowStubInterface.html#method_startUpdate) since [v2.11.0](https://github.com/temporalio/sdk-php/releases/tag/v2.11.0)

:::

:::note

To use the Workflow Update feature in versions prior to v1.25.0, it must be manually enabled.

Set the [frontend.enableUpdateWorkflowExecution](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) and [frontend.enableUpdateWorkflowExecutionAsyncAccepted](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) dynamic config values to `true`.

For example, with the Temporal CLI, run these commands:

```command
temporal server start-dev --dynamic-config-value frontend.enableUpdateWorkflowExecution=true
temporal server start-dev --dynamic-config-value frontend.enableUpdateWorkflowExecutionAsyncAccepted=true
```

:::

Updates can be sent from a Temporal Client or the Temporal CLI to a Workflow Execution. This call is synchronous and will call into the corresponding Update handler. If you’d rather make an asynchronous request, you should use Signals.

In most languages (except Go), you may call `executeUpdate` to complete an Update and get its result.

Alternatively, to start an Update, you may call `startUpdate` and pass in the Workflow Update Stage as an argument. You have two choices on what to await:

- Accepted - wait until the Worker is contacted, which ensures that the Update is persisted. See [Update Validators](/handling-messages#update-validators) for more information.
- Completed - wait until the handler finishes and returns a result. (This is equivalent to `executeUpdate`.)

The start call will give you a handle you can use to track the Update, determine whether it was Accepted, and ultimately get its result or an error.

If you want to send an Update to another Workflow such as a Child Workflow from within a Workflow, you should do so within an Activity and use the Temporal Client as normal.

There are limits on the total number of Updates that may occur during a Workflow Execution run, and also on the number of concurrent in-progress Updates that a Workflow Execution may have.
Use [Update Validators](/handling-messages#update-validators) and [Update IDs](/handling-messages#exactly-once-message-processing) to stay within the system limits in both [Cloud](/cloud/limits#per-workflow-execution-update-limits) and [Self-Hosted](/self-hosted-guide/defaults).

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#send-update-from-client" text="Send Updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-update-from-client" text="Send Updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-update-from-client" text="Send Updates in PHP" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-update-from-client" text="Send Updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-update-from-client" text="Send Updates in Typescript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-update-from-client" text="Send Updates in .NET" archetype="feature-guide" />
</RelatedReadContainer>

#### Update-With-Start {#update-with-start}

:::tip Stability

In [Public Preview](/evaluate/development-production-features/release-stages#public-preview) in Temporal Cloud.

Minimum Temporal Server version [Temporal Server version 1.26](https://github.com/temporalio/temporal/releases/tag/v1.26.2)

- Available in [Go SDK](https://pkg.go.dev/go.temporal.io/sdk@v1.31.0/client#Client.UpdateWithStartWorkflow) since [v1.31.0](https://github.com/temporalio/sdk-go/releases/tag/v1.31.0)
- Available in [Java SDK](https://www.javadoc.io/doc/io.temporal/temporal-sdk/1.27.0/io/temporal/client/WorkflowStub.html#startUpdateWithStart(io.temporal.client.UpdateOptions,java.lang.Object%5B%5D,java.lang.Object%5B%5D)) since [v1.27.0](https://github.com/temporalio/sdk-java/releases/tag/v1.27.0)
- Available in [Python SDK](/develop/python/message-passing#send-update-from-client) since [v1.9.0](https://github.com/temporalio/sdk-python/releases/tag/1.9.0)
- Available in [TypeScript SDK](https://typescript.temporal.io/api/interfaces/client.WorkflowHandle#executeupdate) since [v1.11.6](https://github.com/temporalio/sdk-typescript/releases/tag/v1.11.6)
- Available in [PHP SDK](https://php.temporal.io/classes/Temporal-Client-WorkflowClient.html#method_updateWithStart) since [v2.11.4](https://github.com/temporalio/sdk-php/releases/tag/v2.11.4)
- Available in [.NET SDK](https://dotnet.temporal.io/api/Temporalio.Client.WorkflowStartUpdateWithStartOptions.html) since [v1.4.0](https://github.com/temporalio/sdk-dotnet/releases/tag/1.4.0)

:::

Update-With-Start sends an Update that checks whether an already-running Workflow with that ID exists.
If it does, the Update is processed normally.
If not, it starts a new Workflow Execution with the supplied ID, and immediately processes the Update.

Update-With-Start is great for latency-sensitive use cases:

- **Lazy Initialization** -
  Instead of making separate Start Workflow and Update Workflow calls, Update-With-Start allows you to send them together in a single roundtrip.
  For example, a shopping cart can be modeled using Update-With-Start.
  Updates let you add and remove items from the cart.
  Update-With-Start lets the customer start shopping, whether the cart already exists or they've just started shopping.
  It ensures the cart, modeled by a Workflow Execution, exists before applying any Update that changes the state of items within the cart.
- **Early Return** -
  Using Update-With-Start you can begin a new Workflow Execution and synchronously receive a response, while the Workflow Execution continues to run to completion.
  For example, you might model a payment process using Update-With-Start.
  This allows you to send the payment validation results back to the client synchronously, while the transaction Workflow continues in the background.

:::caution

Unlike Signal-with-Start - Update-With-Start is _not_ atomic.
If the Update can't be delivered, for example, because there's no running Worker available, a new Workflow Execution will still start.
The SDKs will retry the Update-With-Start request, but there is no guarantee that the Update will succeed.

:::

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#update-with-start" text="Update-With-Start with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#update-with-start" text="Update-With-Start with the Java SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Sending Queries {#sending-queries}

Queries can be sent from a Temporal Client or the Temporal CLI to a Workflow Execution--even if this Workflow has Completed. This call is synchronous and will call into the corresponding Query handler.
You can also send a built-in "Stack Trace Query" for debugging.

<RelatedReadContainer>
    <RelatedReadItem path="/cli/workflow#query" text="Send a Query using the Temporal CLI" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#send-query" text="Send a Query with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-query" text="Send a Query with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-query" text="Send a Query with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-query" text="Send a Query with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-query" text="Send a Query with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-query" text="Send a Query with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Stack Trace Query {#stack-trace-query}

In many SDKs, the Temporal Client exposes a predefined `__stack_trace` Query that returns the call stack of all the threads owned by that Workflow Execution.
This is a great way to troubleshoot a Workflow Execution in production.
For example, if a Workflow Execution has been stuck at a state for longer than an expected period of time, you can send a `__stack_trace` Query to return the current call stack.
The `__stack_trace` Query name does not require special handling in your Workflow code.

:::note

Stack Trace Queries are available only for running Workflow Executions.

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/web-ui.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/web-ui.mdx</path>
  <content>
---
id: web-ui
title: Temporal Web UI
sidebar_label: Web UI
description: The Temporal Web UI offers comprehensive Workflow management, debugging tools, and metadata access.
toc_max_heading_level: 4
keywords:
  - web-ui
tags:
  - Temporal Web UI
---

import {RelatedReadContainer, RelatedReadItem} from '@site/src/components/related-read/RelatedRead';

The Temporal Web UI provides users with Workflow Execution state and metadata for debugging purposes.
It ships with every [Temporal CLI](/cli) release and [Docker Compose](https://github.com/temporalio/docker-compose) update and is available with [Temporal Cloud](/cloud).

You can configure the Temporal Web UI to work in your own environment.
See the [UI configuration reference](/references/web-ui-configuration).

Web UI open source repos:

- [temporalio/ui](https://github.com/temporalio/ui)
- [temporalio/ui-server](https://github.com/temporalio/ui-server)

The Web UI is packed with several features.

### Namespaces

All Namespaces in your self-hosted Temporal Service or Temporal Cloud account are listed under **Namespaces** in the left section of the window.
You can also switch Namespaces from the Workflows view by selecting from the Namespace switcher at the top right corner of the window.
After you select a Namespace, the Web UI shows the Recent Workflows page for that Namespace.
In Temporal Cloud, users can access only the Namespaces that they have been granted access to.
For details, see [Namespace-level permissions](/cloud/users#namespace-level-permissions).

### Recent Workflows

The main Workflows page displays a table of recent Workflow Executions.
The Web UI displays a maximum of 1,000 Workflow Executions.

Users can list Workflow Executions by any of the following:

- Status
- [Workflow ID](/workflows#workflow-id)
- [Workflow Type](/workflows#workflow-type)
- Start time
- End time
- A [List Filter](/list-filter)

For start time and end time, users can set their preferred date and time format as one of the following:

- UTC
- Local
- Relative

Select a Workflow Execution to view the Workflow Execution's History, Workers, and pending Activities.

#### History

This is a view of the [Events](/workflows#event) and Event fields within the Workflow Execution.
Approximately [40 different Events](/references/events) can appear in a Workflow Execution's Event History.

The top of the page lists the following execution metadata:

- [Workflow Type](/workflows#workflow-type)
- [Run ID](/workflows#run-id)
- Start Time and Close Time
- [Task Queue](/task-queue)
- Parent and Parent ID
- [State Transitions](/workflows#state-transition)

The Input and Results section displays the function arguments and return values for debugging purposes.
Results are not available until the Workflow finishes.

The Recent Events tab has the following views:

- Timeline: A chronological or reverse-chronological order of events with a summary.
  Clicking into an Event displays all details for that Event.
  Clicking “Expand all” displays all Event details.
  Similarly, clicking “Collapse all” collapses the table and displays only the summary.
- Compact: A logical grouping of Activities, Signals and Timers.
- JSON: The full JSON code for the workflow.

#### Download Event History

The entire Workflow Execution Event History, in JSON format, can be downloaded from this section.

#### Terminate Workflow

Workflow Executions can be Terminated directly from the UI.
A custom note can be logged from the UI when that happens.

#### Workers

Displays the Workers currently polling on the Workflow Task Queue with a count.
If no Workers are polling, an error displays.

#### Pending Activities

Displays a summary of recently active and/or pending Activity Executions.
Clicking a pending Activity directs the user to the Pending Activities tab to view details.

#### Call Stack

The screen shows the captured result from the [\_\_stack_trace](/sending-messages#stack-trace-query) Query.
The Query is performed when the tab is selected.
It works only if a Worker is running and available to return the call stack. The call stack shows each location where Workflow code is waiting.

#### Queries

Lists all Queries sent to the Workflow Execution.

### Schedules

On Temporal Cloud and self-hosted Temporal Service Web UI, the Schedules page lists all the [Schedules](/workflows#schedule) created on the selected Namespace.

Click a Schedule to see details, such as configured frequency, start and end times, and recent and upcoming runs.

:::tip Setting Schedules with Strings

Temporal Workflow Schedule Cron strings follow this format:

```
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
* * * * *
```

:::

To read more about Schedules, explore these links:

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/schedules" text="Schedules using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/schedules" text="Schedules using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/schedules" text="Schedules using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/schedules" text="Schedules using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/schedules" text="Schedules using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/schedules" text="Schedules using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Settings

On Temporal Cloud, **Settings** is visible only to Account Owner and Global Admin [roles](/cloud/users#account-level-roles).

Click **Settings** to see and manage the list of users in your account and to set up integrations such as [Observability](/cloud/metrics) and [Audit logging](/cloud/audit-logging).

On a self-hosted Temporal Service, manage your users, metrics, and logging in your [server configuration](/references/configuration).

### Archive

On a self-hosted Temporal Service, Archive shows [Archived](/clusters#archival) data of your Workflow Executions on the Namespace.

To see data in your self-hosted Temporal Service, you must have [Archival set up and configured](/self-hosted-guide/archival).

For information and details on the Archive feature in Temporal Cloud, contact your Temporal representative.

### Codec Server

The Web UI can use a [Codec Server](/codec-server) with a custom Data Converter to decode inputs and return values.
For details, see [Securing your data](/production-deployment/data-encryption).

The UI supports a [Codec Server endpoint](/production-deployment/data-encryption#web-ui).
For details on setting the Codec Server endpoint, see [Codec Server setup](/production-deployment/data-encryption#codec-server-setup).

### Labs mode

The Web UI provides a "labs" mode for users to try out upcoming, production-ready UI features and improvements.
When off, users will experience the current UI.
Features will move in and out of labs mode according to demand and feedback.
Labs mode can be turned on or off at any time in the left navigation bar via the Labs icon.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/support.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/support.mdx</path>
  <content>
---

id: support
title: Services, support, and training - Temporal Cloud
sidebar_label: Support
description: Temporal Cloud offers support, services, and training for seamless onboarding, efficient app design, and scaling. Services include technical onboarding, design/code reviews, pre-production optimization, and load tests.
slug: /cloud/support
toc_max_heading_level: 3
keywords:
- how-to
- introduction
- support
- temporal cloud
- training
tags:
- Temporal Cloud
- Support

---

Temporal Cloud includes the right level of technical support and guidance, services and training needed to onboard you successfully, assist with design and deployment of your application efficiently and at scale.
Our team has extensive knowledge of Temporal, and a broad set of skills to help you succeed with any project.

Temporal Cloud provides several levels of support, from assisting with for break/fix scenarios to issues and services to helping with onboarding, design/code reviews for your application, and pre-production optimizations and operational readiness.
note

:::note

The content of this page applies to Temporal Cloud customers only.

:::

## Services offered by Temporal Cloud {#support}

|                             | Essentials                                                                     | Business                                                                                                                                                            | Enterprise                                                                                      | Mission Critical                                                                                                                  |
| --------------------------- | ------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| Support Staff               | Trained staff providing break-fix support and general guidance.                | Trained staff providing break-fix support and general guidance.                                                                                                     | Developer experts who provide advanced support                                                  | Developer experts who provide advanced support                                                                                    |
| Technical Guidance          | Core platform config, auth-n methods, documented features, and basic inquiries | Advanced technical support, Workflow troubleshooting, SDK implementations, and Worker configuration, Quarterly code review or design implementation best practices. | Business+ expert-led code reviews and design implementation best practices, available as needed | Enterprise+ expert guidance on Workflow latency monitoring and optimization; performance recommendations based on real time tests |
| Billing & Cost Optimization | Generic Billing Questions                                                      | Generic Billing Questions                                                                                                                                           | Quarterly review of spend                                                                       | Quarterly review of spend, proactive cost optimization                                                                            |

## Temporal Cloud support guarantees {#guarantees}

Temporal endeavors to ensure you are successful with Temporal Cloud.
We offer explicit guarantees for support.
Temporal Cloud customers get break/fix support with an agreed-upon set of SLAs for prioritized issues.
We use a ticketing system for entering, tracking, and closing these issues.

If an issue occurs, the team also provides support through a dedicated Slack channel, forums, and a knowledge base.
We offer two levels of support defined by their availability and SLAs in the following table:

|                                                  | Essentials                                                                                                     | Business                                                                                                           | Enterprise                                                                                                   | Mission Critical                                                                                             |
| ------------------------------------------------ | -------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------ |
| **Availability**<br />(Based on<br />Time-zones) | **P0–3**: 9–5 Mon–Fri                                                                                          | **P0–3**: 9–5 Mon–Fri                                                                                              | **P0**: 24×7, <br />(On Page Service)<br /> **P1–3**: 9–5 Mon–Fri                                            | **P0**: 24×7 (On Page Service)<br /> **P1**: 9-5, 7 days/week<br /> **P2–3**: Mon–Fri                        |
| **Response Time**                                | **P0**: 1 business day<br /> **P1**: 1 business day<br /> **P2**: 1 business day<br /> **P3**: 2 business days | **P0**: 2 business hours<br /> **P1**: 2 business hours<br /> **P2**: 1 business day<br /> **P3**: 2 business days | **P0**: 30 minutes<br /> **P1**: 1 business hour<br /> **P2**: 4 business hours<br /> **P3**: 1 business day | **P0**: 15 minutes<br /> **P1**: 1 business hour<br /> **P2**: 4 business hours<br /> **P3**: 1 business day |
| **DSE**                                          | -                                                                                                              | -                                                                                                                  | Add-on                                                                                                       | DSE Included (1 Unit)                                                                                        |
| **Channels**                                     | Community<br/>Temporal Support Portal                                                                          | Community<br />Temporal Support Portal                                                                             | Community<br />Temporal Support Portal<br />Private Slack                                                    | Community<br />Temporal Support Portal<br />Private Slack                                                    |

:::info Business Hours Timezones

Business Hours will be specified in your contract, including one of three locations: US Pacific time, European Central time, Australia Eastern time

:::

**Priority definitions**

- **P0 - Critical** (Production impacted)
  - The Temporal Cloud service is unavailable or degraded with a significant impact.
- **P1 - High** (Production issue)
  - An issue related to production workloads running on the Temporal Cloud service, or a significant project is blocked.
- **P2 - Normal** (General issues)
  - General Temporal Cloud service or other issues where there is no production impact, or a workaround exists to mitigate the impact.
- **P3 - Low** (General guidance)
  - Questions or an issue with the Temporal Cloud service that is not impacting system availability or functionality.

:::note On Page Service

P0: 24×7 (On Page Service) is offered for Enterprise and Mission Critical accounts.

:::

For pricing details of these support levels, please visit our [pricing page](/cloud/pricing).

## Temporal Dedicated Support Engineer {#dedicated-support-engineer}

Customers on the Mission Critical Plan and (by opting in) Enterprise customers receive access to a Dedicated Support Engineer.
We offer:

- Direct access to a senior developer expert, who becomes part of your Temporal account team, adding deep technical expertise.
  - Our high-touch engagement model goes beyond traditional support to deliver transformative value through hands-on collaboration, proactive optimization, implementation design and operations.
  - Faster issue resolution with direct assistance from someone who already knows your implementation.
  - Focused advisory on best practices and development pairing to ensure high-quality code and scalability.
  - Optimizations through regular checks and recommendations to improve performance and efficiency.
- Priority access to a senior engineer for up to 20 hours per month, providing expert guidance and proactive support for one business unit or major group, specifically within a single region.

Our Services focus on local time zone alignment to ensure optimal responsiveness and efficiency.
Additional service units for this service can be purchased to cover additional groups or regions at &#36;6,000/Mo/Unit.
One unit of Mission Critical Support includes:

- Up to 20 hours per month
- One major group or business unit
- Limited to one region
- Quarterly onsite visits

## Ticketing

Temporal offers a ticketing system for Temporal Cloud customers.
We have an active [community Slack](https://temporalio.slack.com) and an active [community Discourse forum](https://community.temporal.io/) where you can post questions and ask for help.

:::info

The Temporal Support Portal is for Cloud customers only.
Other Temporal users (non-cloud) have full community access excluding the "support-cloud" channel.
All Cloud customers pay for support as part of their plan.

:::

### Create an account for Temporal Support {#support-account}

The Temporal Support Portal has a per organization setting to associate user emails based on the domain name.
For Temporal Cloud users, there is no need to manually create an account, as this included in the onboarding process.

:::info

This procedure applies only to Temporal Cloud customers whose contracts include paid support.
If you need assistance and don't have paid support, post your request in the [Temporal Community Forum](https://community.temporal.io) or the `#support-cloud` channel of the [Temporal workspace](https://t.mp/slack) in Slack.

:::

### Access Temporal Support

1. Go to [support.temporal.io](https://support.temporal.io/).
2. Log in using the company email address provided during your Temporal Cloud onboarding.
   You can log in using one of the following methods:
   1. **Google Single Sign-On (SSO)**.
      1. Select **Sign in with Google**.
      2. Select the email address associated with your company.
   2. **Email and Password**.
      1. Enter your **Email** and **Password**.
      2. Select **Sign in**.
3. You will be presented with a screen where you can submit ticket.

To request assistance from Temporal Support, see [Create a ticket](#support-ticket).

### Create a Ticket {#support-ticket}

To create a ticket for Temporal Support, you must have an [account](#support-account) with the same domain name as your Temporal Cloud account to create a ticket in the Temporal Support Portal.

:::info

This procedure applies only to Temporal Cloud customers whose contracts include paid support.
If you need assistance and don't have paid support, post your request in the [Temporal Community Forum](https://community.temporal.io) or the `#support-cloud` channel of the [Temporal workspace](https://t.mp/slack) in Slack.

:::

### Request Temporal Support assistance

To request assistance from Temporal Support, create a ticket in the Temporal Support Portal:

1. Go to [support.temporal.io](https://support.temporal.io/).
2. Use your Temporal Support credentials to sign in.
3. Choose **Create a ticket**.
4. On the **Submit a request** page, choose your issue.
   Unless your request involves one of the specific areas listed, choose **Submit a Ticket**.
5. In the form, enter the details of your request.
   **Subject** and **Description** are required.
6. If you specify **Priority** (available only on the default form), follow these guidelines:
   - Select **Normal** for most issues.
   - Select **High** only for issues to which your service-level agreement (SLA) applies.
     If you're not sure, select **Normal**.
   - Select **Page** only if you are experiencing a complete service outage and urgently need contact with an on-call support person.
7. At the bottom of the form, choose **Submit**.

## Developer resources {#developer-resources}

Temporal offers developer resources and a variety of hands-on tutorials to get you started and learn more advanced Temporal concepts.

- [Get started with Temporal](https://learn.temporal.io/getting_started): Start your journey with Temporal with this guide that helps you set up your development environment, run an existing Temporal app, and then build your first app from scratch using our SDKs.
- [Courses](https://learn.temporal.io/courses): Learn and apply Temporal concepts in our free, self-paced, hands-on courses.
- [Tutorials](https://learn.temporal.io/tutorials): Apply Temporal concepts to build real-world applications with these hands-on tutorials.
- [Example applications](https://learn.temporal.io/examples): Explore example applications that use Temporal and gain a clearer understanding of how Temporal concepts work in a complex application.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/limits.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/limits.mdx</path>
  <content>
---
id: limits
title: System limits - Temporal Cloud
sidebar_label: Limits
description: This page outlines the limits of the Temporal Cloud system for accounts, namespaces, and programming models, providing key information on user capacity, namespace creation, throughput, certificates, task pollers, retention periods, batch jobs, search attributes, visibility API rate limit, identifier length, gRPC message limits, event
slug: /cloud/limits
toc_max_heading_level: 4
keywords:
  - configuration
  - defaults
  - limits
  - settings
  - temporal cloud
tags:
  - Temporal Cloud
  - Limits
---

This page addresses the limits of the Temporal Cloud system.
Reach out to your account team should you have any questions about these limits.

These limits fall into the following three main categories:

- At the Temporal Cloud [Account level](#account-level)
- At the [Namespace level](#namespace-level)
- Within the [programming model](#programming-model-level) itself

## Account level

The following aspects apply at the Temporal Cloud Account level (per account).

### Users

**How many users can I add?**

By default, 300 users across all Namespaces.

### Namespaces

**How many namespaces can I create?​**

By default, each account is provisioned with ten Namespaces.
As you start using Namespaces by scheduling Workflows, Temporal Cloud automatically raises your allowance.
This automatic adjustment happens whenever all your Namespaces are in use, up to a maximum of 100 Namespaces.
You can request further increases beyond the 100 Namespace limit by opening a [support ticket](/cloud/support#support-ticket).

### Retained Prometheus endpoint data

**How much metrics data does the Prometheus endpoint retain?​**

The Prometheus endpoint retains 30 days of data.

### Supported operators in List Filters

**Which operators aren't supported in Temporal Cloud?**

The `ORDER BY` operator isn't supported in List Filters in Temporal Cloud.

This means that custom ordering of Workflows with Temporal Cloud Visibility isn't possible.
Lists of Workflows are still ordered by a default ordering rule, but be aware that this rule might change.

## Namespace level

The following aspects apply at the Namespace level (per Namespace).

### Throughput

**What is the limit of Actions per second?**

Each Namespace has a rate limit, which is measured in Actions per second (APS).
A Namespace may be throttled when its throughput becomes too high.
Throttling means limiting the rate at which Actions are performed to prevent the Namespace from exceeding its APS limit.

A Namespace's default limit is set at 400 APS and automatically adjusts based on recent usage (over the prior 7 days).
Your throughput limit will never fall below this default value.
You can request this limit be manually raised by opening a [support ticket](/cloud/support#support-ticket).

### Schedules rate limit

Each Namespace has a default [Schedule](/glossary#schedule) rate limit of 10 requests per second (RPS).
If too many Schedules trigger at once, they may be throttled.
Throttling limits the rate at which Schedules create new Workflow Executions, ensuring the Namespace does not exceed its RPS limit.

To avoid throttling, don't schedule all your Workflow Executions to start at the same time (daily, weekly, monthly, etc.).
Every Temporal SDK supports jittering, which adds small random delays to Schedule specifications, helping to reduce load at any specific moment.
Set the `jitter` value to the largest delay you will permit before your Workflow Execution must begin.
This approach uniformly distributes the scheduled Workflow Execution launches through that period and reduces your Schedule Workflow Execution RPS load.

If you need a higher Schedule RPS limit, open a [support ticket](/cloud/support#support-ticket).

### Certificates

**What are the certificate limits?**

Temporal Cloud limits each Namespace to a total of 32 KB or 16 certificates, whichever is reached first.

### Concurrent Task pollers

**Is there a limit to concurrent Task pollers?**

Temporal Cloud limits each Namespace to 5,000 concurrent Task pollers, regardless of whether they are Activity or Workflow Task pollers.

Each SDK offers a way to configure Workers for per-Worker maximum Activity and Workflow Task pollers.
Those values do not affect the global Namespace limit.

### Default Retention Period

**What is the default Retention Period?**

The [Retention Period](/clusters#retention-period) is set per Namespace.

Temporal Cloud sets the default Retention Period to 30 days.
This is configurable in the Temporal Web UI.

[Navigate to your list of Namespaces](https://cloud.temporal.io/namespaces), choose the Namespace you want to update, and select edit:

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Choose your Namespace and select Edit</p>
  </div>
  <div className="tdiiw" height="462">
    <img
      className="img_ev3q"
      src="/img/cloud/cloud-guide/edit-namespace-option.png"
      alt="Choose your Namespace and select Edit"
    />
  </div>
</div>

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Update the Retention Period</p>
  </div>
  <div className="tdiiw" height="482">
    <img
      className="img_ev3q"
      src="/img/cloud/cloud-guide/edit-retention-period.png"
      alt="Update the Retention Period"
    />
  </div>
</div>

You can set the Retention Period between 1 and 90 days.

### Batch jobs

**How many batch jobs can run at a time?**

A Namespace can have just one [Batch job](/cli/batch) running at a time.

Each batch job operates on a maximum of 50 Workflow Executions per second.

### Number of Custom Search Attributes

**How many custom Search Attributes are allowed per Namespace?**

There is a limit to the number of custom Search Attributes per attribute type per Namespace:

| Search Attribute type | Limit |
| --------------------- | ----- |
| Bool                  | 20    |
| Datetime              | 20    |
| Double                | 20    |
| Int                   | 20    |
| Keyword               | 40    |
| KeywordList           | 5     |
| Text                  | 5     |

### Custom Search Attribute names

**What constraints are there for Custom Search Attribute names in Temporal Cloud?**

When creating custom Search Attributes in Temporal Cloud, the attribute names must adhere to the following constraints:

- Maximum characters: 64
- Allowed characters: `[a-zA-Z0-9.,:-_\/ ]`.

For more information on custom Search Attributes see [Custom Search Attributes limits](/search-attribute#custom-search-attribute).

### Visibility API Rate Limit

**What is the rate limit for requests to the Visibility APIs?**

The rate limit for requests to the Visibility APIs varies, and may be as low as 30 requests per second.
This limit is not configurable.

### Nexus Rate Limit {#nexus-rate-limits}

Nexus requests (such as starting a Nexus Operation or sending a Nexus completion callback) are counted as part of the overall Namespace RPS limit.
If too many Nexus requests are sent at once, they may be throttled, along with other requests to the Namespace.
Throttling limits the rate at which Nexus requests are processed, ensuring the RPS limit isn't exceeded.

You can request this limit be manually raised by [opening a support ticket](https://docs.temporal.io/cloud/support#support-ticket).

:::note

For the target Namespace of a Nexus Endpoint, even though there are no Action results for handling a Nexus Operation itself, the Nexus requests on a target Namespace do count towards the overall RPS limit for the Namespace as a whole.

:::

## Nexus Endpoint level

### Nexus Endpoints limits

**How many Nexus Endpoints can you create?​**

By default, each account is provisioned with 10 Nexus Endpoints.
You can request further increases beyond the initial 10 Endpoint limit by [opening a support ticket](/cloud/support#support-ticket).

## Programming model level

The following aspects apply at the programming model level.
See also: [Self-hosted Temporal Service defaults](/self-hosted-guide/defaults).

### Identifier length limit

**What is the maximum length for identifiers?**

Identifiers, such as Workflow Id, Workflow Type, and Task Queue names, are limited to a maximum length of 1,000 bytes.
Note that Unicode characters may use multiple bytes.

### Per message gRPC limit

**What is the gRPC limit for each message received?**

Each gRPC message received has a limit of 4 MB.
This limit applies to all gRPC endpoints across the Temporal Platform.

### Event History transaction size limit

**What is the size limit for an Event History transaction?**

An Event History transaction encompasses a set of operations such as initiating a new Workflow, scheduling an Activity, processing a Signal, or starting a Child Workflow.
These operations create Events that are then logged in the Event History.
The transaction size limit restricts the total size of Events that can be accommodated within a single transaction.

The size limit for any given [Event History](/workflows#event-history) transaction is 4 MB.
This limit is non-configurable for Temporal Cloud.

**What is the blob size limit for a transaction?**

- **Blob size limit** for Payloads, including Workflow context and each Workflow and Activity argument and return value:
  - The max payload for a single request is 2 MB.
  - The max size limit for any given [Event History](/workflows#event-history) transaction is 4 MB.

This limit is non-configurable for Temporal Cloud.

The [BlobSizeLimitError guide](/troubleshooting/blob-size-limit-error) provides solutions for handling large payloads.

### Per Workflow Execution concurrency limits

**How many incomplete concurrent operations can a Workflow Execution have?**

If a Workflow Execution has 2,000 incomplete Activities, Signals, Child Workflows, or external Workflow Cancellation requests, additional [Commands](/workflows#command) of that type will fail to be applied to that Workflow Execution:

- `ScheduleActivityTask`
- `SignalExternalWorkflowExecution`
- `StartChildWorkflowExecution`
- `RequestCancelExternalWorkflowExecution`

For optimal performance, limit concurrent operations to 500 or fewer.
This reduces Workflow's Event History size and decreases the loading time in the Web UI.

### Per Workflow Execution Signal limit

**What is the limit on the total number of Signals received per Workflow Execution?**

A single Workflow Execution may receive up to 10,000 Signals.
After that limit is reached, no more Signals will be processed for that Workflow Execution.

### Per Workflow Execution Update limits

**What is the maximum number of Updates for a single Workflow Execution?**

A single Workflow Execution can have a maximum of 10 in-flight Updates and 2000 total Updates in History.

### Workflow Execution Event History limits

**What are the limits that apply to the Workflow Execution's Event History?**

As a precautionary measure, a Workflow Execution's Event History is limited to 51,200 Events or 50 MB.
It warns you after 10,240 Events or 10 MB.
This limit applies to all Temporal Workflow Executions, whether on Temporal Cloud or other deployments.
Read more about [Temporal Workflow Execution limits](/workflows#limits) on the [Temporal Workflow](/workflows) documentation page.

### Per Workflow Nexus Operation limits {#per-workflow-nexus-operation-limits}

**What is the maximum number of Nexus Operations that can be started from a single Workflow Execution?**

A single Workflow Execution can have a maximum of 30 in-flight Nexus Operations.

See the Nexus Encyclopedia entry for [additional details](/workflows#workflow-execution-nexus-operation-limits).

### Nexus Operation request timeout {#nexus-operation-request-timeout}

**What is the context deadline timeout for a Nexus handler to process a Nexus start or cancel request?**

Less than 10 seconds is the maximum duration for a Nexus handler to process a single Nexus start or cancel request.

The timeout is measured from the calling History Service and the request must go through matching, so the available time for a handler to respond is often much less than 10 seconds.
Handlers should observe the context deadline and ensure they don't exceed it.
This includes fully processing a synchronous Nexus operation and starting an asynchronous Nexus operation, for example one that starts a Workflow.

If a Nexus handler doesn’t process a start or cancel request within 10 seconds, it will receive a context deadline exceeded error, and the caller will retry, with an exponential backoff, for the ScheduleToClose duration for the overall Nexus Operation.
This has a default and maximum as defined below in [Nexus Operation duration limits](/cloud/limits#nexus-operation-duration-limits).

### Nexus Operation duration limits {#nexus-operation-duration-limits}

Each Nexus Operation has a maximum ScheduleToClose duration of 60 days.
This is most applicable to asynchronous Nexus Operations completed with an asynchronous callback using a separate Nexus request from the handler back to the caller Namespace.

For enhanced security, you may sign completion callbacks with a single-use token in the future, and the 60 day maximum allows you to rotate the asymmetric encryption keys used for completion callback request signing.

While the caller of a Nexus Operation can configure the ScheduleToClose duration to be shorter than 60 days, the maximum duration can not extend beyond 60 days and capped by the server to 60 days.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/failure-detection.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/failure-detection.mdx</path>
  <content>
---
id: failure-detection
title: Failure detection - Temporal feature
description: Explore Temporal's robust timeout and Retry Policy features for Workflows and Activities. Start with our tutorials or dive deep with our SDK guides and Encyclopedia resources.
sidebar_label: Failure detection
tags:
  - Workflows
  - Activities
  - Timeouts
  - Failures
  - Errors
keywords:
  - temporal timeouts
  - application failure detection
  - automatic failure mitigation
  - temporal retries
  - workflow timeout configuration
  - activity timeout configuration
  - temporal retry policy
  - temporal sdk tutorial
  - temporal sdk feature guide
  - go sdk workflow timeout
  - java sdk workflow timeout
  - php sdk workflow timeout
  - python sdk workflow timeout
  - typescript sdk workflow timeout
  - detecting workflow failures
  - detecting activity failures
  - temporal retry policies
  - temporal courses
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

In Temporal, timeouts detect application failures.
The system can then automatically mitigate these failures through retries.
Both major application function primitives, **Workflows** and **Activities**, have dedicated **timeout configurations** and can be configured with a **Retry Policy**.

**Follow one of our tutorials to [Get started](https://learn.temporal.io/getting_started/) exploring timeouts and Retry Policies.**

Or jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into timeouts and Retry Policies visit the following Temporal Encyclopedia pages or enroll in one of [our courses](https://learn.temporal.io/courses/).

<RelatedReadContainer>
    <RelatedReadItem path="/encyclopedia/detecting-workflow-failures" text="Detecting Workflow failures" archetype="encyclopedia" />
    <RelatedReadItem path="/encyclopedia/detecting-activity-failures" text="Detecting Activity failures" archetype="encyclopedia" />
    <RelatedReadItem path="/encyclopedia/retry-policies" text="Retry Policies" archetype="encyclopedia" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/low-latency.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/low-latency.mdx</path>
  <content>
---
id: low-latency
title: Low latency - Temporal feature
description: Discover how Temporal's design and features ensure low latency for your applications.
sidebar_label: Low latency
keywords:
  - low latency
  - temporal performance
  - temporal cloud
  - self-hosted temporal
  - workflow latency
  - temporal benchmarks
  - temporal sdk metrics
  - optimized workflow performance
  - latency-sensitive applications
  - temporal cloud advantages
tags:
  - Temporal Cloud
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal Cloud provides features that significantly reduce latency compared to self-hosted instances, making your applications faster, more performant, and more efficient.
In the world of modern applications, low latency is crucial for ensuring minimal delay in Workflow Executions.
This low-latency architecture ensures rapid Workflow Execution and responsiveness, critical for time-sensitive applications and high-performance systems.

Temporal Cloud's custom persistence layer incorporates three key components that contribute to low latency:

- **Better Sharding:** Distributes load across multiple databases, preventing bottlenecks.
  Enables independent resizing, improving scalability and handling high-traffic events without delay.
- **Write-Ahead Log (WAL):** Aggregates updates before writing to the database, reducing write latency.
  Stores writes in an append-only format, reducing latency and database size by batching updates before writing to the database.
- **Tiered Storage of Workflow Event History:** Offloads completed Workflow Event Histories, improving database efficiency.

Temporal Cloud provides lower latency, making it suitable for latency-sensitive, large-scale, or business-critical applications.

<RelatedReadContainer>
  <RelatedReadItem path="https://temporal.io/blog/exploring-temporal-cloud-automation-features" text="Exploring Temporal Cloud Automation Features" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/high-availability-and-disaster-recovery-with-temporal-cloud" text="High Availability and Disaster Recovery with Temporal Cloud" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/higher-throughput-and-lower-latency-temporal-clouds-custom-persistence-layer" text="Higher throughput and lower latency: Temporal Cloud’s custom persistence layer" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/how-to-migrate-your-self-hosted-service-to-temporal-cloud" text="How to Migrate Your Self-Hosted Service to Temporal Cloud" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/scaling-temporal-the-basics" text="Scaling your self-hosted instance" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/benchmarking-latency-temporal-cloud-vs-self-hosted-temporal" text="Benchmarking Latency: Temporal Cloud vs. Self-Hosted Temporal" archetype="blog-post" />
  <RelatedReadItem path="https://docs.temporal.io/cloud/service-availability#latency" text="Temporal Cloud’s Latency SLO" archetype="cloud-guide" />
  <RelatedReadItem path="https://www.youtube.com/watch?v=SQv9ot-jB6o&list=PLl9kRkvFJrlREHL7fiEKBWTp5QuFeYS2r&index=5" text="Replay Conference Talk: Custom Persistence Layer" archetype="replay-talk" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/activities.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/activities.mdx</path>
  <content>
---
id: activities
title: What is a Temporal Activity?
sidebar_label: Activities
description: Understand Temporal Activities, including  Activity Definitions, Types, Executions, idempotency, cancellations, and Local Activities.
slug: /activities
toc_max_heading_level: 4
keywords:
  - explanation
  - term
  - timeouts
tags:
  - Concepts
  - Activities
  - Durable Execution
---

This guide provides a comprehensive overview of Temporal Activities.

In day-to-day conversation, the term _Activity_ denotes an [Activity Definition](#activity-definition), [Activity Type](#activity-type), or [Activity Execution](#activity-execution).
Temporal documentation aims to be explicit and differentiate between them.

An Activity is a normal function or method that executes a single, well-defined action (either short or long running), such as calling another service, transcoding a media file, or sending an email message.
Activity code can be non-deterministic.
We recommend that it be [idempotent](#idempotency).

Workflow code orchestrates the execution of Activities, persisting the results.
If an Activity Function Execution fails, any future execution starts from initial state (except [Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat)).

Activity Functions are executed by Worker Processes.
When the Activity Function returns, the Worker sends the results back to the Temporal Service as part of the [ActivityTaskCompleted](/references/events#activitytaskcompleted) Event.
The Event is added to the Workflow Execution's Event History.
For other Activity-related Events, see [Activity Events](/workflows#activity-events).

## What is an Activity Definition? {#activity-definition}

An Activity Definition is the code that defines the constraints of an [Activity Task Execution](/tasks#activity-task-execution).

- [How to develop an Activity Definition using the Go SDK](/develop/go/core-application#activity-definition)
- [How to develop an Activity Definition using the Java SDK](/develop/java/core-application#develop-activities)
- [How to develop an Activity Definition using the PHP SDK](/develop/php/core-application#develop-activities)
- [How to develop an Activity Definition using the Python SDK](/develop/python/core-application#develop-activities)
- [How to develop an Activity Definition using the TypeScript SDK](/develop/typescript/core-application#develop-activities)
- [How to develop an Activity Definition using the .NET SDK](/develop/dotnet/core-application#develop-activity)

The term 'Activity Definition' is used to refer to the full set of primitives in any given language SDK that provides an access point to an Activity Function Definition——the method or function that is invoked for an [Activity Task Execution](/tasks#activity-task-execution).
Therefore, the terms Activity Function and Activity Method refer to the source of an instance of an execution.

Activity Definitions are named and referenced in code by their [Activity Type](#activity-type).

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Activity Definition</p>
  </div>
  <div className="tdiiw" height="680">
    <img
      className="img_ev3q"
      src="/diagrams/activity-definition.svg"
      alt="Activity Definition"
    />
  </div>
</div>

#### Idempotency

Temporal recommends that Activities be idempotent.

Idempotent means that performing an operation multiple times has the same result as performing it once.
In the context of Temporal, Activities should be designed to be safely executed multiple times without causing unexpected or undesired side effects.

:::info

By design, completed Activities will not re-execute as part of a [Workflow Replay](/workflows#replays). However, Activities won’t record to the [Event History](/encyclopedia/retry-policies#event-history) until they return or produce an error. If an Activity fails to report to the server at all, it will be retried. Designing for idempotence, especially if you have a [Global Namespace](/global-namespace), will improve reusability and reliability.

:::

An Activity is idempotent if multiple [Activity Task Executions](/tasks#activity-task-execution) do not change the state of the system beyond the first Activity Task Execution.

We recommend using idempotency keys for critical side effects.

The lack of idempotency might affect the correctness of your application but does not affect the Temporal Platform.
In other words, lack of idempotency doesn't lead to a platform error.

In some cases, whether something is idempotent doesn't affect the correctness of an application.
For example, if you have a monotonically incrementing counter, you might not care that retries increment the counter because you don't care about the actual value, only that the current value is greater than a previous value.

For more information about idempotency in Temporal, see the following post:

[Idempotency and Durable Execution](https://temporal.io/blog/idempotency-and-durable-execution)

#### Constraints

Activity Definitions are executed as normal functions.

In the event of failure, the function begins at its initial state when retried (except when Activity Heartbeats are established).

Therefore, an Activity Definition has no restrictions on the code it contains.

#### Parameters

An Activity Definition can support as many parameters as needed.

All values passed through these parameters are recorded in the [Event History](/workflows#event-history) of the Workflow Execution.
Return values are also captured in the Event History for the calling Workflow Execution.

Activity Definitions must contain the following parameters:

- Context: an optional parameter that provides Activity context within multiple APIs.
- Heartbeat: a notification from the Worker to the Temporal Service that the Activity Execution is progressing. Cancelations are allowed only if the Activity Definition permits Heartbeating.
- Timeouts: intervals that control the execution and retrying of Activity Task Executions.

Other parameters, such as [Retry Policies](/encyclopedia/retry-policies) and return values, can be seen in the implementation guides, listed in the next section.

### What is an Activity Type? {#activity-type}

An Activity Type is the mapping of a name to an Activity Definition.

Activity Types are scoped through Task Queues.

## What is an Activity Execution? {#activity-execution}

An Activity Execution is the full chain of [Activity Task Executions](/tasks#activity-task-execution).

- [How to start an Activity Execution using the Go SDK](/develop/go/core-application#activity-execution)
- [How to start an Activity Execution using the Java SDK](/develop/java/core-application#activity-execution)
- [How to start an Activity Execution using the PHP SDK](/develop/php/core-application#activity-execution)
- [How to start an Activity Execution using the Python SDK](/develop/python/core-application#activity-execution)
- [How to start an Activity Execution using the TypeScript SDK](/develop/typescript/core-application#activity-execution)
- [How to start an Activity Execution using the .NET SDK](/develop/dotnet/core-application#activity-execution)

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">Activity Execution</p>
  </div>
  <div className="tdiiw" height="1780">
    <img
      className="img_ev3q"
      src="/diagrams/activity-execution.svg"
      alt="Activity Execution"
    />
  </div>
</div>

You can customize [Activity Execution timeouts](/encyclopedia/detecting-activity-failures#start-to-close-timeout) and [retry policies](/encyclopedia/retry-policies).

If an Activity Execution fails (because it exhausted all retries, threw a [non-retryable error](/encyclopedia/retry-policies#non-retryable-errors), or was canceled), the error is returned to the [Workflow](/workflows), which decides how to handle it.

:::note

Temporal guarantees that an Activity Task either runs or timeouts.
There are multiple failure scenarios when an Activity Task is lost.
It can be lost during delivery to a Worker or after the Activity Function is called and the Worker crashed.

Temporal doesn't detect task loss directly.
It relies on [Start-To-Close timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout).
If the Activity Task times out, the Activity Execution will be retried according to the Activity Execution Retry Policy.

In scenarios where the Activity Execution Retry Policy is set to `1` and a Timeout occurs, the Activity Execution will not be tried.

:::

### Cancellation

Activity Cancellation:

- lets the Activity know it doesn't need to keep doing work, and
- gives the Activity time to clean up any resources it has created.

Activities must heartbeat to receive cancellations from a Temporal Service.

An Activity may receive Cancellation if:

- The Activity was requested to be Cancelled. This can often cascade from Workflow Cancellation, but not always—SDKs have ways to stop Cancellation from cascading. {/* TODO link to workflow cancellation */}
- The Activity was considered failed by the Server because any of the Activity timeouts have triggered (for example, the Server didn't receive a heartbeat within the Activity's Heartbeat timeout). The [Cancelled Failure](/references/failures#cancelled-failure) that the Activity receives will have `message: 'TIMED_OUT'`.
- The Workflow Run reached a [Closed state](/workflows#status), in which case the Cancelled Failure will have `message: 'NOT_FOUND'`.
- In some SDKs:
  - The Worker is shutting down.
  - An Activity sends a Heartbeat but the Heartbeat details can't be converted by the Worker's configured [Data Converter](/dataconversion). This fails the Activity Task Execution with an Application Failure.
  - The Activity timed out on the Worker side and is not Heartbeating or the Temporal Service hasn't relayed a Cancellation.

There are different ways to receive Cancellation depending on the SDK. {/* TODO link to dev guide */}
An Activity may accept or ignore Cancellation:

- To allow Cancellation to happen, let the Cancellation Failure propagate.
- To ignore Cancellation, catch it and continue executing.

Some SDKs have ways to shield tasks from being stopped while still letting the Cancellation propagate.

The Workflow can also decide if it wants to wait for the Activity Cancellation to be accepted or to proceed without waiting.

Cancellation can only be requested a single time.
If you try to cancel your Activity Execution more than once, it will not receive more than one Cancellation request.

### What is an Activity Id? {#activity-id}

The identifier for an [Activity Execution](#activity-execution).
The identifier can be generated by the system, or it can be provided by the Workflow code that spawns the Activity Execution.
The identifier is unique among the open Activity Executions of a [Workflow Run](/workflows#run-id).
(A single Workflow Run may reuse an Activity Id if an earlier Activity Execution with the same Id has closed.)

An Activity Id can be used to [complete the Activity asynchronously](#asynchronous-activity-completion).

### What is Asynchronous Activity Completion? {#asynchronous-activity-completion}

Asynchronous Activity Completion is a feature that enables an Activity Function to return without causing the Activity Execution to complete.
The Temporal Client can then be used from anywhere to both Heartbeat Activity Execution progress and eventually complete the Activity Execution and provide a result.

How to complete an Activity Asynchronously in:

- [Go](/develop/go/asynchronous-activity-completion)
- [Java](/develop/java/asynchronous-activity-completion)
- [PHP](/develop/php/asynchronous-activity-completion)
- [Python](/develop/python/asynchronous-activity-completion)
- [TypeScript](/develop/typescript/asynchronous-activity-completion)
- [.NET](/develop/dotnet/asynchronous-activity)

#### When to use Async Completion

When an external system has the final result of a computation that is started by an Activity, there are three main ways of getting the result to the Workflow:

1. The external system uses Async Completion to complete the Activity with the result.
2. The Activity completes normally, without the result. Later, the external system sends a Signal to the Workflow with the result.
3. A subsequent Activity [polls the external system](https://community.temporal.io/t/what-is-the-best-practice-for-a-polling-activity/328/2) for the result.

If you don't have control over the external system—that is, you can't add Async Completion or a Signal to its code—then

- you can poll (#3), or
- if the external system can reliably call a webhook (and retry calling in the case of failure), you can write a webhook handler that sends a Signal to the Workflow (#2).

The decision between using #1 vs #2 involves a few factors.
Use Async Completion if

- the external system is unreliable and might fail to Signal, or
- you want the external process to Heartbeat or receive Cancellation.

Otherwise, if the external system can reliably be trusted to do the task and Signal back with the result, and it doesn't need to Heartbeat or receive Cancellation, then you may want to use Signals.

The benefit to using Signals has to do with the timing of failure retries.
For example, consider an external process that is waiting for a human to review something and respond, and they could take up to a week to do so.
If you use Async Completion (#1), you would

- set a [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) of one week on the Activity,
- in the Activity, notify the external process you need the human review, and
- have the external process Asynchronously Complete the Activity when the human responds.

If the Activity fails on the second step to notify the external system and doesn't throw an error (for example, if the Worker dies), then the Activity won't be retried for a week, when the Start-To-Close Timeout is hit.

If you use Signals, you would:

- set a [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) of one minute on the Activity,
- in the Activity, notify the external process you need the human review,
- complete the Activity without the result, and
- have the external process Signal the Workflow when the human responds.

If the Activity fails on the second step to notify the external system and doesn't throw an error, then the Activity will be retried in a minute.

In the second scenario, the failure is retried sooner. This is particularly helpful in scenarios like this in which the external process might take a long time.

#### What is a Task Token? {#task-token}

A Task Token is a unique identifier for an [Activity Task Execution](/tasks#activity-task-execution).

[Asynchronous Activity Completion](#asynchronous-activity-completion) calls take either of the following as arguments:

- a Task Token, or
- an [Activity Id](#activity-id), a [Workflow Id](/workflows#workflow-id), and optionally a [Run Id](/workflows#run-id).

## What is a Local Activity? {#local-activity}

A Local Activity is an [Activity Execution](#activity-execution) that executes in the same process as the [Workflow Execution](/workflows#workflow-execution) that spawns it.

Some Activity Executions are very short-living and do not need the queuing semantic, flow control, rate limiting, and routing capabilities.
For this case, Temporal supports the Local Activity feature.

The main benefit of Local Activities is that they use less Temporal Service resources (for example, fewer History events) and have much lower latency overhead (because no need to roundtrip to the Temporal Service) compared to normal Activity Executions.
However, Local Activities are subject to shorter durations and a lack of rate limiting.

Consider using Local Activities for functions that are the following:

- can be implemented in the same binary as the Workflow that calls them.
- do not require global rate limiting.
- do not require routing to a specific Worker or Worker pool.
- no longer than a few seconds, inclusive of retries.

If it takes longer than 80% of the Workflow Task Timeout (which is 10 seconds by default), the Worker will ask the Temporal Service to create a new Workflow Task to extend the "lease" for processing the Local Activity.
The Worker will continue doing so until the Local Activity has completed.
This is called Workflow Task Heartbeating.
The drawbacks of long-running Local Activities are:

- Each new Workflow Task results in 3 more Events in History.
- The Workflow won't get notified of new events like Signals and completions until the next Workflow Task Heartbeat.
- New Commands created by the Workflow concurrently with the Local Activity will not be sent to the Temporal Service until either the Local Activity completes or the next Workflow Task Heartbeat.

Using a Local Activity without understanding its limitations can cause various production issues.
**We recommend using regular Activities unless your use case requires very high throughput and large Activity fan outs of very short-lived Activities.**
More guidance in choosing between [Local Activity vs Activity](https://community.temporal.io/t/local-activity-vs-activity/290/3) is available in our forums.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/detecting-activity-failures.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/detecting-activity-failures.mdx</path>
  <content>
---
id: detecting-activity-failures
title: Detecting Activity failures
sidebar_label: Activities
description: Understand Activity Execution timeouts in Temporal; Schedule-To-Start, Start-To-Close, Schedule-To-Close, and Activity Heartbeats, for effective Workflow management.
toc_max_heading_level: 4
keywords:
  - explanation
  - term
  - timeouts
tags:
  - Concepts
  - Activities
  - Failures
  - Timeouts
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

A Workflow can detect different kinds of Activity Execution failures through the following timeouts:

- [Schedule-To-Start Timeout](#schedule-to-start-timeout)
- [Start-To-Close Timeout](#start-to-close-timeout)
- [Schedule-To-Close Timeout](#schedule-to-close-timeout)
- [Activity Heartbeats](#activity-heartbeat)

## Schedule-To-Start Timeout {#schedule-to-start-timeout}

**What is a Schedule-To-Start Timeout in Temporal?**

A Schedule-To-Start Timeout is the maximum amount of time that is allowed from when an [Activity Task](/tasks#activity-task) is scheduled (that is, placed in a Task Queue) to when a [Worker](/workers#worker) starts (that is, picks up from the Task Queue) that Activity Task.
In other words, it's a limit for how long an Activity Task can be enqueued.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

The moment that the Task is picked by the Worker, from the Task Queue, is considered to be the start of the Activity Task Execution for the purposes of the Schedule-To-Start Timeout and associated metrics.
This definition of "Start" avoids issues that a clock difference between the Temporal Service and a Worker might create.

<PrettyImage src="/diagrams/schedule-to-start-timeout.svg" title="Schedule-To-Start Timeout period" />

"Schedule" in Schedule-To-Start and Schedule-To-Close have different frequency guarantees.

The Schedule-To-Start Timeout is enforced for each Activity Task, whereas the Schedule-To-Close Timeout is enforced once per Activity Execution.
Thus, "Schedule" in Schedule-To-Start refers to the scheduling moment of _every_ Activity Task in the sequence of Activity Tasks that make up the Activity Execution, while
"Schedule" in Schedule-To-Close refers to the _first_ Activity Task in that sequence.

A [Retry Policy](/encyclopedia/retry-policies) attached to an Activity Execution retries an Activity Task.

<PrettyImage src="/diagrams/schedule-to-start-timeout-with-retry.svg" title="Start-To-Close Timeout period with retries" />

This timeout has two primary use cases:

1. Detect whether an individual Worker has crashed.
2. Detect whether the fleet of Workers polling the Task Queue is not able to keep up with the rate of Activity Tasks.

**The default Schedule-To-Start Timeout is ∞ (infinity).**

If this timeout is used, we recommend setting this timeout to the maximum time a Workflow Execution is willing to wait for an Activity Execution in the presence of all possible Worker outages, and have a concrete plan in place to reroute Activity Tasks to a different Task Queue.
This timeout **does not** trigger any retries regardless of the Retry Policy, as a retry would place the Activity Task back into the same Task Queue.
We do not recommend using this timeout unless you know what you are doing.

In most cases, we recommend monitoring the `temporal_activity_schedule_to_start_latency` metric to know when Workers slow down picking up Activity Tasks, instead of setting this timeout.

## Start-To-Close Timeout {#start-to-close-timeout}

**What is a Start-To-Close Timeout in Temporal?**

A Start-To-Close Timeout is the maximum time allowed for a single [Activity Task Execution](/tasks#activity-task-execution).

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

**The default Start-To-Close Timeout is the same as the default [Schedule-To-Close Timeout](#schedule-to-close-timeout).**

An Activity Execution must have either this timeout (Start-To-Close) or the [Schedule-To-Close Timeout](#schedule-to-close-timeout) set.
We recommend always setting this timeout; however, make sure that Start-To-Close Timeout is always set to be longer than the maximum possible time for the Activity Execution to complete.
For long running Activity Executions, we recommend also using [Activity Heartbeats](#activity-heartbeat) and [Heartbeat Timeouts](#heartbeat-timeout).

:::tip

We strongly recommend setting a Start-To-Close Timeout.

The Temporal Server doesn't detect failures when a Worker loses communication with the Server or crashes.
Therefore, the Temporal Server relies on the Start-To-Close Timeout to force Activity retries.

:::

The main use case for the Start-To-Close timeout is to detect when a Worker crashes after it has started executing an Activity Task.

<PrettyImage src="/diagrams/start-to-close-timeout.svg" title="Start-To-Close Timeout period" />

A [Retry Policy](/encyclopedia/retry-policies) attached to an Activity Execution retries an Activity Task Execution.
Thus, the Start-To-Close Timeout is applied to each Activity Task Execution within an Activity Execution.

If the first Activity Task Execution returns an error the first time, then the full Activity Execution might look like this:

<PrettyImage src="/diagrams/start-to-close-timeout-with-retry.svg" title="Start-To-Close Timeout period with retries" />

If this timeout is reached, the following actions occur:

- An [ActivityTaskTimedOut](/references/events#activitytasktimedout) Event is written to the Workflow Execution's mutable state.
- If a Retry Policy dictates a retry, the Temporal Service schedules another Activity Task.
  - The attempt count increments by 1 in the Workflow Execution's mutable state.
  - The Start-To-Close Timeout timer is reset.

## Schedule-To-Close Timeout {#schedule-to-close-timeout}

**What is a Schedule-To-Close Timeout in Temporal?**

A Schedule-To-Close Timeout is the maximum amount of time allowed for the overall [Activity Execution](/activities#activity-execution), from when the first [Activity Task](/tasks#activity-task) is scheduled to when the last Activity Task, in the chain of Activity Tasks that make up the Activity Execution, reaches a Closed status.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<PrettyImage src="/diagrams/schedule-to-close-timeout.svg" title="Schedule-To-Close Timeout period" />

Example Schedule-To-Close Timeout period for an Activity Execution that has a chain Activity Task Executions:

<PrettyImage src="/diagrams/schedule-to-close-timeout-with-retry.svg" title="Schedule-To-Close Timeout period with a retry" />

**The default Schedule-To-Close Timeout is ∞ (infinity).**

An Activity Execution must have either this timeout (Schedule-To-Close) or [Start-To-Close](#start-to-close-timeout) set.
This timeout can be used to control the overall duration of an Activity Execution in the face of failures (repeated Activity Task Executions), without altering the Maximum Attempts field of the Retry Policy.

:::tip

We strongly recommend setting a Start-To-Close Timeout.

The Temporal Server doesn't detect failures when a Worker loses communication with the Server or crashes.
Therefore, the Temporal Server relies on the Start-To-Close Timeout to force Activity retries.

:::

## Activity Heartbeat {#activity-heartbeat}

**What is an Activity Heartbeat in Temporal?**

An Activity Heartbeat is a ping from the Worker that is executing the Activity to the Temporal Service.
Each ping informs the Temporal Service that the Activity Execution is making progress and the Worker has not crashed.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

Activity Heartbeats work in conjunction with a [Heartbeat Timeout](#heartbeat-timeout).

Activity Heartbeats are implemented within the Activity Definition.
Custom progress information can be included in the Heartbeat which can then be used by the Activity Execution should a retry occur.

An Activity Heartbeat can be recorded as often as needed (e.g. once a minute or every loop iteration).
It is often a good practice to Heartbeat on anything but the shortest Activity Function Execution.
Temporal SDKs control the rate at which Heartbeats are sent to the Temporal Service.

Heartbeating is not required from [Local Activities](/activities#local-activity), and does nothing.

For _long-running_ Activities, we recommend using a relatively short Heartbeat Timeout and a frequent Heartbeat.
That way if a Worker fails it can be handled in a timely manner.

A Heartbeat can include an application layer payload that can be used to _save_ Activity Execution progress.
If an [Activity Task Execution](/tasks#activity-task-execution) times out due to a missed Heartbeat, the next Activity Task can access and continue with that payload.

Activity Cancellations are delivered to Activities from the Temporal Service when they Heartbeat. Activities that don't Heartbeat can't receive a Cancellation.
Heartbeat throttling may lead to Cancellation getting delivered later than expected.

### Throttling

Heartbeats may not always be sent to the Temporal Service—they may be throttled by the Worker.
The throttle interval is the smaller of the following:

- If `heartbeatTimeout` is provided, `heartbeatTimeout * 0.8`; otherwise, `defaultHeartbeatThrottleInterval`
- `maxHeartbeatThrottleInterval`

`defaultHeartbeatThrottleInterval` is 30 seconds by default, and `maxHeartbeatThrottleInterval` is 60 seconds by default.
Each can be set in Worker options.

Throttling is implemented as follows:

- After sending a Heartbeat, the Worker sets a timer for the throttle interval.
- The Worker stops sending Heartbeats, but continues receiving Heartbeats from the Activity and remembers the most recent one.
- When the timer fires, the Worker:
  - Sends the most recent Heartbeat.
  - Sets the timer again.

Throttling allows the Worker to reduce network traffic and load on the Temporal Service by suppressing Heartbeats that aren’t necessary to prevent a Heartbeat Timeout.
Throttling does not apply to the final Heartbeat message in the case of Activity Failure.
If an Activity fails just after recording progress information in a Heartbeat message, that progress information will be available during the next retry attempt, provided that the Worker itself did not crash before delivering it to the Temporal Service.

### Which Activities should Heartbeat?

Heartbeating is best thought about not in terms of time, but in terms of "How do you know you are making progress?"
For short-term operations, progress updates are not a requirement.
However, checking the progress and status of Activity Executions that run over long periods is almost always useful.

Consider the following when setting Activity Hearbeats:

- Your underlying task must be able to report definite progress.
  Note that your Workflow cannot read this progress information while the Activity is still executing (or it would have to store it in Event History).
  You can report progress to external sources if you need it exposed to the user.

- Your Activity Execution is long-running, and you need to verify whether the Worker that is processing your Activity is still alive and has not run out of memory or silently crashed.

For example, the following scenarios are suitable for Heartbeating:

- Reading a large file from Amazon S3.
- Running a ML training job on some local GPUs.

And the following scenarios are not suitable for Heartbeating:

- Making a quick API call.
- Reading a small file from disk.

### Heartbeat Timeout {#heartbeat-timeout}

**What is a Heartbeat Timeout in Temporal?**

A Heartbeat Timeout is the maximum time between [Activity Heartbeats](#activity-heartbeat).

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-heartbeats" text="Set a Heartbeat Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-heartbeat-timeout" text="Set a Heartbeat Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<PrettyImage src="/diagrams/heartbeat-timeout.svg" title="Heartbeat Timeout periods" />

If this timeout is reached, the Activity Task fails and a retry occurs if a [Retry Policy](/encyclopedia/retry-policies) dictates it.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/observability.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/observability.mdx</path>
  <content>
---
id: observability
title: Observability - Temporal feature
description: Explore the observability and visibility features of Temporal, including Metrics, Tracing, Logging, and Visibility.
sidebar_label: Observability
tags:
  - Observability
  - Metrics
  - Logging
  - Visibility
keywords:
  - temporal observability
  - monitor temporal workflows
  - temporal metrics
  - temporal tracing
  - temporal logging
  - temporal visibility
  - workflow state monitoring
  - temporal SDK observability
  - temporal performance insights
  - temporal search attributes
  - best practices for temporal monitoring
  - temporal observability tools
  - temporal dashboard integration
  - monitoring temporal applications
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal's observability feature helps you track the state of your Workflows in real-time, providing tools for detailed metrics, tracing, comprehensive logging, and visibility into your application state.

Monitor performance, trace Activity and Workflow Executions, debug, and filter Workflow Executions to gain deeper insights into your Workflows.

**Key Components of Temporal's Observability and Visibility**

- **Metrics**: Detailed performance metrics to track the health and efficiency of your Temporal Service and Workflows.
- **Tracing**: End-to-end tracing of Workflow and Activity Executions to understand the flow and timing of operations.
- **Logging**: Comprehensive logging capabilities for debugging and auditing purposes.
- **Search Attributes**: Custom attributes that can be used to enhance searchability and provide additional context to Workflow Executions.
- **Web UI**: A user-friendly interface for visualizing and interacting with your Workflows and Temporal Service state.

**Benefits of Temporal's Observability and Visibility Features**

- **Real-time Monitoring**: Track the state and progress of your Workflows as they execute.
- **Performance Optimization**: Identify bottlenecks and optimize your Workflow and Activity implementations.
- **Effective Debugging**: Quickly locate and diagnose issues in your Temporal applications.
- **Compliance and Auditing**: Maintain detailed records of all Workflow executions for compliance and auditing purposes.
- **Operational Insights**: Gain a deep understanding of your application's behavior and usage patterns.
- **Scalability Management**: Monitor and manage the scalability of your Temporal Service effectively.

Jump straight into the Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/observability" text="Observability using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/observability" text="Observability using the .NET SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/observability" text="Observability using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/observability" text="Observability using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/observability" text="Observability using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/observability" text="Observability using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/message-passing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/message-passing.mdx</path>
  <content>
---
id: message-passing
title: Workflow message passing - Python SDK
sidebar_label: Messages
description: Develop with Queries, Signals, and Updates with the Temporal Python SDK.
toc_max_heading_level: 3
keywords:
  - temporal python signals
  - send signal from client
  - send signal from workflow
  - signal with start
  - workflow queries
  - sending queries
  - workflow updates
  - dynamic workflows
  - dynamic activities
  - dynamic signals
  - dynamic queries
tags:
  - Workflows
  - Messages
  - Signals
  - Queries
  - Updates
  - Python SDK
  - Temporal SDKs
---

A Workflow can act like a stateful web service that receives messages: Queries, Signals, and Updates.
The Workflow implementation defines these endpoints via handler methods that can react to incoming messages and return values.
Temporal Clients use messages to read Workflow state and control its execution.
See [Workflow message passing](/encyclopedia/workflow-message-passing) for a general overview of this topic.
This page introduces these features for the Temporal Python SDK.

## Write message handlers {#writing-message-handlers}

:::info
The code that follows is part of a working message passing [sample](https://github.com/temporalio/samples-python/tree/main/message_passing/introduction).
:::

Follow these guidelines when writing your message handlers:

- Message handlers are defined as methods on the Workflow class, using one of the three decorators: [`@workflow.query`](https://python.temporal.io/temporalio.workflow.html#query), [`@workflow.signal`](https://python.temporal.io/temporalio.workflow.html#signal), and [`@workflow.update`](https://python.temporal.io/temporalio.workflow.html#update).
- The parameters and return values of handlers and the main Workflow function must be [serializable](/dataconversion).
- Prefer [data classes](https://docs.python.org/3/library/dataclasses.html) to multiple input parameters.
  Data class parameters allow you to add fields without changing the calling signature.

### Query handlers {#queries}

A [Query](/sending-messages#sending-queries) is a synchronous operation that retrieves state from a Workflow Execution:

```python
class Language(IntEnum):
    Chinese = 1
    English = 2
    French = 3

@dataclass
class GetLanguagesInput:
    include_unsupported: bool

@workflow.defn
class GreetingWorkflow:
    def __init__(self) -> None:
        self.greetings = {
            Language.CHINESE: "你好，世界",
            Language.ENGLISH: "Hello, world",
        }

    @workflow.query
    def get_languages(self, input: GetLanguagesInput) -> list[Language]:
        # 👉 A Query handler returns a value: it can inspect but must not mutate the Workflow state.
        if input.include_unsupported:
            return list(Language)
        else:
            return list(self.greetings)
```

- The Query decorator can accept arguments.
  Refer to the API docs: [`@workflow.query`](https://python.temporal.io/temporalio.workflow.html#query).

- A Query handler uses `def`, not `async def`.
  You can't perform async operations like executing an Activity in a Query handler.

### Signal handlers {#signals}

A [Signal](/sending-messages#sending-signals) is an asynchronous message sent to a running Workflow Execution to change its state and control its flow:

```python
@dataclass
class ApproveInput:
    name: str

@workflow.defn
class GreetingWorkflow:
    ...
    @workflow.signal
    def approve(self, input: ApproveInput) -> None:
        # 👉 A Signal handler mutates the Workflow state but cannot return a value.
        self.approved_for_release = True
        self.approver_name = input.name
```

- The Signal decorator can accept arguments.
  Refer to the API docs: [`@workflow.signal`](https://python.temporal.io/temporalio.workflow.html#signal).

- The handler should not return a value.
  The response is sent immediately from the server, without waiting for the Workflow to process the Signal.

- Signal (and Update) handlers can be `async def`.
  This allows you to use Activities, Child Workflows, durable [`asyncio.sleep`](https://docs.python.org/3/library/asyncio-task.html#asyncio.sleep) Timers, [`workflow.wait_condition`](https://python.temporal.io/temporalio.workflow.html#wait_condition) conditions, and more.
  See [Async handlers](#async-handlers) and [Workflow message passing](/encyclopedia/workflow-message-passing) for guidelines on safely using async Signal and Update handlers.

### Update handlers and validators {#updates}

An [Update](/sending-messages#sending-updates) is a trackable synchronous request sent to a running Workflow Execution.
It can change the Workflow state, control its flow, and return a result.
The sender must wait until the Worker accepts or rejects the Update.
The sender may wait further to receive a returned value or an exception if something goes wrong:

```python
class Language(IntEnum):
    Chinese = 1
    English = 2
    French = 3

@workflow.defn
class GreetingWorkflow:
    ...
    @workflow.update
    def set_language(self, language: Language) -> Language:
        # 👉 An Update handler can mutate the Workflow state and return a value.
        previous_language, self.language = self.language, language
        return previous_language

    @set_language.validator
    def validate_language(self, language: Language) -> None:
        if language not in self.greetings:
            # 👉 In an Update validator you raise any exception to reject the Update.
            raise ValueError(f"{language.name} is not supported")
```

- The Update decorator can take arguments (like, `name`, `dynamic` and `unfinished_policy`) as described in the API reference docs for [`workflow.update`](https://python.temporal.io/temporalio.workflow.html#update).

- About validators:
  - Use validators to reject an Update before it is written to History.
    Validators are always optional.
    If you don't need to reject Updates, you can skip them.
  - The SDK automatically provides a validator decorator named `@<update-handler-name>.validator`.
    The validator must accept the same argument types as the handler and return `None`.

- Accepting and rejecting Updates with validators:
  - To reject an Update, raise an exception of any type in the validator.
  - Without a validator, Updates are always accepted.
- Validators and Event History:
  - The `WorkflowExecutionUpdateAccepted` event is written into the History whether the acceptance was automatic or programmatic.
  - When a Validator raises an error, the Update is rejected and `WorkflowExecutionUpdateAccepted` _won't_ be added to the Event History.
    The caller receives an "Update failed" error.

- Use [`workflow.current_update_info`](https://python.temporal.io/temporalio.workflow.html#current_update_info) to obtain information about the current Update.
  This includes the Update ID, which can be useful for deduplication when using Continue-As-New: see [Ensuring your messages are processed exactly once](/handling-messages#exactly-once-message-processing).
- Update (and Signal) handlers can be `async def`, letting them use Activities, Child Workflows, durable [`asyncio.sleep`](https://docs.python.org/3/library/asyncio-task.html#asyncio.sleep) Timers, [`workflow.wait_condition`](https://python.temporal.io/temporalio.workflow.html#wait_condition) conditions, and more.
  See [Async handlers](#async-handlers) and [Workflow message passing](/encyclopedia/workflow-message-passing) for safe usage guidelines.

## Send messages {#send-messages}

To send Queries, Signals, or Updates, you call methods on a [WorkflowHandle](https://python.temporal.io/temporalio.client.WorkflowHandle.html) object:

- Use [start_workflow](https://python.temporal.io/temporalio.client.Client.html#start_workflow) to start a Workflow and return its handle.

- Use [get_workflow_handle_for](https://python.temporal.io/temporalio.client.Client.html#get_workflow_handle_for) to retrieve a typed Workflow handle by its Workflow Id.

For example:

```python
client = await Client.connect("localhost:7233")
workflow_handle = await client.start_workflow(
    GreetingWorkflow.run, id="greeting-workflow-1234", task_queue="my-task-queue"
)
```

To check the argument types required when sending messages -- and the return type for Queries and Updates -- refer to the corresponding handler method in the Workflow Definition.

:::warning Using Continue-as-New and Updates

- Temporal _does not_ support Continue-as-New functionality within Update handlers.
- Complete all handlers _before_ using Continue-as-New.
- Use Continue-as-New from your main Workflow Definition method, just as you would complete or fail a Workflow Execution.

:::

### Send a Query {#send-query}

Use [`WorkflowHandle.query`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#query) to send a Query to a Workflow Execution:

```python
supported_languages = await workflow_handle.query(
    GreetingWorkflow.get_languages, GetLanguagesInput(supported_only=True)
)
```

- Sending a Query doesn’t add events to a Workflow's Event History.

- You can send Queries to closed Workflow Executions within a Namespace's Workflow retention period.
  This includes Workflows that have completed, failed, or timed out.
  Querying terminated Workflows is not safe and, therefore, not supported.

- A Worker must be online and polling the Task Queue to process a Query.

### Send a Signal {#send-signal}

You can send a Signal to a Workflow Execution from a Temporal Client or from another Workflow Execution.
However, you can only send Signals to Workflow Executions that haven’t closed.

#### Send a Signal from a Client {#send-signal-from-client}

Use [`WorkflowHandle.signal`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#signal) to send a Signal:

```python
await workflow_handle.signal(GreetingWorkflow.approve, ApproveInput(name="me"))
```

- The call returns when the server accepts the Signal; it does _not_ wait for the Signal to be delivered to the Workflow Execution.

- The [WorkflowExecutionSignaled](/references/events#workflowexecutionsignaled) Event appears in the Workflow's Event History.

#### Send a Signal from a Workflow {#send-signal-from-workflow}

A Workflow can send a Signal to another Workflow, known as an _External Signal_.
You'll need a Workflow handle for the external Workflow.
Use [`get_external_workflow_handle_for`](https://python.temporal.io/temporalio.workflow.html#get_external_workflow_handle_for):

<div style={{backgroundColor: '#e0e0e0',padding: '0px 15px',borderRadius: '5px',border: '1px solid #cccccc',display: 'inline-block'}}><a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/signal_your_workflow/signal_external_wf_dacx.py"><tt>See full sample</tt></a></div>

```python
# ...
@workflow.defn
class WorkflowB:
    @workflow.run
    async def run(self) -> None:
        handle = workflow.get_external_workflow_handle_for(WorkflowA.run, "workflow-a")
        await handle.signal(WorkflowA.your_signal, "signal argument")
```

When an External Signal is sent:

- A [SignalExternalWorkflowExecutionInitiated](/references/events#signalexternalworkflowexecutioninitiated) Event appears in the sender's Event History.
- A [WorkflowExecutionSignaled](/references/events#workflowexecutionsignaled) Event appears in the recipient's Event History.

#### Signal-With-Start {#signal-with-start}

Signal-With-Start allows a Client to send a Signal to a Workflow Execution, starting the Execution if it is not already running.
To use Signal-With-Start, call the [`start_workflow`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) method and pass the `start_signal` argument with the name of your Signal:

<div style={{backgroundColor: '#e0e0e0',padding: '0px 15px',borderRadius: '5px',border: '1px solid #cccccc',display: 'inline-block'}}><a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/signal_your_workflow/signal_with_start_dacx.py"><tt>See full sample</tt></a></div>

```python
from temporalio.client import Client
# ...
async def main():
    client = await Client.connect("localhost:7233")
    await client.start_workflow(
        GreetingWorkflow.run,
        id="your-signal-with-start-workflow",
        task_queue="signal-tq",
        start_signal="submit_greeting",
        start_signal_args=["User Signal with Start"],
    )
```

### Send an Update {#send-update-from-client}

An Update is a synchronous, blocking call that can change Workflow state, control its flow, and return a result.

A client sending an Update must wait until the Server delivers the Update to a Worker.
Workers must be available and responsive.
If you need a response as soon as the Server receives the request, use a Signal instead.
Also note that you can't send Updates to other Workflow Executions.

- `WorkflowExecutionUpdateAccepted` is added to the Event History when the Worker confirms that the Update passed validation.
- `WorkflowExecutionUpdateCompleted` is added to the Event History when the Worker confirms that the Update has finished.

To send an Update to a Workflow Execution, you can:

- Call [`execute_update`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#execute_update) and wait for the Update to complete.
  This code fetches an Update result:

  ```python
  previous_language = await workflow_handle.execute_update(
      GreetingWorkflow.set_language, Language.Chinese
  )
  ```

- Send [`start_update`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#start_update) to receive an [`UpdateHandle`](https://python.temporal.io/temporalio.client.WorkflowUpdateHandle.html) as soon as the Update is accepted.

  - Use this `UpdateHandle` later to fetch your results.
  - `async def` Update handlers normally perform long-running asynchronous operations, such as executing an Activity.
  - `start_update` only waits until the Worker has accepted or rejected the Update, not until all asynchronous operations are complete.

  For example:

  ```python
  # Wait until the update is accepted
  update_handle = await workflow_handle.start_update(
      HelloWorldWorkflow.set_greeting,
      HelloWorldInput("World"),
      wait_for_stage=client.WorkflowUpdateStage.ACCEPTED,
  )
  # Wait until the update is completed
  update_result = await update_handle.result()
  ```

  For more details, see the "Async handlers" section.

To obtain an Update handle, you can:

- Use [`start_update`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#start_update) to start an Update and return the handle, as shown in the preceding example.
- Use [`get_update_handle_for`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#get_update_handle_for) to fetch a handle for an in-progress Update using the Update ID.

#### Update-With-Start {#update-with-start}

:::tip Stability

In [Public Preview](/evaluate/development-production-features/release-stages#public-preview) in Temporal Cloud.

Minimum Temporal Server version [Temporal Server version 1.26](https://github.com/temporalio/temporal/releases/tag/v1.26.2)

:::

[Update-with-Start](/sending-messages#update-with-start) lets you
[send an Update](/develop/python/message-passing#send-update-from-client) that checks whether an already-running Workflow with that ID exists:

- If the Workflow exists, the Update is processed.
- If the Workflow does not exist, a new Workflow Execution is started with the given ID, and the Update is processed before the main Workflow method starts to execute.

Use [`execute_update_with_start_workflow`](https://python.temporal.io/temporalio.client.Client.html#start_update_with_start_workflow) to start the Update and wait for the result in one go.

Alternatively, use [`start_update_with_start_workflow`](https://python.temporal.io/temporalio.client.Client.html#start_update_with_start_workflow) to start the Update and receive a [`WorkflowUpdateHandle`](https://python.temporal.io/temporalio.client.WorkflowUpdateHandle.html), and then use `await update_handle.result()` to retrieve the result from the Update.

These calls return once the requested Update wait stage has been reached, or when the request times out.

You will need to provide a [`WithStartWorkflowOperation`](https://python.temporal.io/temporalio.client.WithStartWorkflowOperation.html) to define the Workflow that will be started if necessary, and its arguments.
You must specify a [WorkflowIdConflictPolicy](/workflows#workflow-id-conflict-policy) when creating the `WithStartWorkflowOperation`.
Note that a `WithStartWorkflowOperation` can only be used once.

Here's an example taken from the [lazy_initialization](https://github.com/temporalio/samples-python/blob/main/message_passing/update_with_start/lazy_initialization/starter.py) sample:

```python
start_op = WithStartWorkflowOperation(
    ShoppingCartWorkflow.run,
    id=cart_id,
    id_conflict_policy=common.WorkflowIDConflictPolicy.USE_EXISTING,
    task_queue="my-task-queue",
)
try:
    price = Decimal(
        await temporal_client.execute_update_with_start_workflow(
            ShoppingCartWorkflow.add_item,
            ShoppingCartItem(sku=item_id, quantity=quantity),
            start_workflow_operation=start_op,
        )
    )
except WorkflowUpdateFailedError:
    price = None

workflow_handle = await start_op.workflow_handle()

return price, workflow_handle
```

:::info SEND MESSAGES WITHOUT TYPE SAFETY

In real-world development, sometimes you may be unable to import Workflow Definition method signatures.
When you don't have access to the Workflow Definition or it isn't written in Python, you can still use APIs that aren't type-safe, and dynamic method invocation.
Pass method names instead of method objects to:

- [`Client.start_workflow`](https://python.temporal.io/temporalio.client.Client.html#start_workflow)
- [`WorkflowHandle.query`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#query)
- [`WorkflowHandle.signal`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#signal)
- [`WorkflowHandle.execute_update`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#execute_update)
- [`WorkflowHandle.start_update`](https://python.temporal.io/temporalio.client.WorkflowHandle.html#start_update)

Use these non-type safe APIs:

- [`get_workflow_handle`](https://python.temporal.io/temporalio.client.Client.html#get_workflow_handle)
- [`get_external_workflow_handle`](https://python.temporal.io/temporalio.workflow.html#get_external_workflow_handle).

:::

## Message handler patterns {#message-handler-patterns}

This section covers common write operations, such as Signal and Update handlers.
It doesn't apply to pure read operations, like Queries or Update Validators.

:::tip

For additional information, see [Inject work into the main Workflow](/handling-messages#injecting-work-into-main-workflow), [Ensuring your messages are processed exactly once](/handling-messages#exactly-once-message-processing), and [this sample](https://github.com/temporalio/samples-python/blob/message-passing/message_passing/safe_message_handlers/README.md) demonstrating safe `async` message handling.

:::

### Use async handlers {#async-handlers}

Signal and Update handlers can be `async def` as well as `def`.
Using `async def` allows you to use `await` with Activities, Child Workflows, [`asyncio.sleep`](https://docs.python.org/3/library/asyncio-task.html#asyncio.sleep) Timers, [`workflow.wait_condition`](https://python.temporal.io/temporalio.workflow.html#wait_condition) conditions, etc.
This expands the possibilities for what can be done by a handler but it also means that handler executions and your main Workflow method are all running concurrently, with switching occurring between them at `await` calls.
It's essential to understand the things that could go wrong in order to use `async def` handlers safely.
See [Workflow message passing](/encyclopedia/workflow-message-passing) for guidance on safe usage of async Signal and Update handlers, the [Safe message handlers](https://github.com/temporalio/samples-python/tree/main/updates_and_signals/safe_message_handlers) sample, and the [Controlling handler concurrency](#control-handler-concurrency) and [Waiting for message handlers to finish](#wait-for-message-handlers) sections below.

The following code executes an Activity that makes a network call to a remote service.
It modifies the Update handler from earlier on this page, turning it into an `async def`:

```python
@activity.defn
async def call_greeting_service(to_language: Language) -> Optional[str]:
    await asyncio.sleep(0.2)  # Pretend that we are calling a remote service.
    greetings = {
        Language.Arabic: "مرحبا بالعالم",
        Language.Chinese: "你好，世界",
        Language.English: "Hello, world",
        Language.French: "Bonjour, monde",
        Language.Hindi: "नमस्ते दुनिया",
        Language.Spanish: "Hola mundo",
    }
    return greetings.get(to_language)


@workflow.defn
class GreetingWorkflow:
    def __init__(self) -> None:
        self.lock = asyncio.Lock()
        ...
    ...
    @workflow.update
    async def set_language(self, language: Language) -> Language:
        if language not in self.greetings:
            # 👉 Use a lock here to ensure that multiple calls to set_language are processed in order.
            async with self.lock:
                greeting = await workflow.execute_activity(
                    call_greeting_service,
                    language,
                    start_to_close_timeout=timedelta(seconds=10),
                )
                if greeting is None:
                    # 👉 An update validator cannot be async, so cannot be used to check that the remote
                    # call_greeting_service supports the requested language. Raising ApplicationError
                    # will fail the Update, but the WorkflowExecutionUpdateAccepted event will still be
                    # added to history.
                    raise ApplicationError(
                        f"Greeting service does not support {language.name}"
                    )
                self.greetings[language] = greeting
        previous_language, self.language = self.language, language
        return previous_language
```

After updating the code to use an `async def`, your Update handler can schedule an Activity and await the result.
Although an `async def` Signal handler can also execute an Activity, using an Update handler allows the Client to receive a result or error once the Activity completes.
This lets your client track the progress of asynchronous work performed by the Update's Activities, Child Workflows, etc.

### Add wait conditions to block

Sometimes, `async def` Signal or Update handlers need to meet certain conditions before they should continue.
You can use [`workflow.wait_condition`](https://python.temporal.io/temporalio.workflow.html#wait_condition) to prevent the code from proceeding until a condition is true.
You specify the condition by passing a function that returns `True` or `False`, and you can optionally set a timeout.
This is an important feature that helps you control your handler logic.

Here are three important use cases for `workflow.wait_condition`:

- Wait for a Signal or Update to arrive.
- Wait in a handler until it's appropriate to continue.
- Wait in the main Workflow until all active handlers have finished.

#### Wait for a Signal or Update to arrive

It's common to use `workflow.condition` to wait for a particular Signal or Update to be sent by a Client:

```python
@workflow.defn
class GreetingWorkflow:
    def __init__(self) -> None:
        self.approved_for_release = False
        self.approver_name: Optional[str] = None

    @workflow.signal
    def approve(self, input: ApproveInput) -> None:
        self.approved_for_release = True
        self.approver_name = input.name

    @workflow.run
    async def run(self) -> str:
        await workflow.wait_condition(lambda: self.approved_for_release)
        ...
        return self.greetings[self.language]
```

#### Use wait conditions in handlers {#wait-in-message-handler}

It's common to use a Workflow wait condition to wait until a handler should start.
You can also use wait conditions anywhere else in the handler to wait for a specific condition to become `True`.
This allows you to write handlers that pause at multiple points, each time waiting for a required condition to become `True`.

Consider a `ready_for_update_to_execute` method that runs before your Update handler executes.
The `workflow.wait_condition` method waits until your condition is met:

```python
@workflow.update
async def my_update(self, update_input: UpdateInput) -> str:
    await workflow.wait_condition(
        lambda: self.ready_for_update_to_execute(update_input)
    )
```

You can also use wait conditions anywhere else in the handler to wait for a specific condition to become true.
This allows you to write handlers that pause at multiple points, each time waiting for a required condition to become true.

#### Ensure your handlers finish before the Workflow completes {#wait-for-message-handlers}

Workflow wait conditions can ensure your handler completes before a Workflow finishes.
When your Workflow uses `async def` Signal or Update handlers, your main Workflow method can return or continue-as-new while a handler is still waiting on an async task, such as an Activity result.
The Workflow completing may interrupt the handler before it finishes crucial work and cause client errors when trying retrieve Update results.
Use [`workflow.wait_condition`](https://python.temporal.io/temporalio.workflow.html#wait_condition) and [`all_handlers_finished`](https://python.temporal.io/temporalio.workflow.html#all_handlers_finished) to address this problem and allow your Workflow to end smoothly:

```python
@workflow.defn
class MyWorkflow:
    @workflow.run
    async def run(self) -> str:
        ...
        await workflow.wait_condition(workflow.all_handlers_finished)
        return "workflow-result"
```

By default, your Worker will log a warning when you allow a Workflow Execution to finish with unfinished handler executions.
You can silence these warnings on a per-handler basis by passing the `unfinished_policy` argument to the [`@workflow.signal`](https://python.temporal.io/temporalio.workflow.html#signal) / [`workflow.update`](https://python.temporal.io/temporalio.workflow.html#update) decorator:

```python
@workflow.update(unfinished_policy=workflow.HandlerUnfinishedPolicy.ABANDON)
async def my_update(self) -> None:
    ...
```

See [Finishing handlers before the Workflow completes](/handling-messages#finishing-message-handlers) for more information.

### Use `@workflow.init` to operate on Workflow input before any handler executes

Normally, your Workflow `__init__` method won't have any parameters.
However, if you use the `@workflow.init` decorator on your `__init__` method, you can give it the same [Workflow parameters](/develop/python/core-application#workflow-parameters) as your `@workflow.run` method.
The SDK will then ensure that your `__init__` method receives the Workflow input arguments that the [Client sent](/develop/python/temporal-clients#start-workflow-execution).
(The Workflow input arguments are also passed to your `@workflow.run` method -- that always happens, whether or not you use the `@workflow.init` decorator.)
This is useful if you have message handlers that need access to workflow input: see [Initializing the Workflow first](/handling-messages#workflow-initializers).

Here's an example.
Notice that `__init__` and `get_greeting` must have the same parameters, with the same type annotations:

```python
@dataclass
class MyWorkflowInput:
    name: str


@workflow.defn
class WorkflowRunSeesWorkflowInitWorkflow:
    @workflow.init
    def __init__(self, workflow_input: MyWorkflowInput) -> None:
        self.name_with_title = f"Sir {workflow_input.name}"
        self.title_has_been_checked = False

    @workflow.run
    async def get_greeting(self, workflow_input: MyWorkflowInput) -> str:
        await workflow.wait_condition(lambda: self.title_has_been_checked)
        return f"Hello, {self.name_with_title}"

    @workflow.update
    async def check_title_validity(self) -> bool:
        # 👉 The handler is now guaranteed to see the workflow input
        # after it has been processed by __init__.
        is_valid = await workflow.execute_activity(
            check_title_validity,
            self.name_with_title,
            schedule_to_close_timeout=timedelta(seconds=10),
        )
        self.title_has_been_checked = True
        return is_valid
```

### Use `asyncio.Lock` to prevent concurrent handler execution {#control-handler-concurrency}

Concurrent processes can interact in unpredictable ways.
Incorrectly written [concurrent message-passing](/handling-messages#message-handler-concurrency) code may not work correctly when multiple handler instances run simultaneously.
Here's an example of a pathological case:

```python
@workflow.defn
class MyWorkflow:

    @workflow.signal
    async def bad_async_handler(self):
        data = await workflow.execute_activity(
            fetch_data, start_to_close_timeout=timedelta(seconds=10)
        )
        self.x = data.x
        # 🐛🐛 Bug!! If multiple instances of this handler are executing concurrently, then
        # there may be times when the Workflow has self.x from one Activity execution and self.y from another.
        await asyncio.sleep(1)  # or await anything else
        self.y = data.y
```

Coordinating access using `asyncio.Lock` corrects this code.
Locking makes sure that only one handler instance can execute a specific section of code at any given time:

```python
@workflow.defn
class MyWorkflow:
    def __init__(self) -> None:
        ...
        self.lock = asyncio.Lock()
        ...

    @workflow.signal
    async def safe_async_handler(self):
        async with self.lock:
            data = await workflow.execute_activity(
                fetch_data, start_to_close_timeout=timedelta(seconds=10)
            )
            self.x = data.x
            # ✅ OK: the scheduler may switch now to a different handler execution, or to the main workflow
            # method, but no other execution of this handler can run until this execution finishes.
            await asyncio.sleep(1)  # or await anything else
            self.y = data.y
```

## Message handler troubleshooting {#message-handler-troubleshooting}

When sending a Signal, Update, or Query to a Workflow, your Client might encounter the following errors:

- **The client can't contact the server**:
  You'll receive a [`temporalio.service.RPCError`](https://python.temporal.io/temporalio.service.RPCError.html) on which the `status` attribute is [`RPCStatusCode`](https://python.temporal.io/temporalio.service.RPCStatusCode.html) `UNAVAILABLE` (after some retries; see the `retry_config` argument to [`Client.connect`](https://python.temporal.io/temporalio.client.Client.html#connect)).

- **The workflow does not exist**:
  You'll receive an [`temporalio.service.RPCError`](https://python.temporal.io/temporalio.service.RPCError.html) exception on which the `status` attribute is [`RPCStatusCode`](https://python.temporal.io/temporalio.service.RPCStatusCode.html) `NOT_FOUND`.

See [Exceptions in message handlers](/handling-messages#exceptions) for a non–Python-specific discussion of this topic.

### Problems when sending a Signal {#signal-problems}

When using Signal, the only exceptions that will result from your requests during its execution are the `RPCError`s described above.

For Queries and Updates, the Client waits for a response from the Worker, and therefore additional errors may occur during the handler Execution by the Worker.

### Problems when sending an Update {#update-problems}

When working with Updates, in addition to the `RPCError`s described above, you may encounter these errors:

- **No Workflow Workers are polling the Task Queue**:
  Your request will be retried by the SDK Client indefinitely.
  You can use [`asyncio.timeout`](https://docs.python.org/3/library/asyncio-task.html#timeouts) to impose a timeout.
  This raises a [`temporalio.client.WorkflowUpdateRPCTimeoutOrCancelledError`](https://python.temporal.io/temporalio.client.WorkflowUpdateRPCTimeoutOrCancelledError.html) exception.

- **Update failed**: You'll receive a [`temporalio.client.WorkflowUpdateFailedError`](https://python.temporal.io/temporalio.client.WorkflowUpdateFailedError.html) exception.
  There are two ways this can happen:

  - The Update was rejected by an Update validator defined in the Workflow alongside the Update handler.

  - The Update failed after having been accepted.

  Update failures are like [Workflow failures](/references/failures#errors-in-workflows).
  Issues that cause a Workflow failure in the main method also cause Update failures in the Update handler.
  These might include:

      - A failed Child Workflow
      - A failed Activity (if the Activity retries have been set to a finite number)
      - The Workflow author raising [`ApplicationError`](/references/failures#application-failure)
      - Any error listed in [workflow_failure_exception_types](https://python.temporal.io/temporalio.worker.Worker.html) (empty by default)

- **The handler caused the Workflow Task to fail**:
  A [Workflow Task Failure](/references/failures#errors-in-workflows) causes the server to retry Workflow Tasks indefinitely. What happens to your Update request depends on its stage:
  - If the request hasn't been accepted by the server, you receive a `FAILED_PRECONDITION` [`temporalio.service.RPCError`](https://python.temporal.io/temporalio.service.RPCError.html) exception.
  - If the request has been accepted, it is durable.
    Once the Workflow is healthy again after a code deploy, use an [`UpdateHandle`](https://python.temporal.io/temporalio.client.WorkflowUpdateHandle.html) to fetch the Update result.

- **The Workflow finished while the Update handler execution was in progress**:
  You'll receive a [`temporalio.service.RPCError`](https://python.temporal.io/temporalio.service.RPCError.html) exception with a `status` attribute of [`RPCStatusCode`](https://python.temporal.io/temporalio.service.RPCStatusCode.html) `NOT_FOUND`.
  This happens if the Workflow finished while the Update handler execution was in progress, for example because

  - The Workflow was canceled or failed.

  - The Workflow completed normally or continued-as-new and the Workflow author did not [wait for handlers to be finished](/handling-messages#finishing-message-handlers).

### Problems when sending a Query {#query-problems}

When working with Queries, in addition to the `RPCError`s described above, you may encounter these errors:

- **There is no Workflow Worker polling the Task Queue**:
  You'll receive a [`temporalio.service.RPCError`](https://python.temporal.io/temporalio.service.RPCError.html) exception on which the `status` attribute is [`RPCStatusCode`](https://python.temporal.io/temporalio.service.RPCStatusCode.html) `FAILED_PRECONDITION`.

- **Query failed**:
  You'll receive a [`temporalio.client.WorkflowQueryFailedError`](https://python.temporal.io/temporalio.client.WorkflowQueryFailedError.html) exception if something goes wrong during a Query.
  Any exception in a Query handler will trigger this error.
  This differs from Signal and Update requests, where exceptions can lead to Workflow Task Failure instead.

- **The handler caused the Workflow Task to fail.**
  This would happen, for example, if the Query handler blocks the thread for too long without yielding.

## Dynamic components {#dynamic-handler}

A dynamic Workflow, Activity, Signal, Update, or Query is a kind of unnamed item.
Normally, these items are registered by name with the Worker and invoked at runtime.
When an unregistered or unrecognized Workflow, Activity, or message request arrives with a recognized method signature, the Worker can use a pre-registered dynamic stand-in.

For example, you might send a request to start a Workflow named "MyUnknownWorkflow".
After receiving a Workflow Task, the Worker may find that there's no registered Workflow Definitions of that type.
It then checks to see if there's a registered dynamic Workflow.
If the dynamic Workflow signature matches the incoming Workflow signature, the Worker invokes that just as it would invoke a non-dynamic statically named version.

By registering dynamic versions of your Temporal components, the Worker can fall back to these alternate implementations for name mismatches.

:::caution

Use dynamic elements judiciously and as a fallback mechanism, not a primary design.
They can introduce long-term maintainability and debugging issues.
Reserve dynamic invocation use for cases where a name is not or can't be known at compile time.

:::

### Set a dynamic Signal, Query, or Update handler {#set-a-dynamic-signal}

A dynamic Signal, Query, or Update refers to a special stand-in handler.
It's used when an unregistered handler request arrives.

Consider a Signal, where you might send something like `workflow.signal(MyWorkflow.my_signal_method, my_arg)`.
This is a type-safe compiler-checked approach that guarantees a method exists.
There's also a non-type-safe string-based form: `workflow.signal('some-name', my_arg)`.
When sent to the server, the name is checked only after arriving at the Worker.
This is where "dynamic handlers" come in.

After failing to find a handler with a matching name and type, the Worker checks for a registered dynamic stand-in handler.
If found, the Worker uses that instead.

You must opt handlers into dynamic access.
Add `dynamic=True` to the handler decorator (for example, `@workflow.signal(dynamic=True)`) to make a handler dynamic.
The handler's signature must accept `(self, name: str, args: Sequence[RawValue])`.
Use a [payload_converter](https://python.temporal.io/temporalio.workflow.html#payload_converter) function to convert `RawValue` objects to your required type.
For example:

```python
from typing import Sequence

from temporalio.common import RawValue
...

    @workflow.signal(dynamic=True)
    async def dynamic_signal(self, name: str, args: Sequence[RawValue]) -> None:
        ...
```

This sample creates a `dynamic_signal` Signal.
When an unregistered or unrecognized Signal arrives with a matching signature, dynamic assignment uses this handler to manage the Signal.
It is responsible for transforming the sequence contents into usable data in a form that the method's logic can process and act on.

### Set a dynamic Workflow {#set-a-dynamic-workflow}

A dynamic Workflow refers to a special stand-in Workflow Definition.
It's used when an unknown Workflow Execution request arrives.

Consider the "MyUnknownWorkflow" example described earlier.
The Worker may find there's no registered Workflow Definitions of that name or type.
After failing to find a Workflow Definition with a matching type, the Worker looks for a dynamic stand-in.
If found, it invokes that instead.

To participate, your Workflow must opt into dynamic access.
Adding `dynamic=True` to the `@workflow.defn` decorator makes the Workflow Definition eligible to participate in dynamic invocation.
You must register the Workflow with the [Worker](https://python.temporal.io/temporalio.worker.html) before it can be invoked.

The Workflow Definition's primary Workflow method must accept a single argument of type `Sequence[temporalio.common.RawValue]`.
Use a [payload_converter](https://python.temporal.io/temporalio.workflow.html#payload_converter) function to convert `RawValue` objects to your required type.
For example:

<div style={{backgroundColor: '#e0e0e0',padding: '0px 15px',borderRadius: '5px',border: '1px solid #cccccc',display: 'inline-block'}}><a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/dynamic_handlers/your_dynamic_workflow_dacx.py"><tt>See full sample</tt></a></div>

```python
# ...
@workflow.defn(dynamic=True)
class DynamicWorkflow:
    @workflow.run
    async def run(self, args: Sequence[RawValue]) -> str:
        name = workflow.payload_converter().from_payload(args[0].payload, str)
        return await workflow.execute_activity(
            default_greeting,
            YourDataClass("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

This Workflow converts the first `Sequence` element to a string, and uses that to execute an Activity.

### Set a dynamic Activity {#set-a-dynamic-activity}

A dynamic Activity is a stand-in implementation.
It's used when an Activity Task with an unknown Activity type is received by the Worker.

To participate, your Activity must opt into dynamic access.
Adding `dynamic=True` to the `@activity.defn` decorator makes the Workflow Definition eligible to participate in dynamic invocation.
You must register the Activity with the [Worker](https://python.temporal.io/temporalio.worker.html) before it can be invoked.

The Activity Definition must then accept a single argument of type `Sequence[temporalio.common.RawValue]`.
Use a [payload_converter](https://python.temporal.io/temporalio.activity.html#payload_converter) function to convert `RawValue` objects to your required types.
For example:

<div style={{backgroundColor: '#e0e0e0',padding: '0px 15px',borderRadius: '5px',border: '1px solid #cccccc',display: 'inline-block'}}><a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/dynamic_handlers/your_dynamic_activity_dacx.py"><tt>See full sample</tt></a></div>

```python
# ...
@activity.defn(dynamic=True)
async def dynamic_greeting(args: Sequence[RawValue]) -> str:
    arg1 = activity.payload_converter().from_payload(args[0].payload, YourDataClass)
    return (
        f"{arg1.greeting}, {arg1.name}!\nActivity Type: {activity.info().activity_type}"
    )
# ...
@workflow.defn
class GreetingWorkflow:
    @workflow.run
    async def run(self, name: str) -> str:
        return await workflow.execute_activity(
            "unregistered_activity",
            YourDataClass("Hello", name),
            start_to_close_timeout=timedelta(seconds=10),
        )
```

This example invokes an unregistered Activity by name.
The Worker resolves it using the registered dynamic Activity instead.
When possible, prefer to use compiler-checked type-safe arguments rather than Activity name strings.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/key-management.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/key-management.mdx</path>
  <content>
---
id: key-management
title: Key Management
sidebar_label: Key Management
description: Learn about key management practices for securing encryption keys in Temporal applications.
slug: /key-management
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - key-management
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Key Management](#key-management). 

## What is Key Management? {#key-management}

Key Management is a fundamental part of working with encryption keys.

There are many computational and logistical aspects to generating and rotating keys, and this usually calls for a dedicated application in your stack. Here are some general recommendations for working with encryption keys for Temporal applications:

- [Symmetric Encryption](https://en.wikipedia.org/wiki/Symmetric-key_algorithm) is generally faster and will produce smaller payloads than asymmetric. Normally, an advantage of _asymmetric_ encryption is that it allows you to distribute your encryption and decryption keys separately, but depending on your infrastructure, this might not offer any security benefits with Temporal.

- AES-based algorithms are [hardware accelerated in Go](https://pkg.go.dev/crypto/aes) and other languages. AES algorithms are widely vetted and trusted, and there are many different variants that may suit your requirements. Load tests using `ALG_AES_256_GCM_HKDF_SHA512_COMMIT_KEY` have performed well.

- Store your encryption keys in the same manner as you store passwords, config details, and other sensitive data. When possible, load the key into your application, so you don't need to make a network call to retrieve it. Separate keys for each environment or namespace as much as possible.

- Make sure you have a key rotation strategy in place in the event that your keys are compromised or need to be replaced for another reason. Consider using a dedicated secrets engine or a key management system (KMS). Note that when you rotate keys, you may also need to retain old keys to query old Workflows.

### Key Rotation

National Institute of Standards and Technology (NIST) guidance recommends periodic rotation of encryption keys. For AES-GCM keys, rotation should occur before approximately 2^32 encryptions have been performed by a key version, following the guidelines of NIST publication 800-38D.

It is recommended that operators estimate the encryption rate of a key and use that to determine a frequency of rotation that prevents the guidance limits from being reached. For example, if one determines that the estimated rate is 40 million operations per day, then rotating a key every three months is sufficient.

Key rotation should generally be transparent to the Temporal Data Converter implementation. Temporal's `Encode()` and `Decode()` steps only need to trigger as expected, and Temporal has no knowledge of how or when you are generating your encryption keys.

You should design your Encode and Decode steps to accept all the necessary parameters for your key management, such as the key version, alongside your payloads. Like the Data Converters, keys should be mapped to a Namespace in Temporal.

### Using Vault for Key Management

[This repository](https://github.com/zboralski/codecserver) provides a robust and complete example of using Temporal with HashiCorp's [Vault](https://www.vaultproject.io/) secrets engine.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/getting-started.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/getting-started.mdx</path>
  <content>
---
id: getting-started
title: Getting started with Temporal
description: Explore Temporal SDKs for .Net, Go, Java, TypeScript, PHP, and Python to build robust Temporal applications. Start with the Temporal SDK of your choice today!
sidebar_label: Get started
---

Temporal offers a range of SDKs to help you build Temporal applications.
The SDKs are available for .Net, Go, Java, TypeScript, PHP, and Python.

## Temporal Go SDK

Get started with the [Temporal Go SDK](https://learn.temporal.io/getting_started/go).

[<img src="/get-started/go.svg" width="450" height="127"/>](https://learn.temporal.io/getting_started/go)

## Temporal Java SDK

Get started with the [Temporal Java SDK](https://learn.temporal.io/getting_started/java).

[<img src="/get-started/java.svg" width="450" height="127"/>](https://learn.temporal.io/getting_started/java)

## Temporal PHP SDK

Get started with the [Temporal PHP SDK](https://learn.temporal.io/getting_started/php).

[<img src="/get-started/php.svg" width="450" height="127"/>](https://learn.temporal.io/getting_started/php)

## Temporal Python SDK

Get started with the [Temporal Python SDK](https://learn.temporal.io/getting_started/python).

[<img src="/get-started/python.svg" width="450" height="127"/>](https://learn.temporal.io/getting_started/python)

## Temporal TypeScript SDK

Get started with the [Temporal TypeScript SDK](https://learn.temporal.io/getting_started/typescript).

[<img src="/get-started/typescript.svg" width="450" height="127"/>](https://learn.temporal.io/getting_started/typescript)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/index.mdx</path>
  <content>
---
id: index
title: Temporal Platform Documentation
sidebar_label: Documentation Home
description: Explore Temporal's comprehensive documentation to build, scale, and manage reliable, fault-tolerant workflows with Workflow-as-Code solutions.
---

<head>
  <title>Temporal Platform Documentation</title>
</head>

import { Intro } from '/docs/components/Intro.js';

<Intro />

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/security.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/security.mdx</path>
  <content>
---
id: security
title: Security model - Temporal Cloud
sidebar_label: Security model
description: Temporal Cloud provides robust security for applications, data, and its platform with features like mTLS, client-side encryption, PrivateLink, and SOC 2 Type 2 compliance.
slug: /cloud/security
toc_max_heading_level: 4
keywords:
  - introduction
  - security
  - temporal cloud
tags:
  - Security
  - Temporal Cloud
---

**What kind of security does Temporal Cloud provide?**

The security model of [Temporal Cloud](/cloud) encompasses applications, data, and the Temporal Cloud platform itself.

:::info General platform security

For information about the general security features of Temporal, see our [Platform security page](/security).

:::

## Application and data {#applications-and-data}

**What is the security model for applications and data in Temporal Cloud?**

### Code execution boundaries

Temporal Cloud provides the capabilities of Temporal Server as a managed service; it does not manage your applications or [Workers](/workers#worker).
Applications and services written using [Temporal SDKs](/encyclopedia/temporal-sdks) run in your computing environment, such as containers (Docker, Kubernetes) or virtual machines (in any hosting environment).
You have full control over how you secure your applications and services.

### Data Converter: Client-side encryption

The optional [Data Conversion](/dataconversion) capability of the Temporal Platform lets you transparently encrypt data before it's sent to Temporal Cloud and decrypt it when it comes out.

Data Conversion runs on your Temporal Workers and [Clients](/encyclopedia/temporal-sdks#temporal-client); Temporal Cloud cannot see or decrypt your data.
If you use this feature, data stored in Temporal Cloud remains encrypted even if the service itself is compromised.

By deploying a [Codec Server](/production-deployment/data-encryption) you can securely decrypt data in the [Temporal Web UI](/web-ui) without sharing encryption keys with Temporal.

## The platform {#the-platform}

**What is the security model for the Temporal Cloud platform?**

### Namespace isolation

The base unit of isolation in a Temporal environment is a [Namespace](/namespaces).
Each Temporal Cloud account can have multiple Namespaces.
A Namespace (regardless of account) cannot interact with other Namespaces.
Each Namespace is available through a secure gRPC (mTLS) endpoint and an HTTPS (TLS) endpoint.
Temporal Cloud is a multi-tenant service.
Namespaces in the same environment are logically segregated.
Namespaces do not share data processing or data storage across regional boundaries.

### Private Connectivity

Temporal Cloud supports private connectivity to enable you to connects to Temporal Cloud from a segregated cluster.
You can find more details per cloud:

- [AWS PrivateLink](aws-privatelink.mdx)
- [Google Cloud Private Service Connect](gcp-private-service-connect.mdx)

### Temporal Nexus

Like Namespaces, a Nexus Endpoint is an account-scoped resource that is global within a Temporal Cloud account.
Any Developer role (or higher) in an account, who is also a Namespace Admin on the endpoint’s target Namespace, can manage (create/update/delete) a Nexus Endpoint.
All users with a Read-only role (or higher) in an account, can view and browse the full list of Endpoints.

Runtime access from a Workflow in a caller Namespace to a Nexus Endpoint is controlled by an allowlist policy (of caller Namespaces) for each Endpoint in the Nexus API registry.
Workers authenticate with Temporal Cloud as they do today with mTLS certificates or API keys as allowed by the Namespace configuration.
Nexus requests are sent from the caller’s Namespace to the handler’s Namespace over a secure multi-region mTLS Envoy mesh.

For payload encryption, the DataConverter works the same for a Nexus Operation as it does for other payloads sent between a Worker and Temporal Cloud.

See [Nexus Security](/nexus/security) for more information.

### Encryption

Communication into and out of Namespaces is over TLS.
All communication within our production environments is over TLS 1.3.
Data is stored in two separate locations: an Elasticsearch instance (used when filtering Workflows in SDK clients, the [CLI](/cloud/tcld), or the Web UI) and the core Temporal Cloud persistence layer.
Both are encrypted at rest with AES-256-GCM.

For more information, see [Requirements for CA certificates in Temporal Cloud](/cloud/certificates#certificate-requirements).

### Identity

Authentication to gRPC endpoints is provided by mTLS per Namespace.

For more information, see [How to manage SAML authentication with Temporal Cloud](/cloud/saml).

### Access

Authorization is managed at the account and Namespace level.
Users and systems are assigned one or more preconfigured roles.
Users hold [account-level Roles](/cloud/users#account-level-roles) of administrators, developers, and read-only users.
Systems and applications processes hold their own distinct roles.

### Monitoring

In addition to extensive system monitoring for operational and availability requirements, we collect and monitor audit logs from the AWS environment and all calls to the gRPC API (which is used by the SDKs, CLI, and Web UI).
These audit logs can be made available for ingestion into your security monitoring system.

### Testing

We contract with a third party to perform a full-scope pentest (with the exception of social engineering) annually.
Additionally, we perform targeted third-party and internal testing on an as-needed basis, such as when a significant feature is being released.

### Internal Temporal access

We restrict access to production systems to the small team of employees who maintain our production infrastructure.
We log all access to production systems; shared accounts are not allowed.
Access to all production systems is through SSO, with MFA enabled.

Access to our cloud environments is granted only for limited periods of time, with a maximum of 8 hours.
(For more information, see the blog post [Rolling out access hours at Temporal](https://temporal.io/blog/rolling-out-access-hours-at-temporal).)

All Temporal engineering systems are secured by GitHub credentials, which require both membership in the Temporal GitHub organization and MFA.
Access grants are reviewed quarterly.

### Compliance

Temporal Technologies is SOC 2 Type 2 certified and compliant with GDPR and HIPAA regulations.
Compliance audits are available by request through our [Contact](https://pages.temporal.io/contact-us) page.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/pricing.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/pricing.mdx</path>
  <content>
---
id: pricing
title: Temporal Cloud pricing
sidebar_label: Pricing
description: Temporal Cloud offers flexible, predictable pricing for Workflows, Activities, Workers, and Storage. Pay for what you use with volume discounts and credit savings.
slug: /cloud/pricing
toc_max_heading_level: 4
keywords:
  - explanation
  - faq
  - introduction
  - pricing
  - security
  - storage
  - support
  - temporal cloud
  - term
tags:
  - Temporal Cloud
  - Pricing
  - Support
---

import DiscoverableDisclosure from '@site/src/components/disclosures/DiscoverableDisclosure';

Temporal Cloud is a consumption-based service.
You pay only for what you use.
Our pricing reflects your use of [_Actions_](#action), [_Storage_](#storage), and [_Support_](/cloud/support#support).
It is flexible, transparent, and predictable, so you know your costs.

This page describes the elements of Temporal Cloud pricing.
It gives you the information you need to understand and estimate costs for your implementation.
For more exact estimates, please reach out to [our team](https://pages.temporal.io/ask-an-expert).

Billing and cost information is available directly in the Temporal Cloud UI.
For more information, visit the [Billing and Cost](/cloud/billing-and-cost) page.

## Temporal Cloud pricing model {#pricing-model}

This section explains the basis of the Temporal Cloud pricing model and how it works.
Your total invoice each calendar month is the combination of Temporal Cloud consumption ([Actions](#action) and [Storage](#storage)), and a [Temporal Cloud Plan](#base_plans) that includes [Support](/cloud/support#support).

### Temporal Cloud Plans {#base_plans}

**How plans work**

Each Temporal Cloud account includes a plan with Support, Actions, Active Storage, Retained Storage and platform features.
Base allocations help you get started with the Temporal platform, so you can better estimate costs.

- Temporal Cloud Plans are charged monthly.
- Action and Storage allocations are reset each calendar month.

Temporal offers four plans: Essential, Business, Enterprise, Mission Critical.
Prices are outlined in the following table:

|                   | Essentials                                                                     | Business                                                                                                                          | Enterprise                                                                                                                      | Mission Critical                                                                                                                |
| ----------------- | ------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------- |
| Support Targeting | Basic use                                                                      | Production deployments<br />that scale                                                                                            | Enterprise deployments<br/>w/ stringent uptime demands                                                                          | Mission-critical applications<br />w/ the highest support needs                                                                 |
| Support Features  | Access to Support                                                              | <li>P0 Response Times</li>                                                                                                        | <li>P0: \<30 Min, 24/7</li><li>Private Slack</li>                                                                               | <li>P0: \<15 Min, 24/7</li><li>Private Slack</li><li>Dedicated DSE</li>                                                         |
| Product Features  | <li>1M Actions</li><li>1 GB Active Storage</li><li>40 GB Retained Storage</li> | <li>Commit discounts</li><li>SSO (Add-on)</li><li>2.5M Actions</li><li>2.5 GB Active Storage</li><li>100 GB Retained Storage</li> | <li>Commit discounts</li><li>SSO included</li><li>10M Actions</li><li>10 GB Active Storage</li><li>400 GB Retained Storage</li> | <li>Commit discounts</li><li>SSO included</li><li>10M Actions</li><li>10 GB Active Storage</li><li>400 GB Retained Storage</li> |
| Plan Pricing      | Greater of<li>&#36;100/mo or</li><li>5% of Usage Spend</li>                    | Greater of<li>&#36;500/mo or</li><li>10% of Usage Spend</li>                                                                      | Priced annually:<br /> [contact Sales](mailto:sales@temporal.io) for details                                                    | Priced annually:<br /> [contact Sales](mailto:sales@temporal.io) for details                                                    |
| Usage Pricing     | [Pay-As-You-Go](#payg) Pricing                                                 | Choose from <br /> [Pay-As-You-Go](#payg) or [Commitment Pricing](#commitment-pricing)                                            | Choose from <br /> [Pay-As-You-Go](#payg) or [Commitment Pricing](#commitment-pricing)                                          | Choose from <br /> [Pay-As-You-Go](#payg) or [Commitment Pricing](#commitment-pricing)                                          |

Please note, partial months are prorated to the day.
Find a complete description of Support offerings and response times in our [Support](/cloud/support) documentation.

:::note Converting GB to GBH

Active and Retained Storage allocations are translated into GBh at a rate of 1GB equals 744GBh.

:::

### Actions {#action}

**What are Temporal Actions?**

Actions are the primary unit of consumption-based pricing for Temporal Cloud.
They track billable operations within the Temporal Cloud Service, such as starting Workflows, recording a Heartbeat or sending messages.

<DiscoverableDisclosure label="Operations that result in Actions">

**WORKFLOWS**

- **Workflow started**.
  Occurs via client start, client [Signal-With-Start](/sending-messages#signal-with-start), [Continue-As-New](/workflows#continue-as-new), or [Child Workflow](/encyclopedia/child-workflows) start.
  If a Workflow start fails, an Action is not recorded.
- **Workflow reset**.
  Occurs when a [Workflow](/workflows) is reset.
  (Actions that occur before a [Reset](/workflows#reset) are counted even if they are no longer visible in [Event History](/workflows#event-history).)
- **Timer started**.
  Includes implicit Timers that are started by a Temporal SDK when timeouts are set, such as `AwaitWithTimeout` in Go or `condition` in TypeScript.
- **Search Attribute upsert requested**.
  Occurs for each invocation of `UpsertSearchAttributes` command.
  Multiple Search Attributes updated in a single `UpsertSearchAttributes` command count as one Action.
  Search Attributes specified during Workflow start are _excluded_ from Action counts.
  The `TemporalChangeVersion` Search Attribute, used for Workflow versioning, is also exempt from Action counting.
- **Signal sent**.
  An Action occurs for every [Signal](/sending-messages#sending-signals), whether sent from a Client or from a Workflow.
- **Query received by Worker**.
  An Action occurs for every [Query](/sending-messages#sending-queries), including viewing the call stack in the Temporal Cloud UI, which results in a Query behind the scenes.
- **Update received by Worker**.
  An Action occurs for every successful [Update](/sending-messages#sending-updates) and every [rejected](/handling-messages#update-validators) Update.
- **Side Effect recorded**.
  For a mutable [Side Effect](/workflows#side-effect), an Action occurs only when the value changes.
  (Be aware that some SDKs don't support Side Effects.)

**CHILD WORKFLOWS**

- **Child Workflows spawned**.
  The parent Workflow spawning a Child Workflow results in one Action.
- **Child Workflows executed**.
  Execution of the Child Workflow results in one Action.

**ACTIVITIES**

- **Activity started or retried**.
  Occurs each time an Activity is started or retried.
- **Local Activity started**.
  All [Local Activities](/activities#local-activity) associated with one Workflow Task count as a single Action.
  That's because Temporal Cloud counts all [RecordMarkers](/references/commands#recordmarker) from each Workflow Task as one action, and not _N_ actions.
  Please note:
  - Each additional Workflow Task heartbeat after counts as an additional Action.
  - Local Activities retried following a Workflow Task heartbeat count as one Action (capped at 100 Actions).
- **Activity Heartbeat recorded**.
  A Heartbeat call from Activity code counts as an Action only if it reaches the [Temporal Server](/clusters#temporal-server).
  Temporal SDKs throttle [Activity Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat).
  The default throttle is 80% of the [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout).
  Heartbeats don't apply to Local Activities.

**SCHEDULES**

[Schedules](/workflows#schedule) allows you to "schedule" a Workflow to start at a particular time.
Each execution of a Schedule accrues three actions:

- **Schedule Start**.
  This accounts for two actions.
- **Workflow started**.
  This is a single action to start the target Workflow.
  It includes initial Search Attributes as part of the start request.

**EXPORT**

[Workflow History Export](/cloud/export) enables you to export closed Workflow Histories to a cloud storage sink of your choice.

- **Workflow exported**.
  Each Workflow exported accrues a single action.

**TEMPORAL NEXUS**

- For Nexus Operation scheduled, the caller Workflow starting a Nexus Operation results in one Action on the caller Namespace.
- For Nexus Operation canceled, the caller Workflow canceling a Nexus Operation results in one Action on the caller Namespace.
- The underlying Temporal primitives (such as Workflows, Activities, and Signals) created by a Nexus Operation handler (directly or indirectly) result in the normal Actions for those primitives billed to the handler’s Namespace.
  This includes retries for underlying Temporal primitives like Activities but _not_ for handling the Nexus Operation itself or a retry of the Nexus Operation itself.

</DiscoverableDisclosure>

[Reach out](https://pages.temporal.io/contact-us) to our team for more information or to help size your number of Actions.

### Storage {#storage}

**How Workflow Storage works**

A Workflow's execution might exist for a few seconds, a day, month, or even forever.
The Temporal Service stores the Workflow Execution's [Event History](/workflows#event-history).
Under this framework, a Workflow Execution has only two states, open (Active Storage) or closed (Retained Storage).

- _Active Storage_ measures the amount of storage used by active Workflows.

- When the execution of a Workflow finishes, Temporal Cloud stores Event History for a defined Retention Period, which is set by the user per Namespace.
  This is _Retained Storage_.
  Typical uses of Retained Storage include compliance, debugging, workload refresh, and business analytics.
  When closed Workflow Histories need to be retained for more than the 90-day maximum period on Temporal Cloud, we recommend using our [**Export**](/cloud/export) feature.

Storage costs are measured in gigabyte-hours (GBh).

### Pricing options {#pricing-options}

**How to Pay for Temporal Cloud**

After you exceed your Actions and Storage allocations in your base tier, Temporal Cloud offers two payment options: Pay-As-You-Go and Commitments.
Both models meter and bill for three primary components: [Actions](#action), [Storage](#storage), and [your Temporal Cloud Plan](/cloud/support#support).

- With Pay-As-You-Go, you are invoiced each calendar month based on your consumption.
  Pay-As-You-Go pricing automatically applies volume prices as your Actions scale.
- With Commitments, you pre-purchase your Temporal Cloud spend with Temporal Credits.
  Temporal Credits pay for your Temporal Cloud consumption, including Temporal Cloud Plan charges.

## Pay-As-You-Go {#payg}

**How does Pay-As-You-Go pricing work?**

Pay-As-You-Go pricing is based on consumption.
This section explains how you're billed each calendar month and gives examples.

### Action pricing {#payg-action-pricing}

Actions pricing starts at &#36;50 per million Actions (&#36;0.00005 per Action).
You gain progressive volume discounts as you scale.
Discounts are based on your account's total usage, metered and billed for each calendar month:

| Actions               | Price per Million Actions                                                                 |
| --------------------- | ----------------------------------------------------------------------------------------- |
| First 5M              | &#36;50                                                                                   |
| Next 5M, up to 10M    | &#36;45                                                                                   |
| Next 10M, up to 20M   | &#36;40                                                                                   |
| Next 30M, up to 50M   | &#36;35                                                                                   |
| Next 50M, up to 100M  | &#36;30                                                                                   |
| Next 100M, up to 200M | &#36;25                                                                                   |
| Over 200M             | Contact [Sales](mailto:sales@temporal.io) for info<br /> _More discounts, helpful humans_ |

**Example**

If you consume 11.25M Actions in excess of your Temporal Cloud Plan allocation in one calendar month, your bill for Actions will be:

```
5M Actions ⨉ $50 Per Million Actions = $250
5M Actions ⨉ $45 Per Million Actions = $225
1.25M Actions ⨉ $40 Per Million Actions = $50
Actions
$250 (First Tier) + $225 (Second Tier) + $50 (Third Tier) = $525
```

### Storage pricing {#payg-storage-pricing}

Most accounts’ storage needs are met by our Temporal Cloud Plans.
For additional storage within a calendar month, you are billed for Active and Retained Storage as follows:
| **Storage** | **Price per GBh (USD)** |
| ----------- | ----------------------- |
| Retained | &#36;0.00105 |
| Active | &#36;0.042 |

**Example**

If you have 720 GBh of Active Storage and 3,600 GBh of Retained Storage in excess of your Base Tier allocations in one calendar month, your bill will be:

```
720 GBh Active Storage ⨉ $0.042 per GBh = $30.24
3,600 GBh Retained Storage ⨉ $0.00105 per GBh = $3.78
Total Storage Bill: $30.24 Active Storage + $3.78 Retained Storage = $34.02
```

## Temporal Cloud Plan pricing

Your Temporal Cloud Plan pricing is the greater of the minimum monthly price or a percent (%) of your consumption spend:

- The Essentials tier is priced at the greater of &#36;100/month or 5% of your Temporal Cloud consumption.
- The Business tier is priced at the greater of &#36;500/month or 10% of Temporal Cloud consumption.
- The Enterprise and Mission Critical Support plans must be paid annually. Contact [Sales](mailto:sales@temporal.io) to discuss your needs.

Your Temporal Cloud consumption combines the costs of Actions and Storage.

**Example**

If you are signed up for Essentials, with &#36;3,000 of monthly spend, your bill will be:

```
Greater of $100 or 5% ⨉ $3,000 = $150, so $150.
```

## Commitment Pricing {#commitment-pricing}

**Commitments with Temporal Credits**

Temporal Cloud offers the option to commit to a minimum spend over a given timeframe.
In exchange for this commitment you receive additional discounts.
Key discount levers include:

- Account Action volume over 200M Actions
- Duration of your commitment (1, 2, or 3 years)

Meet your commitments with any Temporal Cloud spend, including Actions, Storage and your Temporal Cloud Plan.
After making a commitment, Temporal locks in your Actions price based on your expected volume and discounts your Active Storage costs.
This price is used to bill your Actions and Active Storage across your account for the timeframe specified in your commitment.

Commitments must be paid for with Temporal Credits.
Temporal Credits are used to pay your Temporal Cloud consumption, including Temporal Cloud Plan charges.
A Temporal Credit is equivalent to &#36;1 USD.
For example, a credit purchase of &#36;20,000 results in 20,000 Temporal Credits.
A minimum credit purchase equivalent to the first year of your commitment is required.
For multi-year deals please contact [Sales](mailto:sales@temporal.io) for the most accurate pricing.

### Commitment Pricing Q&A

**How do multi-year commitments work?**

Our sales team works with you to match annual credit purchases in line with your expected spend.
This aligns your payments to annual terms rather than one up-front expense.

**What happens if I exhaust my commitment-based Temporal Credits before the end of my term?**

You continue to receive the negotiated discounted prices for the remainder of your term.
You'll be invoiced for another credit purchase based on your most recent calendar month's spend.
This amount is multiplied by the months remaining in the annual portion of your term.
If your previous month spend was &#36;5,000, and you're 10 months through your annual term, you'll be invoiced for 10,000 Temporal Credits to cover the remaining two months.

**What happens if I have unused Temporal Credits at the end of my term?**

Commitments can be difficult to estimate.
Temporal Cloud offers two ways to roll-over unused credits:

- When you renew a commitment for the same or larger amount, Temporal Cloud rolls over any unused credits into your new commitment.
- Should you need to downsize your commitment, Temporal Cloud rolls over up to 10% of your initial credit purchase amount into the new commitment.

**How do I make a commitment and purchase Temporal Credits?**

Contact our team at [sales@temporal.io](mailto:sales@temporal.io) or reach out to your dedicated account manager.
You can also purchase Temporal Cloud commitments credits through [AWS Marketplace](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu).

### Credit Balance

Your Credit Balance is adjusted each calendar month based on your Credit Usage.

**Example**

An account has purchased credits with an annual spend commitment of &#36;72,000.
In the first calendar month, the account is billed &#36;500 for a Business plan, &#36;5,000 for Actions, &#36;250 for Active Storage and &#36;50 for Retained Storage, a total of &#36;5800.
Their invoice would state:

```
Beginning credit balance of 72,000 - 5800 credits used = 66,200, Temporal Credits remaining.
```

If you have additional questions about credits and volume-based pricing, please contact [sales](mailto:sales@temporal.io) or, if you're already a Temporal Cloud customer, reach out to your dedicated account executive.

## Other pricing {#other-pricing}

Temporal Cloud has additional pricing for other elements of the platform.
Following are additional pricing considerations for High Availability features and SSO/SAML.

### High Availability feature pricing {#high-availability-features}

**How does the pricing for High Availability (HA) features work?**

For workloads with stringent high availability requirements, Temporal Cloud provides same-region and multi-region replicas, which add a failover capability.
Enabling HA features for Namespace automatically replicates Workflow Execution data and metadata to a replica in the same region or in a different region.
This allows for a near-seamless failover when incidents or outages occur.

The pricing for High Availability features aligns with the volume of your workloads.
Actions and Storage in your Namespace contribute to your Actions and Storage consumption.
To estimate costs for this deployment model, apply a 2x multiplier to the Actions and Storage in the Namespace you are replicating and include this scaling in your account’s consumption.

:::tip Future Pricing Update

To align with cloud provider network traffic pricing, we are introducing adjustments for multi-region replication.
Your plan will include a generous base allocation, with additional pay-per-use charges for any network usage beyond that threshold.
Most multi-region customers will not be impacted by this change.

:::

When upgrading an existing Namespace, some points to consider:

- Temporal won't charge for historical Actions completed prior to upgrading to a Namespace with High Availability features.
  Only ongoing (in-flight) and new Workflow Executions will generate consumption.
- Temporal charges for all Actions of existing (ongoing) and new Workflows from the point of adding a replica.
- Temporal charges for Replicated Storage of retained (historical), running (ongoing), and new Workflow Executions from the point of adding a new replica.

### SSO and SAML pricing {#sso-and-saml}

**What costs are associated with SSO/SAML use?**

Single sign-on (SSO) integration using SAML is included for all customers on the Enterprise and Mission Critical Plans.
For business plan customers, a monthly fixed fee based on the number of users registered in Temporal Cloud is required:

| **Users** | **Cost per month** |
| --------- | ------------------ |
| 0 to 25   | &#36;200           |
| 26 to 50  | &#36;300           |
| 51+       | &#36;500           |

### Use case cost estimates {#pricing-estimates}

Temporal Cloud uses a consumption-based pricing model based primarily on [Actions](#action) and [Storage](#storage).
Each workload is different.
You can estimate the cost of a specific Workflow by running it at a low volume.
Use the resulting Storage and compute measurements to project your production scale cost.

The examples below provide general estimates based on workload size.
You can also use our calculator on the pricing page to build your estimate.
Our team is always happy to [help you estimate costs] (https://pages.temporal.io/contact-us) for your specific workloads and requirements.

| Workload size | Cost (monthly) | Characteristics                            | Actions                                            | Typical use cases                                                                                             |
| ------------- | -------------- | ------------------------------------------ | -------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |
| Small         | < &#36;50.00   | Modest / transient throughput              | < 1M / month  <br /> _(< 0.38 actions per second)_ | General automation <br /> Human dependent processes <br /> Data pipelines <br /> Nightly batch processes      |
| Medium        | < &#36;2K      | Steady or burst throughput                 | < 40M / month <br /> _(< 15 actions per second)_   | Transaction & order systems <br /> Infrastructure automation <br /> Payment Processing <br /> Batch processes |
| Large         | < &#36;15K     | Sustained throughput or multiple use cases | < 400M / month <br /> _(< 150 actions per second)_ | Data processing / sync <br /> Retail order system <br /> KYC & fraud detection                                |
| Web Scale     | &#36;20K+      | "Web scale" and / or numerous use cases    | 1B+ / month <br /> _(400+ actions per second)_     | Social media application <br /> SaaS application service                                                      |

## Billing Questions FAQs {#pricing-faq}

**What payment methods does Temporal accept?**

You can pay with a credit card, ACH, or wire transfer.
To pay for Temporal Cloud with an AWS Account, sign up for [Temporal Cloud Pay-As-You-Go](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu) on the AWS Marketplace.

**How often will I be billed?**

Temporal Cloud issues invoices for the previous month’s usage and costs.
Invoices are issued on the 3rd of the month for the previous month.
For example, invoices for May will be issued at midnight UTC on June 3rd.

**Where can I view my usage and billing information?**

Account Owners and Finance Admins can view their detailed billing data at any time.
Visit the [Usage and Billing dashboards](/cloud/billing-and-cost) in Temporal Cloud.

**How do I purchase Temporal Cloud credits?**

You can purchase Temporal Cloud credits by contacting our team at [sales@temporal.io](mailto:sales@temporal.io).

**What's the minimum cost to run Temporal Cloud?**

The Essentials plan starts at &#36;100/month.
Consumption in excess of your plan's allocations are billed on a consumption basis.

**Can I purchase Temporal Cloud through my Amazon, Azure, or Google Cloud Platform Marketplace?**

There are two ways to purchase Temporal Cloud through AWS Marketplace:

- Pay-As-You-Go available [here](https://aws.amazon.com/marketplace/pp/prodview-hbcjz7wcl2mvu)
- Credits: available via private offer, please contact our team at [sales@temporal.io](mailto:sales@temporal.io)

To purchase Temporal Cloud on the Google Cloud Marketplace, please contact our team at [sales@temporal.io](mailto:sales@temporal.io).

**How do I see how many Temporal Cloud credits are remaining?**

To view remaining Temporal Cloud credits, Account Owners and Finance Admins can log in to Temporal Cloud and go to Settings > Billing.
You need appropriate administrative permissions to access this section.

**What happens if I exceed my available credits under a promotion such as the startup program?**

Customers with free credits from the startup program or from a promotion are invoiced once their credit balance is exhausted at the end of that month.

**Do promotional credits expire?**

Credits received through the startup program or an offer have an expiry date.
This date is stated as part of the sign-up process.

**How do I update my payment information?**

Account Owners and Finance Admins can update payment information at any time on the Temporal Cloud [Billing](https://cloud.temporal.io/billing) page under the Plan tab.
You need appropriate administrative permissions to access this section.
Select the "Manage Payment Method" button.

See [this overview](/cloud/billing-and-cost) for more details.

**What happens if my payment fails?**

Temporal will periodically send you email reminders to complete the payment.

**How do I view my invoices and billing history?**

Invoices are emailed to Account Owners or the designated billing contacts.
Account Owners and Finance Admins can view their [detailed billing information](https://cloud.temporal.io/billing) at any time.
See our [billing and cost](/cloud/billing-and-cost) page for details.
You need appropriate administrative permissions to access this section.
Alternatively, to view invoices and billing history, contact Temporal Finance at [ar@temporal.io](mailto: ar@temporal.io).

**Does Temporal charge sales tax/VAT?**

We charge applicable sales tax in US jurisdictions as required.

**How do I cancel my account?**

Account Owners can delete their account and cancel their subscription in the Plans tab in the billing center.
See the [billing and cost](/cloud/billing-and-cost) page for details on how to access the billing center.

**Will I lose access immediately if I cancel my account?**

Customers lose access to Temporal Cloud once Temporal completes the off-boarding process.
Billing is independent of this process.

**Can I reactivate my account after cancellation?**

No.
When your account is canceled, your account data is deleted and cannot be restored.
To return to Temporal Cloud, you must sign up again.
We will assign you a new Temporal account and consider you as a new customer.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/payload-codec.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/payload-codec.mdx</path>
  <content>
---
id: payload-codec
title: Payload Codec
sidebar_label: Payload Codec
description: A Payload Codec performs bytes-to-bytes transformations on Temporal Payloads, often for compression and encryption.
slug: /payload-codec
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - payload-codec
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Payload Codec](#payload-codec). 

## What is a Payload Codec? {#payload-codec}

A Payload Codec transforms an array of [Payloads](/dataconversion#payload) (for example, a list of Workflow arguments) into another array of Payloads.

When serializing to Payloads, the Payload Converter is applied first to convert your objects to bytes, followed by codecs that convert bytes to bytes.
When deserializing from Payloads, codecs are applied first to last to reverse the effect, followed by the Payload Converter.

Use a custom Payload Codec to transform your Payloads; for example, implementing compression and/or encryption on your Workflow Execution data.

### Encryption {#encryption}

Using end-to-end encryption in your custom Data Converter ensures that sensitive application data is secure when handled by the Temporal Server.

Apply your encryption logic in a custom Payload Codec and use it locally to encrypt data.
You maintain all the encryption keys, and the Temporal Server sees only encrypted data. Refer to [What is Key Management?](/key-management) for more guidance.

Your data exists unencrypted only on the Client and the Worker process that is executing the Workflows and Activities, on hosts that you control. For details, see [Securing your data](/production-deployment/data-encryption).

The following samples use encryption (AES GCM with 256-bit key) in a custom Data Converter:

- [Go sample](https://github.com/temporalio/samples-go/tree/main/encryption)
- [Java sample](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/encryptedpayloads)
- [Python sample](https://github.com/temporalio/samples-python/tree/main/encryption)
- [TypeScript sample](https://github.com/temporalio/samples-typescript/tree/main/encryption)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/interrupt-a-workflow.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/interrupt-a-workflow.mdx</path>
  <content>
---
id: interrupt-workflow
title: Interrupt a Workflow - Cancellation and Termination
description: Learn how to manage Workflow interruptions in Temporal; understand how to gracefully handle Workflow cancellations and terminations to ensure proper cleanup and state management.
sidebar_label: Interrupt a Workflow
tags:
  - Workflows
keywords:
  - temporal workflow interruption
  - cancel temporal workflows
  - terminate temporal workflows
  - temporal SDK cancellation
  - workflow termination temporal
  - temporal cancellation handling
  - managing workflow state temporal
  - temporal cleanup activities
  - temporal workflow lifecycle
  - temporal interruption strategies
  - temporal SDK tutorial
  - graceful workflow termination temporal
  - temporal workflow management
  - temporal activity interruption
  - temporal termination best practices
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Discover how Temporal enables you to gracefully handle Workflow interruptions through cancellations and terminations.
Understand how to stop a Workflow cleanly with cancellation, allowing for proper cleanup and state management.

For situations where a Workflow is stuck, termination provides an immediate solution, ensuring your applications remain robust and responsive.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/cancellation" text="Handling Cancellation and Termination using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/cancellation" text="Handling Cancellation and Termination using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/cancellation" text="Handling Cancellation and Termination using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/cancellation" text="Handling Cancellation and Termination using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/cancellation" text="Handling Cancellation and Termination using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/operator.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/operator.mdx</path>
  <content>
---
id: operator
title: Temporal CLI operator command reference
sidebar_label: operator
description: Operator commands in Temporal allow actions on Namespaces, Search Attributes, and Clusters using specific subcommands. Execute with "temporal operator [command] [subcommand] [options]".
toc_max_heading_level: 4
keywords:
  - cli reference
  - cluster
  - cluster health
  - cluster list
  - cluster remove
  - cluster upsert
  - command-line-interface-cli
  - describe
  - namespace
  - namespace create
  - namespace delete
  - namespace describe
  - namespace list
  - nexus
  - nexus endpoint
  - nexus endpoint create
  - nexus endpoint delete
  - nexus endpoint get
  - nexus endpoint list
  - nexus endpoint update
  - operator
  - search attribute
  - search attribute create
  - search attribute list
  - search attribute remove
  - system
  - temporal cli
  - update
tags:
  - Temporal CLI
---

Operator commands enable actions on [Namespaces](/namespaces), [Search Attributes](/search-attribute), and [Temporal Clusters](/clusters).
These actions are performed through subcommands.

To run an Operator command, run `temporal operator [command] [subcommand] [command options]`.

## cluster

Cluster commands enable actions on [Temporal Clusters](/clusters).

Cluster commands follow this syntax:
`temporal operator [command] [subcommand] [command options]`.

### describe

The `temporal operator cluster describe` command shows information about the [Cluster](/clusters).
This information can include information about other connected services, such as a remote [Codec Server](/codec-server).

Use the following options to change the output of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### health

The `temporal operator cluster health` command checks the health of the [Frontend Service](/clusters#frontend-service).
A successful execution returns a list of [Cluster](/clusters) metrics.

Use the following options to change the behavior and output of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### list

The `temporal operator cluster list` command prints a list of all remote [Clusters](/clusters) on the system.

`temporal operator cluster list`

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--limit](/cli/cmd-options#limit)

- [--namespace](/cli/cmd-options#namespace)

- [--no-pager](/cli/cmd-options#no-pager)

- [--output](/cli/cmd-options#output)

- [--pager](/cli/cmd-options#pager)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### remove

The `temporal operator cluster remove` command removes a remote [Cluster](/clusters) from the system.

`temporal operator cluster remove --name=SomeCluster`

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### system

The `temporal operator cluster system` command provides information about the system the [Cluster](/clusters) is running on.
This information can be used to diagnose problems occurring in the [Temporal Server](/clusters#temporal-server).

`temporal operator cluster system`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--fields](/cli/cmd-options#fields)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### upsert

The `temporal operator cluster upsert` command allows the user to add or update a remote [Cluster](/clusters).
`temporal operator cluster upsert --frontend-address="127.0.2.1"`

Upserting can also be used to enable or disabled cross-cluster connection.
`temporal operator cluster upsert --enable-connection=true`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--enable-connection](/cli/cmd-options#enable-connection)

- [--env](/cli/cmd-options#env)

- [--frontend-address](/cli/cmd-options#frontend-address)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## namespace

Namespace commands perform operations on [Namespaces](/namespaces) contained in the [Temporal Cluster](/clusters).

Namespace commands follow this syntax:
`temporal operator namespace COMMAND [ARGS]`.

### create

The `temporal operator namespace create` command creates a new [Namespace](/namespaces).
The Namespace can be created on the active [Cluster](/clusters), or any named Cluster within the system.
`temporal operator namespace --cluster=MyCluster`

Global Namespaces can also be created.
`temporal operator namespace create --global`

Other settings, such as [retention](/clusters#retention-period) and [Visibility Archival State](/clusters#visibility), can be configured according to the application's needs.
The Visibility Archive can be set on a separate URI.
`temporal operator namespace create --retention=RetentionMyWorkflow --visibility-archival-state="enabled" --visibility-uri="some-uri"`

Use the options listed below to change the command's behavior.

- [--active-cluster](/cli/cmd-options#active-cluster)

- [--address](/cli/cmd-options#address)

- [--cluster](/cli/cmd-options#cluster)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--data](/cli/cmd-options#data)

- [--description](/cli/cmd-options#description)

- [--email](/cli/cmd-options#email)

- [--env](/cli/cmd-options#env)

- [--global](/cli/cmd-options#global)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--history-archival-state](/cli/cmd-options#history-archival-state)

- [--history-uri](/cli/cmd-options#history-uri)

- [--namespace](/cli/cmd-options#namespace)

- [--retention](/cli/cmd-options#retention)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--visibility-archival-state](/cli/cmd-options#visibility-archival-state)

- [--visibility-uri](/cli/cmd-options#visibility-uri)

### delete

The `temporal operator namespace delete` command deletes a given [Namespace](/namespaces) from the system.
The command follow the syntax `temporal operator namespace delete <namespace>`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--yes](/cli/cmd-options#yes)

### describe

The `temporal operator namespace describe` command provides a description of a [Namespace](/namespaces).
Namespaces are identified by Namespace ID.

`temporal operator namespace describe --namespace-id=meaningful-business-id`

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--namespace-id](/cli/cmd-options#namespace-id)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### list

The `temporal operator namespace list` command lists all [Namespaces](/namespaces) on the [Server](/clusters#frontend-service).

`temporal operator namespace list`

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### update

The `temporal operator namespace update` command updates a [Namespace](/namespaces).

Namespaces can be assigned a different active [Cluster](/clusters).
`temporal operator namespace update --active-cluster=NewActiveCluster`

Namespaces can also be promoted to global Namespaces.
`temporal operator namespace --promote-global=true`

Any [Archives](/clusters#archival) that were previously enabled or disabled can be changed through this command.
However, URI values for archival states cannot be changed after the states are enabled.
`temporal operator namespace update --history-archival-state="enabled" --visibility-archival-state="disabled"`

:::note

The Namespace needs to be the last argument passed in your command.
For example, `temporal operator namespace update --retention 180 your_namespace`.

:::

Use the options listed below to change the command's behavior.

- [--active-cluster](/cli/cmd-options#active-cluster)

- [--address](/cli/cmd-options#address)

- [--cluster](/cli/cmd-options#cluster)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--data](/cli/cmd-options#data)

- [--description](/cli/cmd-options#description)

- [--email](/cli/cmd-options#email)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--history-archival-state](/cli/cmd-options#history-archival-state)

- [--history-uri](/cli/cmd-options#history-uri)

- [--namespace](/cli/cmd-options#namespace)

- [--promote-global](/cli/cmd-options#promote-global)

- [--retention](/cli/cmd-options#retention)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--verbose](/cli/cmd-options#verbose)

- [--visibility-archival-state](/cli/cmd-options#visibility-archival-state)

- [--visibility-uri](/cli/cmd-options#visibility-uri)

## nexus

These commands manage Nexus resources.

Nexus commands follow this syntax:

```
temporal operator nexus [command] [subcommand] [options]
```

### endpoint

These commands manage Nexus Endpoints.

Nexus Endpoint commands follow this syntax:

```
temporal operator nexus endpoint [command] [options]
```

#### create

Create a Nexus Endpoint on the Server.

A Nexus Endpoint name is used in Workflow code to invoke Nexus Operations.
The endpoint target may either be a Worker, in which case `--target-namespace` and `--target-task-queue` must both be provided, or an external URL, in which case `--target-url` must be provided.

This command will fail if an endpoint with the same name is already registered.

```
temporal operator nexus endpoint create \
  --name your-endpoint \
  --target-namespace your-namespace \
  --target-task-queue your-task-queue \
  --description-file DESCRIPTION.md
```

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--api-key](/cli/cmd-options#api-key)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--description](/cli/cmd-options#description)

- [--description-file](/cli/cmd-options#description-file)

- [--env](/cli/cmd-options#env)

- [--env-file](/cli/cmd-options#env-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--no-json-shorthand-payloads](/cli/cmd-options#no-json-shorthand-payloads)

- [--output](/cli/cmd-options#output)

- [--target-namespace](/cli/cmd-options#target-namespace)

- [--target-task-queue](/cli/cmd-options#target-task-queue)

- [--target-url](/cli/cmd-options#target-url)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-data](/cli/cmd-options#tls-ca-data)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-data](/cli/cmd-options#tls-cert-data)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-data](/cli/cmd-options#tls-key-data)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

#### delete

Delete a Nexus Endpoint from the Server.

```
temporal operator nexus endpoint delete --name your-endpoint
```

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--api-key](/cli/cmd-options#api-key)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--env-file](/cli/cmd-options#env-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--no-json-shorthand-payloads](/cli/cmd-options#no-json-shorthand-payloads)

- [--output](/cli/cmd-options#output)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-data](/cli/cmd-options#tls-ca-data)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-data](/cli/cmd-options#tls-cert-data)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-data](/cli/cmd-options#tls-key-data)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

#### get

Get a Nexus Endpoint by name from the Server.

```
temporal operator nexus endpoint get --name your-endpoint
```

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--api-key](/cli/cmd-options#api-key)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--env-file](/cli/cmd-options#env-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--no-json-shorthand-payloads](/cli/cmd-options#no-json-shorthand-payloads)

- [--output](/cli/cmd-options#output)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-data](/cli/cmd-options#tls-ca-data)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-data](/cli/cmd-options#tls-cert-data)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-data](/cli/cmd-options#tls-key-data)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

#### list

List all Nexus Endpoints on the Server.

```
temporal operator nexus endpoint list
```

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--api-key](/cli/cmd-options#api-key)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--env-file](/cli/cmd-options#env-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--namespace](/cli/cmd-options#namespace)

- [--no-json-shorthand-payloads](/cli/cmd-options#no-json-shorthand-payloads)

- [--output](/cli/cmd-options#output)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-data](/cli/cmd-options#tls-ca-data)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-data](/cli/cmd-options#tls-cert-data)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-data](/cli/cmd-options#tls-key-data)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

#### update

Update an existing Nexus Endpoint on the Server.

A Nexus Endpoint name is used in Workflow code to invoke Nexus Operations.
The endpoint target may either be a Worker, in which case `--target-namespace` and `--target-task-queue` must both be provided, or an external URL, in which case `--target-url` must be provided.

The endpoint is patched; existing fields for which flags are not provided are
left as they were.

Update only the target task queue:

```
temporal operator nexus endpoint update \
  --name your-endpoint \
  --target-task-queue your-other-queue
```

Update only the description:

```
temporal operator nexus endpoint update \
  --name your-endpoint \
  --description-file DESCRIPTION.md
```

Use the following options to change the behavior of this command.

- [--address](/cli/cmd-options#address)

- [--api-key](/cli/cmd-options#api-key)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--description](/cli/cmd-options#description)

- [--description-file](/cli/cmd-options#description-file)

- [--env](/cli/cmd-options#env)

- [--env-file](/cli/cmd-options#env-file)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--no-json-shorthand-payloads](/cli/cmd-options#no-json-shorthand-payloads)

- [--output](/cli/cmd-options#output)

- [--target-namespace](/cli/cmd-options#target-namespace)

- [--target-task-queue](/cli/cmd-options#target-task-queue)

- [--target-url](/cli/cmd-options#target-url)

- [--time-format](/cli/cmd-options#time-format)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-data](/cli/cmd-options#tls-ca-data)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-data](/cli/cmd-options#tls-cert-data)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-data](/cli/cmd-options#tls-key-data)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--unset-description](/cli/cmd-options#unset-description)

## search-attribute

Search Attribute commands enable operations for the creation, listing, and removal of [Search Attributes](/search-attribute).

Search Attribute commands follow this syntax:
`temporal operator search-attribute COMMAND [ARGS]`.

### create

The `temporal operator search-attribute create` command adds one or more custom [Search Attributes](/search-attribute).
These Search Attributes can be used to [filter a list](/list-filter) of [Workflow Executions](/workflows#workflow-execution) that contain the given Search Attributes in their metadata.

Use the following options to change this command's behavior.

- [--fields](/cli/cmd-options#fields)
- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--type](/cli/cmd-options#type)

### list

The `temporal operator search-attribute list` command displays a list of all [Search Attributes](/search-attribute) that can be used in [Queries](/sending-messages#sending-queries).

`temporal workflow list --query`.

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

### remove

The `temporal operator search-attribute remove` command removes custom [Search Attribute](/search-attribute) metadata.
This command does not remove custom Search Attributes from Elasticsearch or change the index schema.

Use the following options to change this command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--name](/cli/cmd-options#name)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

- [--yes](/cli/cmd-options#yes)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/troubleshooting/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/troubleshooting/index.mdx</path>
  <content>
---
id: index
title: Error Handling and Troubleshooting
sidebar_label: Troubleshooting
description: Discover effective troubleshooting solutions for potential Temporal errors and edge cases with our comprehensive guides, ensuring smooth Workflow execution and error management.
toc_max_heading_level: 4
keywords:
  - error handling
  - guide-context
  - troubleshooting
tags:
 - Errors
 - Failures
---

Even the most reliable systems can encounter issues.
Our troubleshooting guides are designed to help you quickly identify and resolve potential errors, ensuring your Temporal applications run smoothly and efficiently.

- [Troubleshoot the BlobSizeLimitError](/troubleshooting/blob-size-limit-error): The `BlobSizeLimitError` happens when the size of a blob (payloads including Workflow context and each Workflow and Activity argument and return value) is too large.
  The maximum payload for a single request is 2 MB, and the maximum size for any Event History transaction is 4 MB.
- [Troubleshoot the Deadline-Exceeded Error](/troubleshooting/deadline-exceeded-error):
  The "Context: deadline exceeded" error occurs when requests to the Temporal Service by the Client or Worker cannot be completed.
  This can be due to network issues, timeouts, server overload, or Query errors.
- [Troubleshoot the Failed Reaching Server Error](/troubleshooting/last-connection-error): The message "Failed reaching server: last connection error" often happens due to an expired TLS certificate or during the Server startup process when Client requests reach the Server before roles are fully initialized.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/service-availability.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/service-availability.mdx</path>
  <content>
---
id: service-availability
title: Service availability - Temporal Cloud
sidebar_label: Availability
description: Temporal Cloud offers high availability and low latency across multiple cloud provider regions with adjustable throughput limits and robust latency targets. Contact us for more details.
slug: /cloud/service-availability
toc_max_heading_level: 4
keywords:
  - explanation
  - operations
  - temporal cloud
  - throughput
tags:
  - Temporal Cloud
---

The operating envelope of Temporal Cloud includes throughput, latency, and limits.
Service regions are listed on [this page](/cloud/regions).
If you need more details, [contact us](https://pages.temporal.io/contact-us).

## Throughput expectations {#throughput}

**What kind of throughput can I get with Temporal Cloud?**

Each Namespace has a rate limit, which is measured in [Actions](/cloud/pricing#action) per second (APS).
A Namespace's default limit is set at 400 APS and automatically adjusts based on recent usage (over the prior 7 days).
Your throughput limit will never fall below this default value.

When your Action rate exceeds your quota, Temporal Cloud throttles Actions until the rate matches your quota.
Throttling means limiting the rate at which Actions are performed to prevent the Namespace from exceeding its APS limit.

Critical calls to external events, such starting or Signaling a Workflow, are always prioritized and never throttled.
There are four priority levels for Temporal Cloud API calls:

1. External events (Critical calls)
2. Workflow progress updates
3. Visibility API calls
4. Cloud operations such as Namespace creation

When you exceed your APS limits, you might receive warnings about throttling.
However, requests are never dropped, and high-priority calls are never delayed.
Workers might take longer to complete Workflows.

If your usage grows slowly, your throughput limit grows with your usage.
At times, you may hit a maximum throughput threshold and need to switch to a higher consumption tier.
Learn more about our tiers by visiting our [information page](/cloud/pricing#action) or [reach out to our team](https://pages.temporal.io/contact-us) to help size your number of Actions.
Temporal Cloud can provide more than 150,000 Actions per second at its highest tier.

:::tip MEASURING THROUGHPUT WITH APS AND RPS

APS and RPS are both measures of throughput, but apply to different aspects of Temporal.

APS, or Actions Per Second, is specific to Temporal Cloud.
It measures the rate at which Actions, like starting or signaling a Workflow, can be performed in a specific Namespace.
Temporal Cloud uses APS to manage and throttle Actions, preventing a Namespace from exceeding its limit.
APS measures how many high-level operations (Actions) a user can perform in Temporal Cloud each second.

RPS, or Requests Per Second, is used in the Temporal Service, both in self-hosted Temporal and Temporal Cloud.
It measures and controls the rate of gRPC requests to the Service.
This is a lower-level measure that manages rates at the service level, such as the Frontend, History, or Matching Services.

In summary, APS is a higher-level measure to limit and mitigate Action spikes in Temporal Cloud.
RPS is a lower-level measure to control and balance request rates at the service level.

:::

## Latency Service Level Objective (SLO) {#latency}

**What kind of latency can I expect from Temporal Cloud?**

Temporal Cloud has a p99 latency SLO of 200ms per region.

In March 2024, latency over a week-long period for starting and signaling Workflow Executions was as follows:

| Operation                          | p90  |  p99 |
| :--------------------------------- | :--: | ---: |
| `StartWorkflowExecution`           | 24ms | 54ms |
| `SignalWorkflowExecution`          | 14ms | 40ms |
| `SignalWithStartWorkflowExecution` | 24ms | 61ms |

As Temporal continues working on improving latencies, these numbers will progressively decrease.

The same SLO for normal Worker requests (commands and polling) apply to Nexus in both the caller and handler Namespaces.

Latency observed from the Temporal Client is influenced by other system components like the Codec Server, egress proxy, and the network itself.
Also, concurrent operations on the same Workflow Execution may result in higher latency.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/failure-converter.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/failure-converter.mdx</path>
  <content>
---
id: failure-converter
title: Failure Converter
sidebar_label: Failure Converter
description: A Failure Converter transforms error messages and call stacks into encoded formats to enhance security and observability.
slug: /failure-converter
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - failure-converter
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Failure Converter](#failure-converter). 

## What is a Failure Converter? {#failure-converter}

As with input and output, Temporal also uses its own default converter logic for errors that are generated by Workflows.
The default Failure Converter copies error messages and call stacks as plain text, and this text output is then directly accessible in the `Message` field of these Workflow Executions.

This may be undesirable for your application. In some cases, errors could contain privileged or sensitive information that you would need to prevent from leaking or being available via a side channel.
Failure messages and call stacks are not encoded as codec-capable Payloads by default; you must explicitly enable encoding these common attributes on failures.

If your errors might contain sensitive information, you can encrypt the message and call stack by configuring the default Failure Converter to use your encoding.
This moves your `message` and `stack_trace` fields to a Payload that's run through your codec.

For example, with the Temporal Go SDK, you can do this by adding a `FailureConverter` parameter to your `client.Options{}` array when calling `client.Dial()`.
The `FailureConverter` should override the `DefaultFailureConverterOptions{}` by setting `EncodeCommonAttributes: true` like so:

```go
c, err := client.Dial(client.Options{
	// Set DataConverter here to ensure that workflow inputs and results are
	// encoded as required.
	DataConverter: mycustom.DataConverter,
	FailureConverter: temporal.NewDefaultFailureConverter(temporal.DefaultFailureConverterOptions{
		EncodeCommonAttributes: true,
	}),
})
```

If for some reason you need to specify a different set of Converter logic for your Failures, you can replace the `NewDefaultFailureConverter` with a custom method.
For example, if you are both working with highly sensitive data and using a sophisticated logging/observability implementation, you may need to implement different encryption methods for each of them.


  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/timers.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/timers.mdx</path>
  <content>
---
id: timers
title: Durable Timers - Python SDK
sidebar_label: Durable Timers
description: Set durable Timers with Temporal Workflows using sleep() or timer(), ensuring code execution resumes after downtime. Sleep for months using resource-light operations in Python.
slug: /develop/python/timers
toc_max_heading_level: 2
keywords:
  - temporal workflow timers
  - delay workflow execution
  - durable scheduling
  - long-term task scheduling
  - sleep in workflow
tags:
  - Workflows
  - Durable Timers
  - Python SDK
  - Temporal SDKs
---

A Workflow can set a durable Timer for a fixed time period.
In some SDKs, the function is called `sleep()`, and in others, it's called `timer()`.

A Workflow can sleep for months.
Timers are persisted, so even if your Worker or Temporal Service is down when the time period completes, as soon as your Worker and Temporal Service are back up, the `sleep()` call will resolve and your code will continue executing.

Sleeping is a resource-light operation: it does not tie up the process, and you can run millions of Timers off a single Worker.

To set a Timer in Python, call the [`asyncio.sleep()`](https://docs.python.org/3/library/asyncio-task.html#sleeping) function and pass the duration in seconds you want to wait before continuing.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/continue_as_new/your_workflows_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
        await asyncio.sleep(10)
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/regions.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/regions.mdx</path>
  <content>
---
id: regions
title: Service regions - Temporal Cloud
sidebar_label: Service regions
slug: /cloud/regions
toc_max_heading_level: 3
description: Temporal Cloud offers high availability and low latency across multiple cloud provider regions with adjustable throughput limits and robust latency targets. Contact us for more details.
keywords:
  - explanation
  - operations
  - temporal cloud
  - throughput
tags:
  - Temporal Cloud
---

You can access Temporal Cloud from anywhere with Internet connectivity, no matter where your Temporal Cloud Namespaces are physically located.
Your applications can live in the cloud environment or data center of your choice.
With that in mind, you _will_ reduce latency by creating  Namespaces in a region close to where you host your Workers.

This page enumerates the current regions supported by Temporal Cloud Namespaces.

:::tip Service Availability

Visit [status.temporal.io](https://status.temporal.io) to check the status of our supported regions.
On that page, you can also subscribe to updates to receive email notifications whenever Temporal creates, updates or resolves an incident.

:::

### AWS Service Regions

Temporal Cloud operates in the following Amazon Web Services (AWS) regions:

import AWSRegions from '@site/docs/production-deployment/cloud/references/regions/awsregions.md';

<AWSRegions />

### GCP Service Regions

Temporal Cloud operates the following Google Cloud (GCP) regions:

import GCPRegions from '@site/docs/production-deployment/cloud/references/regions/gcpregions.md';

<GCPRegions />



  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/tasks.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/tasks.mdx</path>
  <content>
---
id: tasks
title: Tasks
sidebar_label: Tasks
description: Learn about the types of Tasks in Temporal and their role in Workflow and Activity Executions.
slug: /tasks
toc_max_heading_level: 4
keywords:
  - tasks
  - activity task
  - workflow task
tags:
  - Tasks
  - Concepts
---

This page discusses the following:

- [Task](#task)
- [Workflow Task](#workflow-task)
- [Workflow Task Execution](#workflow-task-execution)
- [Activity Task](#activity-task)
- [Activity Task Execution](#activity-task-execution)
- [Nexus Task](#nexus-task)
- [Nexus Task Execution](#nexus-task-execution)

## What is a Task? {#task}

A Task is the context that a Worker needs to progress with a specific [Workflow Execution](/workflows#workflow-execution), [Activity Execution](/activities#activity-execution), or a [Nexus Task Execution](#nexus-task-execution).

There are three types of Tasks:

- [Workflow Task](#workflow-task)
- [Activity Task](#activity-task)
- [Nexus Task](#nexus-task)

## What is a Workflow Task? {#workflow-task}

A Workflow Task is a Task that contains the context needed to make progress with a Workflow Execution.

- Every time a new external event that might affect a Workflow state is recorded, a Workflow Task that contains the event is added to a Task Queue and then picked up by a Workflow Worker.
- After the new event is handled, the Workflow Task is completed with a list of [Commands](/workflows#command).
- Handling of a Workflow Task is usually very fast and is not related to the duration of operations that the Workflow invokes.

### What is a Workflow Task Execution? {#workflow-task-execution}

A Workflow Task Execution occurs when a [Worker](/workers#worker-entity) picks up a [Workflow Task](#workflow-task) and uses it to make progress on the execution of a [Workflow Definition](/workflows#workflow-definition) (also known as a Workflow function).

## What is an Activity Task? {#activity-task}

An Activity Task contains the context needed to proceed with an [Activity Task Execution](#activity-task-execution).
Activity Tasks largely represent the Activity Task Scheduled Event, which contains the data needed to execute an Activity Function.

If Heartbeat data is being passed, an Activity Task will also contain the latest Heartbeat details.

### What is an Activity Task Execution? {#activity-task-execution}

An Activity Task Execution occurs when a [Worker](/workers#worker-entity) uses the context provided from the [Activity Task](#activity-task) and executes the [Activity Definition](/activities#activity-definition) (also known as the Activity Function).

The [ActivityTaskScheduled Event](/references/events#activitytaskscheduled) corresponds to when the Temporal Service puts the Activity Task into the Task Queue.

The [ActivityTaskStarted Event](/references/events#activitytaskstarted) corresponds to when the Worker picks up the Activity Task from the Task Queue.

Either [ActivityTaskCompleted](/references/events#activitytaskcompleted) or one of the other Closed Activity Task Events corresponds to when the Worker has yielded back to the Temporal Service.

The API to schedule an Activity Execution provides an "effectively once" experience, even though there may be several Activity Task Executions that take place to successfully complete an Activity.

Once an Activity Task finishes execution, the Worker responds to the Temporal Service with a specific Event:

- ActivityTaskCanceled
- ActivityTaskCompleted
- ActivityTaskFailed
- ActivityTaskTerminated
- ActivityTaskTimedOut

## What is a Nexus Task? {#nexus-task}

A Nexus Task represents a single Nexus request to start or cancel a Nexus Operation.
The Nexus Task includes details such as the Nexus Service and Nexus Operation names, and other information required to process the Nexus request.
The Temporal Worker triggers the registered Operation handler based on the Nexus task information.

### What is a Nexus Task Execution? {#nexus-task-execution}

A Nexus Task Execution occurs when a Worker uses the context provided from the Nexus Task and executes an action associated with a Nexus Operation which commonly includes starting a Nexus Operation using it's Nexus Operation handler plus many additional actions that may be performed on a Nexus Operation.

The NexusOperationScheduled Event corresponds to when the Temporal Service records the Workflow's intent to schedule an operation.

The NexusOperationStarted Event corresponds to when the Worker picks up the Nexus Task from the Task Queue, starts an asynchronous Nexus Operation, and returns an Operation token to the caller indicating the asynchronous Nexus Operation has started.

Either NexusOperationCompleted or one of the other Closed Nexus Operation Events corresponds to when the Nexus Operation has reached a final state due to successfully completing the operation or unsuccessfully completing the operation in the case of a failure, timeout, or cancellation.

A Nexus Operation Execution appears to the caller Workflow as a single RPC, while under the hood the Temporal Service may issue several Nexus Tasks to attempt to start the Operation.
Hence, a Nexus Operation Handler implementation should be idempotent.
The WorkflowRunOperation provided by the SDK leverages Workflow ID based deduplication to ensures idempotency and provide an "effectively once" experience.

A Nexus Task Execution completes when a Worker responds to the Temporal Service with either a RespondNexusTaskCompleted or RespondNexusTaskFailed call, or when the Task times out.

The Temporal Service interprets the outcome and determines whether to retry the Task or record the progress in a History Event:

- NexusTaskCompleted
- NexusTaskFailed

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/converters-and-encryption.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/converters-and-encryption.mdx</path>
  <content>
---
id: converters-and-encryption
title: Converters and encryption - Python SDK
sidebar_label: Converters and encryption
description: Learn how to use custom Payload Codecs and Converters with Temporal Python SDK for enhanced Workflow data handling, including custom encoding steps like compression and encryption. Discover how to implement and set up custom Data Converters to convert Temporal payloads efficiently and support various data types.
toc_max_heading_level: 2
keywords:
  - temporal python data encryption
  - custom payload codec
  - custom data converter
  - payload conversion sequence
  - custom payload converter
  - converting custom types
  - custom json encoding
tags:
  - Security
  - Codec Server
  - Data Converters
  - Encryption
  - Python SDK
  - Temporal SDKs
---

Temporal's security model is designed around client-side encryption of Payloads.
A client may encrypt Payloads before sending them to the server, and decrypt them after receiving them from the server.
This provides a high degree of confidentiality because the Temporal Server itself has absolutely no knowledge of the actual data.
It also gives implementers more power and more freedom regarding which client is able to read which data -- they can control access with keys, algorithms, or other security measures.

A Temporal developer adds client-side encryption of Payloads by providing a Custom Payload Codec to its Client.
Depending on business needs, a complete implementation of Payload Encryption may involve selecting appropriate encryption algorithms, managing encryption keys, restricting a subset of their users from viewing payload output, or a combination of these.

The server itself never adds encryption over Payloads.
Therefore, unless client-side encryption is implemented, Payload data will be persisted in non-encrypted form to the data store, and any Client that can make requests to a Temporal namespace (including the Temporal UI and CLI) will be able to read Payloads contained in Workflows.
When working with sensitive data, you should always implement Payload encryption.

## Custom Payload Codec {#custom-payload-codec}

**How to use a custom Payload Codec using Python with the Temporal Python SDK.**

Custom Data Converters can change the default Temporal Data Conversion behavior by adding hooks, sending payloads to external storage, or performing different encoding steps.
If you only need to change the encoding performed on your payloads -- by adding compression or encryption -- you can override the default Data Converter by creating a new `PayloadCodec`.

The `PayloadCodec` needs to implement `encode()` and `decode()` functions at a minimum.
These should loop through all of a Workflow's payloads, perform all of your necessary marshaling, compression, or encryption steps in order, and set an `"encoding"` metadata field.

In this example, the `encode` method marshals and then compresses a payload using Python's [cramjam](https://github.com/milesgranger/cramjam) library to provide `snappy` compression.
The `decode()` function implements the `encode()` logic in reverse:

```python
import cramjam
from temporalio.api.common.v1 import Payload
from temporalio.converter import PayloadCodec

class EncryptionCodec(PayloadCodec):
    async def encode(self, payloads: Iterable[Payload]) -> List[Payload]:
        return [
            Payload(
                metadata={
                    "encoding": b"binary/snappy",
                },
                data=(bytes(cramjam.snappy.compress(p.SerializeToString()))),
            )
            for p in payloads
        ]

    async def decode(self, payloads: Iterable[Payload]) -> List[Payload]:
        ret: List[Payload] = []
        for p in payloads:
            if p.metadata.get("encoding", b"").decode() != "binary/snappy":
                ret.append(p)
                continue
            ret.append(Payload.FromString(bytes(cramjam.snappy.decompress(p.data))))
        return ret
```

This example verifies that an encoded payload matches the `binary/snappy` filetype -- i.e., that it was encoded using the same custom `encode()` function -- and if so, performs decompression followed by unmarshaling.

**Set Data Converter to use custom Payload Codec**

Add a `data_converter` parameter to your `Client.connect()` options that overrides the default Converter with your Payload Codec:

```python
from codec import EncryptionCodec

client = await Client.connect(
	"localhost:7233",
	data_converter=dataclasses.replace(
		temporalio.converter.default(), payload_codec=EncryptionCodec()
	),
)
```

- Data **encoding** is performed by the client using the converters and codecs provided by Temporal or your custom implementation when passing input to the Temporal Cluster. For example, plain text input is usually serialized into a JSON object, and can then be compressed or encrypted.
- Data **decoding** may be performed by your application logic during your Workflows or Activities as necessary, but decoded Workflow results are never persisted back to the Temporal Cluster. Instead, they are stored encoded on the Cluster, and you need to provide an additional parameter when using the [temporal workflow show](/cli/workflow#show) command or when browsing the Web UI to view output.

For reference, see the [Encryption](https://github.com/temporalio/samples-python/tree/main/encryption) sample.

### Using a Codec Server

A Codec Server is an HTTP server that uses your custom Codec logic to decode your data remotely.
The Codec Server is independent of the Temporal Cluster and decodes your encrypted payloads through predefined endpoints.
You create, operate, and manage access to your Codec Server in your own environment.
The Temporal CLI and the Web UI in turn provide built-in hooks to call the Codec Server to decode encrypted payloads on demand.
Refer to the [Codec Server](/production-deployment/data-encryption) documentation for information on how to design and deploy a Codec Server.

## Payload conversion

Temporal SDKs provide a default [Payload Converter](/payload-converter) that can be customized to convert a custom data type to [Payload](/dataconversion#payload) and back.

### Conversion sequence {#conversion-sequence}

The order in which your encoding Payload Converters are applied depends on the order given to the Data Converter.
You can set multiple encoding Payload Converters to run your conversions.
When the Data Converter receives a value for conversion, it passes through each Payload Converter in sequence until the converter that handles the data type does the conversion.

Payload Converters can be customized independently of a Payload Codec.
Temporal's Converter architecture looks like this:

![Temporal converter architecture](/img/info/converter-architecture.png)

### Custom Payload Converter {#custom-payload-converter}

**How to use a custom Payload Converter using the Temporal Python SDK.**

Data Converters convert raw Temporal payloads to/from actual Python types.
A custom Data Converter of type `temporalio.converter.DataConverter` can be set via the `data_converter` client parameter.

The default Data Converter supports converting multiple types including:

- `None`
- `bytes`
- `google.protobuf.message.Message` - As JSON when encoding, but has ability to decode binary proto from other languages
- Anything that can be converted to JSON including:
  - Anything that [`json.dump`](https://docs.python.org/3/library/json.html#json.dump) supports natively
  - [dataclasses](https://docs.python.org/3/library/dataclasses.html)
  - Iterables including ones JSON dump may not support by default, e.g. `set`
  - Any class with a `dict()` method and a static `parse_obj()` method, e.g.
    [Pydantic models](https://pydantic-docs.helpmanual.io/usage/models)
    - The default data converter is deprecated for Pydantic models and will warn if used since not all fields work.
      See [this sample](https://github.com/temporalio/samples-python/tree/main/pydantic_converter) for the recommended
      approach.
  - [IntEnum, StrEnum](https://docs.python.org/3/library/enum.html) based enumerates
  - [UUID](https://docs.python.org/3/library/uuid.html)

This notably doesn't include any `date`, `time`, or `datetime` objects, as they may not work across SDKs.

Users are strongly encouraged to use a single `dataclass` for parameter and return types so fields with defaults can be easily added without breaking compatibility.
Classes with generics may not have the generics properly resolved.
The current implementation does not have generic type resolution. Users should use concrete types.

### Custom Type Data Conversion

When converting from JSON, Workflow and Activity type hints are taken into account to convert to the proper types.
All common Python typings including `Optional`, `Union`, all forms of iterables and mappings, and `NewType` are supported in addition the regular JSON values mentioned before.

In Python, Data Converters contain a reference to a Payload Converter class that is used to convert input and output payloads.
By default, the Payload Converter is a `CompositePayloadConverter` which contains multiple `EncodingPayloadConverter`s to try to serialize/deserialize payloads.
Upon serialization, each `EncodingPayloadConverter` is used in order until one succeeds.

To implement a custom encoding for a custom type, a new `EncodingPayloadConverter` can be created.
For example, to support `IPv4Address` types:

```python
class IPv4AddressEncodingPayloadConverter(EncodingPayloadConverter):
    @property
    def encoding(self) -> str:
        return "text/ipv4-address"

    def to_payload(self, value: Any) -> Optional[Payload]:
        if isinstance(value, ipaddress.IPv4Address):
            return Payload(
                metadata={"encoding": self.encoding.encode()},
                data=str(value).encode(),
            )
        else:
            return None

    def from_payload(self, payload: Payload, type_hint: Optional[Type] = None) -> Any:
        assert not type_hint or type_hint is ipaddress.IPv4Address
        return ipaddress.IPv4Address(payload.data.decode())

class IPv4AddressPayloadConverter(CompositePayloadConverter):
    def __init__(self) -> None:
        # Just add ours as first before the defaults
        super().__init__(
            IPv4AddressEncodingPayloadConverter(),
            *DefaultPayloadConverter.default_encoding_payload_converters,
        )

my_data_converter = dataclasses.replace(
    DataConverter.default,
    payload_converter_className=IPv4AddressPayloadConverter,
)
```

This is good for many custom types. However, you might need to override the behavior of the just the existing JSON encoding payload converter to support a new type.
It is already the last encoding data converter in the list, so it's the fall-through behavior for any otherwise unknown type.
Customizing the existing JSON converter has the benefit of making the type work in lists, unions, etc.
The conversion can be customized for serialization with a custom `json.JSONEncoder` and deserialization with a custom `JSONTypeConverter`.
For example, to support `IPv4Address` types in existing JSON conversion:

```python
class IPv4AddressJSONEncoder(AdvancedJSONEncoder):
    def default(self, o: Any) -> Any:
        if isinstance(o, ipaddress.IPv4Address):
            return str(o)
        return super().default(o)
class IPv4AddressJSONTypeConverter(JSONTypeConverter):
    def to_typed_value(
        self, hint: Type, value: Any
    ) -> Union[Optional[Any], _JSONTypeConverterUnhandled]:
        if issubclass(hint, ipaddress.IPv4Address):
            return ipaddress.IPv4Address(value)
        return JSONTypeConverter.Unhandled

class IPv4AddressPayloadConverter(CompositePayloadConverter):
    def __init__(self) -> None:
        # Replace default JSON plain with our own that has our encoder and type
        # converter
        json_converter = JSONPlainPayloadConverter(
            encoder=IPv4AddressJSONEncoder,
            custom_type_converters=[IPv4AddressJSONTypeConverter()],
        )
        super().__init__(
            *[
                c if not isinstance(c, JSONPlainPayloadConverter) else json_converter
                for c in DefaultPayloadConverter.default_encoding_payload_converters
            ]
        )

my_data_converter = dataclasses.replace(
    DataConverter.default,
    payload_converter_className=IPv4AddressPayloadConverter,
)
```

Now `IPv4Address` can be used in type hints including collections, optionals, etc.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/cloud-automation.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/cloud-automation.mdx</path>
  <content>
---
id: cloud-automation
title: Cloud automation - Temporal feature
description: Explore how cloud automation simplifies cloud management and enhances security through APIs, Terraform, and CLI.
sidebar_label: Cloud automation
tags:
- Temporal Cloud
- tcld
- API Keys
- Terraform
keywords:
- cloud automation
- Temporal Cloud
- cloud management
- automation
- API keys
- Terraform provider
- CLI
- mTLS certificates
- cloud security
- tcld
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal Cloud Automation changes the way how you manage and scale your cloud infrastructure.
Its features enable you to automate critical tasks like user and namespace management, mTLS certificate rotation, and access control, ensuring security and operational efficiency.
Cloud Automation offers secure authentication across all interfaces, reducing errors and enhancing security.

**Key Features:**

- [Secure API Keys](https://docs.temporal.io/cloud/api-keys): Manage resources securely with Temporal Cloud API Keys.
- [Temporal Cloud CLI (tcld)](https://docs.temporal.io/cloud/tcld): Automate operations directly from the command line.
- [Terraform Provider for Cloud](https://docs.temporal.io/production-deployment/cloud/terraform-provider#prerequisites): Scale effortlessly with infrastructure-as-code.

<RelatedReadContainer>
  <RelatedReadItem path="https://docs.temporal.io/cloud/api-keys" text="API Keys documentation" archetype="cloud-guide" />
  <RelatedReadItem path="https://docs.temporal.io/ops?_gl=1*1yf937l*_gcl_au*MTg1MTAxMTEwNC4xNzEzOTcxMjYw*_ga*MTgwODU1MzQyNi4xNzA3NzA4ODIz*_ga_R90Q9SJD3D*MTcyMTI0MTAyNy41MjIuMS4xNzIxMjQ5NTYxLjAuMC4w" text="Cloud Ops API documentation" archetype="cloud-guide" />
  <RelatedReadItem path="/cloud/tcld" text="Temporal Cloud CLI" archetype="cloud-guide" />
  <RelatedReadItem path="/production-deployment/cloud/terraform-provider" text="Terraform Provider for Cloud" archetype="cloud-guide" />
</RelatedReadContainer>

From centralizing cloud operations and automating certificate rotation to streamlining user management and onboarding new teams, Temporal's Cloud Automation features covers a wide range of use cases that enhance efficiency and security across your organization.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/sla.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/sla.mdx</path>
  <content>
---
id: sla
title: Service Level Agreement (SLA) - Temporal Cloud
sidebar_label: SLA
description: Temporal Cloud offers two availability levels; 99.99% uptime for standard and High Availability feature deployments, with SLAs guaranteeing 99.9% and 99.99% against service errors, respectively.
slug: /cloud/sla
toc_max_heading_level: 4
keywords:
  - explanation
  - operations
  - temporal cloud
tags:
  - Temporal Cloud
  - Support
---

**What is Temporal Cloud's Service Level Agreement? SLA?**

Temporal Cloud provides two availability levels: the [service availability](https://en.wikipedia.org/wiki/Reliability,_availability_and_serviceability) and the contractual [service level agreement](https://en.wikipedia.org/wiki/Service-level_agreement) (SLA).
These levels are set by your deployment mode:

- **Temporal Cloud with standard single-region deployment**:
  Standard Temporal Cloud deployment provides 99.99% availability and a contractual service level agreement (SLA) of 99.9% guarantee against service errors.
- **Temporal Cloud with High Availability feature Namespace deployment**:
  Temporal Cloud Namespaces that use the High Availability feature provide 99.99% availability and contractual service level agreement (SLA) of 99.99% guarantee against service errors.

The same SLA for normal Worker requests (commands and polling) apply to Nexus in both the caller and handler Namespaces.

To calculate the service-error rate, Temporal Cloud captures all requests that arrive in a Namespace during a five-minute interval.
We record the number of gRPC service errors that occurred.
For each Namespace, we calculate the service-error rate as 1 - (count of errors / count of requests).
Rates are averaged per month and reset quarterly.

Errors are recorded against the SLA are service errors, such as the `UNAVAILABLE` [gRPC status code](https://grpc.github.io/grpc/core/md_doc_statuscodes.html).
The following errors are _not_ counted against the SLA:

- `ClientVersionNotSupported`
- `InvalidArgument`
- `NamespaceAlreadyExists`
- `NamespaceInvalidState`
- `NamespaceNotActive`
- `NamespaceNotFound`
- `NotFound`
- `PermissionDenied`
- `QueryFailed`
- `RetryReplication`
- `StickyWorkerUnavailable`
- `TaskAlreadyStarted`
- `Throttling (resources exhausted; triggers retry)`
- `WorkflowExecutionAlreadyStarted`
- `WorkflowNotReady`

Our internal alerting system is based on a [service level objective](https://en.wikipedia.org/wiki/Service-level_objective) (SLO) for all errors, not just errors that count against the SLA.
When we receive an alert that an SLO is not being met, we page our on-call engineers, which often means that issues are resolved before they become noticeable.

Internally, our components are distributed across a minimum of three availability zones per region.
We implement a cell architecture.
Each cell contains the software and services necessary to host a Namespace.
Within each cell, the components are distributed across a minimum of three availability zones per region.

For current system status and information about recent incidents, see [Temporal Status](https://status.temporal.io).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/workers.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/workers.mdx</path>
  <content>
---
id: workers
title: What is a Temporal Worker?
sidebar_label: Workers
description: Temporal Workers are tightly coupled with Task Queues and Worker Processes.
slug: /workers
toc_max_heading_level: 4
keywords:
  - workers
  - versioning
tags:
  - Workers
  - Concepts
---

This page discusses the following:

- [Worker](#worker)
- [Worker Program](#worker-program)
- [Worker Entity](#worker-entity)
- [Worker Identity?](#worker-identity)

## What is a Worker? {#worker}

In day-to-day conversations, the term Worker is used to denote either a [Worker Program](#worker-program), a [Worker Process](#worker-process), or a [Worker Entity](/workers#worker-entity).
Temporal documentation aims to be explicit and differentiate between them.

## What is a Worker Program? {#worker-program}

A Worker Program is the static code that defines the constraints of the Worker Process, developed using the APIs of a Temporal SDK.

:::info

- [How to run a development Worker using the Go SDK](/develop/go/core-application#develop-worker)
- [How to run a development Worker using the Java SDK](/develop/java/core-application#run-a-dev-worker)
- [How to run a development Worker using the PHP SDK](/develop/php/core-application#run-a-dev-worker)
- [How to run a development Worker using the Python SDK](/develop/python/core-application#run-a-dev-worker)
- [How to run a development Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-dev-worker)
- [How to run a development Worker using the .NET SDK](/develop/dotnet/core-application#run-worker-process)

- [How to run a Temporal Cloud Worker using the Go SDK](/develop/go/core-application#run-a-temporal-cloud-worker)
- [How to run a Temporal Cloud Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-temporal-cloud-worker)

:::

## What is a Worker Entity? {#worker-entity}

A Worker Entity is the individual Worker within a Worker Process that listens to a specific Task Queue.

A Worker Entity listens and polls on a single Task Queue.
A Worker Entity contains a Workflow Worker and/or an Activity Worker, which makes progress on Workflow Executions and Activity Executions, respectively.

**Can a Worker handle more Workflow Executions than its cache size or number of supported threads?**

Yes it can.
However, the trade off is added latency.

Workers are stateless, so any Workflow Execution in a blocked state can be safely removed from a Worker.
Later on, it can be resurrected on the same or different Worker when the need arises (in the form of an external event).
Therefore, a single Worker can handle millions of open Workflow Executions, assuming it can handle the update rate and that a slightly higher latency is not a concern.

**Operation guides:**

- [How to tune Workers](/develop/worker-performance)

## What is a Worker Identity? {#worker-identity}

Workers have an associated identifier that helps identify the specific Worker instance.
By default, Temporal SDKs set a Worker Identity to `${process.pid}@${os.hostname()}`, which combines the Worker's process ID (`process.pid`) and the hostname of the machine running the Worker (`os.hostname()`).

The Worker Identity is visible in various contexts, such as Workflow History and the list of pollers on a Task Queue.

You can use the Worker Identity to aid in debugging operational issues.
By providing a user assigned identifier, you can trace issues back to specific Worker instances.

**What are some limitations of the default identity?**

While the default identity format may seem sensible, it often proves to be of limited usefulness in cloud environments.
Some common issues include:

- **Docker containers**: When running Workers inside Docker containers, the process ID is always `1`, as each container typically runs a single process. This makes the process identifier meaningless for identification purposes.
- **Random hostnames**: In some cloud environments, such as Amazon ECS (Elastic Container Service), the hostname is a randomly generated string that does not provide any meaningful information about the Worker's execution context.
- **Ephemeral IP addresses**: In certain cases, the hostname might be set to an ephemeral IP address, which can change over time and does not uniquely identify a Worker instance.

**What are some recommended approaches?**

It is recommended that you ensure that the Worker Identity can be linked back to the corresponding machine, process, execution context, or log stream.
In some execution environment, this might require that you explicitly specify the Worker Identity.

Here are some approaches:

- **Use environment-specific identifiers**: Choose an identifier that is specific to your execution environment. For example, when running Workers on Amazon ECS, you can set the Worker Identity to the ECS Task ID, which uniquely identifies the task running the Worker.
- **Include relevant context**: Incorporate information that helps establish the context of the Worker, such as the deployment environment (`staging` or `production`), region, or any other relevant details.
- **Ensure uniqueness**: Make sure that the Worker Identity is unique within your system to avoid ambiguity when debugging issues.
- **Keep it concise**: While including relevant information is important, try to keep the Worker Identity concise and easily readable to facilitate quick identification and troubleshooting.

## What is a Worker Process? {#worker-process}

<div className="tdiw">
  <div className="tditw">
    <p className="tdit">
      Component diagram of a Worker Process and the Temporal Server
    </p>
  </div>
  <div className="tdiiw" height="422">
    <img
      className="img_ev3q"
      src="/diagrams/worker-and-server-component.svg"
      alt="Component diagram of a Worker Process and the Temporal Server"
    />
  </div>
</div>

A Worker Process is responsible for polling a [Task Queue](/task-queue), dequeueing a [Task](/tasks#task), executing your code in response to a Task, and responding to the [Temporal Service](/clusters) with the results.

More formally, a Worker Process is any process that implements the Task Queue Protocol and the Task Execution Protocol.

- A Worker Process is a Workflow Worker Process if the process implements the Workflow Task Queue Protocol and executes the Workflow Task Execution Protocol to make progress on a Workflow Execution.
  A Workflow Worker Process can listen on an arbitrary number of Workflow Task Queues and can execute an arbitrary number of Workflow Tasks.
- A Worker Process is an Activity Worker Process if the process implements the Activity Task Queue Protocol and executes the Activity Task Processing Protocol to make progress on an Activity Execution.
  An Activity Worker Process can listen on an arbitrary number of Activity Task Queues and can execute an arbitrary number of Activity Tasks.

**Worker Processes are external to a Temporal Service.**
Temporal Application developers are responsible for developing [Worker Programs](#worker-program) and operating Worker Processes.
Said another way, the [Temporal Service](/clusters) (including the Temporal Cloud) doesn't execute any of your code (Workflow and Activity Definitions) on Temporal Service machines. The Temporal Service is solely responsible for orchestrating [State Transitions](/workflows#state-transition) and providing Tasks to the next available [Worker Entity](/workers#worker-entity).

While data transferred in Event Histories is [secured by mTLS](/self-hosted-guide/security#encryption-in-transit-with-mtls), by default, it is still readable at rest in the Temporal Service.

To solve this, Temporal SDKs offer a [Data Converter API](/dataconversion) that you can use to customize the serialization of data going out of and coming back in to a Worker Entity, with the net effect of guaranteeing that the Temporal Service cannot read sensitive business data.

In many of our tutorials, we show you how to run both a Temporal Service and one Worker on the same machine for local development.
However, a production-grade Temporal Application typically has a _fleet_ of Worker Processes, all running on hosts external to the Temporal Service.
A Temporal Application can have as many Worker Processes as needed.

A Worker Process can be both a Workflow Worker Process and an Activity Worker Process.
Many SDKs support the ability to have multiple Worker Entities in a single Worker Process.
(Worker Entity creation and management differ between SDKs.)
A single Worker Entity can listen to only a single Task Queue.
But if a Worker Process has multiple Worker Entities, the Worker Process could be listening to multiple Task Queues.

![Entity relationship diagram (meta model) of Worker Processes, Task Queues, and Tasks](/diagrams/worker-and-server-entity-relationship.svg)

Worker Processes executing Activity Tasks must have access to any resources needed to execute the actions that are defined in Activity Definitions, such as the following:

- Network access for external API calls.
- Credentials for infrastructure provisioning.
- Specialized GPUs for machine learning utilities.

The Temporal Service itself has [internal workers](https://temporal.io/blog/workflow-engine-principles/#system-workflows-1910) for system Workflow Executions.
However, these internal workers are not visible to the developer.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/index.mdx</path>
  <content>
---
id: index
title: Temporal Encyclopedia
description: Discover the key concepts, components, and features of Temporal for building scalable and reliable applications. Learn about Temporal SDKs, Workflows, Activities, Workers, and more.
sidebar_label: Encyclopedia
keywords:
  - concepts
---

[Temporal](/evaluate/why-temporal) provides developers a suite of effective tools for building reliable applications at scale.

The following Encyclopedia pages describe the concepts, components, and features of Temporal in detail:

- [Temporal](/temporal)
- [Temporal SDKs](/encyclopedia/temporal-sdks)
- [Workflows](/workflows)
- [Activities](/activities)
- [Workers](/workers)
- [Retry Policies](/encyclopedia/retry-policies)
- [Temporal Service](/clusters)
- [Visibility](/visibility)
- [Namespaces](/namespaces)
- [Temporal Nexus](/nexus)
- [Data conversion](/dataconversion)

For a complete list of Temporal terms, see the [Glossary](/glossary).

For information on how to implement the developer-facing features see the [Develop](/develop) section.

For information on how to use Temporal Cloud see the [Temporal Cloud production deployment](/cloud) section.

For information on how to self-host a Temporal Service see the [Self-hosted production deployment](/self-hosted-guide) section.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/worker-deployments.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/worker-deployments.mdx</path>
  <content>
---
id: worker-deployments
title: What is a Temporal Worker Deployment? 
sidebar_label: Worker Deployments
description: Temporal Worker Deployments help you manage and deploy your Worker services.
slug: /worker-deployments
toc_max_heading_level: 4
keywords:
  - workers
  - versioning
  - deployments
  - deployment versions
tags:
  - Workers
  - Concepts
  - Deployments
  - Deployment Versions
---

This page defines [Worker Deployments](#deployments) and [Worker Deployment Versions](#deployment-versions) and explains their use cases.

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

The Worker Deployments feature is available in [Pre-release](/evaluate/development-production-features/release-stages#pre-release).

Supported Worker Deployment Clients include:

- Temporal CLI: version [v1.3.0](https://github.com/temporalio/cli/releases/tag/v1.3.0) or higher
- Go SDK: version [v1.33.0](https://github.com/temporalio/sdk-go/releases/tag/v1.33.0) or higher
- Other SDKs: coming soon!

Open source users need:

- Temporal Server: version [v1.27.1](https://github.com/temporalio/temporal/releases/tag/v1.27.1) or higher
- Open Source UI: version [v2.36.0](https://github.com/temporalio/ui/releases/tag/v2.36.0) or higher

:::

## What are Worker Deployments? {#deployments}

A Worker Deployment is a logical service that groups similar Workers together for unified management.
Each Deployment has a name (such as your service name) and supports versioning through a series of [Worker Deployment Versions](#deployment-versions).

## What are Worker Deployment Versions? {#deployment-versions}

A Worker Deployment Version represents an iteration of a Worker Deployment.
Each Deployment Version consists of Workers that share the same code build and environment.
When a Worker starts polling for Workflow and Activity Tasks, it reports its Deployment Version to the Temporal Server.

## What can I do with Worker Deployments? {#use-cases}

Worker Deployments currently support [Worker Versioning](/worker-versioning), with more features planned for the future.

## How do I enable Worker Deployments? {#how-to}

:::note

Temporal Server disables Worker Deployments by default.

Temporal Cloud customers: Contact your Temporal account team or the [Temporal Support Team](https://docs.temporal.io/cloud/support#support-ticket) for Pre-release access.

Open source users: Enable the [system.enableDeploymentVersions](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) and [frontend.workerVersioningWorkflowAPIs](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) dynamic config values by setting both to `true`.

For example, with the Temporal CLI, run:

```command
temporal server start-dev \
   --dynamic-config-value system.enableDeploymentVersions=true \
   --dynamic-config-value frontend.workerVersioningWorkflowAPIs=true
```

:::

To add your Worker to a Deployment, provide both the Deployment name and Version when creating your Worker.
When your deployment system is ready, turn on Versioning as well. Refer to [Worker Versioning](/worker-versioning) for details.

When running multiple Workers in one process (such as using multiple [Task Queues](/task-queue)), you'll typically use the same Deployment name for all of them, since they belong to the same service.

The server will automatically register new Deployments and Deployment Versions when a Worker connects. You can see the status of Versions on the Deployments page in [Temporal UI](https://docs.temporal.io/web-ui).

:::info

SDK-specific  documentation will be available soon.

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/server-options.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/server-options.mdx</path>
  <content>
---
id: server-options
title: Temporal Server options reference
sidebar_label: Server options
description: Run the Temporal Server as a Go application by incorporating the package go.temporal.io/server/temporal. Customize server options like Config, Authorization, and TLS.
toc_max_heading_level: 4
keywords:
  - reference
  - web-ui
tags:
  - Reference
---

You can run the [Temporal Server](/clusters#temporal-server) as a Go application by including the server package `go.temporal.io/server/temporal` and using it to create and start a Temporal Server.

The Temporal Server services can be run in various ways.
We recommend this approach for a limited number of situations.

```go
s, err := temporal.NewServer()
if err != nil {
	log.Fatal(err)
}
err = s.Start()
if err != nil{
	log.Fatal(err)
}
```

`NewServer()` accepts functions as parameters.
Each function returns a `ServerOption` that is applied to the instance.
Source code for parameter reference is here: https://github.com/temporalio/temporal/blob/main/temporal/server_option.go

### WithConfig

To launch a Temporal server, a configuration file is required. The server automatically searches for this configuration
in the default location ./config/development.yaml when starting. If you need to use a custom configuration, you can
specify it through the server's configuration option. For comprehensive details about configuration parameters and
structure, refer to the [official configuration documentation](https://pkg.go.dev/go.temporal.io/server/common/config).

```go
s, err := temporal.NewServer(
	temporal.WithConfig(cfg),
)
```

### WithConfigLoader

Load a custom configuration from a file.

```go
s, err := temporal.NewServer(
	temporal.WithConfigLoader(configDir, env, zone),
)
```

### ForServices

Sets the list of all valid temporal services.
The default can be used from the `go.temporal.io/server/temporal` package.

```go
s, err := temporal.NewServer(
	temporal.ForServices(temporal.Services),
)
```

### InterruptOn

This option provides a channel that interrupts the server on the signal from that channel.

- If `temporal.InterruptOn()` is not passed, `server.Start()` is never blocked and you need to call `server.Stop()` somewhere.
- If `temporal.InterruptOn(nil)` is passed, `server.Start()` blocks forever until the process is killed.
- If `temporal.InterruptOn(temporal.InterruptCh())` is passed, `server.Start()` blocks until you use Ctrl+C, which then gracefully shuts the server down.
- If `temporal.Interrupt(someCustomChan)` is passed, `server.Start()` blocks until a signal is sent to `someCustomChan`.

```go
s, err := temporal.NewServer(
	temporal.InterruptOn(temporal.InterruptCh()),
)
```

### WithAuthorizer

Sets a low level [authorization mechanism](/self-hosted-guide/security#authorizer-plugin) that determines whether to allow or deny inbound API calls.

```go
s, err := temporal.NewServer(
	temporal.WithAuthorizer(myAuthorizer),
)
```

### WithTLSConfigFactory

Overrides the default TLS configuration provider.
`TLSConfigProvider` is defined in the `go.temporal.io/server/common/rpc/encryption` package.

```go
s, err := temporal.NewServer(
	temporal.WithTLSConfigFactory(yourTLSConfigProvider),
)
```

### WithClaimMapper

Configures a [mechanism to map roles](/self-hosted-guide/security#claim-mapper) to `Claims` for authorization.

```go
s, err := temporal.NewServer(
  temporal.WithClaimMapper(func(cfg *config.Config) authorization.ClaimMapper {
  		logger := getYourLogger() // Replace with how you retrieve or initialize your logger
		return authorization.NewDefaultJWTClaimMapper(
			authorization.NewDefaultTokenKeyProvider(cfg, logger),
			cfg
		)
	}),
)
```

### WithCustomMetricsReporter

Sets a custom tally metric reporter.

```go
s, err := temporal.NewServer(
	temporal.WithCustomMetricsReporter(myReporter),
)
```

You can see the [Uber tally docs on custom reporter](https://github.com/uber-go/tally#report-your-metrics) and see a community implementation of [a reporter for Datadog's `dogstatsd` format](https://github.com/temporalio/temporal/pull/998#issuecomment-857884983).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/testing-suite.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/testing-suite.mdx</path>
  <content>
---
id: testing-suite
title: Testing - Python SDK
sidebar_label: Testing
description: The Temporal Application Testing guide covers Frameworks facilitating Workflow and integration testing, including end-to-end, integration, and unit tests. Learn to use mocked Activities, skip time in tests, and replay Workflow Executions.
toc_max_heading_level: 2
keywords:
  - python
  - sdk
  - testing
  - time-skipping
tags:
  - Testing
  - Python SDK
  - Temporal SDKs
---

The Testing section of the Temporal Application development guide describes the frameworks that facilitate Workflow and integration testing.

In the context of Temporal, you can create these types of automated tests:

- **End-to-end:** Running a Temporal Server and Worker with all its Workflows and Activities; starting and interacting with Workflows from a Client.
- **Integration:** Anything between end-to-end and unit testing.
  - Running Activities with mocked Context and other SDK imports (and usually network requests).
  - Running Workers with mock Activities, and using a Client to start Workflows.
  - Running Workflows with mocked SDK imports.
- **Unit:** Running a piece of Workflow or Activity code (a function or method) and mocking any code it calls.

We generally recommend writing the majority of your tests as integration tests.

Because the test server supports skipping time, use the test server for both end-to-end and integration tests with Workers.

## Test frameworks {#test-frameworks}

Some SDKs have support or examples for popular test frameworks, runners, or libraries.

One recommended framework for testing in Python for the Temporal SDK is [pytest](https://docs.pytest.org/), which can help with fixtures to stand up and tear down test environments, provide useful test discovery, and make it easy to write parameterized tests.

## Testing Activities {#test-activities}

An Activity can be tested with a mock Activity environment, which provides a way to mock the Activity context, listen to Heartbeats, and cancel the Activity.
This behavior allows you to test the Activity in isolation by calling it directly, without needing to create a Worker to run the Activity.

### Run an Activity {#run-an-activity}

If an Activity references its context, you need to mock that context when testing in isolation.

To run an Activity in a test, use the [`ActivityEnvironment`](https://python.temporal.io/temporalio.testing.ActivityEnvironment.html) class.

This class allows you to run any callable inside an Activity context.
Use it to test the behavior of your code under various conditions.

### Listen to Heartbeats {#listen-to-heartbeats}

When an Activity sends a Heartbeat, be sure that you can see the Heartbeats in your test code so that you can verify them.

To test a Heartbeat in an Activity, use the [`on_heartbeat()`](https://python.temporal.io/temporalio.testing.ActivityEnvironment.html#on_heartbeat) property of the [`ActivityEnvironment`](https://python.temporal.io/temporalio.testing.ActivityEnvironment.html) class.
This property sets a custom function that is called every time the `activity.heartbeat()` function is called within the Activity.

```python
@activity.defn
async def activity_with_heartbeats(param: str):
    activity.heartbeat(f"param: {param}")
    activity.heartbeat("second heartbeat")

env = ActivityEnvironment()
heartbeats = []
# Set the `on_heartbeat` property to a callback function that will be called for each Heartbeat sent by the Activity.
env.on_heartbeat = lambda *args: heartbeats.append(args[0])
# Use the run method to start the Activity, passing in the function that contains the Heartbeats and any necessary parameters.
await env.run(activity_with_heartbeats, "test")
# Verify that the expected Heartbeats are received by the callback function.
assert heartbeats == ["param: test", "second heartbeat"]
```

## Testing Workflows {#test-workflows}

### How to mock Activities {#mock-activities}

Mock the Activity invocation when unit testing your Workflows.

When integration testing Workflows with a Worker, you can mock Activities by providing mock Activity implementations to the Worker.

Provide mock Activity implementations to the Worker.

```python
import uuid
from temporalio.client import Client
from temporalio.worker import Worker

# Import your Activity Definition and real implementation
from hello.hello_activity import (
    ComposeGreetingInput,
    GreetingWorkflow,
    compose_greeting,
)

# Define your mocked Activity implementation
@activity.defn(name="compose_greeting")
async def compose_greeting_mocked(input: ComposeGreetingInput) -> str:
    return f"{input.greeting}, {input.name} from mocked activity!"

async def test_mock_activity(client: Client):
    task_queue_name = str(uuid.uuid4())
    # Provide the mocked Activity implementation to the Worker
    async with Worker(
        client,
        task_queue=task_queue_name,
        workflows=[GreetingWorkflow],
        activities=[compose_greeting_mocked],
    ):
        # Execute your Workflow as usual
        assert "Hello, World from mocked activity!" == await client.execute_workflow(
            GreetingWorkflow.run,
            "World",
            id=str(uuid.uuid4()),
            task_queue=task_queue_name,
        )
```

The mocked Activity implementation should have the same signature as the real implementation (including the input and output types) and the same name.
When the Workflow invokes the Activity, it invokes the mocked implementation instead of the real one, allowing you to test your Workflow isolated.

### How to skip time {#skip-time}

Some long-running Workflows can persist for months or even years.
Implementing the test framework allows your Workflow code to skip time and complete your tests in seconds rather than the Workflow's specified amount.

For example, if you have a Workflow sleep for a day, or have an Activity failure with a long retry interval, you don't need to wait the entire length of the sleep period to test whether the sleep function works.
Instead, test the logic that happens after the sleep by skipping forward in time and complete your tests in a timely manner.

The test framework included in most SDKs is an in-memory implementation of Temporal Server that supports skipping time.
Time is a global property of an instance of `TestWorkflowEnvironment`: skipping time (either automatically or manually) applies to all currently running tests.
If you need different time behaviors for different tests, run your tests in a series or with separate instances of the test server.
For example, you could run all tests with automatic time skipping in parallel, and then all tests with manual time skipping in series, and then all tests without time skipping in parallel.

#### Skip time automatically {#automatic-method}

You can skip time automatically in the SDK of your choice.
Start a test server process that skips time as needed.
For example, in the time-skipping mode, Timers, which include sleeps and conditional timeouts, are fast-forwarded except when Activities are running.

Use the [`start_time_skipping()`](https://python.temporal.io/temporalio.testing.WorkflowEnvironment.html#start_time_skipping) method to start a test server process and skip time automatically.

Use the [`start_local()`](https://python.temporal.io/temporalio.testing.WorkflowEnvironment.html#start_local) method for a full local Temporal Server.

Use the [`from_client()`](https://python.temporal.io/temporalio.testing.WorkflowEnvironment.html#from_client) method for an existing Temporal Server.

#### Skip time manually {#manual-method}

Learn to skip time manually in the SDK of your choice.

To implement time skipping, use the [`start_time_skipping()`](https://python.temporal.io/temporalio.testing.WorkflowEnvironment.html#start_time_skipping) static method.

```python
from temporalio.testing import WorkflowEnvironment

async def test_manual_time_skipping():
    async with await WorkflowEnvironment.start_time_skipping() as env:
        # Your code here
        # You can use the env.sleep(seconds) method to manually advance time
        await env.sleep(3) # This will advance time by 3 seconds
        # Your code here
```

### Assert in Workflow {#assert-in-workflow}

The `assert` statement is a convenient way to insert debugging assertions into the Workflow context.

The `assert` method is available in Python and TypeScript.

For information about assert statements in Python, see [`assert`](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement) in the Python Language Reference.

## How to Replay a Workflow Execution {#replay}

Replay recreates the exact state of a Workflow Execution.
You can replay a Workflow from the beginning of its Event History.

Replay succeeds only if the [Workflow Definition](/workflows#workflow-definition) is compatible with the provided history from a deterministic point of view.

When you test changes to your Workflow Definitions, we recommend doing the following as part of your CI checks:

1. Determine which Workflow Types or Task Queues (or both) will be targeted by the Worker code under test.
2. Download the Event Histories of a representative set of recent open and closed Workflows from each Task Queue, either programmatically using the SDK client or via the Temporal CLI.
3. Run the Event Histories through replay.
4. Fail CI if any error is encountered during replay.

The following are examples of fetching and replaying Event Histories:

To replay Workflow Executions, use the [`replay_workflows`](https://python.temporal.io/temporalio.worker.Replayer.html#replay_workflows) or [`replay_workflow`](https://python.temporal.io/temporalio.worker.Replayer.html#replay_workflow) methods, passing one or more Event Histories as arguments.

In the following example (which, as of server v1.18, requires Advanced Visibility to be enabled), Event Histories are downloaded from the server and then replayed.
If any replay fails, the code raises an exception.

```python
workflows = client.list_workflows(f"TaskQueue=foo and StartTime > '2022-01-01T12:00:00'")
histories = workflows.map_histories()
replayer = Replayer(
    workflows=[MyWorkflowA, MyWorkflowB, MyWorkflowC]
)
await replayer.replay_workflows(histories)
```

In the next example, a single history is loaded from a JSON string:

```python
replayer = Replayer(workflows=[YourWorkflow])
await replayer.replay_workflow(WorkflowHistory.from_json(history_json_str))
```

In both examples, if Event History is non-deterministic, an error is thrown.
You can choose to wait until all histories have been replayed with `replay_workflows` by setting the `fail_fast` option to `false`.

:::note

If the Workflow History is exported by [Temporal Web UI](/web-ui) or through [Temporal CLI](/cli), you can pass the JSON file history object as a JSON string or as a Python dictionary through the `json.load()` function, which takes a file object and returns the JSON object.

:::

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/schedules.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/schedules.mdx</path>
  <content>
---
id: schedules
title: Schedules - Python SDK
sidebar_label: Schedules
description: Learn how to Schedule, Create, Backfill, Delete, Describe, List, Pause, Trigger, and Update a Scheduled Workflow, along with Temporal Cron Jobs and Start Delay options.
slug: /develop/python/schedules
toc_max_heading_level: 2
keywords:
  - temporal python schedule workflow
  - create scheduled workflow
  - backfill scheduled workflow
  - delete scheduled workflow
  - describe scheduled workflow
  - list scheduled workflows
  - pause scheduled workflow
  - trigger scheduled workflow
  - update scheduled workflow
  - temporal cron jobs
  - workflow start delay
tags:
  - Workflows
  - Schedules
  - Python SDK
  - Temporal SDKs
---

This page shows how to do the following:

- [Schedule a Workflow](#schedule-a-workflow)
  - [Create a Scheduled Workflow](#create)
  - [Backfill a Scheduled Workflow](#backfill)
  - [Delete a Scheduled Workflow](#delete)
  - [Describe a Scheduled Workflow](#describe)
  - [List a Scheduled Workflow](#list)
  - [Pause a Scheduled Workflow](#pause)
  - [Trigger a Scheduled Workflow](#trigger)
  - [Update a Scheduled Workflow](#update)
- [Temporal Cron Jobs](#temporal-cron-jobs)
- [Start Delay](#start-delay)

## Schedule a Workflow {#schedule-a-workflow}

**How to Schedule a Workflow Execution**

Scheduling Workflows is a crucial aspect of any automation process, especially when dealing with time-sensitive tasks. By scheduling a Workflow, you can automate repetitive tasks, reduce the need for manual intervention, and ensure timely execution of your business processes

Use any of the following action to help Schedule a Workflow Execution and take control over your automation process.

### Create a Scheduled Workflow {#create}

**How to create a Scheduled Workflow**

The create action enables you to create a new Schedule. When you create a new Schedule, a unique Schedule ID is generated, which you can use to reference the Schedule in other Schedule commands.

To create a Scheduled Workflow Execution in Python, use the [create_schedule()](https://python.temporal.io/temporalio.client.Client.html#create_schedule)
asynchronous method on the Client.
Then pass the Schedule ID and the Schedule object to the method to create a Scheduled Workflow Execution.
Set the `action` parameter to `ScheduleActionStartWorkflow` to start a Workflow Execution.
Optionally, you can set the `spec` parameter to `ScheduleSpec` to specify the schedule or set the `intervals` parameter to `ScheduleIntervalSpec` to specify the interval.
Other options include: `cron_expressions`, `skip`, `start_at`, and `jitter`.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/start_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")

    await client.create_schedule(
        "workflow-schedule-id",
        Schedule(
            action=ScheduleActionStartWorkflow(
                YourSchedulesWorkflow.run,
                "my schedule arg",
                id="schedules-workflow-id",
                task_queue="schedules-task-queue",
            ),
            spec=ScheduleSpec(
                intervals=[ScheduleIntervalSpec(every=timedelta(minutes=2))]
            ),
            state=ScheduleState(note="Here's a note on my Schedule."),
        ),
    )
```

:::tip Schedule Auto-Deletion

Once a Schedule has completed creating all its Workflow Executions, the Temporal Service deletes it since it won’t fire again.
The Temporal Service doesn't guarantee when this removal will happen.

:::

### Backfill a Scheduled Workflow {#backfill}

**How to backfill a Scheduled Workflow**

The backfill action executes Actions ahead of their specified time range. This command is useful when you need to execute a missed or delayed Action, or when you want to test the Workflow before its scheduled time.

To Backfill a Scheduled Workflow Execution in Python, use the [backfill()](https://python.temporal.io/temporalio.client.ScheduleHandle.html#backfill) asynchronous
method on the Schedule Handle.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/backfill_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
import asyncio
from datetime import datetime, timedelta

from temporalio.client import Client, ScheduleBackfill, ScheduleOverlapPolicy



async def main():
    client = await Client.connect("localhost:7233")
    handle = client.get_schedule_handle(
        "workflow-schedule-id",
    )
    now = datetime.utcnow()
    (
        await handle.backfill(
            ScheduleBackfill(
                start_at=now - timedelta(minutes=10),
                end_at=now - timedelta(minutes=9),
                overlap=ScheduleOverlapPolicy.ALLOW_ALL,
            ),
        ),
    )
```

### Delete a Scheduled Workflow {#delete}

**How to delete a Scheduled Workflow**

The delete action enables you to delete a Schedule. When you delete a Schedule, it does not affect any Workflows that were started by the Schedule.

To delete a Scheduled Workflow Execution in Python, use the [delete()](https://python.temporal.io/temporalio.client.ScheduleHandle.html#delete) asynchronous method on the Schedule Handle.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/delete_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
async def main():
    client = await Client.connect("localhost:7233")
    handle = client.get_schedule_handle(
        "workflow-schedule-id",
    )

    await handle.delete()
```

### Describe a Scheduled Workflow {#describe}

**How to describe a Scheduled Workflow**

The describe action shows the current Schedule configuration, including information about past, current, and future Workflow Runs. This command is helpful when you want to get a detailed view of the Schedule and its associated Workflow Runs.

To describe a Scheduled Workflow Execution in Python, use the [describe()](https://python.temporal.io/temporalio.client.ScheduleHandle.html#delete) asynchronous method on the Schedule Handle.
You can get a complete list of the attributes of the Scheduled Workflow Execution from the [ScheduleDescription](https://python.temporal.io/temporalio.client.ScheduleDescription.html) class.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/describe_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")
    handle = client.get_schedule_handle(
        "workflow-schedule-id",
    )

    desc = await handle.describe()

    print(f"Returns the note: {desc.schedule.state.note}")
```

### List a Scheduled Workflow {#list}

**How to list a Scheduled Workflow**

The list action lists all the available Schedules. This command is useful when you want to view a list of all the Schedules and their respective Schedule IDs.

To list all schedules, use the [list_schedules()](https://python.temporal.io/temporalio.client.Client.html#list_schedules) asynchronous method on the Client.
If a schedule is added or deleted, it may not be available in the list immediately.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/list_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main() -> None:
    client = await Client.connect("localhost:7233")
    async for schedule in await client.list_schedules():
        print(f"List Schedule Info: {schedule.info}.")
```

### Pause a Scheduled Workflow {#pause}

**How to pause a Scheduled Workflow**

The pause action enables you to pause and unpause a Schedule. When you pause a Schedule, all the future Workflow Runs associated with the Schedule are temporarily stopped. This command is useful when you want to temporarily halt a Workflow due to maintenance or any other reason.

To pause a Scheduled Workflow Execution in Python, use the [pause()](https://python.temporal.io/temporalio.client.ScheduleHandle.html#pause) asynchronous method on the Schedule Handle.
You can pass a `note` to the `pause()` method to provide a reason for pausing the schedule.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/pause_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")
    handle = client.get_schedule_handle(
        "workflow-schedule-id",
    )

    await handle.pause(note="Pausing the schedule for now")
```

### Trigger a Scheduled Workflow {#trigger}

**How to trigger a Scheduled Workflow**

The trigger action triggers an immediate action with a given Schedule. By default, this action is subject to the Overlap Policy of the Schedule. This command is helpful when you want to execute a Workflow outside of its scheduled time.

To trigger a Scheduled Workflow Execution in Python, use the [trigger()](https://python.temporal.io/temporalio.client.ScheduleHandle.html#trigger) asynchronous method on the Schedule Handle.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/trigger_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
async def main():
    client = await Client.connect("localhost:7233")
    handle = client.get_schedule_handle(
        "workflow-schedule-id",
    )

    await handle.trigger()
```

### Update a Scheduled Workflow {#update}

**How to update a Scheduled Workflow**

The update action enables you to update an existing Schedule. This command is useful when you need to modify the Schedule's configuration, such as changing the start time, end time, or interval.

Create a function that takes `ScheduleUpdateInput` and returns `ScheduleUpdate`.
To update a Schedule, use a callback to build the update from the description.
The following example updates the Schedule to use a new argument.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/schedule_your_workflow/update_schedule_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
    async def update_schedule_simple(input: ScheduleUpdateInput) -> ScheduleUpdate:
        schedule_action = input.description.schedule.action

        if isinstance(schedule_action, ScheduleActionStartWorkflow):
            schedule_action.args = ["my new schedule arg"]
        return ScheduleUpdate(schedule=input.description.schedule)
```

## Temporal Cron Jobs {#temporal-cron-jobs}

**How to use Temporal Cron Jobs**

:::caution Cron support is not recommended

We recommend using [Schedules](https://docs.temporal.io/workflows#schedule) instead of Cron Jobs.
Schedules were built to provide a better developer experience, including more configuration options and the ability to update or pause running Schedules.

:::

A [Temporal Cron Job](/workflows#temporal-cron-job) is the series of Workflow Executions that occur when a Cron Schedule is provided in the call to spawn a Workflow Execution.

A Cron Schedule is provided as an option when the call to spawn a Workflow Execution is made.

You can set each Workflow to repeat on a schedule with the `cron_schedule` option from either the [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) asynchronous methods.

<div class="copycode-notice-container">
  <a href="https://github.com/temporalio/documentation/blob/main/sample-apps/python/your_cron_job/your_cron_dacx.py">
    View the source code
  </a>{' '}
  in the context of the rest of the application code.
</div>

```python
# ...
    result = await client.execute_workflow(
        CronWorkflow.run,
        id="your-workflow-id",
        task_queue="your-task-queue",
        cron_schedule="* * * * *",
    )
    print(f"Results: {result}")
```

Temporal Workflow Schedule Cron strings follow this format:

```
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
* * * * *
```


## Start Delay {#start-delay}

**How to use Start Delay**

Use the `start_delay` to schedule a Workflow Execution at a specific one-time future point rather than on a recurring schedule.

Use the `start_delay` option in either the [`start_workflow()`](https://python.temporal.io/temporalio.client.Client.html#start_workflow) or [`execute_workflow()`](https://python.temporal.io/temporalio.client.Client.html#execute_workflow) asynchronous methods in the Client.

```python
async def main():
    client = await Client.connect("localhost:7233")

    result = await client.execute_workflow(
        YourWorkflow.run,
        "your name",
        id="your-workflow-id",
        task_queue="your-task-queue",
        start_delay=timedelta(hours=1, minutes=20, seconds=30)
    )

    print(f"Result: {result}")


if __name__ == "__main__":
    asyncio.run(main())
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/high-availability.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/high-availability.mdx</path>
  <content>
---
id: high-availability
title: High availability - Temporal Cloud and Self Hosted production feature
description: Temporal Cloud's Multi-region Namespaces offer automated failover, synchronized data replication, and high availability for workloads requiring disaster-tolerant deployment and 99.99% uptime. Use Global Namespace for self-hosted.
sidebar_label: High availability
tags:
  - Temporal Cloud
  - Production
  - High availability
keywords:
  - availability
  - explanation
  - failover
  - high-availability
  - multi-region
  - multi-region namespace
  - namespaces
  - temporal-cloud
  - term
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal offers high availability as a feature for both Temporal Cloud and self-hosted deployments. Multi-region Namespace ensures your applications remain operational even in the face of regional outages or service disruptions.

[Multi-region Namespaces for Temporal Cloud](/evaluate/development-production-features/multi-region-namespace): Temporal Cloud's Multi-region Namespaces offer automated failover, synchronized data replication, and high availability for workloads requiring disaster-tolerant deployment and 99.99% uptime.

<RelatedReadContainer>
    <RelatedReadItem path="/cloud/high-availability" text=" Namespaces with High Availability features for Temporal Cloud" archetype="encyclopedia" />
    <RelatedReadItem path="/global-namespace" text="Global Namespace for self-hosted deployments" archetype="encyclopedia" />
    <RelatedReadItem path="/cloud/pricing" text="Multi-region Pricing" archetype="encyclopedia" />
    <RelatedReadItem path="/cloud/high-availability/private-link" text="PrivateLink routing for Multi-region replication" archetype="encyclopedia" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/server.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/server.mdx</path>
  <content>
---
id: server
title: Temporal CLI server command reference
sidebar_label: server
description: Manage your Temporal Server easily with CLI commands. Start a local server using `temporal server start-dev` and access the Web UI at http://localhost:8233. Customize with multiple options.
toc_max_heading_level: 4
keywords:
  - cli reference
  - command-line-interface-cli
  - server
  - server start-dev
  - temporal cli
tags:
  - Temporal CLI
  - Development Server
---

Server commands allow you to start and manage the [Temporal Server](/clusters#temporal-server) from the command line.

Currently, `cli` server functionality extends to starting the Server.

## start-dev

The `temporal server start-dev` command starts a local [Temporal Server](/clusters#temporal-server).
You can access the Web UI at http://localhost:8233.
The default Frontend Service gRPC port used as a target endpoint for client calls is 7233.

Use the following options to change the behavior of this command.

- [--db-filename](/cli/cmd-options#db-filename)

- [--dynamic-config-value](/cli/cmd-options#dynamic-config-value)

- [--headless](/cli/cmd-options#headless)

- [--ip](/cli/cmd-options#ip)

- [--log-format](/cli/cmd-options#log-format)

- [--log-level](/cli/cmd-options#log-level)

- [--metrics-port](/cli/cmd-options#metrics-port)

- [--namespace](/cli/cmd-options#namespace)

- [--port](/cli/cmd-options#port)

- [--sqlite-pragma](/cli/cmd-options#sqlite-pragma)

- [--ui-asset-path](/cli/cmd-options#ui-asset-path)

- [--ui-codec-endpoint](/cli/cmd-options#ui-codec-endpoint)

- [--ui-ip](/cli/cmd-options#ui-ip)

- [--ui-port](/cli/cmd-options#ui-port)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/worker-versioning-legacy.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/worker-versioning-legacy.mdx</path>
  <content>
---
id: worker-versioning-legacy
title: Worker Versioning (Legacy) - Python SDK
description: Learn the Python SDK's outdated Worker Versioning APIs.
slug: /develop/python/worker-versioning-legacy
toc_max_heading_level: 2
keywords:
  - deprecated
  - python
tags:
  - Deprecated
  - Python SDK
---

## (Deprecated) How to use Worker Versioning in Python {#worker-versioning}

:::caution

This section is for a previous Worker Versioning API that is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning).

See the [Pre-release README](https://github.com/temporalio/temporal/blob/main/docs/worker-versioning.md) for more information.

:::

A Build ID corresponds to a deployment. If you don't already have one, we recommend a hash of the code--such as a Git SHA--combined with a human-readable timestamp.
To use [Worker Versioning](/worker-versioning), you need to pass a Build ID to your Java Worker and opt in to Worker Versioning.

### Assign a Build ID to your Worker and opt in to Worker Versioning

You should understand assignment rules before completing this step.
See the [Worker Versioning Pre-release README](https://github.com/temporalio/temporal/blob/main/docs/worker-versioning.md) for more information.

To enable Worker Versioning for your Worker, assign the Build ID--perhaps from an environment variable--and turn it on.

```python
# ...
worker = Worker(
  task_queue="your_task_queue_name",
  build_id=build_id,
  use_worker_versioning=True,
  # ... register workflows & activities, etc
)
# ...
```

:::warning

Importantly, when you start this Worker, it won't receive any tasks until you set up assignment rules.

:::

### Specify versions for Activities, Child Workflows, and Continue-as-New Workflows

:::caution

Python support for this feature is under construction!

:::

By default, Activities, Child Workflows, and Continue-as-New Workflows are run on the build of the workflow that created them if they are also configured to run on the same Task Queue.
When configured to run on a separate Task Queue, they will default to using the current assignment rules.

If you want to override this behavior, you can specify your intent via the `versioning_intent` argument available on the methods you use to invoke these commands.

For example, if you want an Activity to use the latest assignment rules rather than inheriting from its parent:

```python
# ...
await workflow.execute_activity(
    say_hello,
    "hi",
    versioning_intent=VersioningIntent.USE_ASSIGNMENT_RULES,
    start_to_close_timeout=timedelta(seconds=5),
)
# ...
```

### Tell the Task Queue about your Worker's Build ID (Deprecated)

:::caution

This section is for a previous Worker Versioning API that is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning).

:::

Now you can use the SDK (or the Temporal CLI) to tell the Task Queue about your Worker's Build ID.
You might want to do this as part of your CI deployment process.

```python
# ...
await client.update_worker_build_id_compatibility(
    "your_task_queue_name", BuildIdOpAddNewDefault("deadbeef")
)
```

This code adds the `deadbeef` Build ID to the Task Queue as the sole version in a new version set, which becomes the default for the queue.
New Workflows execute on Workers with this Build ID, and existing ones will continue to process by appropriately compatible Workers.

If, instead, you want to add the Build ID to an existing compatible set, you can do this:

```python
# ...
await client.update_worker_build_id_compatibility(
    "your_task_queue_name", BuildIdOpAddNewCompatible("deadbeef", "some-existing-build-id")
)
```

This code adds `deadbeef` to the existing compatible set containing `some-existing-build-id` and marks it as the new default Build ID for that set.

You can also promote an existing Build ID in a set to be the default for that set:

```python
# ...
await client.update_worker_build_id_compatibility(
    "your_task_queue_name", BuildIdOpPromoteBuildIdWithinSet("deadbeef")
)
```

You can also promote an entire set to become the default set for the queue. New Workflows will start using that set's default build.

```python
# ...
await client.update_worker_build_id_compatibility(
    "your_task_queue_name", BuildIdOpPromoteSetByBuildId("deadbeef")
)
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/visibility/dual-visibility.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/visibility/dual-visibility.mdx</path>
  <content>
---
id: dual-visibility
title: Dual Visibility
sidebar_label: Dual Visibility
description: This guide on Temporal Dual Visibility explains how to set up, configure, and use Dual Visibility in Temporal Server versions. Learn about configuring primary and secondary Visibility stores, migrating databases, and ensuring a smooth transition for Visibility data.
slug: /dual-visibility
toc_max_heading_level: 4
keywords:
  - explanation
  - filtered-lists
  - term
  - visibility
  - dual visibility
tags:
  - Concepts
  - Visibility
---

This page discusses [Dual Visibility](#dual-visibility).

## What is Dual Visibility? {#dual-visibility}

Dual Visibility is a feature that lets you set a secondary Visibility store in addition to a primary store in your Temporal Service.
Setting up Dual Visibility is optional and can be used to [migrate your Visibility database](/self-hosted-guide/visibility#migrating-visibility-database) or create a backup Visibility store.

For example, if you have Cassandra configured as your Visibility database, you can set up a supported SQL database as your secondary Visibility store and gradually migrate your data to the secondary store before deprecating your primary one.

A Dual Visibility setup requires two Visibility store configurations:

- **Primary Visibility:** The primary Visibility store where Visibility data is written to and read from by default. The primary Visibility store is set with the `visibilityStore` configuration key in your Temporal Service.
- **Secondary Visibility:** A secondary storage for your Visibility data. The secondary Visibility store is set with the `secondaryVisibilityStore` configuration key in your Temporal Service.

For configuration details, see [Dual Visibility setup](/self-hosted-guide/visibility#dual-visibility).

The following combinations are allowed in a Dual Visibility setting.

| Primary                     | Secondary                       |
| --------------------------- | ------------------------------- |
| Standard (Cassandra or SQL) | Advanced (SQL or Elasticsearch) |
| Advanced (SQL)              | Advanced (SQL)                  |
| Advanced (Elasticsearch)    | Advanced (Elasticsearch)        |

With Dual Visibility, you can read from only one Visibility store at a time, but can configure your Temporal Service to write to primary only, secondary only, or to both primary and secondary Visibility stores.
When migrating from one Visibility store database to another, set up the database you want to migrate to as your secondary Visibility store.

You can plan your migration using specific dynamic configuration keys that help you transition your read and write operations from the primary to the secondary Visibility store.
For details on migrating your Visibility store databases, see [Dual Visibility](/self-hosted-guide/visibility#dual-visibility).



  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/namespaces/namespaces.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/namespaces/namespaces.mdx</path>
  <content>
---
id: namespaces
title: Temporal Namespace
sidebar_label: Namespace
description: This guide covers everything about Namespaces within the Temporal Platform, highlighting their role in Workflow isolation, setting up, registering, and managing Namespaces, and the concept and benefits of Global Namespaces.
slug: /namespaces
toc_max_heading_level: 4
keywords:
  - namespaces
tags:
  - Concepts
  - Namespaces
---

This guide provides a comprehensive overview of Namespaces.

A Namespace is a unit of isolation within the Temporal Platform.

A single Namespace is still multi-tenant.

## Usage

Namespaces are created on the Temporal Service, and provide a range of controls to achieve isolation on Workflow Executions.

- Namespaces are a mechanism for resource isolation. Heavy traffic from one Namespace will not impact other Namespaces running on the same Temporal Service.
  For example, you can use Namespaces to match the development lifecycle by having separate `dev` and `prod` Namespaces.
- If no other Namespace is specified, the Temporal Service uses the Namespace "default" for all Temporal SDKs and the Temporal CLI.
  See the [Registration](#registration) section for details.
- Namespaces created on self-hosted Temporal Service are case-sensitive. For example, `foo` and `Foo` are two different Namespaces.
  On Temporal Cloud, Namespaces are case-insensitive, and we recommend using lowercase for Namespace names to avoid potential issues.
- **Membership:** [Task Queue](/task-queue) names and [Workflow Ids](/workflows#workflow-id) must all correspond to a specific Namespace.
  For example, when a Workflow Execution is spawned, it does so within a specific Namespace.
- **Uniqueness:** Temporal guarantees a unique Workflow Id within a Namespace.
  Workflow Executions may have the same Workflow Id if they are in different Namespaces.
- **Namespace Configuration:** Various configuration options like the [Retention Period](/clusters#retention-period) and the [Archival](/clusters#archival) destination are configured per Namespace through a special CRUD API or through the [Temporal CLI](/cli).

## Registration

Registering a Namespace creates the Namespace on the Temporal Service.
When you register your Namespace, you must also set the [Retention Period](/clusters#retention-period) for the Namespace.

On Temporal Cloud, use the [Temporal Cloud UI](/cloud/namespaces#create-a-namespace) or [tcld commands](https://docs.temporal.io/cloud/tcld/namespace/) to create and manage Namespaces.

On self-hosted Temporal Service, you can register your Namespaces using the Temporal CLI (recommended) or programmatically using APIs. Note that these APIs and Temporal CLI commands will not work with Temporal Cloud.

All SDKs require a Namespace on the Temporal Service (or Temporal Cloud) for their Client calls. If not set using Client options, the Workflow Client API looks for the `default` Namespace. If there is no default Namespace registered with your Temporal Service (or Temporal Cloud), all calls will throw errors.
You must register your Namespace with the Temporal Service (or Temporal Cloud) before setting it in your Client.

On self-hosted Temporal Service, you can register your Namespaces in the following ways:

- In your Temporal Service setup, create your Namespaces, including the default, in your setup script.
  For example:

  - If deploying through Docker Compose or using the [auto-setup image](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) in a custom Docker Compose application, the Namespace "default" is created, through the auto-setup script.
  - If deploying through the [Temporal Helm charts](https://github.com/temporalio/helm-charts), you can create the "default" Namespace by using the Temporal CLI; for example, `temporal operator namespace create --namespace default`

- Use the `temporal operator namespace create` or `temporal operator namespace update` command with the `--retention` modfiier to register your Namespaces, one at a time, and set the Retention Period on each.

  - [How to create a new Namespace using the Temporal CLI](/cli/operator#create)
  - [How to create a new Namespace using the Go SDK](/develop/go/namespaces#register-namespace)
  - [How to create a new Namespace using the Java SDK](/develop/java/namespaces#register-namespace)

- In your Client program, register your Namespace using `RegisterNamespaceRequest` API available in all the SDKs.

Note that registering a Namespace takes up to 15 seconds to complete. Ensure that you are waiting for this process to complete before making calls to the Namespace.

## Manage Namespaces

Use a custom [Authorizer](/self-hosted-guide/security#authorizer-plugin) on your Frontend Service in the Temporal Service to set restrictions on who can create, update, or deprecate Namespaces.

On Temporal Cloud, use the [Temporal Cloud UI](/cloud/namespaces) or [tcld commands](/cloud/tcld/namespace/) to manage Namespaces.

On self-hosted Temporal Service, you can manage your registered Namespaces using the Temporal CLI (recommended) or programmatically using APIs.

{/* Technically correct but is this confusing for people since you can do this for non-self-hosted: _/}
{/_ Note that these APIs and temporal CLI commands will not work with Temporal Cloud. */}

- [How to manage Namespaces using the Go SDK](/develop/go/namespaces#manage-namespaces)
- [How to manage Namespaces using the Java SDK](/develop/java/namespaces#manage-namespaces)

- Update information and configuration for a registered Namespace on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace update`](/cli/operator#update)
  - Use the Update Namespace API to update configuration on a Namespace.

- Get details for a registered Namespace on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace describe`](/cli/operator#describe)
  - Use the Describe Namespace to return information and configuration details for a registered Namespace.

- Get details for all registered Namespaces on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace list`](/cli/operator#list)
  - Use the List Namespace API to return information and configuration details for all registered Namespaces on your Temporal Service.

- Deprecate a Namespace: The Deprecate Namespace updates the state of a registered Namespace to "DEPRECATED". Once a Namespace is deprecated, you cannot start new Workflow Executions on it. All existing and running Workflow Executions on a deprecated Namespace will continue to run.

- Delete a Namespace: Deletes a Namespace and all Workflow Executions on the Namespace. Note that this API is supported for Temporal Server version 1.17 and later.
- With the Temporal CLI: [`temporal operator namespace delete`](/cli/operator#delete).
- Use the DeleteNamespace API to delete a registered Namespaces. All the running Workflow Executions on a deleted Namespace are also deleted.

## Setting

Set Namespaces in your SDK Client to isolate your Workflow Executions to the Namespace.
If you do not set a Namespace, all Workflow Executions started using the Client will be associated with the "default" Namespace. This means, you must have a default Namespace called "default" registered with your Temporal Service. See [Registration](#registration) for details.

{/* TODO add sample for this to link to -[How to set the Namespace for a Temporal Client](/) */}

- [How to list Namespaces in a Temporal Service using the Temporal CLI](/cli/operator#list)
- [How to view (describe) Namespace metadata and details using the Temporal CLI](/cli/operator#describe)


  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/configuration.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/configuration.mdx</path>
  <content>
---
id: configuration
title: Temporal Cluster configuration reference
sidebar_label: Cluster configuration
description: Configure a Temporal Cluster using the development.yaml file to set global parameters, metrics, security, persistence, and service roles, ensuring a streamlined setup and management process.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
---

Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file and may contain the following top-level sections:

- [`global`](#global)
- [`persistence`](#persistence)
- [`log`](#log)
- [`clusterMetadata`](#clustermetadata)
- [`services`](#services)
- [`publicClient`](#publicclient)
- [`archival`](#archival)
- [`namespaceDefaults`](#namespacedefaults)
- [`dcRedirectionPolicy`](#dcredirectionpolicy)
- [`dynamicConfigClient`](#dynamicconfigclient)

Changing any properties in the `development.yaml` file requires a process restart for changes to take effect.
Configuration parsing code is available [here](https://github.com/temporalio/temporal/blob/main/common/config/config.go).

## global

The `global` section contains process-wide configuration. See below for a minimal configuration (optional parameters are commented out.)

```yaml
global:
  membership:
    broadcastAddress: '127.0.0.1'
  metrics:
    prometheus:
      framework: 'tally'
      listenAddress: '127.0.0.1:8000'
```

### membership

The `membership` section controls the following membership layer parameters.

#### maxJoinDuration

The amount of time the service will attempt to join the gossip layer before failing.

Default is 10s.

#### broadcastAddress

Used by gossip protocol to communicate with other hosts in the same Cluster for membership info.
Use IP address that is reachable by other hosts in the same Cluster.
If there is only one host in the Cluster, you can use 127.0.0.1.
Check `net.ParseIP` for supported syntax, only IPv4 is supported.

### metrics

Configures the Cluster's metric subsystem.
Specific provides are configured using provider names as the keys.

- [`statsd`](#statsd)
- `prometheus`
- `m3`

#### prefix

The prefix to be applied to all outgoing metrics.

#### tags

The set of key-value pairs to be reported as part of every metric.

#### excludeTags

A map from tag name string to tag values string list.
This is useful to exclude some tags that might have unbounded cardinality.
The value string list can be used to whitelist values of that excluded tag to continue to be included.
For example, if you want to exclude `task_queue` because it has unbounded cardinality, but you still want to see a whitelisted value for `task_queue`.

#### statsd

The `statsd` sections supports the following settings:

- `hostPort`: The host:port of the statsd server.
- `prefix`: Specific prefix in reporting to `statsd`.
- `flushInterval`: Maximum interval for sending packets. (_Default_ 300ms).
- `flushBytes`: Specifies the maximum UDP packet size you wish to send. (_Default_ 1432 bytes).

#### prometheus

The `prometheus` sections supports the following settings:

- `framework`: The framework to use, currently supports `opentelemetry` and `tally`, default is `tally`. We plan to switch default to `opentelemetry` once its API become stable.
- `listenAddress`: Address for Prometheus to scrape metrics from.
  The Temporal Server uses the Prometheus client API, and the `listenAddress` configuration is used to listen for metrics.
- `handlerPath`: Metrics handler path for scraper; default is `/metrics`.

#### m3

The `m3` sections supports the following settings:

- `hostPort`: The host:port of the M3 server.
- `service`: The service tag to that this client emits.
- `queue`: M3 reporter queue size, default is 4k.
- `packetSize`: M3 reporter max packet size, default is 32k.

### pprof

- `port`: If specified, this will initialize pprof upon process start on the listed port.

### tls

The `tls` section controls the SSL/TLS settings for network communication and contains two subsections, `internode` and `frontend`.
The `internode` section governs internal service communication among roles where the `frontend` governs SDK client communication to the Frontend Service role.

Each of these subsections contain a `server` section and a `client` section.
The `server` contains the following parameters:

- `certFile`: The path to the file containing the PEM-encoded public key of the certificate to use.
- `keyFile`: The path to the file containing the PEM-encoded private key of the certificate to use.
- `requireClientAuth`: _boolean_ - Requires clients to authenticate with a certificate when connecting, otherwise known as mutual TLS.
- `clientCaFiles`: A list of paths to files containing the PEM-encoded public key of the Certificate Authorities you wish to trust for client authentication. This value is ignored if `requireClientAuth` is not enabled.

:::tip

See the [server samples repo](https://github.com/temporalio/samples-server/tree/master/tls) for sample TLS configurations.

:::

Below is an example enabling Server TLS (https) between SDKs and the Frontend APIs:

```yaml
global:
  tls:
    frontend:
      server:
        certFile: /path/to/cert/file
        keyFile: /path/to/key/file
      client:
        serverName: dnsSanInFrontendCertificate
```

Note, the `client` section generally needs to be provided to specify an expected DNS SubjectName contained in the presented server certificate via the `serverName` field; this is needed as Temporal uses IP to IP communication.
You can avoid specifying this if your server certificates contain the appropriate IP Subject Alternative Names.

Additionally, the `rootCaFiles` field needs to be provided when the client's host does not trust the Root CA used by the server.
The example below extends the above example to manually specify the Root CA used by the Frontend Services:

```yaml
global:
  tls:
    frontend:
      server:
        certFile: /path/to/cert/file
        keyFile: /path/to/key/file
      client:
        serverName: dnsSanInFrontendCertificate
        rootCaFiles:
          - /path/to/frontend/server/CA/files
```

Below is an additional example of a fully secured cluster using mutual TLS for both frontend and internode communication with manually specified CAs:

```yaml
global:
  tls:
    internode:
      server:
        certFile: /path/to/internode/cert/file
        keyFile: /path/to/internode/key/file
        requireClientAuth: true
        clientCaFiles:
          - /path/to/internode/serverCa
      client:
        serverName: dnsSanInInternodeCertificate
        rootCaFiles:
          - /path/to/internode/serverCa
    frontend:
      server:
        certFile: /path/to/frontend/cert/file
        keyFile: /path/to/frontend/key/file
        requireClientAuth: true
        clientCaFiles:
          - /path/to/internode/serverCa
          - /path/to/sdkClientPool1/ca
          - /path/to/sdkClientPool2/ca
      client:
        serverName: dnsSanInFrontendCertificate
        rootCaFiles:
          - /path/to/frontend/serverCa
```

**Note:** In the case that client authentication is enabled, the `internode.server` certificate is used as the client certificate among services. This adds the following requirements:

- The `internode.server` certificate must be specified on all roles, even for a frontend-only configuration.
- Internode server certificates must be minted with either **no** Extended Key Usages or **both** ServerAuth and ClientAuth EKUs.
- If your Certificate Authorities are untrusted, such as in the previous example, the internode server Ca will need to be specified in the following places:

  - `internode.server.clientCaFiles`
  - `internode.client.rootCaFiles`
  - `frontend.server.clientCaFiles`

## persistence

The `persistence` section holds configuration for the data store/persistence layer.
The following example shows a minimal specification for a password-secured Cluster using Cassandra.

```yaml
persistence:
  defaultStore: default
  visibilityStore: cass-visibility # The primary Visibility store.
  secondaryVisibilityStore: es-visibility # A secondary Visibility store added to enable Dual Visibility.
  numHistoryShards: 512
  datastores:
    default:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal'
        user: 'username'
        password: 'password'
    cass-visibility:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal_visibility'
    es-visibility:
      elasticsearch:
        version: 'v7'
        logLevel: 'error'
        url:
          scheme: 'http'
          host: '127.0.0.1:9200'
        indices:
          visibility: temporal_visibility_v1_dev
        closeIdleConnectionsInterval: 15s
```

The following top level configuration items are required:

### numHistoryShards

_Required_ - The number of history shards to create when initializing the Cluster.

**Warning:** This value is immutable and will be ignored after the first run.
Please ensure you set this value appropriately high enough to scale with the worst case peak load for this Cluster.

### defaultStore

_Required_ - The name of the data store definition that should be used by the Temporal server.

### visibilityStore

_Required_ - The name of the primary data store definition that should be used to set up [Visibility](/clusters#visibility) on the Temporal Cluster.

### secondaryVisibilityStore

_Optional_ - The name of the secondary data store definition that should be used to set up [Dual Visibility](/dual-visibility) on the Temporal Cluster.

### datastores

_Required_ - contains named data store definitions to be referenced.

Each definition is defined with a heading declaring a name (ie: `default:` and `visibility:` above), which contains a data store definition.

Data store definitions must be either `cassandra` or `sql`.

#### cassandra

A `cassandra` data store definition can contain the following values:

- `hosts`: _Required_ - "," separated Cassandra endpoints, e.g. "192.168.1.2,192.168.1.3,192.168.1.4".
- `port`: Default: 9042 - Cassandra port used for connection by `gocql` client.
- `user`: Cassandra username used for authentication by `gocql` client.
- `password`: Cassandra password used for authentication by `gocql` client.
- `keyspace`: _Required_ - the Cassandra keyspace.
- `datacenter`: The data center filter arg for Cassandra.
- `maxConns`: The max number of connections to this data store for a single TLS configuration.
- `tls`: See TLS below.

#### sql

A `sql` data store definition can contain the following values:

- `user`: Username used for authentication.
- `password`: Password used for authentication.
- `pluginName`: _Required_ - SQL database type.
  - _Valid values_: `mysql` or `postgres`.
- `databaseName` - _required_ - the name of SQL database to connect to.
- `connectAddr` - _required_ - the remote address of the database, e.g. "192.168.1.2".
- `connectProtocol` - _required_ - the protocol that goes with the `connectAddr`
  - _Valid values_: `tcp` or `unix`
- `connectAttributes` - a map of key-value attributes to be sent as part of connect `data_source_name` url.
- `maxConns` - the max number of connections to this data store.
- `maxIdleConns` - the max number of idle connections to this data store
- `maxConnLifetime` - is the maximum time a connection can be alive.
- `tls` - See below.

#### tls

The `tls` and `mtls` sections can contain the following values:

- `enabled` - _boolean_.
- `serverName` - name of the server hosting the data store.
- `certFile` - path to the cert file.
- `keyFile` - path to the key file.
- `caFile` - path to the ca file.
- `enableHostVerification` - _boolean_ - `true` to verify the hostname and server cert (like a wildcard for Cassandra cluster). This option is basically the inverse of `InSecureSkipVerify`. See `InSecureSkipVerify` in http://golang.org/pkg/crypto/tls/ for more info.

Note: `certFile` and `keyFile` are optional depending on server config, but both fields must be omitted to avoid using a client certificate.

## log

The `log` section is optional and contains the following possible values:

- `stdout` - _boolean_ - `true` if the output needs to go to standard out.
- `level` - sets the logging level.
  - _Valid values_ - debug, info, warn, error or fatal, default to info.
- `outputFile` - path to output log file.

## clusterMetadata

`clusterMetadata` contains the local cluster information. The information is used in [Multi-Cluster Replication](/clusters#multi-cluster-replication).

An example `clusterMetadata` section:

```yaml
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 10
  masterClusterName: 'active'
  currentClusterName: 'active'
  clusterInformation:
    active:
      enabled: true
      initialFailoverVersion: 0
      rpcAddress: '127.0.0.1:7233'
  #replicationConsumer:
  #type: kafka
```

- `currentClusterName` - _required_ - the name of the current cluster. **Warning:** This value is immutable and will be ignored after the first run.
- `enableGlobalNamespace` - _Default:_ `false`.
- `replicationConsumer` - determines which method to use to consume replication tasks. The type may be either `kafka` or `rpc`.
- `failoverVersionIncrement` - the increment of each cluster version when failover happens.
- `masterClusterName` - the master cluster name, only the master cluster can register/update namespace. All clusters can do namespace failover.
- `clusterInformation` - contains the local cluster name to `ClusterInformation` definition. The local cluster name should be consistent with `currentClusterName`. `ClusterInformation` sections consist of:
  - `enabled` - _boolean_ - whether a remote cluster is enabled for replication.
  - `initialFailoverVersion`
  - `rpcAddress` - indicate the remote service address (host:port). Host can be DNS name. Use `dns:///` prefix to enable round-robin between IP address for DNS name.

## services

The `services` section contains configuration keyed by service role type.
There are four supported service roles:

- `frontend`
- `matching`
- `worker`
- `history`

Below is a minimal example of a `frontend` service definition under `services`:

```yaml
services:
  frontend:
    rpc:
      grpcPort: 8233
      membershipPort: 8933
      bindOnIP: '0.0.0.0'
```

There are two sections defined under each service heading:

### rpc

_Required_

`rpc` contains settings related to the way a service interacts with other services. The following values are supported:

- `grpcPort`: Port on which gRPC will listen.
- `membershipPort`: Port used to communicate with other hosts in the same Cluster for membership info.
  Each service should use different port.
  If there are multiple Temporal Clusters in your environment (Kubernetes for example), and they have network access to each other, each Cluster should use a different membership port.
- `bindOnLocalHost`: Determines whether uses `127.0.0.1` as the listener address.
- `bindOnIP`: Used to bind service on specific IP, or `0.0.0.0`.
  Check `net.ParseIP` for supported syntax, only IPv4 is supported, mutually exclusive with `BindOnLocalHost` option.

**Note:** Port values are currently expected to be consistent among role types across all hosts.

## publicClient

The `publicClient` a required section describing the configuration needed to for worker to connect to Temporal server for background server maintenance.

- `hostPort` IPv4 host port or DNS name to reach Temporal frontend, [reference](https://github.com/grpc/grpc/blob/master/doc/naming.md)

Example:

```yaml
publicClient:
  hostPort: 'localhost:8933'
```

Use `dns:///` prefix to enable round-robin between IP address for DNS name.

## archival

_Optional_

Archival is an optional configuration needed to set up the [Archival store](/clusters#archival).
It can be enabled on `history` and `visibility` data.

The following list describes supported values for each configuration on the `history` and `visibility` data.

- `state`: State for Archival setting. Supported values are `enabled`, `disabled`. This value must be `enabled` to use Archival with any Namespace in your Cluster.
  - `enabled`: Enables Archival in your Cluster setup. When set to `enabled`, `URI` and `namespaceDefaults` values must be provided.
  - `disabled`: Disables Archival in your Cluster setup. When set to `disabled`, the `enableRead` value must be set to `false`, and under `namespaceDefaults`, `state` must be set to `disabled`, with no values set for `provider` and `URI` fields.
- `enableRead`: Supported values are `true` or `false`. Set to `true` to allow read operations from the archived Event History data.
- `provider`: Location where data should be archived. Subprovider configs are `filestore`, `gstorage`, `s3`, or `your_custom_provider`. Default configuration specifies `filestore`.

Example:

- To enable Archival in your Cluster configuration:

  ```yaml
  # Cluster-level Archival config enabled
  archival:
    # Event History configuration
    history:
      # Archival is enabled for the History Service data.
      state: 'enabled'
      enableRead: true
      # Namespaces can use either the local filestore provider or the Google Cloud provider.
      provider:
        filestore:
          fileMode: '0666'
          dirMode: '0766'
        gstorage:
          credentialsPath: '/tmp/gcloud/keyfile.json'
    # Configuration for archiving Visibility data.
    visibility:
      # Archival is enabled for Visibility data.
      state: 'enabled'
      enableRead: true
      provider:
        filestore:
          fileMode: '0666'
          dirMode: '0766'
  ```

- To disable Archival in your Cluster configuration:

  ```yaml
  # Cluster-level Archival config disabled
  archival:
    history:
      state: 'disabled'
      enableRead: false
    visibility:
      state: 'disabled'
      enableRead: false

  namespaceDefaults:
    archival:
      history:
        state: 'disabled'
      visibility:
        state: 'disabled'
  ```

For more details on Archival setup, see [Set up Archival](/self-hosted-guide/archival#set-up-archival).

## namespaceDefaults

_Optional_

Sets default Archival configuration for each Namespace using `namespaceDefaults` for `history` and `visibility` data.

- `state`: Default state of the Archival for the Namespace. Supported values are `enabled` or `disabled`.
- `URI`: Default URI for the Namespace.

For more details on setting Namespace defaults on Archival, see [Namespace creation in Archival setup](/self-hosted-guide/archival#namespace-creation)

Example:

```yaml
# Default values for a Namespace if none are provided at creation.
namespaceDefaults:
  # Archival defaults.
  archival:
    # Event History defaults.
    history:
      state: 'enabled'
      # New Namespaces will default to the local provider.
      URI: 'file:///tmp/temporal_archival/development'
    visibility:
      state: 'disabled'
      URI: 'file:///tmp/temporal_vis_archival/development'
```

## dcRedirectionPolicy

_Optional_

Contains the Frontend datacenter API redirection policy that you can use for cross-DC replication.

Supported values:

- `policy`: Supported values are `noop`, `selected-apis-forwarding`, and `all-apis-forwarding`.
  - `noop`: Not setting a value or setting `noop` means no redirection. This is the default value.
  - `selected-apis-forwarding`: Sets up forwarding for the following APIs to the active Cluster based on the Namespace.
    - `StartWorkflowExecution`
    - `SignalWithStartWorkflowExecution`
    - `SignalWorkflowExecution`
    - `RequestCancelWorkflowExecution`
    - `TerminateWorkflowExecution`
    - `QueryWorkflow`
  - `all-apis-forwarding`: Sets up forwarding for all APIs on the Namespace in the active Cluster.

Example:

```yaml
#...
dcRedirectionPolicy:
  policy: 'selected-apis-forwarding'
#...
```

## dynamicConfigClient

_Optional_

Configuration for setting up file-based [dynamic configuration](/clusters#dynamic-configuration) client for the Cluster.

This setting is required if specifying dynamic configuration. Supported configuration values are as follows:

- `filepath`: Specifies the path where the dynamic configuration YAML file is stored. The path should be relative to the root directory.
- `pollInterval`: Interval between the file-based client polls to check for dynamic configuration updates. The minimum period you can set is 5 seconds.

Example:

```yaml
dynamicConfigClient:
  filepath: 'config/dynamicconfig/development-cass.yaml'
  pollInterval: '10s'
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/index.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/index.mdx</path>
  <content>
---
id: index
title: Evaluate Temporal
sidebar_label: Evaluate
description: Temporal enhances distributed application development with clear code structure, fault-tolerance, and execution guarantees, trusted by thousands for mission-critical workloads.
collapsed: false
toc_max_heading_level: 4
keywords:
  - evaluate temporal
  - temporal
  - what is temporal
  - introduction to temporal
tags:
  - Temporal
---

Temporal is designed to make developing distributed applications a delightful experience.
Developers benefit from a clear approach to structure their code and visibility into the state of their application.
Applications benefit from fault-tolerance and execution guarantees.
Thousands of companies of all sizes are leveraging Temporal's capabilities for both mission critical and standard workloads.

- [Why Temporal](/evaluate/why-temporal)
- [Development and production features](/evaluate/development-production-features)
- [Use cases](/evaluate/use-cases-design-patterns)
- [Temporal Cloud](/cloud)
- [Security](/security)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/schedules.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/schedules.mdx</path>
  <content>
---
id: schedules
title: Schedules - Temporal feature
description: Learn the benefits of scheduling Temporal Workflows and explore best practices to ensure timely and efficient execution of your business processes.
sidebar_label: Schedules
tags:
  - Schedules
  - Workflows
keywords:
  - temporal schedules
  - automate Workflows
  - schedule Workflow executions
  - temporal scheduling best practices
  - Workflow automation temporal
  - schedule management
  - temporal Workflow scheduling
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal Schedules is a feature that allows you to "schedule" Temporal Workflows at specified times or intervals, adjusting for peak use.

It offers a flexible way to automate and manage your Temporal Workflows, ensuring your business processes run smoothly and efficiently especially when handling time-sensitive tasks.

1. **Automate Repetitive Tasks:**
   Schedules automate repetitive tasks, reducing manual intervention and ensuring timely execution of business processes.
2. **Enhanced Workflow Control and Observability:**
   Gain complete control over your automation processes. With Schedules, you can create, backfill, delete, describe, list, pause, trigger, and update Workflow Executions.
3. **Flexible Timing:**
   Schedule Workflow Executions to run at regular intervals or specific future times, ensuring they execute precisely when needed.
4. **Reliable and Scalable:**
   Designed for reliability and scalability, Temporal Schedules handle the complexities of distributed systems while ensuring your Workflows run as intended, even during failures.
5. **Eliminate External Dependencies:**
   Schedules remove the need to integrate external scheduling systems.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/schedules" text="Schedules using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/schedules" text="Schedules using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/schedules" text="Schedules using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/schedules" text="Schedules using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/schedules" text="Schedules using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/schedules" text="Schedules using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workers/worker-versioning.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workers/worker-versioning.mdx</path>
  <content>
---
id: worker-versioning
title: Worker Versioning
sidebar_label: Worker Versioning
description: Understand how Worker Versioning facilitates deployment changes.
slug: /worker-versioning
toc_max_heading_level: 4
keywords:
  - safe deployments
  - worker versioning
  - deployments
  - deployment versions
tags:
  - Workers
  - Concepts
  - Worker Versioning
---

This page discusses [Worker Versioning](#worker-versioning).

## What is Worker Versioning? {#worker-versioning}

Worker Versioning documentation is coming soon!

For now, please join #safe-deploys in our [Community Slack](https://temporal.io/slack) to find the latest status and pre-release docs.

If you're using the deprecated version that shipped in mid-2024, see the [Pre-release README.md](https://github.com/temporalio/temporal/blob/main/docs/worker-versioning.md).

If you're using the deprecated version that was released in late 2023, go [here](/encyclopedia/worker-versioning-legacy.mdx).

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/commands.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/commands.mdx</path>
  <content>
---
id: commands
title: Temporal Commands reference
sidebar_label: Commands
description: Discover the range of Commands Workers can issue to the Temporal Service after Workflow Task Execution, from Completing Workflow Execution to Start Timer and Signal External Workflow Execution.
toc_max_heading_level: 4
keywords:
  - reference
tags:
  - Reference
---

A [Command](/workflows#command) is a requested action issued by a [Worker](/workers#worker) to the [Temporal Service](/clusters) after a [Workflow Task Execution](/tasks#workflow-task-execution) completes.

The following is a complete list of possible Commands.

### CompleteWorkflowExecution

This Command is triggered when the Workflow Function Execution returns.
It indicates to the Temporal Service that the [Workflow Execution](/workflows#workflow-execution) is complete.
The corresponding [Event](/workflows#event) for this Command is one of the few Events that will be the last in a Workflow Execution [Event History](/workflows#event-history).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionCompleted](/references/events#workflowexecutioncompleted)

### ContinueAsNewWorkflowExecution

This Command is triggered when there is a call to [Continue-As-New](/workflows#continue-as-new) from within the [Workflow](/workflows).
The corresponding Event for this Command is one of the few Events that will be the last in a Workflow Execution Event History.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionContinuedAsNew](/references/events#workflowexecutioncontinuedasnew)

### FailWorkflowExecution

This Command is triggered when the Workflow Execution returns an error or an exception is thrown.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionFailed](/references/events#workflowexecutionfailed)

### CancelWorkflowExecution

This Command is triggered when the Workflow has successfully cleaned up after receiving a Cancellation Request (which will be present as [WorkflowExecutionCancelRequestedEvent](/references/events#workflowexecutioncancelrequested) in the Event History).
The Corresponding Event for this Command is one of the few Events that will be the last in a Workflow Execution Event History.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionCanceled](/references/events#workflowexecutioncanceled)

### StartChildWorkflowExecution

This Command is triggered by a call to spawn a [Child Workflow Execution](/encyclopedia/child-workflows).

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [ChildWorkflowExecutionStarted](/references/events#childworkflowexecutionstarted)

By default, you cannot have more than 2,000 pending Child Workflows.

### SignalExternalWorkflowExecution

This Command is triggered by a call to [Signal](/sending-messages#sending-signals) another Workflow Execution.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [SignalExternalWorkflowExecutionInitiated](/references/events#signalexternalworkflowexecutioninitiated)

By default, you cannot have more than 2,000 pending Signals to other Workflows.

### RequestCancelExternalWorkflowExecution

This Command is triggered by a call to request cancellation of another Workflow Execution.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [RequestCancelExternalWorkflowExecutionInitiated](/references/events#requestcancelexternalworkflowexecutioninitiated)

By default, you cannot have more than 2,000 pending Signals to other Workflows.

### ScheduleActivityTask

This Command is triggered by a call to execute an [Activity](/activities).

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [ActivityTaskScheduled](/references/events#activitytaskscheduled)

By default, you cannot schedule more than 2,000 Activities concurrently.

### RequestCancelActivityTask

This Command is triggered by a call to request the cancellation of an [Activity Task](/tasks#activity-task).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [ActivityTaskCancelRequested](/references/events#activitytaskcancelrequested)

### StartTimer

This Command is triggered by a call to start a Timer.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [TimerStarted](/references/events#timerstarted)

### CancelTimer

This Command is triggered by a call to cancel a Timer.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [TimerCanceled](/references/events#timercanceled)

### RecordMarker

This Command is triggered by the SDK.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [MarkerRecorded](/references/events#markerrecorded)

### UpsertWorkflowSearchAttributes

This Command is triggered by a call to "upsert" Workflow [Search Attributes](/search-attribute).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [UpsertWorkflowSearchAttributes](/references/events#upsertworkflowsearchattributes)

### ProtocolMessageCommand

This Command helps guarantee ordering constraints for features such as Updates.

This Command points at the message from which the Event is created.
Therefore, just from the Command, you can't predict the resulting Event type.

### ScheduleNexusOperation

This Command is triggered by a call to execute an Nexus Operation in the caller Workflow.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [NexusOperationScheduled](/references/events#nexusoperationscheduled)

By default, you can't schedule more than 30 Nexus Operations concurrently, see [Limits](/workflows#workflow-execution-nexus-operation-limits) for details.

### CancelNexusOperation

This Command is triggered by a call to request the cancellation of a Nexus Operation.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [NexusOperationCancelRequested](/references/events#nexusoperationcancelrequested)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/development-production-features/debugging.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/development-production-features/debugging.mdx</path>
  <content>
---
id: debugging
title: Debugging - Temporal feature
description: Discover Temporal's comprehensive debugging capabilities; tools and frameworks that facilitate Workflow and activity debugging across different programming languages with Temporal.
sidebar_label: Debugging
tags:
  - Debugging
  - Errors
keywords:
  - temporal debugging
  - debug temporal workflows
  - temporal activity debugging
  - workflow troubleshooting temporal
  - temporal SDK debugging
  - temporal integration debugging
  - debugging tools for temporal
  - temporal worker diagnostics
  - temporal framework debugging
  - best practices for temporal debugging
  - temporal debugging examples
  - temporal SDK tutorial
  - end-to-end debugging temporal
  - temporal performance debugging
  - temporal debugging strategies
---

import { RelatedReadContainer, RelatedReadItem } from '@site/src/components/related-read/RelatedRead';

Temporal offers powerful and efficient debugging capabilities for both development and production. These capabilities help developers inspect and troubleshoot Workflows and Activities with precision, ensuring that Workflows perform as expected.

By leveraging detailed event histories and intuitive tooling, you can trace the execution path of Workflows, identify issues, and understand the state of your application at any given point in time.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/debugging" text="Debugging using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/debugging" text="Debugging using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/debugging" text="Debugging using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/debugging" text="Debugging using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/debugging" text="Debugging using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/debugging" text="Debugging using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/cli/env.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/cli/env.mdx</path>
  <content>
---
id: env
title: Temporal CLI env command reference
sidebar_label: env
description: Temporal CLI 'env' commands allow the configuration, setting, deleting, and listing of environmental properties, making it easy to manage Temporal Server instances.
toc_max_heading_level: 4
keywords:
  - cli reference
  - command-line-interface-cli
  - configuration
  - env
  - env delete
  - env get
  - env list
  - env set
  - environment
  - temporal cli
tags:
  - Temporal CLI
---

Environment (or 'env') commands let the user configure the properties for the environment in use.

Use `env <env name>` alongside other commands to point the Temporal CLI at a different Temporal Server instance.

## get

The `temporal env get` command prints the environmental properties for the environment in use.

For example, passing the 'local' [Namespace](/namespaces) returns the name, address, and certificate paths for the local environment.
`temporal env get local`
`Output: tls-cert-path  /home/my-user/certs/cluster.cert tls-key-path   /home/my-user/certs/cluster.key address        127.0.0.1:7233 namespace      accounting`

Output can be narrowed down to a specific option.
`temporal env get local.tls-key-path`
`tls-key-path  /home/my-user/certs/cluster.key`

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## set

The `temporal env set` command sets the value for an environmental property.
Property names match CLI option names.

`temporal env set prod.tls-cert-path /home/my-user/certs/cluster.cert`

Properties can be set for the entire system, such as the frontend address:
`temporal env set local.address 127.0.0.1:7233`

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## delete

The `temporal env delete` command deletes a given environment or environmental property.

`temporal env delete [environment or property]`

Pass a valid [Namespace](/namespaces) into the command to delete an environment and its saved values.

`temporal env delete local`

Use the following options to change the command's behavior.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

## list

List all environments.

- [--address](/cli/cmd-options#address)

- [--codec-auth](/cli/cmd-options#codec-auth)

- [--codec-endpoint](/cli/cmd-options#codec-endpoint)

- [--color](/cli/cmd-options#color)

- [--command-timeout](/cli/cmd-options#command-timeout)

- [--env](/cli/cmd-options#env)

- [--grpc-meta](/cli/cmd-options#grpc-meta)

- [--namespace](/cli/cmd-options#namespace)

- [--output](/cli/cmd-options#output)

- [--tls](/cli/cmd-options#tls)

- [--tls-ca-path](/cli/cmd-options#tls-ca-path)

- [--tls-cert-path](/cli/cmd-options#tls-cert-path)

- [--tls-disable-host-verification](/cli/cmd-options#tls-disable-host-verification)

- [--tls-key-path](/cli/cmd-options#tls-key-path)

- [--tls-server-name](/cli/cmd-options#tls-server-name)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/cancellation.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/cancellation.mdx</path>
  <content>
---
id: cancellation
title: Interrupt a Workflow Execution - Python SDK
sidebar_label: Interrupt a Workflow
description: Interrupt a Workflow Execution using the Temporal Python SDK. Choose between canceling for a graceful stop or terminating for a forceful stop.
keywords:
  - cancel workflow execution
  - activity cancellation
  - terminate workflow execution
  - interrupt workflow execution
  - graceful workflow cancelation
  - forceful workflow termination
  - workflow cancelation logic
  - activity heartbeats
tags:
  - Workflows
  - Python SDK
  - Temporal SDKs
---

You can interrupt a Workflow Execution in one of the following ways:

- [Cancel](#cancellation): Canceling a Workflow provides a graceful way to stop Workflow Execution.
- [Terminate](#termination): Terminating a Workflow forcefully stops Workflow Execution.

Terminating a Workflow forcefully stops Workflow Execution.
This action resembles killing a process.

- The system records a `WorkflowExecutionTerminated` event in the Workflow History.
- The termination forcefully and immediately stops the Workflow Execution.
- The Workflow code gets no chance to handle termination.
- A Workflow Task doesn't get scheduled.

In most cases, canceling is preferable because it allows the Workflow to finish gracefully.
Terminate only if the Workflow is stuck and cannot be canceled normally.

## Cancel a Workflow Execution {#cancellation}

Canceling a Workflow provides a graceful way to stop Workflow Execution.
This action resembles sending a `SIGTERM` to a process.

- The system records a `WorkflowExecutionCancelRequested` event in the Workflow History.
- A Workflow Task gets scheduled to process the cancelation.
- The Workflow code can handle the cancelation and execute any cleanup logic.
- The system doesn't forcefully stop the Workflow.

To cancel a Workflow Execution in Python, use the [cancel()](https://python.temporal.io/temporalio.client.WorkflowHandle.html#cancel) function on the Workflow handle.

```python
await client.get_workflow_handle("your_workflow_id").cancel()
```

### Cancel an Activity from a Workflow {#cancel-activity}

Canceling an Activity from within a Workflow requires that the Activity Execution sends Heartbeats and sets a Heartbeat Timeout.
If the Heartbeat is not invoked, the Activity cannot receive a cancellation request.
When any non-immediate Activity is executed, the Activity Execution should send Heartbeats and set a [Heartbeat Timeout](/encyclopedia/detecting-activity-failures#heartbeat-timeout) to ensure that the server knows it is still working.

When an Activity is canceled, an error is raised in the Activity at the next available opportunity.
If cleanup logic needs to be performed, it can be done in a `finally` clause or inside a caught cancel error.
However, for the Activity to appear canceled the exception needs to be re-raised.

:::note

Unlike regular Activities, [Local Activities](/activities#local-activity) can be canceled if they don't send Heartbeats.
Local Activities are handled locally, and all the information needed to handle the cancellation logic is available in the same Worker process.

:::

To cancel an Activity from a Workflow Execution, call the [cancel()](https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel) method on the Activity handle that is returned from [start_activity()](https://python.temporal.io/temporalio.workflow.html#start_activity).

```python
@activity.defn
async def cancellable_activity(input: ComposeArgsInput) -> NoReturn:
    try:
        while True:
            print("Heartbeating cancel activity")
            await asyncio.sleep(0.5)
            activity.heartbeat("some details")
    except asyncio.CancelledError:
        print("Activity cancelled")
        raise


@activity.defn
async def run_activity(input: ComposeArgsInput):
    print("Executing activity")
    return input.arg1 + input.arg2

@workflow.defn
 class GreetingWorkflow:
     @workflow.run
     async def run(self, input: ComposeArgsInput) -> None:
        activity_handle = workflow.start_activity(
            cancellable_activity,
            ComposeArgsInput(input.arg1, input.arg2),
            start_to_close_timeout=timedelta(minutes=5),
            heartbeat_timeout=timedelta(seconds=30),
        )

        await asyncio.sleep(3)
        activity_handle.cancel()
```

:::note

The Activity handle is a Python task.
By calling `cancel()`, you're essentially requesting the task to be canceled.

:::

## Terminate a Workflow Execution {#termination}

Terminating a Workflow forcefully stops Workflow Execution.
This action resembles killing a process.

- The system records a `WorkflowExecutionTerminated` event in the Workflow History.
- The termination forcefully and immediately stops the Workflow Execution.
- The Workflow code gets no chance to handle termination.
- A Workflow Task doesn't get scheduled.

To terminate a Workflow Execution in Python, use the [terminate()](https://python.temporal.io/temporalio.client.WorkflowHandle.html#terminate) function on the Workflow handle.

```python
await client.get_workflow_handle("your_workflow_id").terminate()
```

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/worker-versioning-legacy.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/worker-versioning-legacy.mdx</path>
  <content>
---
id: worker-versioning-legacy
title: Worker Versioning (Legacy)
sidebar_label: Worker Versioning (Legacy)
description: Remember how to use the now-deprecated pre-release version of Worker Versioning
toc_max_heading_level: 4
tags:
  - Concepts
  - Versioning
  - Workers
---

:::tip Support, stability, and dependency info

- This version of Worker Versioning is DEPRECATED
- Introduced in Temporal Server version [1.21.0](https://github.com/temporalio/temporal/releases/tag/v1.21.0)
- Available in CLI version [0.10.0](https://github.com/temporalio/cli/releases/tag/v0.10.0)
- Available in [Go SDK](/develop/go/versioning#worker-versioning) since [v1.23.0](https://github.com/temporalio/sdk-go/releases/tag/v1.23.0)
- Available in [Java SDK](/develop/java/versioning#worker-versioning) since [v1.20.0](https://github.com/temporalio/sdk-java/releases/tag/v1.20.0)
- Available in [TypeScript SDK](/develop/typescript/versioning#worker-versioning) since [v1.8.0](https://github.com/temporalio/sdk-typescript/releases/tag/v1.8.0)
- Available in [Python SDK](https://python.temporal.io/temporalio.worker.Worker.html) since [v1.3.0](https://github.com/temporalio/sdk-python/releases/tag/1.3.0)
- Available in [.NET SDK](https://dotnet.temporal.io/api/Temporalio.Worker.TemporalWorkerOptions.html#Temporalio_Worker_TemporalWorkerOptions_UseWorkerVersioning) since [v0.1.0-beta1](https://github.com/temporalio/sdk-dotnet/releases/tag/0.1.0-beta1)
- Not yet available in Temporal Cloud

:::

:::caution

This version of Worker Versioning is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning)

:::

Worker Versioning simplifies the process of deploying changes to [Workflow Definitions](/workflows#workflow-definition).
It does this by letting you define sets of versions that are compatible with each other, and then assigning a Build ID to the code that defines a Worker.
The Temporal Server uses the Build ID to determine which versions of a Workflow Definition a Worker can process.

We recommend that you read about Workflow Definitions before proceeding, because Workflow Versioning is largely concerned with helping to manage nondeterministic changes to those definitions.

Worker Versioning helps manage nondeterministic changes by providing a convenient way to ensure that [Workers](/workers) with different Workflow and Activity Definitions operating on the same Task Queue don't attempt to process [Workflow Tasks](/tasks#workflow-task) and [Activity Tasks](/tasks#activity-task-execution) that they can't successfully process, according to sets of versions associated with that Task Queue that you've defined.

Accomplish this goal by assigning a Build ID (a free-form string) to the code that defines a Worker, and specifying which Build IDs are compatible with each other by updating the version sets associated with the Task Queue, stored by the Temporal Server.

### When and why you should use Worker Versioning

:::caution

This version of Worker Versioning is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning)

:::

The main reason to use this feature is to deploy incompatible changes to short-lived [Workflows](/workflows).
On Task Queues using this feature, the Workflow starter doesn't have to know about the introduction of new versions.

The new code in the newly deployed Workers executes new [Workflow Executions](/workflows#workflow-execution), while only Workers with an appropriate version process old Workflow Executions.

#### Decommission old Workers

You can decommission old Workers after you archive all open Workflows using their version.
If you have no need to query closed Workflows, you can decommission them when no open Workflows remain at that version.

For example, if you have a Workflow that completes within a day, a good strategy is to assign a new Build ID to every new Worker build and add it as the new overall default in the version sets.

Because your Workflow completes in a day, you know that you won't need to keep older Workers running for more than a day after you deploy the new version (assuming availability).
You can apply this technique to longer-lived Workflows too; however, you might need to run multiple Worker versions simultaneously while open Workflows complete.

Version sets have a maximum size limit, which defaults to 100 Build IDs across all sets.
Operations to add new Build IDs to the sets will fail if they exceed this limit.
There is also a limit on the number of Version Sets, which defaults to 10.
A version can only be garbage collected after a Workflow Execution is deleted.

#### Deploy code changes to Workers

The feature also lets you implement compatible changes to or prevent a buggy code path from executing on currently open Workflows.
You can achieve this by adding a new version to an existing set and defining it as _compatible_ with an existing version, which shouldn't execute any future Workflow Tasks.
Because the new version processes existing [Event Histories](/workflows#event-history), it must adhere to the usual [deterministic constraints](/workflows#deterministic-constraints), and you might need to use one of the [versioning APIs](/workflows#workflow-versioning).

Moreover, this feature lets you make incompatible changes to Activity Definitions in conjunction with incompatible changes to Workflow Definitions that use those Activities.
This functionality works because any Activity that a Workflow schedules on the same Task Queue gets dispatched by default only to Workers compatible with the Workflow that scheduled it.
If you want to change an Activity Definition's type signature while creating a new incompatible Build ID for a Worker, you can do so without worrying about the Activity failing to execute on some other Worker with an incompatible definition.
The same principle applies to Child Workflows.
For both Activities and Child Workflows, you can override the default behavior and run the Activity or Child Workflow on latest default version.

:::tip

Public-facing Workflows on a versioned Task Queue shouldn't change their signatures because doing so contradicts the purpose of Workflow-launching Clients remaining unaware of changes in the Workflow Definition.
If you need to change a Workflow's signature, use a different Workflow Type or a completely new Task Queue.

:::

:::note

If you schedule an Activity or a Child Workflow on _a different_ Task Queue from the one the Workflow runs on, the system doesn't assign a specific version.
This means if the target queue is versioned, they run on the latest default, and if it's unversioned, they operate as they would have without this feature.

:::

**Continue-As-New and Worker Versioning**

By default, a versioned Task Queue's Continue-as-New function starts the continued Workflow on the same compatible set as the original Workflow.

If you continue-as-new onto a different Task Queue, the system doesn't assign any particular version.
You also have the option to specify that the continued Workflow should start using the Task Queue's latest default version.

### How to use Worker Versioning

:::caution

This version of Worker Versioning is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning)

:::

To use Worker Versioning, follow these steps:

1. Define Worker build-identifier version sets for the Task Queue.
   You can use either the Temporal CLI or your choice of SDK.
2. Enable the feature on your Worker by specifying a Build ID.

#### Defining the version sets

Whether you use [Temporal CLI](/cli/) or an SDK, updating the version sets feels the same.
You specify the Task Queue that you're targeting, the Build ID that you're adding (or promoting), whether it becomes the new default version, and any existing versions it should be considered compatible with.

The rest of this section uses updates to one Task Queue's version sets as examples.

By default, both Task Queues and Workers are in an unversioned state.
[Unversioned Worker](#unversioned-workers) can poll unversioned Task Queues and receive tasks.
To use this feature, both the Task Queue and the Worker must be associated with Build IDs.

If you run a Worker using versioning against a Task Queue that has not been set up to use versioning (or is missing that Worker's Build ID), it won't get any tasks.
Likewise, a unversioned Worker polling a Task Queue with versioning won't work either.

:::note Versions don't need to follow semver or any other semantic versioning scheme!

The versions in the following examples look like semver versions for clarity, but they don't need to be.
Versions can be any arbitrary string.

:::

First, add a version `1.0` to the Task Queue as the new default.
Your version sets now look like this:

| set 1 (default) |
| --------------- |
| 1.0 (default)   |

All new Workflows started on the Task Queue have their first tasks assigned to version `1.0`.
Workers with their Build ID set to `1.0` receive these Tasks.

If Workflows that don't have an assigned version are still running on the Task Queue, Workers without a version take those tasks.
So ensure that such Workers are still operational if any Workflows were open when you added the first version.
If you deployed any Workers with a _different_ version, those Workers receive no Tasks.

Now, imagine you need change the Workflow for some reason.

Add `2.0` to the sets as the new default:

| set 1         | set 2 (default) |
| ------------- | --------------- |
| 1.0 (default) | 2.0 (default)   |

All new Workflows started on the Task Queue have their first tasks assigned to version `2.0`.
Existing `1.0` Workflows keep generating tasks targeting `1.0`.
Each deployment of Workers receives their respective Tasks.
This same concept carries forward for each new incompatible version.

Maybe you have a bug in `2.0`, and you want to make sure all open `2.0` Workflows switch to some new code as fast as possible.
So, you add `2.1` to the sets, marking it as compatible with `2.0`.
Now your sets look like this:

| set 1         | set 2 (default) |
| ------------- | --------------- |
| 1.0 (default) | 2.0             |
|               | 2.1 (default)   |

All new Workflow Tasks that are generated for Workflows whose last Workflow Task completion was on version `2.0` are now assigned to version `2.1`.
Because you specified that `2.1` is compatible with `2.0`, Temporal Server assumes that Workers with this version can process the existing Event Histories successfully.

Continue with your normal development cycle, adding a `3.0` version.
Nothing new here:

| set 1         | set 2         | set 3 (default) |
| ------------- | ------------- | --------------- |
| 1.0 (default) | 2.0           | 3.0 (default)   |
|               | 2.1 (default) |                 |

Now imagine that version `3.0` doesn't have an explicit bug, but something about the business logic
is less than ideal.
You are okay with existing `3.0` Workflows running to completion, but you want new Workflows to use the old `2.x` branch.
This operation is supported by performing an update targeting `2.1` (or `2.0`) and setting its set as the current default, which results in these sets:

| set 1         | set 3         | set 2 (default) |
| ------------- | ------------- | --------------- |
| 1.0 (default) | 3.0 (default) | 2.0             |
|               |               | 2.1 (default)   |

Now new Workflows start on `2.1`.

#### Permitted and forbidden operations on version sets

A request to change the sets can do one of the following:

- Add a version to the sets as the new default version in a new overall-default compatible set.
- Add a version to an existing set that's compatible with an existing version.
  - Optionally making it the default for that set.
  - Optionally making that set the overall-default set.
- Promote a version within an existing set to become the default for that set.
- Promote a set to become the overall-default set.

You can't explicitly delete versions.This helps you avoid the situation in which Workflows accidentally become stuck with no means of making progress because the version they're associated with no longer exists.

However, sometimes you might want to do this intentionally.
If you _want_ to make sure that all Workflows currently being processed by, say, `2.0` stop (even if you don't yet have a new version ready), you can add a new version `2.1` to the sets marked as compatible with `2.0`.
New tasks will target `2.1`, but because you haven't deployed any `2.1` Workers, they won't make any progress.

#### Set constraints

The sets have a maximum size limit, which defaults to 100 build IDs across all sets.
This limit is configurable on Temporal Server via the `limit.versionBuildIdLimitPerQueue` dynamic config property.
Operations to add new Build IDs to the sets fail if the limit would be exceeded.

There is also a limit on the number of sets, which defaults to 10.
This limit is configurable via the `limit.versionCompatibleSetLimitPerQueue` dynamic config property.

In practice, these limits should rarely be a concern because a version is no longer needed after no open Workflows are using that version, and a background process will delete IDs and sets that are no longer needed.

There is also a limit on the size of each Build ID or version string, which defaults to 255 characters.
This limit is configurable on the server via the `limit.workerBuildIdSize` dynamic config property.

### Build ID reachability

:::caution

This version of Worker Versioning is deprecated and will go away at some point. Please redirect your attention to [Worker Versioning](/worker-versioning)

:::

Eventually, you'll want to know whether you can retire the old Worker versions.
Temporal provides functionality to help you determine whether a version is still in use by open or closed Workflows.
You can use the Temporal CLI to do this with the following command:

```command
temporal task-queue get-build-id-reachability
```

The command determines, for each Task Queue, whether the Build ID in question is unreachable, only reachable by closed Workflows, or reachable by open and new Workflows.
For example, this "2.0" Build ID is shown here by the Temporal CLI to be reachable by both new Workflows and some existing Workflows:

```command
temporal task-queue get-build-id-reachability --build-id "2.0"
```

```output
BuildId                         TaskQueue                                   Reachability
    2.0  build-id-versioning-dc0068f6-0426-428f-b0b2-703a7e409a97  [NewWorkflows
                                                                   ExistingWorkflows]
```

For more information, see the [CLI documentation](/cli/) or help output.

You can also use this API `GetWorkerTaskReachability` directly from within language SDKs.

### Unversioned Workers

Unversioned Workers refer to Workers that have not opted into the Worker Versioning feature in their configuration.
They receive tasks only from Task Queues that do not have any version sets defined on them, or that have open Workflows that began executing before versions were added to the queue.

To migrate from an unversioned Task Queue, add a new default Build ID to the Task Queue.
From there, deploy Workers with the same Build ID.
Unversioned Workers will continue processing open Workflows, while Workers with the new Build ID will process new Workflow Executions.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/detecting-application-failures.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/detecting-application-failures.mdx</path>
  <content>
---
id: detecting-application-failures
title: Detecting application failures
sidebar_label: Detecting application failures
description: In Temporal, timeouts detect and mitigate Workflow and Activity failures with automatic retries using configurable timeout settings and customizable RetryPolicies.
toc_max_heading_level: 4
keywords:
  - failures
  - timeouts
  - timeouts
tags:
  - Concepts
  - Failures
  - Timeouts
---

In Temporal, timeouts detect application failures.
The system can then automatically mitigate these failures through retries.
Both Workflows and Activities have dedicated timeout configurations and can be configured with a RetryPolicy.

- [Detecting Workflow failures](/encyclopedia/detecting-workflow-failures)
- [Detecting Activity failures](/encyclopedia/detecting-activity-failures)
- [Retry Policies](/encyclopedia/retry-policies)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/references/web-ui-environment-variables.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/references/web-ui-environment-variables.mdx</path>
  <content>
---
id: web-ui-environment-variables
title: Temporal Web UI environment variables reference
sidebar_label: Web UI env vars
description: Dynamically configure Temporal Web UI with environment variables in Docker for settings like TEMPORAL_ADDRESS, authentication, TLS, OpenAPI, and more.
toc_max_heading_level: 4
keywords:
  - docker
  - reference
  - ui server
  - webui
tags:
  - Reference
  - Temporal Web UI
---

You can use environment variables to dynamically alter the configuration of your Temporal Web UI.

These can be used in many environments, such as with Docker.
For example:

```
docker run\
-e TEMPORAL_ADDRESS=127.0.0.1:7233\
-e TEMPORAL_UI_PORT=8080\
-e TEMPORAL_UI_PUBLIC_PATH=path/to/webui\
-e TEMPORAL_UI_ENABLED=true\
-e TEMPORAL_BANNER_TEXT="Some banner text"\
-e TEMPORAL_CLOUD_UI=false\
-e TEMPORAL_DEFAULT_NAMESPACE=default\
-e TEMPORAL_FEEDBACK_URL=https://feedback.here\
-e TEMPORAL_NOTIFY_ON_NEW_VERSION=true\
-e TEMPORAL_CONFIG_REFRESH_INTERVAL=0s\
-e TEMPORAL_SHOW_TEMPORAL_SYSTEM_NAMESPACE=false\
-e TEMPORAL_DISABLE_WRITE_ACTIONS=false\
-e TEMPORAL_AUTH_ENABLED=true\
-e TEMPORAL_AUTH_TYPE=oidc\
-e TEMPORAL_AUTH_PROVIDER_URL=https://accounts.google.com\
-e TEMPORAL_AUTH_ISSUER_URL=https://accounts.google.com\
-e TEMPORAL_AUTH_CLIENT_ID=xxxxx-xxxx.apps.googleusercontent.com\
-e TEMPORAL_AUTH_CLIENT_SECRET=xxxxxxxxxxxxxxx\
-e TEMPORAL_AUTH_CALLBACK_URL=https://xxxx.com:8080/auth/sso/callback\
-e TEMPORAL_AUTH_SCOPES=openid,email,profile\
-e TEMPORAL_TLS_CA=../ca.cert\
-e TEMPORAL_TLS_CERT=../cluster.pem\
-e TEMPORAL_TLS_KEY=../cluster.key\
-e TEMPORAL_TLS_ENABLE_HOST_VERIFICATION=true\
-e TEMPORAL_TLS_SERVER_NAME=tls-server\
-e TEMPORAL_CODEC_ENDPOINT=https://codec.server\
-e TEMPORAL_CODEC_PASS_ACCESS_TOKEN=false\
-e TEMPORAL_CODEC_INCLUDE_CREDENTIALS=false\
-e TEMPORAL_HIDE_LOGS=false\
temporalio/ui:<tag>
```

The environment variables are defined in the [UI server configuration template file](https://github.com/temporalio/ui-server/blob/main/docker/config-template.yaml) and described in more detail below.

## `TEMPORAL_ADDRESS`

The [Frontend Service](/clusters#frontend-service) address for the Temporal Cluster.
This environmental variable can be set [in the base configuration file](/references/web-ui-configuration#temporalgrpcaddress) using `temporalGrpcAddress`.

This variable is required for setting other environmental variables.

## `TEMPORAL_UI_PORT`

The port used by the Temporal WebUI Server and the HTTP API.

This variable is needed for `TEMPORAL_OPENAPI_ENABLED` and all auth-related settings to work properly.

## `TEMPORAL_UI_PUBLIC_PATH`

Stores a value such as "" or "/custom-path" that allows the UI to be served from a subpath.

## `TEMPORAL_UI_ENABLED`

Enables or disables the [browser UI](/references/web-ui-configuration#enableui) for the Temporal Cluster.

Enabling the browser UI allows the Server to be accessed from your web browser.
If disabled, the server cannot be viewed on the web, but the UI server APIs remain available for use.

## `TEMPORAL_BANNER_TEXT`

Provides banner text to display on the Web UI.

## `TEMPORAL_CLOUD_UI`

If enabled, use the alternate UI from Temporal Cloud.

## `TEMPORAL_DEFAULT_NAMESPACE`

The default [Namespace](/namespaces) that the Web UI opens first.

## `TEMPORAL_FEEDBACK_URL`

The URL that users are directed to when they click the Feedback button in the UI.

If not specified, this variable defaults to the UI's GitHub Issue page.

## `TEMPORAL_NOTIFY_ON_NEW_VERSION`

Enables or disables notifications that appear in the UI whenever a newer version of the Temporal Cluster is available.

## `TEMPORAL_CONFIG_REFRESH_INTERVAL`

Determines how often the UI Server reads the configuration file for new values.

## `TEMPORAL_SHOW_TEMPORAL_SYSTEM_NAMESPACE`

If enabled, shows the System Namespace that handles internal Temporal Workflows in the Web UI. 

## `TEMPORAL_DISABLE_WRITE_ACTIONS`

Disables any button in the UI that allows the user to modify Workflows or Activities.

## `TEMPORAL_AUTH_ENABLED`

Enables or disables Web UI authentication and authorization methods.

When enabled, the Web UI will use the provider information in the [UI configuration file](/references/web-ui-configuration#auth) to verify the identity of users.

All auth-related variables can be defined when `TEMPORAL_AUTH_ENABLED` is set to "true".
Disabling the variable will retain given values.

## `TEMPORAL_AUTH_TYPE`

Specifies the type of authentication. Defaults to `oidc`.

## `TEMPORAL_AUTH_PROVIDER_URL`

The .well-known IDP discovery URL for authentication and authorization.

This can be set as in the UI server configuration with [auth](/references/web-ui-configuration#auth).

## `TEMPORAL_AUTH_ISSUER_URL`

The URL for the authentication or authorization issuer.

This value is only needed when the issuer differes from the auth provider URL.

## `TEMPORAL_AUTH_CLIENT_ID`

The client ID used for authentication or authorization.

This value is a required parameter.

## `TEMPORAL_AUTH_CLIENT_SECRET`

The client secret used for authentication and authorization.

Client Secrets are used by the oAuth Client for authentication.

## `TEMPORAL_AUTH_CALLBACK_URL`

The callback URL used by Temporal for authentication and authorization.

Callback URLs are invoked by IDP after user has finished authenticating in IDP.

## `TEMPORAL_AUTH_SCOPES`

Specifies a set of scopes for auth. Typically, this is `openid`, `profile`, `email`.

## `TEMPORAL_TLS_CA`

The path for the Transport Layer Security (TLS) Certificate Authority file.

In order to [configure TLS for your server](/references/web-ui-configuration#tls), you'll need a CA certificate issued by a trusted Certificate Authority.
Set this variable to properly locate and use the file.

## `TEMPORAL_TLS_CERT`

The path for the Transport Layer Security (TLS) Certificate.

In order to [configure TLS for your server](/references/web-ui-configuration#tls), you'll need a self-signed certificate.
Set the path to allow the environment to locate and use the certificate.

## `TEMPORAL_TLS_KEY`

The path for the Transport Layer Security (TLS) [key file](/references/web-ui-configuration#tls).

A key file is used to create private and public keys for encryption and signing.
Together, these keys are used to create certificates.

## `TEMPORAL_TLS_CA_DATA`

Stores the data for a TLS CA file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_CA`.

## `TEMPORAL_TLS_CERT_DATA`

Stores the data for a TLS cert file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_CERT`.

## `TEMPORAL_TLS_KEY_DATA`

Stores the data for a TLS key file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_KEY`.

## `TEMPORAL_TLS_ENABLE_HOST_VERIFICATION`

Enables or disables [Transport Layer Security (TLS) host verification](/references/web-ui-configuration#tls).

When enabled, TLS checks the Host Server to ensure that files are being sent to and from the correct URL.

## `TEMPORAL_TLS_SERVER_NAME`

The server on which to operate [Transport Layer Security (TLS) protocols](/references/web-ui-configuration#tls).

TLS allows the current server to transmit encrypted files to other URLs without having to reveal itself.
Because of this, TLS operates a go-between server.

## `TEMPORAL_CODEC_ENDPOINT`

The endpoint for the [Codec Server](/codec-server), if configured.

## `TEMPORAL_CODEC_PASS_ACCESS_TOKEN`

Specifies whether to send a JWT access token as ‘authorization' header in requests with the Codec Server.

## `TEMPORAL_CODEC_INCLUDE_CREDENTIALS`

Specifies whether to include credentials along with requests to the Codec Server.

## `TEMPORAL_FORWARD_HEADERS`

Forward-specified HTTP headers to direct from HTTP API requests to the Temporal gRPC backend.

## `TEMPORAL_HIDE_LOGS`

If enabled, does not print logs from the Temporal Service.
  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/data-conversion/payload-converter.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/data-conversion/payload-converter.mdx</path>
  <content>
---
id: payload-converter
title: Payload Converter
sidebar_label: Payload Converter
description: A Payload Converter serializes and deserializes values to and from bytes for use in the Temporal SDK.
slug: /payload-converter
toc_max_heading_level: 4
keywords:
  - encryption
  - explanation
  - keys
  - payloads
  - secrets
  - data-converters
  - payload-converter
tags:
  - Concepts
  - Encryption
  - Data Converters
  - Security
---

This page discusses [Payload Converter](#payload-converter). 

## What is a Payload Converter? {#payload-converter}

A Payload Converter serializes data, converting values to bytes and back.

When you initiate a Workflow Execution through a Client and pass data as input, the input is serialized using a Data Converter that runs it through a set of Payload Converters.
When your Workflow Execution starts, this data input is deserialized and passed as input to your Workflow.

### Composite Data Converters {#composite-data-converters}

A Composite Data Converter is used to apply custom, type-specific Payload Converters in a specified order.
A Composite Data Converter can be comprised of custom rules that you created, and it can also leverage the default Data Converters built into Temporal.
In fact, the default Data Converter logic is implemented internally in the Temporal source as a Composite Data Converter. It defines these rules in this order:

```go
defaultDataConverter = NewCompositeDataConverter(
    NewNilPayloadConverter(),
    NewByteSlicePayloadConverter(),
    NewProtoJSONPayloadConverter(),
    NewProtoPayloadConverter(),
    NewJSONPayloadConverter(),
)
```

The order in which the Payload Converters are applied is important.
During serialization, the Data Converter tries the Payload Converters in that specific order until a Payload Converter returns a non-nil Payload.
A custom PayloadConverter must implement the functions:

- `FromPayload` (for a single value) or
- `FromPayloads` (for a list of values) to convert to values from a Payload, and
- `ToPayload` (for a single value) or
- `ToPayloads` (for a list of values) to convert values to a Payload.

Defining a new Composite Data Converter is not always necessary to implement custom data handling.
Each SDK allows you to override or configure the default Converter with a custom Payload Codec.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/troubleshooting/blob-size-limit-error.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/troubleshooting/blob-size-limit-error.mdx</path>
  <content>
---
id: blob-size-limit-error
title: Troubleshoot the blob size limit error
sidebar_label: Blob size limit error
description: The BlobSizeLimitError occurs when a Workflow's payload exceeds the 2 MB request limit or the 4 MB Event History transaction limit set by Temporal. Reduce blob size via compression or batching.
toc_max_heading_level: 4
keywords:
  - error
  - troubleshooting
tags:
  - Errors
  - Failures
---

The `BlobSizeLimitError` is an error that occurs when the size of a blob (payloads including Workflow context and each Workflow and Activity argument and return value) exceeds the set limit in Temporal.

- The max payload for a single request is 2 MB.
- The max size limit for any given [Event History](/workflows#event-history) transaction is 4 MB.

## Why does this error occur?

This error occurs when the size of the blob exceeds the maximum size allowed by Temporal.

This limit helps ensure that the Temporal Service prevents excessive resource usage and potential performance issues when handling large payloads.

## How do I resolve this error?

To resolve this error, reduce the size of the blob so that it is within the 4 MB limit.

There are multiple strategies you can use to avoid this error:

1. Use compression with a [custom payload codec](/payload-codec) for large payloads.

   - This addresses the immediate issue of the blob size limit; however, if blob sizes continue to grow this problem can arise again.

2. Break larger batches of commands into smaller batch sizes:

   - Workflow-level batching:
     1. Modify the Workflow to process Activities or Child Workflows into smaller batches.
     2. Iterate through each batch, waiting for completion before moving to the next.
   - Workflow Task-level batching:
     1. Execute Activities in smaller batches within a single Workflow Task.
     2. Introduce brief pauses or sleeps (for example, 1ms) between batches.

3. Consider offloading large payloads to an object store to reduce the risk of exceeding blob size limits:
   1. Pass references to the stored payloads within the Workflow instead of the actual data.
   2. Retrieve the payloads from the object store when needed during execution.

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/develop/python/python-sdk-sandbox.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/develop/python/python-sdk-sandbox.mdx</path>
  <content>
---
id: python-sdk-sandbox
title: Temporal Python SDK sandbox environment
sidebar_label: Python SDK sandbox
description: The Temporal Python SDK offers a sandbox environment to run Workflow code, aiming to prevent non-determinism errors in applications by isolating global state and applying restrictions.
toc_max_heading_level: 4
keywords:
  - temporal python sdk
  - workflow sandbox
  - non-determinism errors
  - python sandbox environment
  - global state isolation
  - python workflow restrictions
  - passthrough modules
  - invalid module members
  - sandbox_unrestricted
  - unsandboxed workflow runner
  - sandboxed workflow runner
  - workflow determinism
  - skip workflow sandboxing
  - temporal workflow exceptions
  - deterministic workflow execution
tags:
  - Temporal SDKs
  - Python SDK
  - Concepts
---

The Temporal Python SDK enables you to run Workflow code in a sandbox environment to help prevent non-determinism errors in your application.
The Temporal Workflow Sandbox for Python is not completely isolated, and some libraries can internally mutate state, which can result in breaking determinism.

## Benefits

Temporal's Python SDK uses a sandbox environment for Workflow runs to make developing Workflow code safer.

If a Workflow Execution performs a non-deterministic event, an exception is thrown, which results in failing the Task Worker.
The Workflow will not progress until the code is fixed.

The Temporal Python sandbox offers a mechanism to _pass through modules_ from outside the sandbox. By default, this includes all standard library modules and Temporal modules. For performance and behavior reasons, users are encouraged to pass through all third-party modules whose calls will be deterministic. For more information, see [Passthrough modules](#passthrough-modules).

## How it works

The Sandbox environment consists of two main components.

- [Global state isolation](#global-state-isolation)
- [Restrictions](#restrictions)

### Global state isolation

The first component of the Sandbox is a global state isolation.
Global state isolation uses `exec` to compile and evaluate statements.

Upon the start of a Workflow, the file in which the Workflow is defined is imported into a newly created sandbox.

If a module is imported by the file, a known set, which includes all of Python's standard library, is _passed through_ from outside the sandbox.

These modules are expected to be free of side effects and have their non-deterministic aspects restricted.

For a full list of modules imported, see [Customize the Sandbox](#customize-the-sandbox).

### Restrictions

Restrictions prevent known non-deterministic library calls.
This is achieved by using proxy objects on modules wrapped around the custom importer set in the sandbox.

Restrictions apply at both the Workflow import level and the Workflow run time.

A default set of restrictions that prevents most dangerous standard library calls.

## Skip Workflow Sandboxing

The following techniques aren't recommended, but they allow you to avoid, skip, or break through the sandbox environment.

Skipping Workflow Sandboxing results in a lack of determinism checks. Using the Workflow Sandboxing environment helps to preventing non-determinism errors but doesn't completely negate the risk.

### Skip Sandboxing for a block of code

To skip a sandbox environment for a specific block of code in a Workflow, use [`sandbox_unrestricted()`](https://python.temporal.io/temporalio.workflow.unsafe.html#sandbox_unrestricted). The Workflow will run without sandbox restrictions.

```python
with temporalio.workflow.unsafe.sandbox_unrestricted():
    # Your code
```

### Skip Sandboxing for an entire Workflow

To skip a sandbox environment for a Workflow, set the `sandboxed` argument in the [`@workflow.defn`](https://python.temporal.io/temporalio.workflow.html#defn) decorator to false.
The entire Workflow will run without sandbox restrictions.

```python
@workflow.defn(sandboxed=False)
```

### Skip Sandboxing for a Worker

To skip a sandbox environment for a Worker, set the `workflow_runner` keyword argument of the `Worker` init to [`UnsandboxedWorkflowRunner()`](https://python.temporal.io/temporalio.worker.UnsandboxedWorkflowRunner.html).

## Customize the sandbox

When creating the Worker, the `workflow_runner` defaults to [`SandboxedWorkflowRunner()`](https://python.temporal.io/temporalio.worker.workflow_sandbox.SandboxedWorkflowRunner.html).
The `SandboxedWorkflowRunner` init accepts a `restrictions` keyword argument that defines a set of restrictions to apply to this sandbox.

The `SandboxRestrictions` dataclass is immutable and contains three fields that can be customized, but only two have notable values.

- [`passthrough_modules`](https://python.temporal.io/temporalio.worker.workflow_sandbox.SandboxRestrictions.html#passthrough_modules)
- [`invalid_modules_members`](https://python.temporal.io/temporalio.worker.workflow_sandbox.SandboxRestrictions.html#invalid_module_members)

### Passthrough modules

By default, the sandbox completely reloads non-standard-library and non-Temporal modules for every workflow run. Passing through a module means that the module will not be reloaded every time the Workflow runs. Instead, the module will be imported from outside the sandbox and used directly in the Workflow. This can improve performance because importing a module can be a time-consuming process, and passing through a module can avoid this overhead.
:::note

It is important to note that you should only import _known-side-effect-free_ third-party modules: meaning they don't have any unintended consequences when imported and used multiple times. This is because passing through a module means that it will be used multiple times in a workflow without being reloaded, so any side effects it has will be repeated. For this reason, it's recommended to only pass through modules that are known to be deterministic, meaning they will always produce the same output given the same input.

:::

One way to pass through a module is at import time in the workflow file using the [`imports_passed_through`](https://python.temporal.io/temporalio.workflow.unsafe.html#imports_passed_through) context manager.

```python
# my_workflow_file.py

from temporalio import workflow

with workflow.unsafe.imports_passed_through():
    import pydantic

@workflow.defn
class MyWorkflow:
     # ...
```

Alternatively, this can be done at worker creation time by customizing the runner's restrictions.

```python
my_worker = Worker(
  ...,
  workflow_runner=SandboxedWorkflowRunner(
    restrictions=SandboxRestrictions.default.with_passthrough_modules("pydantic")
  )
)
```

In both of these cases, now the `pydantic` module will be passed through from outside the sandbox instead of being reloaded for every Workflow run.

### Invalid module members

`invalid_module_members` includes modules that cannot be accessed.

Checks are compared against the fully qualified path to the item.

For example, to remove a restriction on `datetime.date.today()`, see the following example.

```python
my_restrictions = dataclasses.replace(
    SandboxRestrictions.default,
    invalid_module_members=SandboxRestrictions.invalid_module_members_default.with_child_unrestricted(
      "datetime", "date", "today",
    ),
)
my_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))
```

Restrictions can also be added by piping (`|`) together matchers.

The following example restricts the `datetime.date` class from being used.

```python
my_restrictions = dataclasses.replace(
    SandboxRestrictions.default,
    invalid_module_members=SandboxRestrictions.invalid_module_members_default | SandboxMatcher(
      children={"datetime": SandboxMatcher(use={"date"})},
    ),
)
my_worker = Worker(..., workflow_runner=SandboxedWorkflowRunner(restrictions=my_restrictions))
```

For more information on the Python sandbox, see the following resources.

- [Python SDK README](https://github.com/temporalio/sdk-python)
- [Python API docs](https://python.temporal.io/index.html)

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/encyclopedia/workflow-message-passing/handling-messages.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/encyclopedia/workflow-message-passing/handling-messages.mdx</path>
  <content>
---
id: handling-messages
title: Handling Signals, Queries, & Updates
sidebar_label: Handling Signals, Queries, & Updates
description: Signals, Queries, and Updates facilitate interactions with Workflow Executions.
slug: /handling-messages 
tags:
- Concepts
- Signals
- Queries
- Updates
- Messages
keywords:
- temporal workflow signals
- temporal workflow queries
- temporal workflow updates
- temporal workflow execution
- message passing temporal
- signal-with-start temporal
- temporal query handler
- temporal signal handler
- temporal update handler
- temporal update validator
- temporal message passing
- workflow state temporal
- synchronous operation temporal
- asynchronous request temporal
- temporal service events
- temporal client methods
- temporal sdk message passing
---

import PrettyImage from '@site/src/components/pretty-image/PrettyImage';
import {RelatedReadContainer, RelatedReadItem} from '@site/src/components/related-read/RelatedRead';

When Signals, Updates, and Queries arrive at your Workflow, the handlers for these messages will operate on the current state of your Workflow and can use the fields you have set.
In this section, we’ll give you an overview of how messages work with Temporal and cover how to write correct and robust handlers by covering topics like atomicity, guaranteeing completion before the Workflow exits, exceptions, and idempotency.

## Handling Messages {#handling-messages}

### Message handler concurrency {#message-handler-concurrency}

If your Workflow receives messages, you may need to consider how those messages interact with one another or with the main Workflow method.
Behind the scenes, Temporal is running a loop that looks like this:

<PrettyImage src="/img/info/messages-workflow-loop.png" title="Diagram that shows the execution ordering of Workflows" />

Every time the Workflow wakes up--generally, it wakes up when it needs to--it will process messages in the order they were received, followed by making progress in the Workflow’s main method.

This execution is on a single thread–while this means you don’t have to worry about parallelism, you do need to worry about concurrency if you have written Signal and Update handlers that can block. These can run interleaved with the main Workflow and with one another, resulting in potential race conditions. These methods should be made reentrant.

#### Initializing the Workflow first {#workflow-initializers}

Initialize your Workflow's state before handling messages.
This prevents your handler from reading uninitialized instance variables.

To see why, refer to the [diagram](#message-handler-concurrency).
It shows that your Workflow processes messages before the first run of your Workflow's main method.

The message handler runs first in several scenarios, such as:

- When using [Signal-with-Start](/sending-messages#signal-with-start).
- When your Worker experiences delays, such as when the Task Queue it polls gets backlogged.
- When messages arrive immediately after a Workflow continues as new but before it resumes.

For all languages except Go and TypeScript, use your constructor to set up state.
Annotate your constructor as a Workflow Initializer and take the same arguments as your Workflow's main method.

Note that you can't make blocking calls from your constructor.
If you need to block, make your Signal or Update handler [wait](#waiting) for an initialization flag.

In Go and TypeScript, register any message handlers only after completing initialization.

### Message handler patterns {#message-handler-patterns}

Here are several common patterns for write operations, Signal and Update handlers. They don't apply to pure read operations, i.e. Queries or [Update Validators](/handling-messages#update-validators):

- Returning immediately from a handler
- Waiting for the Workflow to be ready to process them
- Kicking off activities and other asynchronous tasks
- Injecting work into the main Workflow
- Finishing handlers before the Workflow completes
- Ensuring your messages are processed exactly once

#### Synchronous handlers

Synchronous handlers don’t kick off any long-running operations or otherwise block. They're guaranteed to run atomically.

#### Waiting {#waiting}

A Signal or Update handler can block waiting for the Workflow to reach a certain state using a Wait Condition. See the links below to find out how to use this with your SDK.

#### Running asynchronous tasks

Sometimes, you need your message handler to wait for long-running operations such as executing an Activity. When this happens, the handler will yield control back to [the loop](#message-handler-concurrency). This means that your handlers can have race conditions if you’re not careful.
You can guard your handlers with concurrency primitives like mutexes or semaphores, but you should use versions of these primitives provided for Workflows in most languages. See the links below for examples of how to use them in your SDK.

#### Inject work into the main Workflow {#injecting-work-into-main-workflow}

Sometimes you want to process work provided by messages in the main Workflow. Perhaps you’d like to accumulate several messages before acting on any of them. For example, message handlers might put work into a queue, which can then be picked up and processed in an event loop that you yourself write.
This option is considered advanced but offers powerful flexibility. And if you serialize the handling of your messages inside your main Workflow, you can avoid using concurrency primitives like mutexes and semaphores. See the links above for how to do this in your SDK.

#### Finishing handlers before the Workflow completes {#finishing-message-handlers}

You should generally finish running all handlers before the Workflow run completes or continues as new. For some Workflows, this means you should explicitly check to make sure that all the handlers have completed before finishing. You can await a condition called All Handlers Finished at the end of your Workflow.

If you don’t need to ensure that your handlers complete, you may specify your handler’s Handler Unfinished Policy as Abandon to turn off the warnings. However, note that clients waiting for Updates will get Not Found errors if they're waiting for Updates that never complete before the Workflow run completes.

See the links below for how to ensure handlers are finished in your SDK.

#### Ensuring your messages are processed exactly once {#exactly-once-message-processing}

Many developers want their message handlers to run exactly once--to be idempotent--in cases where the same Signal or Update is delivered twice or sent by two different call sites. Temporal deduplicates messages for you on the server, but there is one important case when you need to think about this yourself when authoring a Workflow, and one when sending Signals and Updates.

When your workflow Continues-As-New, you should handle deduplication yourself in your message handler. This is because Temporal's built-in deduplication doesn't work across [Continue-As-New](/workflows#continue-as-new) boundaries, meaning you would risk processing messages twice for such Workflows if you don't check for duplicate messages yourself.

To deduplicate in your message handler, you can use an idempotency key.

Clients can provide an idempotency key. This can be important because Temporal's SDKs provide a randomized key by default, which means Temporal only deduplicates retries from the same call. For Updates, if you craft an Update ID, temporal will deduplicate any calls that use that key. This is useful when you have two different callsites that may send the same Update, or when your client itself may get retried. For Signals, you can provide a key as part of your Signal arguments.

Inside your message handler, you can check your idempotency key--the Update ID or the one you provided to the Signal--to check whether the Workflow has already handled the update.

See the links below for examples of solving this in your SDK.

#### Authoring message handler patterns

See examples of the above patterns.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/dotnet/message-passing" text="Author message handler patterns in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#message-handler-patterns" text="Author message handler patterns in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing" text="Author message handler patterns in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing" text="Author message handler patterns in PHP" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#message-handler-patterns" text="Author message handler patterns in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#message-handler-patterns" text="Author message handler patterns in Typescript" archetype="feature-guide" />
</RelatedReadContainer>

### Update Validators {#update-validators}

When you define an Update handler, you may optionally define an Update Validator: a read operation that's responsible for accepting or rejecting the Update. You can use Validators to verify arguments or make sure the Workflow is ready to accept your Updates.

- If it accepts, the Update will become part of your Workflow’s history and the client will be notified that the operation has been Accepted. The Update handler will then run until it returns a value.
- If it rejects, the client will be informed that it was Rejected, and the Workflow will have no indication that it was ever requested, similar to a Query handler.

:::note

Like Queries, Validators are not allowed to block.

:::

Once the Update handler is finished and has returned a value, the operation is considered Completed.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#updates" text="Validate updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#updates" text="Validate updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#updates" text="Validate updates in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#updates" text="Validate updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#updates" text="Validate updates in Typescript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-updates" text="Validate updates in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Exceptions in message handlers {#exceptions}

When throwing an exception in a message handler, you should decide whether to make it an [Application Failure](/references/failures#application-failure). The implications are different between Signals and Updates.

:::caution
The following content applies in every SDK except the Go SDK. See below.
:::

#### Exceptions in Signals

In Signal handlers, throw [Application Failures](/references/failures#application-failure) only for unrecoverable errors, because the entire Workflow will fail.
Similarly, allowing a failing Activity or Child Workflow to exhaust its retries, so that it throws an [Activity Failure](https://docs.temporal.io/references/failures#activity-failure) or [Child Workflow Failure](https://docs.temporal.io/references/failures#child-workflow-failure) will cause the entire Workflow to fail.
Note that for Activities, this will only happen if you change the default Activity [Retry Policy](https://docs.temporal.io/encyclopedia/retry-policies), since by default they retry forever.
If you throw any other exception, by default, it will cause a [Workflow Task Failure](/references/failures#workflow-task-failures). This means the Workflow will get stuck and will retry the handler periodically until the exception is fixed, for example by a code change.

#### Exceptions in Updates

Doing any of the following will fail the Update and cause the client to receive the error:

- Reject the Update by throwing any exception from your [Validator](https://docs.temporal.io/handling-messages#update-validators).
- Allow a failing Activity or Child Workflow to exhaust its retries, so that it throws an [Activity Failure](https://docs.temporal.io/references/failures#activity-failure) or [Child Workflow Failure](https://docs.temporal.io/references/failures#child-workflow-failure). Note that for Activities, this will only happen if you change the default Activity [Retry Policy](https://docs.temporal.io/encyclopedia/retry-policies), since by default they retry forever.
- Throw an [Application Failure](/references/failures#application-failure) from your Update handler.

Unlike with Signals, the Workflow will keep going in these cases.

If you throw any other exception, by default, it will cause a [Workflow Task Failure](/references/failures#workflow-task-failures). This means the Workflow will get stuck and will retry the handler periodically until the exception is fixed, for example by a code change or infrastructure coming back online. Note that this will cause a delay for clients waiting for an Update result.

#### Errors and panics in message handlers in the Go SDK

In Go, returning an error behaves like an [Application Failure](/references/failures#application-failure) in the other SDKs. Panics behave like non-Application Failure exceptions in other languages, in that they cause a [Workflow Task Failure](/references/failures#workflow-task-failures).

### Writing Signal Handlers {#writing-signal-handlers}

Use these links to see a simple Signal handler.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#signals" text="Handle Signals in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#signals" text="Handle Signals in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#signals" text="Handle Signals in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#signals" text="Handle Signals in Typescript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#signals" text="Handle Signals in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-signal" text="Handle Signals in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Writing Update Handlers {#writing-update-handlers}

Use these links to see a simple update handler.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#updates" text="Handle Updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#updates" text="Handle Updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#updates" text="Handle Updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#updates" text="Handle Updates in Typescript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#updates" text="Handle Updates in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-updates" text="Handle Updates in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Writing Query Handlers {#writing-query-handlers}

Author queries using these per-language guides.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#queries" text="Handle Queries in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#queries" text="Handle Queries in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#queries" text="Handle Queries in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#queries" text="Handle Queries in Typescript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#queries" text="Handle Queries in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-query" text="Handle Queries in PHP" archetype="feature-guide" />
</RelatedReadContainer>

  </content>
</document>
<document>
  <source_type>GitHub Repository</source_type>
  <github_url>https://github.com/temporalio/documentation/blob/main/docs/evaluate/temporal-cloud/legacy-support.mdx</github_url>
  <account>temporalio</account>
  <repo>documentation</repo>
  <branch>main</branch>
  <path>docs/evaluate/temporal-cloud/legacy-support.mdx</path>
  <content>
---
id: legacy-support
title: Services, support, and training - Temporal Cloud (Legacy)
sidebar_label: Legacy support
description: Temporal Cloud offers support, services, and training for seamless onboarding, efficient app design, and scaling. Services include technical onboarding, design/code reviews, pre-production optimization, and load tests.
slug: /cloud/legacy_support
toc_max_heading_level: 3
keywords:
  - how-to
  - introduction
  - support
  - temporal cloud
  - training
tags:
  - Temporal Cloud
  - Support
---

:::tip Support, stability, and dependency info

Temporal Cloud support [will update](/cloud/support) in February 2025 to align with the new plans for existing customers.

:::

Temporal Cloud includes the right level of technical support and guidance to onboard you successfully, assist with design and deployment of your application efficiently and at scale.
Our team has extensive knowledge of Temporal, and a broad set of skills to help you succeed with any project.

Temporal Cloud provides several levels of support, from assisting with break/fix scenarios to helping with onboarding, design/code reviews for your application, optimizations, and operational readiness.

:::note

The content of this page applies to Temporal Cloud customers only.

:::

## What are the services offered by Temporal Cloud? {#services}

We offer four services to Temporal Cloud customers.
For access to any of these services, please [create a support ticket](/cloud/support#support-ticket) or contact your dedicated account manager.

- **Technical onboarding:** Temporal Cloud customers can request an onboarding session.
  This session covers basic setup and Namespace planning and provides an overview of metrics and observability, an overview of development resources, and information you will need in preparation for your go-live.
- **Design and code reviews:** Our team works with you to review your Workflow design and code to avoid potential issues and optimize your workload to run on Temporal Cloud.
  These sessions also focus on the optimization of your Workflow Actions and reduce your costs; they also reveal likely trade offs.

## What is the Temporal Cloud support guarantee? {#support}

Temporal endeavors to ensure you are successful with Temporal Cloud.
We offer explicit guarantees for support.
Temporal Cloud customers get break/fix support with an agreed-upon set of SLAs for prioritized issues.
We use a ticketing system for entering, tracking, and closing these issues.

If an issue occurs, the team also provides support through a dedicated Slack channel, forums, and a knowledge base.
We offer two levels of support defined by their availability and SLAs in the following table:

|                          | **Basic**                                                                                      | **Enterprise**                                                                            |
| ------------------------ | ---------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------- |
| **Response times**       | P0: 1 business hour<br />P1: 4 business hours<br />P2: 1 business day<br />P3: 2 business days | P0: 30 minutes<br />P1: 1 business hour<br />P2: 4 business hours<br />P3: 1 business day |
| **Onboarding & Success** | Development, deployment, and optimization guidance                                             | Development, deployment, and optimization guidance                                        |
| **Channels**             | Community Slack, Email, Forums, Documentation, Knowledge Base                                  | Private Slack Channel, Email, Forums, Documentation, Knowledge Base                       |

:::info Business Hour Timezones

Business Hours will be specified in your contract, including one of three locations: US local time, European Central time, Australia Eastern time
:::

**Priority definitions**

- **P0 - Critical** (Production impacted)
  - The Temporal Cloud service is unavailable or degraded with a significant impact.
- **P1 - High** (Production issue)
  - An issue related to production workloads running on the Temporal Cloud service, or a significant project is blocked.
- **P2 - Normal** (General issues)
  - General Temporal Cloud service or other issues where there is no production impact, or a workaround exists to mitigate the impact.
- **P3 - Low** (General guidance)
  - Questions or an issue with the Temporal Cloud service that is not impacting system availability or functionality.

:::note On Page Service

P0: 24×7 (On Page Service) is offered for Enterprise and higher accounts.

:::

For pricing details of these support levels, please visit our [pricing page](/cloud/pricing).

## Ticketing

Temporal offers a ticketing system for Temporal Cloud customers.
We have an active [community Slack](https://temporalio.slack.com) and an active [community Discourse forum](https://community.temporal.io/) where you can post questions and ask for help.

:::info

The Temporal Support Portal is for Cloud customers only.
Other Temporal users (non-Cloud) have full community access excluding the "support-cloud" channel.
All Cloud customers pay for support as part of their plan.

:::

### How to create an account for Temporal Support {#support-account}

The Temporal Support Portal has a per organization setting to associate user emails based on the domain name.
For Temporal Cloud users, there is no need to manually create an account, as this included in the onboarding process.

:::info

This procedure applies only to Temporal Cloud customers whose contracts include paid support.
If you need assistance and don't have paid support, post your request in the [Temporal Community Forum](https://community.temporal.io) or the `#support-cloud` channel of the [Temporal workspace](https://t.mp/slack) in Slack.

:::

### To access Temporal Support

1. Go to [support.temporal.io](https://support.temporal.io/).
2. Log in using the company email address provided during your Temporal Cloud onboarding.
   You can log in using one of the following methods:
   1. **Google Single Sign-On (SSO)**.
      1. Select **Sign in with Google**.
      2. Select the email address associated with your company.
   2. **Email and Password**.
      1. Enter your **Email** and **Password**.
      2. Select **Sign in**.
3. You will be presented with a screen where you can submit ticket.

To request assistance from Temporal Support, see [Create a ticket](#support-ticket).

### How to create a ticket for Temporal Support {#support-ticket}

You must have an [account](#support-account) with the same domain name as your Temporal Cloud account to create a ticket in the Temporal Support Portal.

:::info

This procedure applies only to Temporal Cloud customers whose contracts include paid support.
If you need assistance and don't have paid support, post your request in the [Temporal Community Forum](https://community.temporal.io) or the `#support-cloud` channel of the [Temporal workspace](https://t.mp/slack) in Slack.

:::

### To request assistance from Temporal Support, create a ticket in the Temporal Support Portal:

1. Go to [support.temporal.io](https://support.temporal.io/).
2. Use your Temporal Support credentials to sign in.
3. Choose **Create a ticket**.
4. On the **Submit a request** page, choose your issue.
   Unless your request involves one of the specific areas listed, choose **Submit a Ticket**.
5. In the form, enter the details of your request.
   **Subject** and **Description** are required.
6. If you specify **Priority** (available only on the default form), follow these guidelines:
   - Select **Normal** for most issues.
   - Select **High** only for issues to which your service-level agreement (SLA) applies.
     If you're not sure, select **Normal**.
   - Select **Page** only if you are experiencing a complete service outage and urgently need contact with an on-call support person.
7. At the bottom of the form, choose **Submit**.

## What type of developer resources exist? {#developer-resources}

Temporal offers developer resources and a variety of hands-on tutorials to get you started and learn more advanced Temporal concepts.

- [Get started with Temporal](https://learn.temporal.io/getting_started): Start your journey with Temporal with this guide that helps you set up your development environment, run an existing Temporal app, and then build your first app from scratch using our SDKs.
- [Courses](https://learn.temporal.io/courses): Learn and apply Temporal concepts in our free, self-paced, hands-on courses.
- [Tutorials](https://learn.temporal.io/tutorials): Apply Temporal concepts to build real-world applications with these hands-on tutorials.
- [Example applications](https://learn.temporal.io/examples): Explore example applications that use Temporal and gain a clearer understanding of how Temporal concepts work in a complex application.

  </content>
</document>